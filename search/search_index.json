{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ai-gene-review","text":"<p>This is the project description.</p> <ul> <li>Auto-generated schema documentation</li> </ul>"},{"location":"about/","title":"About ai-gene-review","text":"<p>This is the project description.</p>"},{"location":"pmc_overrides/","title":"PMC ID Override System","text":""},{"location":"pmc_overrides/#overview","title":"Overview","text":"<p>The PMC ID override system addresses incorrect linkages in NCBI's database where PubMed IDs (PMIDs) are incorrectly associated with PMC (PubMed Central) IDs. This can happen when:</p> <ul> <li>NCBI's elink service incorrectly cross-references papers</li> <li>Multiple papers about the same topic get confused in the linkage database</li> <li>Database entries are corrupted or misaligned</li> </ul>"},{"location":"pmc_overrides/#how-it-works","title":"How It Works","text":"<ol> <li>Override Table: A TSV file (<code>src/ai_gene_review/etl/pmc_overrides.tsv</code>) contains manual corrections</li> <li>Format: Simple two-column format: <code>PMID&lt;tab&gt;PMCID</code></li> <li>Loading: The override table is loaded and cached on first use</li> <li>Priority: Overrides take precedence over NCBI's elink results</li> </ol>"},{"location":"pmc_overrides/#file-format","title":"File Format","text":"<p>The override file is a tab-separated values (TSV) file with the following format:</p> <pre><code># Comments start with #\n# PMID  PMCID   Optional comment\n2001740     # No PMC version exists (NCBI incorrectly links to PMC11824087)\n12345   PMC67890    # Correct PMC ID for this paper\n</code></pre> <ul> <li>PMID: The PubMed ID (without \"PMID:\" prefix)</li> <li>PMCID: The correct PMC ID, or empty if no PMC version exists</li> <li>Comments: Lines starting with # are ignored</li> <li>Blank PMCID: Indicates the paper has no PMC version</li> </ul>"},{"location":"pmc_overrides/#usage","title":"Usage","text":""},{"location":"pmc_overrides/#adding-an-override","title":"Adding an Override","text":"<ol> <li>Edit <code>src/ai_gene_review/etl/pmc_overrides.tsv</code></li> <li>Add a new line with the PMID and correct PMCID (or leave blank)</li> <li>Add a comment explaining the issue</li> <li>Report the issue to NCBI at: https://www.ncbi.nlm.nih.gov/home/about/contact/</li> </ol>"},{"location":"pmc_overrides/#example-cases","title":"Example Cases","text":""},{"location":"pmc_overrides/#case-1-no-pmc-version","title":"Case 1: No PMC Version","text":"<pre><code>2001740     # 1991 FEBS Letters paper, no PMC version available\n</code></pre>"},{"location":"pmc_overrides/#case-2-wrong-pmc-linked","title":"Case 2: Wrong PMC Linked","text":"<pre><code>12345   PMC67890    # NCBI links to PMC99999 which is a different paper\n</code></pre>"},{"location":"pmc_overrides/#case-3-pmc-exists-but-not-linked","title":"Case 3: PMC Exists but Not Linked","text":"<pre><code>54321   PMC11111    # NCBI doesn't show PMC link but it exists\n</code></pre>"},{"location":"pmc_overrides/#implementation-details","title":"Implementation Details","text":"<p>The override system is implemented in <code>src/ai_gene_review/etl/publication.py</code>:</p> <ul> <li><code>load_pmc_overrides()</code>: Loads and caches the override table</li> <li><code>fetch_pubmed_data()</code>: Checks overrides before querying NCBI's elink</li> </ul>"},{"location":"pmc_overrides/#testing","title":"Testing","text":"<p>Run tests with:</p> <pre><code>uv run pytest tests/test_pmc_overrides.py\n</code></pre>"},{"location":"pmc_overrides/#reporting-issues-to-ncbi","title":"Reporting Issues to NCBI","text":"<p>When you find an incorrect PMC linkage:</p> <ol> <li>Add it to the override table (immediate fix)</li> <li>Report to NCBI:</li> <li>URL: https://www.ncbi.nlm.nih.gov/home/about/contact/</li> <li>Include both PMIDs and PMC IDs involved</li> <li>Provide paper titles and years to help identify the issue</li> </ol>"},{"location":"pmc_overrides/#example-report-to-ncbi","title":"Example Report to NCBI","text":"<pre><code>Subject: Incorrect PMC ID linkage for PMID 2001740\n\nThe PubMed entry for PMID 2001740 (Yamaguchi &amp; Sakurai, FEBS Lett 1991) \nis incorrectly linked to PMC11824087.\n\nPMC11824087 actually corresponds to PMID 25230901 (Yamaguchi, J Cancer \nRes Clin Oncol 2014), which is a different paper about the same protein.\n\nThe 1991 paper appears to have no PMC version available, as expected for \nolder subscription journal articles.\n\nPlease correct this linkage in the NCBI database.\n</code></pre>"},{"location":"stats/","title":"Stats","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style for beautiful visualizations\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['axes.labelsize'] = 12\n</code></pre> <pre><code># Load the flattened annotation data\ntsv_path = Path('../exports/exported_annotations.tsv')\ndf = pd.read_csv(tsv_path, sep='\\t')\n\n# Basic statistics\nprint(f\"\ud83d\udcca Dataset Overview\")\nprint(f\"\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\")\nprint(f\"Total annotations reviewed: {len(df):,}\")\nprint(f\"Unique genes: {df['gene_symbol'].nunique()}\")\nprint(f\"Unique species: {df['taxon_label'].nunique()}\")\nprint(f\"Unique GO terms: {df['term_id'].nunique()}\")\nprint(f\"\\nSpecies distribution:\")\nfor species, count in df['taxon_label'].value_counts().head().items():\n    print(f\"  \u2022 {species}: {count} annotations\")\n</code></pre> <pre><code># Create figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Count of review actions\naction_counts = df['review_action'].value_counts()\ncolors = sns.color_palette(\"Spectral\", len(action_counts))\n\n# Bar chart\nbars = ax1.bar(range(len(action_counts)), action_counts.values, color=colors)\nax1.set_xticks(range(len(action_counts)))\nax1.set_xticklabels(action_counts.index, rotation=45, ha='right')\nax1.set_ylabel('Number of Annotations')\nax1.set_title('Distribution of Review Actions', fontweight='bold', fontsize=14)\nax1.grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar, value in zip(bars, action_counts.values):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n             f'{int(value)}\\n({value/len(df)*100:.1f}%)',\n             ha='center', va='bottom', fontsize=10)\n\n# Pie chart with exploded slices for important actions\nexplode = [0.1 if action in ['MODIFY', 'REMOVE'] else 0 for action in action_counts.index]\nwedges, texts, autotexts = ax2.pie(action_counts.values, \n                                     labels=action_counts.index,\n                                     colors=colors,\n                                     autopct='%1.1f%%',\n                                     explode=explode,\n                                     startangle=90)\nax2.set_title('Proportion of Review Actions', fontweight='bold', fontsize=14)\n\n# Make percentage text bold\nfor autotext in autotexts:\n    autotext.set_color('white')\n    autotext.set_fontweight('bold')\n    autotext.set_fontsize(10)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\n\ud83d\udcca Action Summary:\")\nprint(f\"  \u2022 Accepted as-is: {action_counts.get('ACCEPT', 0)} ({action_counts.get('ACCEPT', 0)/len(df)*100:.1f}%)\")\nprint(f\"  \u2022 Modifications needed: {action_counts.get('MODIFY', 0)} ({action_counts.get('MODIFY', 0)/len(df)*100:.1f}%)\")\nprint(f\"  \u2022 Removed: {action_counts.get('REMOVE', 0)} ({action_counts.get('REMOVE', 0)/len(df)*100:.1f}%)\")\n</code></pre> <pre><code># Prepare species data\nspecies_action = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index') * 100\nspecies_counts = df['taxon_label'].value_counts()\n\n# Filter to top species by annotation count\ntop_species = species_counts.head(10).index\nspecies_action_filtered = species_action.loc[top_species]\n\n# Create stacked bar chart\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n\n# Stacked percentage bar chart\nspecies_action_filtered.plot(kind='barh', stacked=True, ax=ax1, \n                             colormap='Spectral', width=0.8)\nax1.set_xlabel('Percentage of Annotations (%)')\nax1.set_ylabel('')\nax1.set_title('Review Actions by Species (Percentage)', fontweight='bold', fontsize=14)\nax1.legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\nax1.grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor container in ax1.containers:\n    ax1.bar_label(container, fmt='%.0f%%', label_type='center', fontsize=9)\n\n# Absolute counts heatmap\nspecies_action_abs = pd.crosstab(df['taxon_label'], df['review_action'])\nspecies_action_abs_filtered = species_action_abs.loc[top_species]\n\nsns.heatmap(species_action_abs_filtered, annot=True, fmt='d', cmap='YlOrRd', \n            ax=ax2, cbar_kws={'label': 'Number of Annotations'})\nax2.set_ylabel('')\nax2.set_xlabel('Review Action')\nax2.set_title('Review Actions by Species (Absolute Counts)', fontweight='bold', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Method analysis (combining evidence type and reference source)\n# This provides a higher-level view than raw evidence codes\nif 'method' in df.columns:\n    method_counts = df['method'].value_counts()\n\n    # Create action categories if not already present\n    if 'action_category' not in df.columns:\n        def categorize_action(action):\n            if action == 'ACCEPT':\n                return 'Accept'\n            elif action == 'MODIFY':\n                return 'Modify'\n            elif action == 'REMOVE':\n                return 'Remove'\n            elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n                return 'Non-Core/Over-Annotated'\n            else:\n                return 'Other'\n        df['action_category'] = df['review_action'].apply(categorize_action)\n\n    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n\n    # 1. Method vs Review Action heatmap - COUNTS\n    method_action = pd.crosstab(df['method'], df['review_action'])\n\n    sns.heatmap(method_action, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0, 0],\n                cbar_kws={'label': 'Count'})\n    axes[0, 0].set_title('Review Actions by Method (Counts)', fontweight='bold', fontsize=12)\n    axes[0, 0].set_xlabel('Review Action')\n    axes[0, 0].set_ylabel('Method')\n    axes[0, 0].tick_params(axis='both', which='major', labelsize=9)\n\n    # 2. Method vs Review Action heatmap - PERCENTAGES\n    method_action_pct = pd.crosstab(df['method'], df['review_action'], normalize='index') * 100\n\n    sns.heatmap(method_action_pct, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=axes[0, 1],\n                cbar_kws={'label': 'Percentage (%)'}, vmin=0, vmax=50)\n    axes[0, 1].set_title('Review Actions by Method (Row %)', fontweight='bold', fontsize=12)\n    axes[0, 1].set_xlabel('Review Action')\n    axes[0, 1].set_ylabel('')\n    axes[0, 1].tick_params(axis='both', which='major', labelsize=9)\n\n    # 3. ACTION RATES BY METHOD - STACKED BAR CHART\n    # Calculate percentages for each method\n    method_action_rates = pd.crosstab(df['method'], df['action_category'], normalize='index') * 100\n\n    # Order columns for stacking\n    action_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\n    existing_cols = [col for col in action_order if col in method_action_rates.columns]\n    method_action_rates = method_action_rates[existing_cols]\n\n    # Sort by total annotations (most common first)\n    method_action_rates = method_action_rates.loc[method_counts.index]\n\n    # Create stacked bar chart\n    x = np.arange(len(method_action_rates))\n    width = 0.7\n\n    # Define colors for each action category\n    action_colors = {\n        'Accept': 'green',\n        'Modify': 'orange', \n        'Remove': 'red',\n        'Non-Core/Over-Annotated': 'purple',\n        'Other': 'gray'\n    }\n\n    # Plot stacked bars\n    bottom = np.zeros(len(method_action_rates))\n    for action in existing_cols:\n        values = method_action_rates[action].values\n        color = action_colors.get(action, 'gray')\n        axes[1, 0].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n        bottom += values\n\n    axes[1, 0].set_xticks(x)\n    axes[1, 0].set_xticklabels(method_action_rates.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 0].set_ylabel('Percentage (%)')\n    axes[1, 0].set_title('Action Rates by Method', fontweight='bold', fontsize=12)\n    axes[1, 0].legend(loc='upper right')\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    axes[1, 0].set_ylim(0, 100)\n\n    # Add sample sizes above bars\n    for i, method in enumerate(method_action_rates.index):\n        count = method_counts[method]\n        axes[1, 0].text(i, 102, f'n={count}', ha='center', fontsize=8, color='black')\n\n    # 4. Method distribution bar chart\n    colors_dist = sns.color_palette(\"viridis\", len(method_counts))\n    bars = axes[1, 1].bar(range(len(method_counts)), method_counts.values, color=colors_dist)\n    axes[1, 1].set_xticks(range(len(method_counts)))\n    axes[1, 1].set_xticklabels(method_counts.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 1].set_ylabel('Number of Annotations')\n    axes[1, 1].set_title('Distribution of Methods', fontweight='bold', fontsize=12)\n    axes[1, 1].grid(axis='y', alpha=0.3)\n\n    # Add count labels\n    for bar, value in zip(bars, method_counts.values):\n        height = bar.get_height()\n        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 5,\n                        f'{int(value)}', ha='center', va='bottom', fontsize=9)\n\n    plt.suptitle('Method Analysis Overview', fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n\n    # Print detailed summary\n    print(\"\\n\ud83d\udcca Method Analysis Summary:\")\n    print(\"=\" * 60)\n\n    # Create summary DataFrame\n    method_summary = pd.DataFrame({\n        'Count': df.groupby('method').size(),\n        'Accepted': df[df['review_action'] == 'ACCEPT'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Accept_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'ACCEPT').mean() * 100),\n        'Removed': df[df['review_action'] == 'REMOVE'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Remove_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'REMOVE').mean() * 100),\n        'Non-Core/Over': df[df['review_action'].isin(['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED'])].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n    }).sort_values('Count', ascending=False)\n\n    print(f\"\\n{'Method':&amp;lt;20} {'Count':&amp;gt;6} {'Accept':&amp;gt;8} {'Accept%':&amp;gt;8} {'Remove':&amp;gt;8} {'Remove%':&amp;gt;8} {'NonCore':&amp;gt;8}\")\n    print(\"-\" * 75)\n    for method, row in method_summary.iterrows():\n        print(f\"{method:&amp;lt;20} {int(row['Count']):6d} {int(row['Accepted']):8d} {row['Accept_Rate']:7.1f}% {int(row['Removed']):8d} {row['Remove_Rate']:7.1f}% {int(row['Non-Core/Over']):8d}\")\n\n    print(\"\\n\ud83d\udcc8 Key Insights:\")\n    print(f\"  \u2022 Total methods: {df['method'].nunique()}\")\n    print(f\"  \u2022 Most common: {method_counts.index[0]} ({method_counts.iloc[0]} annotations, {method_counts.iloc[0]/len(df)*100:.1f}%)\")\n\n    # Report on ARBA specifically\n    if 'ARBA' in method_summary.index:\n        arba_row = method_summary.loc['ARBA']\n        print(f\"\\n\ud83d\udd0d ARBA Analysis:\")\n        print(f\"  \u2022 Total: {int(arba_row['Count'])} annotations\")\n        print(f\"  \u2022 Accepted: {int(arba_row['Accepted'])} ({arba_row['Accept_Rate']:.1f}%)\")\n        print(f\"  \u2022 Removed: {int(arba_row['Removed'])} ({arba_row['Remove_Rate']:.1f}%)\")\n        print(f\"  \u2022 Non-Core/Over-Annotated: {int(arba_row['Non-Core/Over'])}\")\nelse:\n    print(\"\u26a0\ufe0f Method column not found in data. Please re-export annotations to include the new method field.\")\n</code></pre> <pre><code># Evidence type distribution with action rates\nevidence_counts = df['evidence_type'].value_counts()\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# 1. Overall evidence type distribution\ncolors = sns.color_palette(\"viridis\", len(evidence_counts))\nbars = axes[0, 0].bar(range(len(evidence_counts)), evidence_counts.values, color=colors)\naxes[0, 0].set_xticks(range(len(evidence_counts)))\naxes[0, 0].set_xticklabels(evidence_counts.index, rotation=45, ha='right')\naxes[0, 0].set_ylabel('Number of Annotations')\naxes[0, 0].set_title('Distribution of Evidence Types', fontweight='bold')\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# Add count labels\nfor bar, value in zip(bars, evidence_counts.values):\n    height = bar.get_height()\n    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n                    f'{int(value)}', ha='center', va='bottom')\n\n# 2. Evidence type vs Review action heatmap\nevidence_action = pd.crosstab(df['evidence_type'], df['review_action'])\nsns.heatmap(evidence_action, annot=True, fmt='d', cmap='coolwarm', ax=axes[0, 1],\n            cbar_kws={'label': 'Count'})\naxes[0, 1].set_title('Evidence Type vs Review Action', fontweight='bold')\naxes[0, 1].set_xlabel('Review Action')\naxes[0, 1].set_ylabel('Evidence Type')\n\n# 3. Acceptance rate by evidence type\nevidence_accept_rate = pd.crosstab(df['evidence_type'], \n                                   df['review_action'] == 'ACCEPT', \n                                   normalize='index')[True] * 100\nevidence_accept_rate = evidence_accept_rate.sort_values(ascending=False)\n\nbars = axes[1, 0].barh(range(len(evidence_accept_rate)), \n                       evidence_accept_rate.values,\n                       color=sns.color_palette(\"RdYlGn\", len(evidence_accept_rate))[::-1])\naxes[1, 0].set_yticks(range(len(evidence_accept_rate)))\naxes[1, 0].set_yticklabels(evidence_accept_rate.index)\naxes[1, 0].set_xlabel('Acceptance Rate (%)')\naxes[1, 0].set_title('Acceptance Rate by Evidence Type', fontweight='bold')\naxes[1, 0].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor bar, value in zip(bars, evidence_accept_rate.values):\n    width = bar.get_width()\n    axes[1, 0].text(width + 1, bar.get_y() + bar.get_height()/2.,\n                    f'{value:.1f}%', ha='left', va='center')\n\n# 4. ACTION RATES BY EVIDENCE TYPE - STACKED BAR CHART\n# Group actions into categories\ndef categorize_action(action):\n    if action == 'ACCEPT':\n        return 'Accept'\n    elif action == 'MODIFY':\n        return 'Modify'\n    elif action == 'REMOVE':\n        return 'Remove'\n    elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n        return 'Non-Core/Over-Annotated'\n    else:\n        return 'Other'\n\ndf['action_category'] = df['review_action'].apply(categorize_action)\n\n# Calculate percentages for each evidence type\nevidence_action_rates = pd.crosstab(df['evidence_type'], df['action_category'], normalize='index') * 100\n\n# Order columns for stacking\naction_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\nexisting_cols = [col for col in action_order if col in evidence_action_rates.columns]\nevidence_action_rates = evidence_action_rates[existing_cols]\n\n# Sort by total annotations (most common first)\nevidence_action_rates = evidence_action_rates.loc[evidence_counts.index]\n\n# Create stacked bar chart\nx = np.arange(len(evidence_action_rates))\nwidth = 0.6\n\n# Define colors for each action category\naction_colors = {\n    'Accept': 'green',\n    'Modify': 'orange', \n    'Remove': 'red',\n    'Non-Core/Over-Annotated': 'purple',\n    'Other': 'gray'\n}\n\n# Plot stacked bars\nbottom = np.zeros(len(evidence_action_rates))\nfor action in existing_cols:\n    values = evidence_action_rates[action].values\n    color = action_colors.get(action, 'gray')\n    axes[1, 1].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n    bottom += values\n\naxes[1, 1].set_xticks(x)\naxes[1, 1].set_xticklabels(evidence_action_rates.index, rotation=45, ha='right')\naxes[1, 1].set_ylabel('Percentage (%)')\naxes[1, 1].set_title('Action Rates by Evidence Type', fontweight='bold')\naxes[1, 1].legend(loc='upper right')\naxes[1, 1].grid(axis='y', alpha=0.3)\naxes[1, 1].set_ylim(0, 100)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Compare Method (consolidated) vs Evidence (raw) views\nif 'method' in df.columns:\n    fig = plt.figure(figsize=(18, 12))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n    # 1. Side-by-side pie charts: Method vs Evidence\n    ax1 = fig.add_subplot(gs[0, 0])\n    method_top = df['method'].value_counts().head(8)\n    colors1 = sns.color_palette(\"Set2\", len(method_top))\n    wedges, texts, autotexts = ax1.pie(method_top.values, labels=method_top.index, \n                                        autopct='%1.1f%%', colors=colors1, startangle=90)\n    ax1.set_title('Top Methods (Consolidated)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('white')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n\n    ax2 = fig.add_subplot(gs[0, 1])\n    evidence_top = df['evidence_type'].value_counts().head(8)\n    colors2 = sns.color_palette(\"Set3\", len(evidence_top))\n    wedges, texts, autotexts = ax2.pie(evidence_top.values, labels=evidence_top.index,\n                                       autopct='%1.1f%%', colors=colors2, startangle=90)\n    ax2.set_title('Top Evidence Types (Raw)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('black')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n\n    # 2. Acceptance rates comparison\n    ax3 = fig.add_subplot(gs[0, 2])\n\n    # Calculate acceptance rates for methods\n    method_accept = df.groupby('method')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n\n    # Calculate acceptance rates for evidence\n    evidence_accept = df.groupby('evidence_type')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n\n    x = np.arange(10)\n    width = 0.35\n\n    bars1 = ax3.barh(x - width/2, method_accept.values[:10], width, \n                     label='By Method', color='steelblue', alpha=0.8)\n    bars2 = ax3.barh(x + width/2, evidence_accept.values[:10], width,\n                     label='By Evidence', color='coral', alpha=0.8)\n\n    ax3.set_yticks(x)\n    ax3.set_yticklabels([f\"{i+1}\" for i in range(10)])\n    ax3.set_xlabel('Acceptance Rate (%)')\n    ax3.set_title('Top 10 Acceptance Rates Comparison', fontweight='bold')\n    ax3.legend()\n    ax3.grid(axis='x', alpha=0.3)\n\n    # 3. Method breakdown for IEA annotations\n    ax4 = fig.add_subplot(gs[1, :])\n    iea_methods = df[df['evidence_type'] == 'IEA']['method'].value_counts()\n\n    bars = ax4.bar(range(len(iea_methods)), iea_methods.values, \n                   color=sns.color_palette(\"viridis\", len(iea_methods)))\n    ax4.set_xticks(range(len(iea_methods)))\n    ax4.set_xticklabels(iea_methods.index, rotation=45, ha='right')\n    ax4.set_ylabel('Number of Annotations')\n    ax4.set_title('IEA Annotations Breakdown by Method/Source', fontweight='bold', fontsize=14)\n    ax4.grid(axis='y', alpha=0.3)\n\n    # Add value and percentage labels\n    for bar, (method, count) in zip(bars, iea_methods.items()):\n        height = bar.get_height()\n        pct = count / df[df['evidence_type'] == 'IEA'].shape[0] * 100\n        ax4.text(bar.get_x() + bar.get_width()/2., height + 2,\n                f'{int(count)}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=9)\n\n    # 4. Sankey-style flow from Evidence to Method\n    ax5 = fig.add_subplot(gs[2, :2])\n\n    # Create crosstab of evidence to method mapping\n    evidence_method = pd.crosstab(df['evidence_type'], df['method'])\n\n    # Filter to most common combinations\n    top_evidence = df['evidence_type'].value_counts().head(8).index\n    top_methods = df['method'].value_counts().head(8).index\n    evidence_method_filtered = evidence_method.loc[\n        evidence_method.index.intersection(top_evidence),\n        evidence_method.columns.intersection(top_methods)\n    ]\n\n    sns.heatmap(evidence_method_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                ax=ax5, cbar_kws={'label': 'Count'})\n    ax5.set_title('Evidence Type to Method Mapping', fontweight='bold', fontsize=12)\n    ax5.set_xlabel('Method (Consolidated)')\n    ax5.set_ylabel('Evidence Type (Raw)')\n\n    # 5. Summary statistics table\n    ax6 = fig.add_subplot(gs[2, 2])\n    ax6.axis('tight')\n    ax6.axis('off')\n\n    # Calculate statistics\n    method_stats = {\n        'Unique Methods': df['method'].nunique(),\n        'Unique Evidence Types': df['evidence_type'].nunique(),\n        'Most Common Method': f\"{method_counts.index[0]} ({method_counts.iloc[0]})\",\n        'Most Common Evidence': f\"{evidence_counts.index[0]} ({evidence_counts.iloc[0]})\",\n        'IEA Breakdown': f\"{df[df['evidence_type'] == 'IEA']['method'].nunique()} sources\",\n        'Experimental %': f\"{(df['method'] == 'Experimental').mean() * 100:.1f}%\"\n    }\n\n    table_data = [[k, str(v)] for k, v in method_stats.items()]\n    table = ax6.table(cellText=table_data, cellLoc='left', loc='center',\n                     colWidths=[0.6, 0.4])\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1.2, 1.8)\n\n    # Style the table\n    for i in range(len(table_data)):\n        table[(i, 0)].set_facecolor('#E8F4F8')\n        table[(i, 0)].set_text_props(weight='bold')\n\n    ax6.set_title('Comparison Summary', fontweight='bold', fontsize=12)\n\n    plt.suptitle('Method vs Evidence Type Analysis', fontsize=16, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.show()\n\n    # Print detailed comparison\n    print(\"\\n\ud83d\udd0d Method vs Evidence Detailed Comparison:\")\n    print(\"=\" * 60)\n\n    print(\"\\n\ud83d\udcca Consolidation Impact:\")\n    total_experimental = df[df['evidence_type'].isin(['IDA', 'IPI', 'IMP', 'IGI', 'IEP', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP'])].shape[0]\n    print(f\"  \u2022 {total_experimental} experimental evidence codes \u2192 1 'Experimental' method\")\n\n    iea_count = df[df['evidence_type'] == 'IEA'].shape[0]\n    iea_methods_count = df[df['evidence_type'] == 'IEA']['method'].nunique()\n    print(f\"  \u2022 {iea_count} IEA annotations \u2192 {iea_methods_count} distinct methods\")\n\n    print(\"\\n\ud83d\udcc8 Quality Indicators:\")\n    exp_accept = df[df['method'] == 'Experimental']['review_action'].eq('ACCEPT').mean() * 100\n    auto_accept = df[df['method'].isin(['ARBA', 'UniProtKB-KW', 'Combined-IEA', 'InterPro2GO'])]['review_action'].eq('ACCEPT').mean() * 100\n    print(f\"  \u2022 Experimental acceptance rate: {exp_accept:.1f}%\")\n    print(f\"  \u2022 Automated acceptance rate: {auto_accept:.1f}%\")\n    print(f\"  \u2022 Difference: {exp_accept - auto_accept:+.1f} percentage points\")\nelse:\n    print(\"\u26a0\ufe0f Method column not found. Please re-export annotations with the updated exporter.\")\n</code></pre> <pre><code># Sankey diagram for Method -&amp;gt; Action flow\ntry:\n    import plotly.graph_objects as go\n    import plotly.offline as pyo\n\n    # Prepare data for Sankey diagram\n    if 'method' in df.columns:\n        # Create the flow data\n        flow_data = df.groupby(['method', 'action_category']).size().reset_index(name='count')\n\n        # Filter to significant flows (at least 5 annotations) for clarity\n        flow_data = flow_data[flow_data['count'] &amp;gt;= 5]\n\n        # Create node lists\n        methods = flow_data['method'].unique().tolist()\n        actions = flow_data['action_category'].unique().tolist()\n\n        # All nodes (methods + actions)\n        all_nodes = methods + actions\n        node_indices = {node: i for i, node in enumerate(all_nodes)}\n\n        # Create source, target, and value lists for Sankey\n        source = [node_indices[method] for method in flow_data['method']]\n        target = [node_indices[action] for action in flow_data['action_category']]\n        value = flow_data['count'].tolist()\n\n        # Define colors\n        method_colors = ['lightblue'] * len(methods)\n        action_color_map = {\n            'Accept': 'green',\n            'Modify': 'orange',\n            'Remove': 'red',\n            'Non-Core/Over-Annotated': 'purple',\n            'Other': 'gray'\n        }\n        action_colors = [action_color_map.get(action, 'gray') for action in actions]\n        node_colors = method_colors + action_colors\n\n        # Create Sankey diagram\n        fig = go.Figure(data=[go.Sankey(\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\", width=0.5),\n                label=all_nodes,\n                color=node_colors,\n                hovertemplate='%{label}&lt;br/&gt;Total: %{value}&lt;extra&gt;&lt;/extra&gt;'\n            ),\n            link=dict(\n                source=source,\n                target=target,\n                value=value,\n                color='rgba(200, 200, 200, 0.4)',\n                hovertemplate='%{source.label} \u2192 %{target.label}&lt;br/&gt;Count: %{value}&lt;extra&gt;&lt;/extra&gt;'\n            )\n        )])\n\n        fig.update_layout(\n            title_text=\"Method to Action Flow (flows \u22655 annotations)\",\n            font_size=12,\n            height=600,\n            margin=dict(l=50, r=50, t=50, b=50)\n        )\n\n        # Display the figure\n        pyo.iplot(fig)\n\n        # Also create a static version using matplotlib\n        fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n\n        # 1. Top flows table\n        top_flows = flow_data.nlargest(20, 'count')\n        top_flows['percentage'] = (top_flows['count'] / top_flows['count'].sum() * 100).round(1)\n\n        # Format for display\n        table_data = []\n        table_data.append(['Method', 'Action', 'Count', '%'])\n        table_data.append(['\u2500' * 20, '\u2500' * 25, '\u2500' * 8, '\u2500' * 8])\n\n        for _, row in top_flows.iterrows():\n            table_data.append([\n                row['method'][:20],\n                row['action_category'][:25],\n                f\"{int(row['count']):4d}\",\n                f\"{row['percentage']:5.1f}%\"\n            ])\n\n        ax1.axis('tight')\n        ax1.axis('off')\n        table = ax1.table(cellText=table_data, cellLoc='left', loc='center',\n                         colWidths=[0.3, 0.35, 0.15, 0.15])\n        table.auto_set_font_size(False)\n        table.set_fontsize(9)\n        table.scale(1.2, 1.2)\n\n        # Style header\n        for i in range(4):\n            table[(0, i)].set_facecolor('#4CAF50')\n            table[(0, i)].set_text_props(weight='bold', color='white')\n\n        ax1.set_title('Top 20 Method\u2192Action Flows', fontweight='bold', fontsize=12)\n\n        # 2. Summary by method\n        method_flow_summary = flow_data.pivot_table(\n            index='method', \n            columns='action_category', \n            values='count', \n            aggfunc='sum',\n            fill_value=0\n        )\n\n        # Sort by total flow\n        method_flow_summary['Total'] = method_flow_summary.sum(axis=1)\n        method_flow_summary = method_flow_summary.sort_values('Total', ascending=False).head(10)\n\n        # Create stacked bar chart\n        categories = [col for col in method_flow_summary.columns if col != 'Total']\n        x = np.arange(len(method_flow_summary))\n\n        bottom = np.zeros(len(method_flow_summary))\n        for category in categories:\n            if category in method_flow_summary.columns:\n                values = method_flow_summary[category].values\n                color = action_color_map.get(category, 'gray')\n                ax2.barh(x, values, left=bottom, label=category, color=color, alpha=0.8)\n                bottom += values\n\n        ax2.set_yticks(x)\n        ax2.set_yticklabels(method_flow_summary.index, fontsize=10)\n        ax2.set_xlabel('Number of Annotations')\n        ax2.set_title('Top 10 Methods: Action Distribution', fontweight='bold', fontsize=12)\n        ax2.legend(loc='lower right')\n        ax2.grid(axis='x', alpha=0.3)\n\n        # Add totals at the end of bars\n        for i, total in enumerate(method_flow_summary['Total']):\n            ax2.text(total + 5, i, f'{int(total)}', va='center', fontsize=9)\n\n        plt.suptitle('Method to Action Flow Analysis', fontsize=14, fontweight='bold', y=1.02)\n        plt.tight_layout()\n        plt.show()\n\n        # Print flow statistics\n        print(\"\\n\ud83c\udf0a Flow Analysis Summary:\")\n        print(\"=\" * 60)\n        print(f\"Total unique flows: {len(flow_data)}\")\n        print(f\"Total annotations in flows \u22655: {flow_data['count'].sum()}\")\n        print(f\"Most common flow: {top_flows.iloc[0]['method']} \u2192 {top_flows.iloc[0]['action_category']} ({top_flows.iloc[0]['count']} annotations)\")\n\n        # Calculate percentage of each action across all methods\n        action_totals = flow_data.groupby('action_category')['count'].sum()\n        print(\"\\n\ud83d\udcca Overall Action Distribution (from flows \u22655):\")\n        for action, count in action_totals.sort_values(ascending=False).items():\n            pct = count / action_totals.sum() * 100\n            print(f\"  \u2022 {action}: {count} ({pct:.1f}%)\")\n\nexcept ImportError:\n    print(\"\u26a0\ufe0f Plotly not installed. Installing it will enable interactive Sankey diagrams.\")\n    print(\"   To install: uv add plotly\")\n\n    # Fallback visualization without Plotly\n    if 'method' in df.columns:\n        fig, ax = plt.subplots(figsize=(14, 10))\n\n        # Create flow matrix\n        flow_matrix = pd.crosstab(df['method'], df['action_category'])\n\n        # Filter to top methods for readability\n        top_methods = df['method'].value_counts().head(15).index\n        flow_matrix_filtered = flow_matrix.loc[top_methods]\n\n        # Create heatmap as fallback\n        sns.heatmap(flow_matrix_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                    cbar_kws={'label': 'Count'}, ax=ax)\n        ax.set_title('Method to Action Flow Matrix (Top 15 Methods)', fontweight='bold', fontsize=14)\n        ax.set_xlabel('Action Category', fontsize=12)\n        ax.set_ylabel('Method', fontsize=12)\n\n        plt.tight_layout()\n        plt.show()\n\n        print(\"\\n\ud83d\udcca Method\u2192Action Flow Summary (Top 15 Methods):\")\n        for method in top_methods[:5]:\n            flows = flow_matrix.loc[method]\n            flows = flows[flows &amp;gt; 0].sort_values(ascending=False)\n            print(f\"\\n{method}:\")\n            for action, count in flows.items():\n                pct = count / flows.sum() * 100\n                print(f\"  \u2192 {action}: {count} ({pct:.1f}%)\")\n</code></pre> <pre><code># Extract ontology from term_id (GO:XXXXXXX)\n# Determine ontology based on term_ontology column or infer from common patterns\ndef get_ontology(row):\n    if pd.notna(row['term_ontology']):\n        return row['term_ontology']\n    # Infer from term label patterns\n    term = str(row['term_label']).lower()\n    if 'binding' in term or 'activity' in term or 'transporter' in term:\n        return 'Molecular Function'\n    elif 'process' in term or 'regulation' in term or 'pathway' in term:\n        return 'Biological Process'\n    elif 'complex' in term or 'membrane' in term or 'region' in term:\n        return 'Cellular Component'\n    return 'Unknown'\n\ndf['ontology'] = df.apply(get_ontology, axis=1)\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Distribution across ontologies\nontology_counts = df['ontology'].value_counts()\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\nwedges, texts, autotexts = axes[0, 0].pie(ontology_counts.values, \n                                           labels=ontology_counts.index,\n                                           colors=colors[:len(ontology_counts)],\n                                           autopct='%1.1f%%',\n                                           startangle=90)\naxes[0, 0].set_title('GO Ontology Distribution', fontweight='bold')\n\n# 2. Review actions by ontology\nontology_action = pd.crosstab(df['ontology'], df['review_action'], normalize='index') * 100\nontology_action.plot(kind='bar', ax=axes[0, 1], colormap='Set3')\naxes[0, 1].set_xlabel('Ontology')\naxes[0, 1].set_ylabel('Percentage of Annotations')\naxes[0, 1].set_title('Review Actions by GO Ontology', fontweight='bold')\naxes[0, 1].legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\naxes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n\n# 3. Most frequently reviewed terms\ntop_terms = df['term_label'].value_counts().head(15)\naxes[1, 0].barh(range(len(top_terms)), top_terms.values, \n               color=sns.color_palette(\"muted\", len(top_terms)))\naxes[1, 0].set_yticks(range(len(top_terms)))\naxes[1, 0].set_yticklabels(top_terms.index, fontsize=9)\naxes[1, 0].set_xlabel('Number of Annotations')\naxes[1, 0].set_title('Top 15 Most Frequently Annotated GO Terms', fontweight='bold')\naxes[1, 0].grid(axis='x', alpha=0.3)\n\n# Add count labels\nfor i, value in enumerate(top_terms.values):\n    axes[1, 0].text(value + 0.5, i, str(value), va='center')\n\n# 4. Terms with highest modification rates\nterm_stats = df.groupby('term_label').agg({\n    'review_action': ['count', lambda x: (x == 'MODIFY').mean() * 100]\n}).reset_index()\nterm_stats.columns = ['term', 'count', 'modify_rate']\nterm_stats = term_stats[term_stats['count'] &amp;gt;= 5]  # Filter for terms with at least 5 annotations\nterm_stats = term_stats.nlargest(10, 'modify_rate')\n\naxes[1, 1].barh(range(len(term_stats)), term_stats['modify_rate'].values,\n               color=sns.color_palette(\"YlOrRd\", len(term_stats)))\naxes[1, 1].set_yticks(range(len(term_stats)))\naxes[1, 1].set_yticklabels(term_stats['term'].values, fontsize=9)\naxes[1, 1].set_xlabel('Modification Rate (%)')\naxes[1, 1].set_title('GO Terms with Highest Modification Rates (n\u22655)', fontweight='bold')\naxes[1, 1].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor i, (rate, count) in enumerate(zip(term_stats['modify_rate'].values, term_stats['count'].values)):\n    axes[1, 1].text(rate + 1, i, f'{rate:.1f}% (n={int(count)})', va='center', fontsize=8)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Gene-level aggregations\ngene_stats = df.groupby('gene_symbol').agg({\n    'term_id': 'count',\n    'review_action': lambda x: (x == 'ACCEPT').sum(),\n    'taxon_label': 'first'\n}).reset_index()\ngene_stats.columns = ['gene', 'total_annotations', 'accepted_annotations', 'species']\ngene_stats['acceptance_rate'] = (gene_stats['accepted_annotations'] / gene_stats['total_annotations']) * 100\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Distribution of annotations per gene\naxes[0, 0].hist(gene_stats['total_annotations'], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\naxes[0, 0].set_xlabel('Number of Annotations per Gene')\naxes[0, 0].set_ylabel('Number of Genes')\naxes[0, 0].set_title('Distribution of Annotation Counts per Gene', fontweight='bold')\naxes[0, 0].axvline(gene_stats['total_annotations'].mean(), color='red', \n                   linestyle='--', label=f'Mean: {gene_stats[\"total_annotations\"].mean():.1f}')\naxes[0, 0].axvline(gene_stats['total_annotations'].median(), color='green', \n                   linestyle='--', label=f'Median: {gene_stats[\"total_annotations\"].median():.0f}')\naxes[0, 0].legend()\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# 2. Genes with most annotations\ntop_genes = gene_stats.nlargest(15, 'total_annotations')\nbars = axes[0, 1].bar(range(len(top_genes)), top_genes['total_annotations'].values,\n                      color=sns.color_palette(\"viridis\", len(top_genes)))\naxes[0, 1].set_xticks(range(len(top_genes)))\naxes[0, 1].set_xticklabels(top_genes['gene'].values, rotation=45, ha='right')\naxes[0, 1].set_ylabel('Number of Annotations')\naxes[0, 1].set_title('Top 15 Most Heavily Annotated Genes', fontweight='bold')\naxes[0, 1].grid(axis='y', alpha=0.3)\n\n# Add count labels\nfor bar, value in zip(bars, top_genes['total_annotations'].values):\n    height = bar.get_height()\n    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n                    f'{int(value)}', ha='center', va='bottom', fontsize=9)\n\n# 3. Gene acceptance rate distribution\naxes[1, 0].hist(gene_stats['acceptance_rate'], bins=20, edgecolor='black', \n                alpha=0.7, color='lightgreen')\naxes[1, 0].set_xlabel('Acceptance Rate (%)')\naxes[1, 0].set_ylabel('Number of Genes')\naxes[1, 0].set_title('Distribution of Gene Annotation Acceptance Rates', fontweight='bold')\naxes[1, 0].axvline(gene_stats['acceptance_rate'].mean(), color='red', \n                   linestyle='--', label=f'Mean: {gene_stats[\"acceptance_rate\"].mean():.1f}%')\naxes[1, 0].grid(axis='y', alpha=0.3)\naxes[1, 0].legend()\n\n# 4. Scatter plot: Total annotations vs acceptance rate\nscatter = axes[1, 1].scatter(gene_stats['total_annotations'], \n                             gene_stats['acceptance_rate'],\n                             c=pd.factorize(gene_stats['species'])[0],\n                             cmap='tab10', alpha=0.6, s=50)\naxes[1, 1].set_xlabel('Total Annotations per Gene')\naxes[1, 1].set_ylabel('Acceptance Rate (%)')\naxes[1, 1].set_title('Annotation Count vs Acceptance Rate by Gene', fontweight='bold')\naxes[1, 1].grid(True, alpha=0.3)\n\n# Add trend line\nz = np.polyfit(gene_stats['total_annotations'], gene_stats['acceptance_rate'], 1)\np = np.poly1d(z)\naxes[1, 1].plot(gene_stats['total_annotations'].sort_values(), \n                p(gene_stats['total_annotations'].sort_values()),\n                \"r--\", alpha=0.5, label='Trend line')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\n\ud83d\udcc8 Gene-Level Summary:\")\nprint(f\"  \u2022 Average annotations per gene: {gene_stats['total_annotations'].mean():.1f}\")\nprint(f\"  \u2022 Median annotations per gene: {gene_stats['total_annotations'].median():.0f}\")\nprint(f\"  \u2022 Average acceptance rate: {gene_stats['acceptance_rate'].mean():.1f}%\")\nprint(f\"  \u2022 Genes with 100% acceptance: {(gene_stats['acceptance_rate'] == 100).sum()}\")\nprint(f\"  \u2022 Genes with 0% acceptance: {(gene_stats['acceptance_rate'] == 0).sum()}\")\n</code></pre> <pre><code># Create a comprehensive quality dashboard\nfig = plt.figure(figsize=(18, 10))\ngs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n# Calculate quality metrics\nhas_supporting_text = df['review_supporting_text'].notna()\nhas_references = df['review_supporting_reference_ids'].notna()\nhas_proposed_terms = df['review_proposed_replacement_terms'].notna()\nneeds_modification = df['review_action'] == 'MODIFY'\n\n# 1. Review completeness pie chart\nax1 = fig.add_subplot(gs[0, 0])\ncompleteness_data = [\n    has_supporting_text.sum(),\n    has_references.sum(),\n    (has_supporting_text &amp;amp; has_references).sum()\n]\nlabels = ['Has Supporting Text', 'Has References', 'Has Both']\nax1.pie(completeness_data, labels=labels, autopct='%1.1f%%', \n        colors=['#3498db', '#2ecc71', '#9b59b6'])\nax1.set_title('Review Documentation Completeness', fontweight='bold')\n\n# 2. Modification compliance\nax2 = fig.add_subplot(gs[0, 1])\nmodify_with_terms = (needs_modification &amp;amp; has_proposed_terms).sum()\nmodify_without_terms = (needs_modification &amp;amp; ~has_proposed_terms).sum()\nax2.bar(['With Proposed Terms', 'Without Proposed Terms'], \n        [modify_with_terms, modify_without_terms],\n        color=['green', 'orange'])\nax2.set_title('MODIFY Actions: Proposed Terms Compliance', fontweight='bold')\nax2.set_ylabel('Count')\ncompliance_rate = modify_with_terms / (modify_with_terms + modify_without_terms) * 100 if needs_modification.sum() &amp;gt; 0 else 0\nax2.text(0.5, ax2.get_ylim()[1] * 0.9, f'Compliance: {compliance_rate:.1f}%', \n         ha='center', fontsize=12, fontweight='bold')\n\n# 3. Species coverage\nax3 = fig.add_subplot(gs[0, 2])\nspecies_genes = df.groupby('taxon_label')['gene_symbol'].nunique().sort_values(ascending=False).head(8)\nax3.barh(range(len(species_genes)), species_genes.values, \n         color=sns.color_palette(\"husl\", len(species_genes)))\nax3.set_yticks(range(len(species_genes)))\nax3.set_yticklabels(species_genes.index, fontsize=9)\nax3.set_xlabel('Number of Unique Genes')\nax3.set_title('Gene Coverage by Species', fontweight='bold')\n\n# 4. Evidence type quality\nax4 = fig.add_subplot(gs[1, :])\nevidence_quality = df.groupby('evidence_type').agg({\n    'review_action': [\n        ('Total', 'count'),\n        ('Accepted', lambda x: (x == 'ACCEPT').sum()),\n        ('Modified', lambda x: (x == 'MODIFY').sum()),\n        ('Removed', lambda x: (x == 'REMOVE').sum())\n    ]\n}).reset_index()\nevidence_quality.columns = ['Evidence Type', 'Total', 'Accepted', 'Modified', 'Removed']\n\nx = np.arange(len(evidence_quality))\nwidth = 0.2\nax4.bar(x - 1.5*width, evidence_quality['Total'], width, label='Total', color='gray', alpha=0.5)\nax4.bar(x - 0.5*width, evidence_quality['Accepted'], width, label='Accepted', color='green', alpha=0.7)\nax4.bar(x + 0.5*width, evidence_quality['Modified'], width, label='Modified', color='orange', alpha=0.7)\nax4.bar(x + 1.5*width, evidence_quality['Removed'], width, label='Removed', color='red', alpha=0.7)\n\nax4.set_xticks(x)\nax4.set_xticklabels(evidence_quality['Evidence Type'], rotation=45, ha='right')\nax4.set_ylabel('Number of Annotations')\nax4.set_title('Annotation Quality by Evidence Type', fontweight='bold', fontsize=14)\nax4.legend(loc='upper right')\nax4.grid(axis='y', alpha=0.3)\n\n# 5. Term frequency vs action correlation\nax5 = fig.add_subplot(gs[2, 0:2])\nterm_frequency = df['term_label'].value_counts()\nterm_actions = df.groupby('term_label')['review_action'].apply(\n    lambda x: (x == 'ACCEPT').mean() * 100\n)\n\n# Match indices\ncommon_terms = term_frequency.index.intersection(term_actions.index)\nfreq_data = term_frequency[common_terms].head(20)\naction_data = term_actions[common_terms].head(20)\n\nax5_twin = ax5.twinx()\nbars = ax5.bar(range(len(freq_data)), freq_data.values, alpha=0.5, color='blue', label='Frequency')\nline = ax5_twin.plot(range(len(freq_data)), action_data[freq_data.index].values, \n                     'ro-', label='Acceptance Rate', markersize=6)\n\nax5.set_xticks(range(len(freq_data)))\nax5.set_xticklabels(freq_data.index, rotation=45, ha='right', fontsize=8)\nax5.set_ylabel('Frequency', color='blue')\nax5_twin.set_ylabel('Acceptance Rate (%)', color='red')\nax5.set_title('Term Frequency vs Acceptance Rate (Top 20)', fontweight='bold')\nax5.tick_params(axis='y', labelcolor='blue')\nax5_twin.tick_params(axis='y', labelcolor='red')\n\n# 6. Overall quality score\nax6 = fig.add_subplot(gs[2, 2])\nquality_scores = {\n    'Documentation\\nCompleteness': (has_supporting_text.sum() / len(df)) * 100,\n    'Reference\\nCoverage': (has_references.sum() / len(df)) * 100,\n    'Modification\\nCompliance': compliance_rate,\n    'Overall\\nAcceptance': (df['review_action'] == 'ACCEPT').mean() * 100\n}\n\ncolors_score = ['green' if v &amp;gt;= 70 else 'orange' if v &amp;gt;= 40 else 'red' \n                for v in quality_scores.values()]\nbars = ax6.bar(range(len(quality_scores)), list(quality_scores.values()), \n               color=colors_score, alpha=0.7)\nax6.set_xticks(range(len(quality_scores)))\nax6.set_xticklabels(list(quality_scores.keys()), fontsize=9)\nax6.set_ylabel('Score (%)')\nax6.set_title('Quality Metrics Summary', fontweight='bold')\nax6.axhline(y=70, color='green', linestyle='--', alpha=0.3, label='Good (&amp;gt;70%)')\nax6.axhline(y=40, color='orange', linestyle='--', alpha=0.3, label='Fair (&amp;gt;40%)')\nax6.set_ylim(0, 100)\nax6.grid(axis='y', alpha=0.3)\n\n# Add value labels\nfor bar, value in zip(bars, quality_scores.values()):\n    height = bar.get_height()\n    ax6.text(bar.get_x() + bar.get_width()/2., height + 2,\n             f'{value:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.suptitle('Gene Annotation Review Quality Dashboard', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Print quality summary\nprint(\"\\n\ud83c\udfc6 Quality Summary:\")\nprint(\"\u2501\" * 50)\nfor metric, score in quality_scores.items():\n    metric_clean = metric.replace('\\n', ' ')\n    status = \"\u2705\" if score &amp;gt;= 70 else \"\u26a0\ufe0f\" if score &amp;gt;= 40 else \"\u274c\"\n    print(f\"{status} {metric_clean}: {score:.1f}%\")\n</code></pre> <pre><code># Advanced analysis: Identify patterns and outliers\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Action distribution by species (normalized heatmap)\nspecies_action_norm = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index')\nsns.heatmap(species_action_norm, annot=True, fmt='.2f', cmap='RdYlGn', \n            ax=axes[0, 0], vmin=0, vmax=1, cbar_kws={'label': 'Proportion'})\naxes[0, 0].set_title('Review Action Proportions by Species', fontweight='bold')\naxes[0, 0].set_xlabel('Review Action')\naxes[0, 0].set_ylabel('Species')\n\n# 2. Outlier detection - genes with unusual patterns\ngene_pattern = df.groupby('gene_symbol').agg({\n    'review_action': lambda x: (x == 'REMOVE').mean() * 100,\n    'term_id': 'count'\n}).reset_index()\ngene_pattern.columns = ['gene', 'removal_rate', 'n_annotations']\ngene_pattern = gene_pattern[gene_pattern['n_annotations'] &amp;gt;= 5]  # Filter for statistical significance\n\n# Identify outliers (high removal rate)\noutliers = gene_pattern[gene_pattern['removal_rate'] &amp;gt; gene_pattern['removal_rate'].quantile(0.9)]\n\naxes[0, 1].scatter(gene_pattern['n_annotations'], gene_pattern['removal_rate'], \n                   alpha=0.5, s=30, color='blue', label='Normal')\naxes[0, 1].scatter(outliers['n_annotations'], outliers['removal_rate'], \n                   alpha=0.8, s=60, color='red', label='High removal rate')\n\n# Annotate outliers\nfor _, row in outliers.head(5).iterrows():\n    axes[0, 1].annotate(row['gene'], (row['n_annotations'], row['removal_rate']),\n                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n\naxes[0, 1].set_xlabel('Number of Annotations')\naxes[0, 1].set_ylabel('Removal Rate (%)')\naxes[0, 1].set_title('Genes with Unusual Annotation Patterns', fontweight='bold')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. Co-occurrence matrix of review actions and evidence types\naction_evidence_matrix = pd.crosstab(df['review_action'], df['evidence_type'])\naction_evidence_norm = action_evidence_matrix.div(action_evidence_matrix.sum(axis=1), axis=0)\n\nsns.heatmap(action_evidence_norm, annot=True, fmt='.2f', cmap='coolwarm',\n            ax=axes[1, 0], cbar_kws={'label': 'Proportion'})\naxes[1, 0].set_title('Review Action - Evidence Type Associations', fontweight='bold')\naxes[1, 0].set_xlabel('Evidence Type')\naxes[1, 0].set_ylabel('Review Action')\n\n# 4. Summary statistics table\naxes[1, 1].axis('tight')\naxes[1, 1].axis('off')\n\nsummary_data = [\n    ['Metric', 'Value'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Total Annotations', f'{len(df):,}'],\n    ['Unique Genes', f'{df[\"gene_symbol\"].nunique()}'],\n    ['Unique Species', f'{df[\"taxon_label\"].nunique()}'],\n    ['Unique GO Terms', f'{df[\"term_id\"].nunique()}'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Acceptance Rate', f'{(df[\"review_action\"] == \"ACCEPT\").mean() * 100:.1f}%'],\n    ['Modification Rate', f'{(df[\"review_action\"] == \"MODIFY\").mean() * 100:.1f}%'],\n    ['Removal Rate', f'{(df[\"review_action\"] == \"REMOVE\").mean() * 100:.1f}%'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Avg Annotations/Gene', f'{df.groupby(\"gene_symbol\")[\"term_id\"].count().mean():.1f}'],\n    ['Documentation Rate', f'{has_supporting_text.mean() * 100:.1f}%'],\n    ['Reference Coverage', f'{has_references.mean() * 100:.1f}%']\n]\n\ntable = axes[1, 1].table(cellText=summary_data, cellLoc='left', loc='center',\n                        colWidths=[0.6, 0.4])\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.2, 1.5)\n\n# Style the header\nfor i in range(2):\n    table[(0, i)].set_facecolor('#4CAF50')\n    table[(0, i)].set_text_props(weight='bold', color='white')\n\naxes[1, 1].set_title('Summary Statistics', fontweight='bold', fontsize=14)\n\nplt.suptitle('Advanced Analytics &amp;amp; Pattern Detection', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Generate automated insights\nprint(\"\\n\" + \"=\"*60)\nprint(\"\ud83d\udcca KEY INSIGHTS FROM GENE ANNOTATION REVIEW\")\nprint(\"=\"*60)\n\n# Calculate key metrics\ntotal_annotations = len(df)\nacceptance_rate = (df['review_action'] == 'ACCEPT').mean() * 100\nmodification_rate = (df['review_action'] == 'MODIFY').mean() * 100\nremoval_rate = (df['review_action'] == 'REMOVE').mean() * 100\n\n# Evidence type insights\nevidence_accept = df.groupby('evidence_type')['review_action'].apply(\n    lambda x: (x == 'ACCEPT').mean() * 100\n).sort_values(ascending=False)\n\nprint(\"\\n\ud83c\udfaf Overall Performance:\")\nprint(f\"  \u2022 {acceptance_rate:.1f}% of annotations were accepted as-is\")\nprint(f\"  \u2022 {modification_rate:.1f}% need modifications\")\nprint(f\"  \u2022 {removal_rate:.1f}% should be removed\")\n\nprint(\"\\n\ud83d\udd2c Evidence Type Analysis:\")\nprint(f\"  \u2022 Most reliable evidence: {evidence_accept.index[0]} ({evidence_accept.iloc[0]:.1f}% acceptance)\")\nprint(f\"  \u2022 Least reliable evidence: {evidence_accept.index[-1]} ({evidence_accept.iloc[-1]:.1f}% acceptance)\")\n\n# Species insights\nspecies_stats = df.groupby('taxon_label').agg({\n    'review_action': lambda x: (x == 'ACCEPT').mean() * 100,\n    'gene_symbol': 'nunique'\n}).sort_values('review_action', ascending=False)\n\nprint(\"\\n\ud83e\uddec Species Quality Rankings:\")\nfor i, (species, row) in enumerate(species_stats.head(3).iterrows(), 1):\n    print(f\"  {i}. {species}: {row['review_action']:.1f}% acceptance ({row['gene_symbol']} genes)\")\n\n# Problem areas\nprint(\"\\n\u26a0\ufe0f Areas Requiring Attention:\")\n\n# Terms with high modification rates\nproblem_terms = df[df['review_action'].isin(['MODIFY', 'REMOVE'])].groupby('term_label').size()\nproblem_terms = problem_terms.sort_values(ascending=False).head(3)\n\nprint(\"  Most problematic GO terms:\")\nfor term, count in problem_terms.items():\n    print(f\"    \u2022 {term}: {count} issues\")\n\n# Compliance issues\nmodify_compliance = (df[df['review_action'] == 'MODIFY']['review_proposed_replacement_terms'].notna()).mean() * 100\nprint(f\"\\n  Modification compliance: {modify_compliance:.1f}% have proposed replacements\")\n\nprint(\"\\n\u2705 Recommendations:\")\nif modification_rate &amp;gt; 30:\n    print(\"  1. High modification rate suggests need for annotation guidelines review\")\nif removal_rate &amp;gt; 20:\n    print(\"  2. High removal rate indicates quality control issues in original annotations\")\nif modify_compliance &amp;lt; 80:\n    print(\"  3. Improve documentation of proposed replacement terms for modifications\")\nif evidence_accept.iloc[-1] &amp;lt; 50:\n    print(f\"  4. Review {evidence_accept.index[-1]} evidence type annotations more carefully\")\n\nprint(\"\\n\" + \"=\"*60)\n</code></pre>"},{"location":"stats/#gene-review-statistics-dashboard","title":"Gene Review Statistics Dashboard","text":"<p>Comprehensive statistical analysis of gene annotation reviews across species, evidence types, and curation actions.</p>"},{"location":"stats/#overall-review-actions-distribution","title":"\ud83d\udcc8 Overall Review Actions Distribution","text":""},{"location":"stats/#species-specific-analysis","title":"\ud83e\uddec Species-Specific Analysis","text":""},{"location":"stats/#evidence-type-analysis","title":"\ud83d\udd2c Evidence Type Analysis","text":""},{"location":"stats/#method-analysis-evidence-reference","title":"\ud83e\uddea Method Analysis (Evidence + Reference)","text":""},{"location":"stats/#method-vs-evidence-comparison","title":"\ud83d\udd2c\ud83d\udcca Method vs Evidence Comparison","text":""},{"location":"stats/#method-to-action-flow-analysis","title":"\ud83c\udf0a Method to Action Flow Analysis","text":""},{"location":"stats/#go-term-ontology-analysis","title":"\ud83c\udfaf GO Term Ontology Analysis","text":""},{"location":"stats/#gene-level-statistics","title":"\ud83d\udcca Gene-Level Statistics","text":""},{"location":"stats/#quality-metrics-dashboard","title":"\ud83d\udd0d Quality Metrics Dashboard","text":""},{"location":"stats/#temporal-and-trend-analysis","title":"\ud83d\udcc8 Temporal and Trend Analysis","text":""},{"location":"stats/#key-insights-recommendations","title":"\ud83d\udca1 Key Insights &amp; Recommendations","text":""}]}