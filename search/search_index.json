{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ai-gene-review","text":"<p>This is the project description.</p> <ul> <li>Auto-generated schema documentation</li> </ul>"},{"location":"about/","title":"About ai-gene-review","text":"<p>This is the project description.</p>"},{"location":"imodulondb_integration/","title":"iModulonDB Integration","text":""},{"location":"imodulondb_integration/#overview","title":"Overview","text":"<p>The iModulonDB integration allows you to compare gene reviews with machine learning-derived transcriptional modules (iModulons) for bacterial genes. This provides independent validation of gene regulatory annotations using data-driven approaches.</p>"},{"location":"imodulondb_integration/#what-is-imodulondb","title":"What is iModulonDB?","text":"<p>iModulonDB is a database of independently modulated gene sets (iModulons) derived from applying Independent Component Analysis (ICA) to bacterial transcriptomes. iModulons represent co-regulated gene groups that explain variance across diverse growth conditions.</p> <p>Key Features: - Data-driven approach using hundreds of transcriptomes - Identifies co-regulated gene modules - Provides precision/recall metrics vs. known regulons - Available for multiple bacterial species</p> <p>Reference: Sastry et al. 2021, Nucleic Acids Research 49:D112-D120</p>"},{"location":"imodulondb_integration/#supported-organisms","title":"Supported Organisms","text":"<p>Currently supported organisms with iModulonDB datasets:</p> Organism Code Dataset Reference Pseudomonas putida KT2440 PSEPK / p_putida precise321 Lim et al. 2022 Escherichia coli K-12 MG1655 ecoli / e_coli precise456 Sastry et al. 2019 Bacillus subtilis 168 b_subtilis precise91 Rychel et al. 2020 <p>To see the current list:</p> <pre><code>just list-imodulondb-organisms\n</code></pre>"},{"location":"imodulondb_integration/#quick-start","title":"Quick Start","text":""},{"location":"imodulondb_integration/#compare-a-single-gene","title":"Compare a Single Gene","text":"<pre><code>just compare-imodulondb PSEPK BenR\n</code></pre> <p>This will: 1. Download iModulonDB data for P. putida (cached locally) 2. Find the BenR iModulon 3. Extract gene weights and statistics 4. Generate comparison report</p> <p>Output: <code>genes/p_putida/BenR/BenR-imodulondb-comparison.md</code></p>"},{"location":"imodulondb_integration/#example-output","title":"Example Output","text":"<pre><code># BenR iModulonDB Comparison\n\n## BenR iModulon Statistics\n\n| Metric | Value |\n|--------|-------|\n| **iModulon Size** | 10 genes |\n| **Known Regulon Size** | 4 genes |\n| **Precision** | 0.40 (40%) |\n| **Recall** | 1.00 (100%) |\n| **F1 Score** | 0.57 |\n\n## Interpretation\n\n**Consistency Level**: HIGH\n\n\u2705 **Perfect Recall**: All known regulon members captured in iModulon.\n\u26a0\ufe0f **Moderate Precision**: iModulon contains additional genes suggesting functional coupling.\n</code></pre>"},{"location":"imodulondb_integration/#use-cases","title":"Use Cases","text":""},{"location":"imodulondb_integration/#1-validate-gene-review","title":"1. Validate Gene Review","text":"<p>After completing a gene review, compare with iModulonDB to: - Confirm direct regulatory targets - Identify potential novel targets - Assess consistency with transcriptomic data</p> <pre><code>just compare-imodulondb PSEPK BenR\n</code></pre>"},{"location":"imodulondb_integration/#2-identify-novel-regulatory-targets","title":"2. Identify Novel Regulatory Targets","text":"<p>iModulons may include genes not in literature-based regulons: - Genes with high weights but not in review \u2192 novel predictions - Functionally coupled genes (indirect regulation) - Cross-pathway regulatory connections</p>"},{"location":"imodulondb_integration/#3-distinguish-direct-vs-functional-coupling","title":"3. Distinguish Direct vs. Functional Coupling","text":"<p>Direct regulation: High weight + known target (e.g., benABCD for BenR) Functional coupling: High weight + downstream pathway (e.g., cat genes with ben genes)</p>"},{"location":"imodulondb_integration/#4-cross-organism-comparison","title":"4. Cross-Organism Comparison","text":"<p>Compare regulatory patterns across species:</p> <pre><code>just compare-imodulondb ecoli FliA\njust compare-imodulondb bsubtilis SigD\n# Compare flagellar regulation across organisms\n</code></pre>"},{"location":"imodulondb_integration/#understanding-the-metrics","title":"Understanding the Metrics","text":""},{"location":"imodulondb_integration/#imodulon-statistics","title":"iModulon Statistics","text":"<ul> <li>iModulon Size: Number of genes in data-driven module</li> <li>Known Regulon Size: Number of validated targets from literature</li> <li>True Positives (TP): Genes in both iModulon and known regulon</li> <li>Precision: TP / iModulon Size (fraction of iModulon that's validated)</li> <li>Recall: TP / Regulon Size (fraction of known targets captured)</li> <li>F1 Score: Harmonic mean of precision and recall</li> </ul>"},{"location":"imodulondb_integration/#consistency-levels","title":"Consistency Levels","text":"<ul> <li>HIGH (F1 \u2265 0.5, Recall \u2265 0.8): Strong validation</li> <li>MEDIUM (F1 \u2265 0.4, Recall \u2265 0.6): Partial validation</li> <li>LOW (F1 &lt; 0.4 or Recall &lt; 0.6): Discrepancies warrant investigation</li> </ul>"},{"location":"imodulondb_integration/#gene-weights","title":"Gene Weights","text":"<p>Gene weights from ICA indicate strength of co-regulation: - |weight| &gt; 0.2: Strong association (likely direct targets) - |weight| 0.1-0.2: Moderate association (direct or coupled) - |weight| 0.05-0.1: Weak association (may be indirect) - |weight| &lt; 0.05: Not significantly associated</p>"},{"location":"imodulondb_integration/#interpreting-results","title":"Interpreting Results","text":""},{"location":"imodulondb_integration/#perfect-recall-moderate-precision","title":"Perfect Recall, Moderate Precision","text":"<p>Example: BenR has recall=1.0, precision=0.4</p> <p>Interpretation: - \u2705 All known targets captured (good!) - \u26a0\ufe0f iModulon includes 6 additional genes - These may be: (a) novel predictions, (b) functionally coupled, or (c) false positives</p> <p>Action: Investigate high-weight genes not in review</p>"},{"location":"imodulondb_integration/#imperfect-recall","title":"Imperfect Recall","text":"<p>Example: Recall = 0.7 (missing 30% of known targets)</p> <p>Possible reasons: - Known targets not co-expressed across conditions - Context-specific regulation - Data quality issues - Literature over-annotation</p> <p>Action: Check which genes are missing and why</p>"},{"location":"imodulondb_integration/#low-precision","title":"Low Precision","text":"<p>Example: Precision = 0.2 (80% of iModulon not validated)</p> <p>Possible reasons: - Captures functional pathway, not just direct regulation - Novel targets awaiting experimental validation - Promiscuous regulator with many targets - iModulon captures complex regulatory logic</p> <p>Action: Distinguish functional coupling from direct regulation</p>"},{"location":"imodulondb_integration/#advanced-usage","title":"Advanced Usage","text":""},{"location":"imodulondb_integration/#custom-cache-directory","title":"Custom Cache Directory","text":"<pre><code>just compare-imodulondb PSEPK BenR --cache-dir /path/to/cache\n</code></pre>"},{"location":"imodulondb_integration/#batch-analysis","title":"Batch Analysis","text":"<p>For multiple genes:</p> <pre><code>for gene in BenR CatR PcaR; do\n  just compare-imodulondb PSEPK $gene\ndone\n</code></pre>"},{"location":"imodulondb_integration/#clean-cache","title":"Clean Cache","text":"<p>To re-download data:</p> <pre><code>just clean-imodulondb-cache\njust compare-imodulondb PSEPK BenR\n</code></pre>"},{"location":"imodulondb_integration/#file-structure","title":"File Structure","text":"<pre><code>.cache/imodulondb/\n  p_putida/\n    supplementary_data.xlsx     # Downloaded from GitHub\n  e_coli/\n    supplementary_data.xlsx\n\ngenes/\n  p_putida/\n    BenR/\n      BenR-imodulondb-comparison.md   # Generated comparison\n</code></pre>"},{"location":"imodulondb_integration/#implementation-details","title":"Implementation Details","text":""},{"location":"imodulondb_integration/#data-source","title":"Data Source","text":"<p>iModulonDB data is downloaded from organism-specific GitHub repositories: - P. putida: SBRG/modulome_ppu - E. coli: SBRG/modulome_eco - B. subtilis: SBRG/modulome_bsu</p>"},{"location":"imodulondb_integration/#caching","title":"Caching","text":"<ul> <li>Downloaded files are cached in <code>.cache/imodulondb/</code></li> <li>Subsequent runs use cached data (faster)</li> <li>Cache persists across sessions</li> <li>Use <code>just clean-imodulondb-cache</code> to force re-download</li> </ul>"},{"location":"imodulondb_integration/#organism-mapping","title":"Organism Mapping","text":"<p>Organism codes are mapped in: <code>src/ai_gene_review/data/imodulondb_organisms.yaml</code></p> <p>To add new organisms, edit this file with: - Taxon ID - iModulonDB code - GitHub repository - Dataset name - Reference citation</p>"},{"location":"imodulondb_integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"imodulondb_integration/#organism-not-found-in-imodulondb-mapping","title":"\"Organism not found in iModulonDB mapping\"","text":"<p>Solution: Check organism code with <code>just list-imodulondb-organisms</code></p>"},{"location":"imodulondb_integration/#no-imodulon-found-for-regulator","title":"\"No iModulon found for regulator\"","text":"<p>Possible reasons: 1. Gene is not a transcription factor 2. Gene name mismatch (try alternative names) 3. No iModulon identified for this regulator</p> <p>Solution: Check available regulators in dataset</p>"},{"location":"imodulondb_integration/#download-failed","title":"\"Download failed\"","text":"<p>Possible reasons: 1. Network connectivity issues 2. GitHub repository moved 3. File path changed</p> <p>Solution: Check GitHub repo exists, update organism mapping if needed</p>"},{"location":"imodulondb_integration/#limitations","title":"Limitations","text":"<ol> <li>Bacterial organisms only - iModulonDB currently focuses on bacteria</li> <li>Dataset availability - Only ~20 organisms have published datasets</li> <li>Gene name matching - Requires exact match with regulator name</li> <li>Context-specific regulation - iModulons average across conditions</li> <li>Indirect effects - ICA captures co-expression, not just direct regulation</li> </ol>"},{"location":"imodulondb_integration/#future-enhancements","title":"Future Enhancements","text":"<p>Planned features (see <code>IMODULONDB_INTEGRATION_PLAN.md</code>):</p> <ul> <li>[ ] Automatic integration with <code>just fetch-gene</code></li> <li>[ ] Validation checks during <code>just validate</code></li> <li>[ ] Cross-organism comparison tools</li> <li>[ ] Interactive visualizations</li> <li>[ ] API-based access (when available)</li> <li>[ ] Support for condition-specific iModulons</li> <li>[ ] Integration with other regulatory databases</li> </ul>"},{"location":"imodulondb_integration/#related-documentation","title":"Related Documentation","text":"<ul> <li>iModulonDB website</li> <li>iModulonDB paper</li> <li>Integration plan</li> <li>Example: BenR analysis</li> </ul>"},{"location":"imodulondb_integration/#citation","title":"Citation","text":"<p>If you use iModulonDB data in your work, please cite:</p> <ul> <li>iModulonDB: Sastry AV et al. (2021) iModulonDB: a knowledgebase of microbial transcriptional regulation derived from machine learning. Nucleic Acids Res 49:D112-D120.</li> <li>Organism-specific datasets: See references in organism mapping file</li> </ul>"},{"location":"imodulondb_integration/#questions","title":"Questions?","text":"<p>For questions about: - This integration: File an issue on GitHub - iModulonDB data: Contact iModulonDB team - Specific datasets: See references in organism-specific papers</p>"},{"location":"performance-optimization/","title":"Performance Optimization: Fuzzy Text Matching","text":""},{"location":"performance-optimization/#problem","title":"Problem","text":"<p>The validation pipeline was hanging indefinitely when processing genes with large publications (10K-18K words). The issue was in the supporting text validation step, specifically in the <code>generate_suggested_fix()</code> method that uses fuzzy matching to provide helpful suggestions when exact substring matches fail.</p>"},{"location":"performance-optimization/#root-cause","title":"Root Cause","text":"<p>The original implementation used a sliding window algorithm from <code>difflib.SequenceMatcher</code> that had O(n*m) complexity: - For an 18K-word publication, it would try every possible window position - Each window comparison used <code>SequenceMatcher</code> which is relatively slow - With 9 findings to validate, this became computationally prohibitive</p>"},{"location":"performance-optimization/#solution","title":"Solution","text":"<p>Replaced the slow fuzzy matching with an optimized RapidFuzz-based implementation:</p> <ol> <li>New Module: <code>src/ai_gene_review/validation/fuzzy_text_utils.py</code></li> <li>Clean separation of concerns - utility functions not tied to class hierarchy</li> <li>Uses RapidFuzz library (40% faster than difflib, written in C++)</li> <li> <p>Smart multi-stage matching approach</p> </li> <li> <p>Multi-Stage Matching Strategy:    <code>Stage 1: Exact substring match (O(n), fastest)    Stage 2: Sentence-by-sentence fuzzy matching using RapidFuzz    Stage 3: Fail fast for very short queries (&lt;5 words)</code></p> </li> <li> <p>Key Optimizations:</p> </li> <li>RapidFuzz's <code>partial_ratio</code> uses optimized algorithms internally</li> <li>Splits document into sentences rather than sliding window over entire text</li> <li>Early exit when excellent match (&gt;95%) is found</li> <li>Safety limit on document size (500K chars max)</li> </ol>"},{"location":"performance-optimization/#results","title":"Results","text":""},{"location":"performance-optimization/#performance-improvement","title":"Performance Improvement","text":"Scenario Old Implementation New Implementation Improvement Full validation (9 findings, 18K words) \u221e (hangs) 2.6 seconds \u2705 Works! Exact match N/A 3.5ms Fast Fuzzy match N/A 17ms Fast No match N/A 19ms Fast"},{"location":"performance-optimization/#validation-quality","title":"Validation Quality","text":"<p>The new implementation maintains the same validation quality: - \u2705 Catches real errors (found typo in supporting text) - \u2705 Provides helpful suggestions (99% match with correct text) - \u2705 Same threshold behavior (85% default for validation) - \u2705 No false positives on dissimilar text</p>"},{"location":"performance-optimization/#technical-details","title":"Technical Details","text":""},{"location":"performance-optimization/#rapidfuzz-advantages","title":"RapidFuzz Advantages","text":"<p>From research (2024-2025 benchmarks): - 40% faster than other fuzzy matching libraries - Processes ~2,500 text pairs/second (vs 1,000 for difflib) - Written in C++ with algorithmic improvements - Uses optimized partial matching: O(N[N/64]M) worst case - Only considers alignments starting at longest common substrings</p>"},{"location":"performance-optimization/#api-design","title":"API Design","text":"<p>Clean, reusable utility functions:</p> <pre><code>from ai_gene_review.validation.fuzzy_text_utils import find_fuzzy_match_in_text\n\n# Simple API\nfound, score, match = find_fuzzy_match_in_text(query, document, threshold=85.0)\n\n# Returns:\n# - found: bool (True if score &gt;= threshold)\n# - score: float 0-100 (match quality)\n# - match: Optional[str] (best matching text segment)\n</code></pre>"},{"location":"performance-optimization/#testing","title":"Testing","text":"<p>Comprehensive test coverage: - Unit tests for all utility functions - Doctests for examples - Integration tests with publication-sized documents - Performance regression tests (&lt;100ms for 10K-word documents)</p>"},{"location":"performance-optimization/#future-considerations","title":"Future Considerations","text":"<p>While the current solution works well, potential enhancements:</p> <ol> <li>Semantic Search with Embeddings (for very different phrasings):</li> <li>Current fuzzy matching catches typos and minor variations</li> <li>Embeddings could catch paraphrases (\"car\" \u2248 \"vehicle\")</li> <li>Trade-off: Much higher computational cost, requires GPU/model</li> <li> <p>Decision: Not needed for current use case (validating exact quotes)</p> </li> <li> <p>Caching:</p> </li> <li>Could cache fuzzy match results for repeated queries</li> <li> <p>Current implementation is fast enough without caching</p> </li> <li> <p>Parallel Processing:</p> </li> <li>Could process multiple findings concurrently</li> <li>Current sequential processing is fast enough</li> </ol>"},{"location":"performance-optimization/#files-changed","title":"Files Changed","text":"<ol> <li>New files:</li> <li><code>src/ai_gene_review/validation/fuzzy_text_utils.py</code> - Utility module</li> <li> <p><code>tests/test_fuzzy_text_utils.py</code> - Test suite</p> </li> <li> <p>Modified files:</p> </li> <li> <p><code>src/ai_gene_review/validation/supporting_text_validator.py</code>:</p> <ul> <li>Added import: <code>from ai_gene_review.validation.fuzzy_text_utils import find_fuzzy_match_in_text</code></li> <li>Updated <code>generate_suggested_fix()</code> to use new utility instead of <code>super().find_text_in_publication()</code></li> </ul> </li> <li> <p>Dependencies:</p> </li> <li>Added <code>rapidfuzz==3.14.3</code> to <code>pyproject.toml</code></li> </ol>"},{"location":"performance-optimization/#migration-notes","title":"Migration Notes","text":"<ul> <li>Backward Compatible: The API remains the same for callers</li> <li>No Breaking Changes: Same validation behavior and thresholds</li> <li>Old Code: The parent class <code>SupportingTextValidator</code> remains for now but is deprecated</li> <li>Cleanup: Could eventually remove the slow sliding window code from parent class</li> </ul>"},{"location":"performance-optimization/#references","title":"References","text":"<ul> <li>RapidFuzz documentation: https://rapidfuzz.github.io/RapidFuzz/</li> <li>Performance benchmarks: https://towardsdatascience.com/fuzzy-string-match-with-python-on-large-dataset</li> <li>Comparative analysis (2025): \"A Comparative Analysis of Python Text Matching Libraries\"</li> </ul>"},{"location":"pmc_overrides/","title":"PMC ID Override System","text":""},{"location":"pmc_overrides/#overview","title":"Overview","text":"<p>The PMC ID override system addresses incorrect linkages in NCBI's database where PubMed IDs (PMIDs) are incorrectly associated with PMC (PubMed Central) IDs. This can happen when:</p> <ul> <li>NCBI's elink service incorrectly cross-references papers</li> <li>Multiple papers about the same topic get confused in the linkage database</li> <li>Database entries are corrupted or misaligned</li> </ul>"},{"location":"pmc_overrides/#how-it-works","title":"How It Works","text":"<ol> <li>Override Table: A TSV file (<code>src/ai_gene_review/etl/pmc_overrides.tsv</code>) contains manual corrections</li> <li>Format: Simple two-column format: <code>PMID&lt;tab&gt;PMCID</code></li> <li>Loading: The override table is loaded and cached on first use</li> <li>Priority: Overrides take precedence over NCBI's elink results</li> </ol>"},{"location":"pmc_overrides/#file-format","title":"File Format","text":"<p>The override file is a tab-separated values (TSV) file with the following format:</p> <pre><code># Comments start with #\n# PMID  PMCID   Optional comment\n2001740     # No PMC version exists (NCBI incorrectly links to PMC11824087)\n12345   PMC67890    # Correct PMC ID for this paper\n</code></pre> <ul> <li>PMID: The PubMed ID (without \"PMID:\" prefix)</li> <li>PMCID: The correct PMC ID, or empty if no PMC version exists</li> <li>Comments: Lines starting with # are ignored</li> <li>Blank PMCID: Indicates the paper has no PMC version</li> </ul>"},{"location":"pmc_overrides/#usage","title":"Usage","text":""},{"location":"pmc_overrides/#adding-an-override","title":"Adding an Override","text":"<ol> <li>Edit <code>src/ai_gene_review/etl/pmc_overrides.tsv</code></li> <li>Add a new line with the PMID and correct PMCID (or leave blank)</li> <li>Add a comment explaining the issue</li> <li>Report the issue to NCBI at: https://www.ncbi.nlm.nih.gov/home/about/contact/</li> </ol>"},{"location":"pmc_overrides/#example-cases","title":"Example Cases","text":""},{"location":"pmc_overrides/#case-1-no-pmc-version","title":"Case 1: No PMC Version","text":"<pre><code>2001740     # 1991 FEBS Letters paper, no PMC version available\n</code></pre>"},{"location":"pmc_overrides/#case-2-wrong-pmc-linked","title":"Case 2: Wrong PMC Linked","text":"<pre><code>12345   PMC67890    # NCBI links to PMC99999 which is a different paper\n</code></pre>"},{"location":"pmc_overrides/#case-3-pmc-exists-but-not-linked","title":"Case 3: PMC Exists but Not Linked","text":"<pre><code>54321   PMC11111    # NCBI doesn't show PMC link but it exists\n</code></pre>"},{"location":"pmc_overrides/#implementation-details","title":"Implementation Details","text":"<p>The override system is implemented in <code>src/ai_gene_review/etl/publication.py</code>:</p> <ul> <li><code>load_pmc_overrides()</code>: Loads and caches the override table</li> <li><code>fetch_pubmed_data()</code>: Checks overrides before querying NCBI's elink</li> </ul>"},{"location":"pmc_overrides/#testing","title":"Testing","text":"<p>Run tests with:</p> <pre><code>uv run pytest tests/test_pmc_overrides.py\n</code></pre>"},{"location":"pmc_overrides/#reporting-issues-to-ncbi","title":"Reporting Issues to NCBI","text":"<p>When you find an incorrect PMC linkage:</p> <ol> <li>Add it to the override table (immediate fix)</li> <li>Report to NCBI:</li> <li>URL: https://www.ncbi.nlm.nih.gov/home/about/contact/</li> <li>Include both PMIDs and PMC IDs involved</li> <li>Provide paper titles and years to help identify the issue</li> </ol>"},{"location":"pmc_overrides/#example-report-to-ncbi","title":"Example Report to NCBI","text":"<pre><code>Subject: Incorrect PMC ID linkage for PMID 2001740\n\nThe PubMed entry for PMID 2001740 (Yamaguchi &amp; Sakurai, FEBS Lett 1991) \nis incorrectly linked to PMC11824087.\n\nPMC11824087 actually corresponds to PMID 25230901 (Yamaguchi, J Cancer \nRes Clin Oncol 2014), which is a different paper about the same protein.\n\nThe 1991 paper appears to have no PMC version available, as expected for \nolder subscription journal articles.\n\nPlease correct this linkage in the NCBI database.\n</code></pre>"},{"location":"rule_analysis/","title":"ARBA Rule Post-Enrichment Analysis","text":""},{"location":"rule_analysis/#overview","title":"Overview","text":"<p>The <code>rule_analysis</code> module provides deterministic analysis of UniProt ARBA rules after enrichment. It calculates InterPro domain overlap using Jaccard similarity and detects redundancy with existing InterPro2GO mappings.</p>"},{"location":"rule_analysis/#key-features","title":"Key Features","text":"<ul> <li>InterPro Domain Overlap: Calculate Jaccard similarity, set differences, and containment metrics between InterPro domains</li> <li>Protein Count Queries: Query UniProt API for SwissProt protein counts using boolean AND queries</li> <li>InterPro2GO Mappings: Download and cache official GO Consortium InterPro2GO mappings</li> <li>Redundancy Detection: Identify when rule annotations duplicate existing ipr2go mappings</li> <li>Multiple Output Formats: Export results as YAML, JSON, or human-readable text</li> <li>Interpretation: Automatic classification of overlap patterns (SUBSET, REDUNDANT, HIGH_OVERLAP, etc.)</li> </ul>"},{"location":"rule_analysis/#quick-start","title":"Quick Start","text":"<pre><code>from pathlib import Path\nfrom ai_gene_review.etl.arba import ARBAClient\nfrom ai_gene_review.etl.rule_analysis import analyze_rule_post_enrichment\n\n# Load an ARBA rule\nclient = ARBAClient()\nrule = client.fetch_rule(\"ARBA00026249\")\n\n# Run full analysis\nanalysis = analyze_rule_post_enrichment(rule, Path(\"rules/arba\"))\n\n# Check results\nprint(analysis[\"ipr2go_redundancy\"][\"summary\"])\nprint(analysis[\"condition_sets_analysis\"][0][\"interpro_overlap\"][\"summary\"])\n</code></pre>"},{"location":"rule_analysis/#command-line-tools","title":"Command Line Tools","text":""},{"location":"rule_analysis/#sync-interpro2go-mappings","title":"Sync InterPro2GO Mappings","text":"<p>Download and cache the official InterPro2GO mapping file:</p> <pre><code>just sync-ipr2go\n</code></pre> <p>This downloads ~14,743 InterPro \u2192 GO mappings (2.9MB) from http://geneontology.org/external2go/interpro2go</p>"},{"location":"rule_analysis/#demo-script","title":"Demo Script","text":"<p>Run comprehensive analysis on any ARBA rule with flexible output formats:</p> <pre><code># Display analysis report in console\nuv run python examples/rule_analysis_demo.py ARBA00026249\n\n# Save as YAML (default format, inferred from extension)\nuv run python examples/rule_analysis_demo.py ARBA00026249 --output analysis.yaml\n\n# Save as JSON\nuv run python examples/rule_analysis_demo.py ARBA00026249 --output analysis.json\n\n# Save as text report\nuv run python examples/rule_analysis_demo.py ARBA00026249 --output report.txt --format text\n\n# Explicitly specify format\nuv run python examples/rule_analysis_demo.py ARBA00026249 --output analysis --format yaml\n</code></pre>"},{"location":"rule_analysis/#core-functions","title":"Core Functions","text":""},{"location":"rule_analysis/#fetch_interpro2go_mappingscache_dir-path-dictstr-liststr","title":"<code>fetch_interpro2go_mappings(cache_dir: Path) -&gt; dict[str, list[str]]</code>","text":"<p>Download and parse InterPro2GO mappings from the GO Consortium.</p> <p>Returns: Dict mapping InterPro IDs to lists of GO IDs</p> <pre><code>from pathlib import Path\nfrom ai_gene_review.etl.rule_analysis import fetch_interpro2go_mappings\n\nmappings = fetch_interpro2go_mappings(Path(\"rules/arba\"))\n# {'IPR005982': ['GO:0004791'], 'IPR008255': ['GO:0016491'], ...}\n</code></pre>"},{"location":"rule_analysis/#get_swissprot_count_for_interprointerpro_id-str-int","title":"<code>get_swissprot_count_for_interpro(interpro_id: str) -&gt; int</code>","text":"<p>Query UniProt API for count of SwissProt proteins with an InterPro domain.</p> <p>Query: <code>(xref:interpro-{id}) AND (reviewed:true)</code></p> <pre><code>from ai_gene_review.etl.rule_analysis import get_swissprot_count_for_interpro\n\ncount = get_swissprot_count_for_interpro(\"IPR005982\")\n# 65\n</code></pre>"},{"location":"rule_analysis/#get_swissprot_count_for_interpro_intersectioninterpro_ids-liststr-int","title":"<code>get_swissprot_count_for_interpro_intersection(interpro_ids: list[str]) -&gt; int</code>","text":"<p>Query UniProt API for count of proteins matching ALL InterPro domains.</p> <p>Query: <code>(xref:interpro-{id1}) AND (xref:interpro-{id2}) AND ... AND (reviewed:true)</code></p> <pre><code>from ai_gene_review.etl.rule_analysis import get_swissprot_count_for_interpro_intersection\n\ncount = get_swissprot_count_for_interpro_intersection([\"IPR005982\", \"IPR008255\"])\n# 65\n</code></pre>"},{"location":"rule_analysis/#calculate_jaccard_similarityinterpro_a-str-interpro_b-str-float","title":"<code>calculate_jaccard_similarity(interpro_a: str, interpro_b: str) -&gt; float</code>","text":"<p>Calculate Jaccard similarity coefficient between two InterPro domains.</p> <p>Formula: <code>Jaccard = |A \u2229 B| / (|A| + |B| - |A \u2229 B|)</code></p> <pre><code>from ai_gene_review.etl.rule_analysis import calculate_jaccard_similarity\n\nsimilarity = calculate_jaccard_similarity(\"IPR005982\", \"IPR008255\")\n# 0.774\n</code></pre>"},{"location":"rule_analysis/#analyze_interpro_overlap_in_condition_setcondition_set-conditionset-dict","title":"<code>analyze_interpro_overlap_in_condition_set(condition_set: ConditionSet) -&gt; dict</code>","text":"<p>Analyze all pairwise InterPro domain overlaps in a conjunctive condition set.</p> <p>Returns: Dict with pairwise statistics (Jaccard, containment, counts) and summary</p> <pre><code>from ai_gene_review.etl.arba import ARBAClient\nfrom ai_gene_review.etl.rule_analysis import analyze_interpro_overlap_in_condition_set\n\nclient = ARBAClient()\nrule = client.fetch_rule(\"ARBA00026249\")\nresult = analyze_interpro_overlap_in_condition_set(rule.condition_sets[0])\n\nprint(result[\"summary\"])\n# \"Analyzed 3 InterPro pairs. Average Jaccard similarity: 0.315. 1 pairs with &gt;50% overlap.\"\n</code></pre>"},{"location":"rule_analysis/#analyze_ipr2go_redundancyinterpro_ids-liststr-rule_go_ids-liststr-ipr2go_mappings-dict-dict","title":"<code>analyze_ipr2go_redundancy(interpro_ids: list[str], rule_go_ids: list[str], ipr2go_mappings: dict) -&gt; dict</code>","text":"<p>Check if rule GO annotations are redundant with existing InterPro2GO mappings.</p> <p>Returns: Dict with redundant_annotations, novel_annotations, and summary</p> <pre><code>from pathlib import Path\nfrom ai_gene_review.etl.rule_analysis import fetch_interpro2go_mappings, analyze_ipr2go_redundancy\n\nmappings = fetch_interpro2go_mappings(Path(\"rules/arba\"))\nresult = analyze_ipr2go_redundancy(\n    interpro_ids=[\"IPR005982\", \"IPR008255\"],\n    rule_go_ids=[\"GO:0004791\"],\n    ipr2go_mappings=mappings\n)\n\nprint(result[\"summary\"])\n# \"1 redundant annotation(s) (already in ipr2go). All annotations already in ipr2go.\"\n</code></pre>"},{"location":"rule_analysis/#analyze_rule_post_enrichmentrule-arbarule-cache_dir-path-dict","title":"<code>analyze_rule_post_enrichment(rule: ARBARule, cache_dir: Path) -&gt; dict</code>","text":"<p>Main analysis function - runs all 4 steps deterministically.</p> <p>Steps: 1. Fetch SwissProt protein counts for InterPro IDs 2. Get InterPro2GO mappings from cached file 3. Calculate overlap (Jaccard similarity) for InterPro pairs 4. Analyze redundancy with ipr2go mappings</p> <p>Returns: Complete analysis dict</p> <pre><code>from pathlib import Path\nfrom ai_gene_review.etl.arba import ARBAClient\nfrom ai_gene_review.etl.rule_analysis import analyze_rule_post_enrichment\n\nclient = ARBAClient()\nrule = client.fetch_rule(\"ARBA00026249\")\nanalysis = analyze_rule_post_enrichment(rule, Path(\"rules/arba\"))\n\n# Structure:\n# {\n#   \"rule_id\": \"ARBA00026249\",\n#   \"condition_sets_analysis\": [\n#     {\n#       \"condition_set_index\": 0,\n#       \"interpro_overlap\": {\n#         \"pairs\": [\n#           {\n#             \"condition_a\": \"IPR005982\",\n#             \"condition_b\": \"IPR008255\",\n#             \"protein_database\": \"SWISSPROT\",\n#             \"count_a\": 65,\n#             \"count_b\": 84,\n#             \"intersection_count\": 65,\n#             \"a_minus_b_count\": 0,\n#             \"b_minus_a_count\": 19,\n#             \"jaccard_similarity\": 0.774,\n#             \"containment_a_in_b\": 1.0,\n#             \"containment_b_in_a\": 0.774,\n#             \"interpretation\": \"SUBSET\"\n#           }\n#         ],\n#         \"summary\": \"...\"\n#       }\n#     }\n#   ],\n#   \"ipr2go_redundancy\": {\n#     \"redundant_annotations\": [\n#       {\"go_id\": \"GO:0004791\", \"interpro_source\": \"IPR005982\"}\n#     ],\n#     \"novel_annotations\": [],\n#     \"summary\": \"...\"\n#   }\n# }\n</code></pre>"},{"location":"rule_analysis/#export_analysis_to_yamlanalysis-dict-output_path-path-none","title":"<code>export_analysis_to_yaml(analysis: dict, output_path: Path) -&gt; None</code>","text":"<p>Export analysis results to YAML file.</p> <pre><code>from pathlib import Path\nfrom ai_gene_review.etl.rule_analysis import export_analysis_to_yaml\n\nexport_analysis_to_yaml(analysis, Path(\"analysis.yaml\"))\n</code></pre>"},{"location":"rule_analysis/#format_analysis_as_textanalysis-dict-str","title":"<code>format_analysis_as_text(analysis: dict) -&gt; str</code>","text":"<p>Format analysis results as human-readable text report.</p> <pre><code>from ai_gene_review.etl.rule_analysis import format_analysis_as_text\n\ntext_report = format_analysis_as_text(analysis)\nprint(text_report)\n</code></pre>"},{"location":"rule_analysis/#example-arba00026249-analysis","title":"Example: ARBA00026249 Analysis","text":""},{"location":"rule_analysis/#rule-structure","title":"Rule Structure","text":"<ul> <li>Condition Set 0: IPR005982 AND IPR008255 AND IPR023753</li> <li>Condition Set 1: CATH.FunFam:3.50.50.60:FF:000064 AND Eukaryota</li> <li>Condition Set 2: Two FunFams AND Rattus</li> <li>Annotation: GO:0004791 (thioredoxin-disulfide reductase activity)</li> </ul>"},{"location":"rule_analysis/#interpro-overlap-results","title":"InterPro Overlap Results","text":"<pre><code>IPR005982 \u2194 IPR008255:\n  Jaccard similarity: 0.774 (high overlap)\n  Intersection: 65 proteins\n  Counts: 65 / 84\n  Interpretation: IPR005982 is completely contained in IPR008255\n\nIPR005982 \u2194 IPR023753:\n  Jaccard similarity: 0.075 (low overlap)\n  Intersection: 65 proteins\n  Counts: 65 / 869\n  Interpretation: IPR023753 is much broader\n\nIPR008255 \u2194 IPR023753:\n  Jaccard similarity: 0.097 (low overlap)\n  Intersection: 84 proteins\n  Counts: 84 / 869\n  Interpretation: IPR023753 is much broader\n</code></pre>"},{"location":"rule_analysis/#redundancy-analysis","title":"Redundancy Analysis","text":"<pre><code>Redundant: GO:0004791 already mapped by IPR005982\n</code></pre> <p>The rule is redundant - the official InterPro2GO file already maps IPR005982 \u2192 GO:0004791, so this ARBA rule doesn't add novel information.</p>"},{"location":"rule_analysis/#architecture","title":"Architecture","text":""},{"location":"rule_analysis/#api-based-approach","title":"API-Based Approach","text":"<p>Instead of downloading all proteins and computing intersections locally, we use the UniProt API's boolean query capability:</p> <pre><code># Query for intersection\nquery = \"(xref:interpro-IPR005982) AND (xref:interpro-IPR008255) AND (reviewed:true)\"\nresponse = requests.get(UNIPROT_SEARCH_API, params={\"query\": query, \"size\": 1})\ncount = int(response.headers.get(\"X-Total-Results\", 0))\n</code></pre> <p>Benefits: - Fast: Only HTTP requests for counts - Scalable: Works for any number of InterPro conditions - Deterministic: Results are reproducible - Simple: No local protein database needed</p>"},{"location":"rule_analysis/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>InterPro2GO file cached at <code>{cache_dir}/_interpro2go.txt</code></li> <li>Downloaded once, reused on subsequent calls</li> <li>14,743 InterPro \u2192 GO mappings (2.9MB file)</li> <li>No expiration - file is relatively stable</li> </ul>"},{"location":"rule_analysis/#testing","title":"Testing","text":"<p>Run all tests:</p> <pre><code>uv run pytest tests/test_rule_analysis.py -v\n</code></pre> <p>Run only integration tests (requires network):</p> <pre><code>uv run pytest tests/test_rule_analysis.py -v -m integration\n</code></pre> <p>All 13 tests should pass: - \u2713 InterPro2GO download and caching - \u2713 InterPro2GO parsing - \u2713 UniProt API queries (single and intersection) - \u2713 Jaccard similarity calculation - \u2713 InterPro overlap analysis - \u2713 Redundancy detection - \u2713 Edge cases (empty sets, no InterPro conditions)</p>"},{"location":"rule_analysis/#performance","title":"Performance","text":"<p>Typical analysis time for ARBA00026249: - ~26 seconds for full test suite (13 tests) - ~3 seconds for single rule analysis (3 API calls per pair) - Dominated by API request delays (0.1s default between calls)</p> <p>To speed up:</p> <pre><code># Reduce delay between API requests (use with caution - avoid rate limiting)\nanalysis = analyze_rule_post_enrichment(rule, cache_dir, request_delay=0.05)\n</code></pre>"},{"location":"rule_analysis/#future-enhancements","title":"Future Enhancements","text":"<p>The current implementation provides the core analysis functionality. Potential future additions:</p> <ol> <li>Integration with enrichment workflow: Add analysis results to <code>.enriched.json</code> files</li> <li>LinkML schema extension: Add fields for storing analysis in structured format</li> <li>CLI commands: Add <code>ai-gene-review analyze-rule</code> command</li> <li>Batch analysis: Process multiple rules efficiently</li> <li>Visualization: Generate plots of InterPro overlap networks</li> <li>Statistical tests: Determine if overlap is significant vs random</li> </ol>"},{"location":"rule_analysis/#references","title":"References","text":"<ul> <li>UniProt REST API Documentation</li> <li>InterPro2GO Mappings</li> <li>ARBA Rules Documentation</li> </ul>"},{"location":"rule_review_html/","title":"Rule Review HTML Rendering","text":""},{"location":"rule_review_html/#overview","title":"Overview","text":"<p>This feature provides HTML rendering for ARBA/UniRule reviews, similar to the existing gene review HTML rendering. The HTML output combines:</p> <ul> <li>The rule review YAML (source of truth)</li> <li>Quantitative analysis statistics</li> <li>Domain overlap heatmap visualization</li> <li>Interactive tabbed sections for assessments</li> </ul>"},{"location":"rule_review_html/#key-features","title":"Key Features","text":""},{"location":"rule_review_html/#1-comprehensive-rule-information","title":"1. Comprehensive Rule Information","text":"<p>The HTML view displays: - Rule ID, type, status, and action - Detailed description and review summary - Condition sets with domain conditions - GO annotations - Pairwise overlap analysis tables</p>"},{"location":"rule_review_html/#2-visual-statistics-dashboard","title":"2. Visual Statistics Dashboard","text":"<p>Four key metrics displayed in gradient cards: - Domain Pairs Analyzed: Total pairwise comparisons performed - Condition Sets: Number of alternative rule condition sets - Subset Relationships: Count of domain subset relationships found - Redundant Annotations: Number of annotations already in InterPro2GO</p>"},{"location":"rule_review_html/#3-dual-heatmap-visualization","title":"3. Dual Heatmap Visualization","text":"<p>Domain overlap analysis presented in two complementary formats:</p> <p>PNG Heatmap (embedded as base64): - Self-contained HTML files (no external PNG dependencies) - Asymmetric containment matrix - Domain IDs, labels, and protein counts on axes - Color-coded overlap intensity - Condition set grouping with separators - Portable and shareable as a single file</p> <p>Interactive HTML Table Heatmap: - Simple, accessible table format - Clickable cells linking to UniProt intersection queries - Multiple metrics per cell: containment %, Jaccard similarity %, and intersection count - Row and column headers hyperlinked to UniProt domain queries - Condition set annotations on row headers (e.g., \"CS: 0, 1\") - Protein counts for each domain - Color-coded cells based on containment strength:   - Red (\u226590%): High containment   - Orange (70-89%): Medium-high   - Yellow (50-69%): Medium   - Light green (30-49%): Medium-low   - Green (1-29%): Low containment   - Gray (0%): No overlap</p>"},{"location":"rule_review_html/#4-tabbed-assessment-sections","title":"4. Tabbed Assessment Sections","text":"<p>Six assessment categories with color-coded badges: - Parsimony: Evaluation of rule complexity vs value - Literature Support: Strength of scientific evidence - Condition Overlap: Analysis of domain relationships - InterPro2GO: Redundancy with existing manual curation - GO Specificity: Appropriateness of term granularity - Taxonomic Scope: Coverage across species</p>"},{"location":"rule_review_html/#5-comprehensive-hyperlinking","title":"5. Comprehensive Hyperlinking","text":"<p>All identifiers and counts are clickable, linking to external resources: - CURIE links: GO IDs, InterPro domains, CATH FunFam, NCBITaxon, PMIDs link to their respective databases - GO annotations: Link to QuickGO for detailed term information - Condition domains: Link to UniProt queries showing proteins with that domain - Count links: In pairwise overlap tables, counts link to UniProt queries:   - Condition A/B: Links to proteins with that domain   - Count A/B: Links to proteins with respective domain   - Intersection: Links to proteins with BOTH domains (AND query) - Heatmap table cells:   - Row/column headers: Link to UniProt queries for proteins with that domain   - Cell contents: Link to UniProt intersection queries (proteins with BOTH domains)   - All links open in new tabs for easy exploration</p>"},{"location":"rule_review_html/#6-complete-reference-list","title":"6. Complete Reference List","text":"<p>All supporting references with: - Publication IDs (PMIDs, file references) - Titles and key findings - Direct supporting text excerpts</p>"},{"location":"rule_review_html/#usage","title":"Usage","text":""},{"location":"rule_review_html/#using-just-commands-recommended","title":"Using Just Commands (Recommended)","text":"<p>The easiest way to render rule reviews is using the justfile targets:</p> <pre><code># Render a single rule review\njust render-rule ARBA00026249\n\n# Render all rules that have review YAML files\njust render-all-rules\n\n# Use a custom cache directory\njust render-rule ARBA00026249 rules/unirule\njust render-all-rules rules/unirule\n</code></pre>"},{"location":"rule_review_html/#basic-python-api","title":"Basic Python API","text":"<pre><code>from ai_gene_review.etl.rule_analysis import render_rule_review_html\nfrom pathlib import Path\n\nrule_id = \"ARBA00026249\"\ncache_dir = Path(\"rules/arba\")\n\nhtml_path = render_rule_review_html(rule_id, cache_dir)\n# Generates: rules/arba/ARBA00026249/ARBA00026249-review.html\n</code></pre>"},{"location":"rule_review_html/#complete-workflow","title":"Complete Workflow","text":"<p>The demo script shows the full analysis-to-HTML pipeline:</p> <pre><code># Analyze rule and render HTML\nuv run python examples/render_rule_review_demo.py ARBA00026249\n\n# Just render existing YAML to HTML (skip analysis)\nuv run python examples/render_rule_review_demo.py ARBA00026249 --skip-analysis\n\n# Use custom output directory\nuv run python examples/render_rule_review_demo.py ARBA00026249 --output-dir /tmp/demo\n</code></pre>"},{"location":"rule_review_html/#file-structure","title":"File Structure","text":"<p>For rule <code>ARBA00026249</code>, the following files work together:</p> <pre><code>rules/arba/ARBA00026249/\n\u251c\u2500\u2500 ARBA00026249.json              # Raw rule from UniProt API\n\u251c\u2500\u2500 ARBA00026249.enriched.json     # Rule with added labels\n\u251c\u2500\u2500 ARBA00026249-review.yaml       # Manual review (source of truth)\n\u251c\u2500\u2500 ARBA00026249-analysis.txt      # Quantitative analysis text\n\u251c\u2500\u2500 ARBA00026249-heatmap.png       # Domain overlap visualization\n\u2514\u2500\u2500 ARBA00026249-review.html       # Generated HTML view\n</code></pre>"},{"location":"rule_review_html/#template-design","title":"Template Design","text":"<p>The Jinja2 template (<code>rule_review.html.j2</code>) follows the same design principles as gene reviews:</p> <ul> <li>Clean, modern CSS with CSS variables for theming</li> <li>Responsive layout with flexbox/grid</li> <li>Color-coded badges for quick visual scanning</li> <li>Embedded JavaScript for tab switching</li> <li>Mobile-friendly with proper viewport settings</li> </ul>"},{"location":"rule_review_html/#color-scheme","title":"Color Scheme","text":"<p>Status badges: - COMPLETE: Green (#d1fae5) - IN_PROGRESS: Blue (#dbeafe) - INITIALIZED: Yellow (#fef3c7)</p> <p>Action badges: - ACCEPT: Green (#22c55e) - REMOVE: Red (#ef4444) - MODIFY: Orange (#f97316)</p> <p>Assessment badges: - APPROPRIATE/STRONG: Green - MINOR: Blue - POOR/COMPLETE: Yellow-Red gradient</p>"},{"location":"rule_review_html/#implementation-details","title":"Implementation Details","text":""},{"location":"rule_review_html/#function-render_rule_review_html","title":"Function: <code>render_rule_review_html()</code>","text":"<p>Located in <code>src/ai_gene_review/etl/rule_analysis.py</code></p> <p>Parameters: - <code>rule_id</code>: ARBA/UniRule identifier - <code>cache_dir</code>: Directory containing rule files - <code>output_path</code>: Optional custom output path - <code>template_path</code>: Optional custom template</p> <p>Process: 1. Loads rule review YAML 2. Calculates statistics from YAML data 3. Checks for heatmap image 4. Renders Jinja2 template 5. Writes HTML to file</p> <p>Returns: Path to generated HTML file</p>"},{"location":"rule_review_html/#statistics-calculation","title":"Statistics Calculation","text":"<p>Stats are derived from the YAML review data:</p> <pre><code>stats = {\n    'condition_sets': len(condition_sets),\n    'total_pairs': sum(len(cs.pairwise_overlap) for cs in condition_sets),\n    'subset_relationships': count of 'SUBSET' interpretations,\n    'redundant_annotations': len(ipr2go_redundancy.redundant_annotations)\n}\n</code></pre>"},{"location":"rule_review_html/#heatmap-integration","title":"Heatmap Integration","text":"<p>If <code>{rule_id}-heatmap.png</code> exists, it's read and embedded inline as base64:</p> <pre><code>import base64\nwith open(heatmap_path, 'rb') as f:\n    heatmap_data = base64.b64encode(f.read()).decode('utf-8')\nrule_data['heatmap_data'] = f\"data:image/png;base64,{heatmap_data}\"\n</code></pre> <pre><code>&lt;img src=\"data:image/png;base64,iVBORw0KG...\" alt=\"Domain Overlap Heatmap\" /&gt;\n</code></pre> <p>This makes the HTML file self-contained with no external dependencies.</p>"},{"location":"rule_review_html/#design-rationale","title":"Design Rationale","text":""},{"location":"rule_review_html/#why-html","title":"Why HTML?","text":"<ol> <li>Human-friendly: Easier to read than YAML for reviewers</li> <li>Visual: Heatmap and stats provide quick insights</li> <li>Shareable: Can be opened in any browser, no special tools needed</li> <li>Archival: Self-contained documentation of the review</li> <li>Navigable: Tabs and sections organize complex information</li> </ol>"},{"location":"rule_review_html/#yaml-as-source-of-truth","title":"YAML as Source of Truth","text":"<p>The review YAML remains the canonical source: - Version controlled - Machine readable - Programmatically processable - Schema validated</p> <p>The HTML is a rendered view, regenerated as needed from the YAML.</p>"},{"location":"rule_review_html/#separation-of-concerns","title":"Separation of Concerns","text":"<ul> <li>Analysis (<code>analyze_rule_post_enrichment</code>): Quantitative data</li> <li>Review (<code>{rule_id}-review.yaml</code>): Qualitative assessment</li> <li>Rendering (<code>render_rule_review_html</code>): Presentation layer</li> </ul>"},{"location":"rule_review_html/#comparison-to-gene-reviews","title":"Comparison to Gene Reviews","text":""},{"location":"rule_review_html/#similarities","title":"Similarities","text":"<ul> <li>Jinja2 templating</li> <li>CSS design patterns</li> <li>YAML source of truth</li> <li>Embedded visualizations</li> <li>Statistics cards</li> <li>Reference sections</li> </ul>"},{"location":"rule_review_html/#differences","title":"Differences","text":"<ul> <li>Tabbed assessments: Rules have 6 assessment categories vs genes' annotation tables</li> <li>Condition sets: Rules show alternative rule definitions</li> <li>Domain overlap: Pairwise tables instead of annotation history</li> <li>No core functions: Rules annotate, not synthesize function</li> <li>Heatmap: Domain overlap matrix vs gene pathway diagrams</li> </ul>"},{"location":"rule_review_html/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements:</p> <ol> <li>Interactive heatmap: Use Plotly for hover details</li> <li>Comparison view: Show before/after for rule modifications</li> <li>Batch rendering: Generate HTML for all rules at once</li> <li>Export options: PDF generation via Playwright</li> <li>Validation panel: Show schema validation results</li> <li>Change log: Track review evolution over time</li> </ol>"},{"location":"rule_review_html/#examples","title":"Examples","text":"<p>See the generated HTML for ARBA00026249: - <code>rules/arba/ARBA00026249/ARBA00026249-review.html</code></p> <p>This rule demonstrates: - Complete redundancy with InterPro2GO - Three condition sets with different approaches - Subset relationships in domain overlap - Strong literature support but poor parsimony - Comprehensive assessment across all categories</p>"},{"location":"rule_review_workflow/","title":"Rule Review Workflow","text":"<p>This document describes the complete workflow for reviewing ARBA and UniRule annotation rules.</p>"},{"location":"rule_review_workflow/#overview","title":"Overview","text":"<p>The rule review workflow consists of several distinct phases, each with specific dependencies:</p> <ol> <li>Initialize - Create review file with proper structure</li> <li>Analyze - Compute domain overlaps and redundancy</li> <li>Sync - Populate review file with analysis data</li> <li>Research - Gather literature support</li> <li>Review - Fill in TODO placeholders with AI/human curation</li> <li>Render - Generate HTML visualization</li> </ol>"},{"location":"rule_review_workflow/#quick-start","title":"Quick Start","text":"<p>For a new rule, run these commands in order:</p> <pre><code># 1. Initialize the review file\njust init-rule-review ARBA00026249\n\n# 2. Analyze the rule (computes overlaps)\njust analyze-rule ARBA00026249\n\n# 3. Sync analysis data into review YAML\njust sync-rule-review-single ARBA00026249\n\n# 4. Research literature support\njust rules-deep-research-perplexity ARBA00026249\n\n# 5. Edit the review YAML to fill in TODO placeholders\n# (Do this manually or with AI assistance)\n\n# 6. Render HTML\njust render-rule ARBA00026249\n</code></pre>"},{"location":"rule_review_workflow/#detailed-workflow-steps","title":"Detailed Workflow Steps","text":""},{"location":"rule_review_workflow/#step-1-initialize-review-file","title":"Step 1: Initialize Review File","text":"<pre><code>just init-rule-review ARBA00026249\n</code></pre> <p>What it does: - Creates <code>rules/arba/ARBA00026249/ARBA00026249-review.yaml</code> with proper structure - Fetches and enriches the rule if <code>ARBA00026249.enriched.json</code> doesn't exist - Populates all required fields with TODO placeholders</p> <p>IMPORTANT: Will NOT overwrite existing review YAML files - If the review YAML already exists, you'll get an error: <code>FileExistsError: Review file already exists</code> - This prevents accidental overwrites that could lose manual edits - To refresh a review file, manually delete it first: <code>rm rules/arba/ARBA00026249/ARBA00026249-review.yaml</code></p> <p>Creates: - <code>ARBA00026249-review.yaml</code> (review file with TODO stubs) - WILL NOT OVERWRITE IF EXISTS - <code>ARBA00026249.enriched.json</code> (if missing)</p> <p>Dependencies: - None (this is the first step)</p> <p>Output structure:</p> <pre><code>id: ARBA00026249\ndescription: TODO: Provide a concise description\nstatus: IN_PROGRESS\nrule_type: ARBA\nrule:\n  rule_id: ARBA00026249\n  condition_sets:\n    - number: 1\n      conditions: [...]\n      notes: TODO: Describe this condition set\n      # pairwise_overlap will be added by sync-rule-review-single\n  go_annotations: [...]\n  # entries field will be added by sync-rule-review-single\nreview_summary: TODO: Summarize the overall quality\naction: UNDECIDED\n# ... more TODO fields\n</code></pre>"},{"location":"rule_review_workflow/#step-2-analyze-rule","title":"Step 2: Analyze Rule","text":"<pre><code>just analyze-rule ARBA00026249\n</code></pre> <p>What it does: - Computes pairwise domain overlaps (Jaccard, containment) - Identifies InterPro2GO redundancies - Generates heatmap visualization - Creates analysis files in YAML, JSON, and text formats</p> <p>Creates: - <code>ARBA00026249-analysis.yaml</code> (required for sync step) - <code>ARBA00026249-analysis.json</code> - <code>ARBA00026249-analysis.txt</code> - <code>ARBA00026249-heatmap.png</code></p> <p>Dependencies: - <code>ARBA00026249.enriched.json</code></p> <p>Lazy evaluation: Skips analysis if both <code>enriched.json</code> AND <code>analysis.yaml</code> already exist. Use <code>--force</code> to rebuild.</p>"},{"location":"rule_review_workflow/#step-3-sync-analysis-data","title":"Step 3: Sync Analysis Data","text":"<pre><code>just sync-rule-review-single ARBA00026249\n</code></pre> <p>What it does: - Reads <code>ARBA00026249-analysis.yaml</code> - Populates the <code>entries</code> field in <code>ARBA00026249-review.yaml</code> - Adds <code>pairwise_overlap</code> sections to each condition set</p> <p>Modifies: - <code>ARBA00026249-review.yaml</code> (adds <code>entries</code> and <code>pairwise_overlap</code> fields)</p> <p>Dependencies: - <code>ARBA00026249-review.yaml</code> (from init-rule-review) - <code>ARBA00026249-analysis.yaml</code> (automatically created by analyze-rule dependency)</p> <p>Critical: This step populates the <code>entries</code> field that is REQUIRED for HTML rendering to work correctly.</p>"},{"location":"rule_review_workflow/#step-4-research-literature","title":"Step 4: Research Literature","text":"<pre><code>just rules-deep-research-perplexity ARBA00026249\n</code></pre> <p>What it does: - Uses Perplexity AI to research literature support - Creates a markdown file with citations and findings</p> <p>Creates: - <code>ARBA00026249-deep-research-perplexity.md</code></p> <p>Dependencies: - None (can run in parallel with other steps)</p> <p>Alternatives: - <code>just rules-deep-research-falcon ARBA00026249</code> (local model) - <code>just rules-deep-research-openai ARBA00026249</code> (GPT models) - <code>just rules-deep-research-perplexity-lite ARBA00026249</code> (faster, cheaper)</p>"},{"location":"rule_review_workflow/#step-5-manual-review","title":"Step 5: Manual Review","text":"<p>Edit <code>ARBA00026249-review.yaml</code> to replace TODO placeholders with actual content:</p> <p>Key fields to fill in: - <code>description</code> - Concise summary of rule purpose - <code>condition_sets[].notes</code> - Analysis of each condition set - <code>review_summary</code> - Overall quality assessment - <code>action</code> - ACCEPT, MODIFY, DEPRECATE, or UNDECIDED - <code>action_rationale</code> - Justification for the action - <code>parsimony.assessment</code> - PARSIMONIOUS, ACCEPTABLE, REDUNDANT, or OVERLY_COMPLEX - <code>parsimony.notes</code> - Detailed parsimony analysis - <code>literature_support.assessment</code> - STRONG, MODERATE, or WEAK - <code>literature_support.notes</code> - Literature evidence summary - <code>condition_overlap.notes</code> - Domain overlap interpretation - <code>go_specificity.notes</code> - GO term specificity assessment - <code>taxonomic_scope.notes</code> - Taxonomic restriction evaluation - <code>confidence</code> - 0.0-1.0 confidence score</p> <p>Important: The <code>entries</code> field should NOT be edited manually - it's populated automatically by <code>sync-rule-review-single</code>.</p>"},{"location":"rule_review_workflow/#step-6-render-html","title":"Step 6: Render HTML","text":"<pre><code>just render-rule ARBA00026249\n</code></pre> <p>What it does: - Generates interactive HTML visualization - Shows domain overlap heatmap - Displays condition sets with pairwise overlaps - Shows entries with relationships</p> <p>Creates: - <code>ARBA00026249-review.html</code></p> <p>Dependencies: - <code>ARBA00026249-review.yaml</code> with populated <code>entries</code> field - <code>ARBA00026249-analysis.yaml</code> (automatically created by analyze-rule dependency)</p> <p>Critical: If <code>entries</code> field is missing, the HTML will be incomplete (missing CS labels, domain overlap tables, etc.).</p>"},{"location":"rule_review_workflow/#dependency-graph","title":"Dependency Graph","text":"<pre><code>init-rule-review\n    \u2193 (creates review.yaml + enriched.json)\n    \u251c\u2500\u2192 analyze-rule\n    \u2502       \u2193 (creates analysis.yaml)\n    \u2502       \u2193\n    \u2502   sync-rule-review-single\n    \u2502       \u2193 (populates entries field in review.yaml)\n    \u2502       \u2193\n    \u2502   render-rule \u2500\u2500\u2500\u2500\u2192 HTML\n    \u2502\n    \u2514\u2500\u2192 rules-deep-research-*\n            \u2193 (creates deep-research.md)\n            \u2193\n        (use for filling in review.yaml manually)\n</code></pre>"},{"location":"rule_review_workflow/#file-dependencies-summary","title":"File Dependencies Summary","text":"File Created By Required By Purpose <code>{rule_id}.enriched.json</code> init-rule-review analyze-rule Enriched rule data from UniProt <code>{rule_id}-review.yaml</code> init-rule-review sync-rule-review-single, render-rule Main review file <code>{rule_id}-analysis.yaml</code> analyze-rule sync-rule-review-single, render-rule Domain overlap analysis <code>{rule_id}-analysis.json</code> analyze-rule - JSON format of analysis <code>{rule_id}-analysis.txt</code> analyze-rule - Human-readable analysis report <code>{rule_id}-heatmap.png</code> analyze-rule - Overlap visualization <code>{rule_id}-deep-research-*.md</code> rules-deep-research-* - Literature research <code>{rule_id}-review.html</code> render-rule - Final HTML output"},{"location":"rule_review_workflow/#common-issues","title":"Common Issues","text":""},{"location":"rule_review_workflow/#issue-html-missing-cs-labels","title":"Issue: HTML Missing CS Labels","text":"<p>Symptom: HTML shows domain overlap data but no \"CS 1\", \"CS 2\" labels.</p> <p>Cause: Missing <code>entries</code> field in review YAML.</p> <p>Fix: Run <code>just sync-rule-review-single ARBA00026249</code></p>"},{"location":"rule_review_workflow/#issue-html-shows-all-dashes-","title":"Issue: HTML Shows All Dashes (----)","text":"<p>Symptom: Overlap table shows \"----\" instead of protein counts.</p> <p>Cause: Analysis doesn't support that domain type (e.g., PANTHER support was added recently).</p> <p>Fix: Re-run <code>just analyze-rule ARBA00026249</code> to regenerate analysis with updated code.</p>"},{"location":"rule_review_workflow/#issue-review-file-exists-error","title":"Issue: Review File Exists Error","text":"<p>Symptom: <code>init-rule-review</code> fails with <code>FileExistsError: Review file already exists</code>.</p> <p>Cause: Trying to initialize a rule that already has a review file. This is intentional to prevent accidental overwrites.</p> <p>Fix: 1. If you want to keep the existing review: Skip <code>init-rule-review</code> and go directly to <code>analyze-rule</code> and <code>sync-rule-review-single</code>. 2. If you want to start fresh: Delete the existing file and re-run:    <code>bash    rm rules/arba/ARBA00026249/ARBA00026249-review.yaml    just init-rule-review ARBA00026249</code></p>"},{"location":"rule_review_workflow/#issue-analysis-skipped","title":"Issue: Analysis Skipped","text":"<p>Symptom: <code>analyze-rule</code> says \"already exist, skipping expensive rebuild\".</p> <p>Cause: Lazy evaluation detected existing analysis files.</p> <p>Fix: This is intentional. To force rebuild, delete the analysis files or add <code>--force</code> flag.</p>"},{"location":"rule_review_workflow/#batch-operations","title":"Batch Operations","text":""},{"location":"rule_review_workflow/#batch-initialize-multiple-rules","title":"Batch Initialize Multiple Rules","text":"<pre><code>for rule_id in ARBA00026249 ARBA00026372 ARBA00047244; do\n    just init-rule-review $rule_id\ndone\n</code></pre>"},{"location":"rule_review_workflow/#batch-analyze-and-sync","title":"Batch Analyze and Sync","text":"<pre><code>for rule_id in ARBA00026249 ARBA00026372 ARBA00047244; do\n    just analyze-rule $rule_id\n    just sync-rule-review-single $rule_id\ndone\n</code></pre>"},{"location":"rule_review_workflow/#batch-render-all-reviews","title":"Batch Render All Reviews","text":"<pre><code>just render-all-rules\n</code></pre> <p>This automatically analyzes any rules that don't have analysis files yet.</p>"},{"location":"rule_review_workflow/#best-practices","title":"Best Practices","text":"<ol> <li>Always run init-rule-review first for new rules - don't manually create YAML files</li> <li>Run sync-rule-review-single after any re-analysis to keep <code>entries</code> field up to date</li> <li>Don't edit the <code>entries</code> field manually - it's auto-generated from analysis</li> <li>Use lazy evaluation - <code>analyze-rule</code> won't re-compute if files exist unless forced</li> <li>Check HTML after rendering to verify all data is present (CS labels, overlap tables, etc.)</li> <li>Keep analysis and review files in sync - if you re-analyze, re-sync</li> <li>Use deep research output to inform your manual review of TODO placeholders</li> </ol>"},{"location":"rule_review_workflow/#advanced-custom-cache-directory","title":"Advanced: Custom Cache Directory","text":"<p>For UniRule reviews, use a different cache directory:</p> <pre><code>just init-rule-review UR000000070 --cache-dir rules/unirule\njust analyze-rule UR000000070 --cache-dir rules/unirule\njust sync-rule-review-single UR000000070 rules/unirule\njust render-rule UR000000070 rules/unirule\n</code></pre>"},{"location":"rule_review_workflow/#see-also","title":"See Also","text":"<ul> <li>Rule Analysis Documentation - Details on the analysis algorithm</li> <li>Rule Review HTML Documentation - Details on HTML rendering</li> <li>Rule Reviewer Agent Guide - AI-assisted review workflow</li> </ul>"},{"location":"stats/","title":"Stats","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style for beautiful visualizations\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['axes.labelsize'] = 12\n</code></pre> <pre><code># Load the flattened annotation data\ntsv_path = Path('../exports/exported_annotations.tsv')\ndf = pd.read_csv(tsv_path, sep='\\t')\n\n# Report PENDING annotations first\npending_df = df[df['review_action'] == 'PENDING'].copy() if 'PENDING' in df['review_action'].values else pd.DataFrame()\n\nif not pending_df.empty:\n    print(\"\u26a0\ufe0f  PENDING ANNOTATIONS\")\n    print(\"\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\")\n    print(f\"Total PENDING: {len(pending_df):,} annotations\")\n    print(\"\\nPENDING by Species:\")\n    for species, count in pending_df['taxon_label'].value_counts().items():\n        genes = pending_df[pending_df['taxon_label'] == species]['gene_symbol'].nunique()\n        print(f\"  \u2022 {species}: {count} annotations ({genes} genes)\")\n\n    print(\"\\nGenes with most PENDING annotations:\")\n    gene_pending = pending_df.groupby('gene_symbol').agg({\n        'term_id': 'count',\n        'taxon_label': 'first'\n    }).rename(columns={'term_id': 'pending_count'}).sort_values('pending_count', ascending=False)\n    for gene, row in gene_pending.head(10).iterrows():\n        print(f\"  \u2022 {gene} ({row['taxon_label']}): {row['pending_count']} pending\")\n\n    print(\"\\n\" + \"=\"*50)\n    print(\"Note: PENDING annotations are excluded from percentage calculations below\")\n    print(\"=\"*50 + \"\\n\")\n\n# Filter out PENDING for analysis\ndf_analyzed = df[df['review_action'] != 'PENDING'].copy()\n\n# Basic statistics (excluding PENDING)\nprint(\"\ud83d\udcca Dataset Overview (Analyzed Annotations Only)\")\nprint(\"\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\")\nprint(f\"Total annotations analyzed: {len(df_analyzed):,}\")\nprint(f\"Total PENDING (excluded): {len(pending_df):,}\")\nprint(f\"Unique genes: {df_analyzed['gene_symbol'].nunique()}\")\nprint(f\"Unique species: {df_analyzed['taxon_label'].nunique()}\")\nprint(f\"Unique GO terms: {df_analyzed['term_id'].nunique()}\")\nprint(\"\\nSpecies distribution (analyzed only):\")\nfor species, count in df_analyzed['taxon_label'].value_counts().head().items():\n    print(f\"  \u2022 {species}: {count} annotations\")\n\n# Keep original df variable name for compatibility, but use filtered data\ndf = df_analyzed\n</code></pre> <pre><code># Create figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Count of review actions\naction_counts = df['review_action'].value_counts()\ncolors = sns.color_palette(\"Spectral\", len(action_counts))\n\n# Bar chart\nbars = ax1.bar(range(len(action_counts)), action_counts.values, color=colors)\nax1.set_xticks(range(len(action_counts)))\nax1.set_xticklabels(action_counts.index, rotation=45, ha='right')\nax1.set_ylabel('Number of Annotations')\nax1.set_title('Distribution of Review Actions', fontweight='bold', fontsize=14)\nax1.grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar, value in zip(bars, action_counts.values):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n             f'{int(value)}\\n({value/len(df)*100:.1f}%)',\n             ha='center', va='bottom', fontsize=10)\n\n# Pie chart with exploded slices for important actions\nexplode = [0.1 if action in ['MODIFY', 'REMOVE'] else 0 for action in action_counts.index]\nwedges, texts, autotexts = ax2.pie(action_counts.values, \n                                     labels=action_counts.index,\n                                     colors=colors,\n                                     autopct='%1.1f%%',\n                                     explode=explode,\n                                     startangle=90)\nax2.set_title('Proportion of Review Actions', fontweight='bold', fontsize=14)\n\n# Make percentage text bold\nfor autotext in autotexts:\n    autotext.set_color('white')\n    autotext.set_fontweight('bold')\n    autotext.set_fontsize(10)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\n\ud83d\udcca Action Summary:\")\nprint(f\"  \u2022 Accepted as-is: {action_counts.get('ACCEPT', 0)} ({action_counts.get('ACCEPT', 0)/len(df)*100:.1f}%)\")\nprint(f\"  \u2022 Modifications needed: {action_counts.get('MODIFY', 0)} ({action_counts.get('MODIFY', 0)/len(df)*100:.1f}%)\")\nprint(f\"  \u2022 Removed: {action_counts.get('REMOVE', 0)} ({action_counts.get('REMOVE', 0)/len(df)*100:.1f}%)\")\n</code></pre> <pre><code># Prepare species data\nspecies_action = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index') * 100\nspecies_counts = df['taxon_label'].value_counts()\n\n# Filter to top species by annotation count\ntop_species = species_counts.head(10).index\nspecies_action_filtered = species_action.loc[top_species]\n\n# Create stacked bar chart\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n\n# Stacked percentage bar chart\nspecies_action_filtered.plot(kind='barh', stacked=True, ax=ax1, \n                             colormap='Spectral', width=0.8)\nax1.set_xlabel('Percentage of Annotations (%)')\nax1.set_ylabel('')\nax1.set_title('Review Actions by Species (Percentage)', fontweight='bold', fontsize=14)\nax1.legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\nax1.grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor container in ax1.containers:\n    ax1.bar_label(container, fmt='%.0f%%', label_type='center', fontsize=9)\n\n# Absolute counts heatmap\nspecies_action_abs = pd.crosstab(df['taxon_label'], df['review_action'])\nspecies_action_abs_filtered = species_action_abs.loc[top_species]\n\nsns.heatmap(species_action_abs_filtered, annot=True, fmt='d', cmap='YlOrRd', \n            ax=ax2, cbar_kws={'label': 'Number of Annotations'})\nax2.set_ylabel('')\nax2.set_xlabel('Review Action')\nax2.set_title('Review Actions by Species (Absolute Counts)', fontweight='bold', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Method analysis (combining evidence type and reference source)\n# This provides a higher-level view than raw evidence codes\nif 'method' in df.columns:\n    method_counts = df['method'].value_counts()\n\n    # Create action categories if not already present\n    if 'action_category' not in df.columns:\n        def categorize_action(action):\n            if action == 'ACCEPT':\n                return 'Accept'\n            elif action == 'MODIFY':\n                return 'Modify'\n            elif action == 'REMOVE':\n                return 'Remove'\n            elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n                return 'Non-Core/Over-Annotated'\n            else:\n                return 'Other'\n        df['action_category'] = df['review_action'].apply(categorize_action)\n\n    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n\n    # 1. Method vs Review Action heatmap - COUNTS\n    method_action = pd.crosstab(df['method'], df['review_action'])\n\n    sns.heatmap(method_action, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0, 0],\n                cbar_kws={'label': 'Count'})\n    axes[0, 0].set_title('Review Actions by Method (Counts)', fontweight='bold', fontsize=12)\n    axes[0, 0].set_xlabel('Review Action')\n    axes[0, 0].set_ylabel('Method')\n    axes[0, 0].tick_params(axis='both', which='major', labelsize=9)\n\n    # 2. Method vs Review Action heatmap - PERCENTAGES\n    method_action_pct = pd.crosstab(df['method'], df['review_action'], normalize='index') * 100\n\n    sns.heatmap(method_action_pct, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=axes[0, 1],\n                cbar_kws={'label': 'Percentage (%)'}, vmin=0, vmax=50)\n    axes[0, 1].set_title('Review Actions by Method (Row %)', fontweight='bold', fontsize=12)\n    axes[0, 1].set_xlabel('Review Action')\n    axes[0, 1].set_ylabel('')\n    axes[0, 1].tick_params(axis='both', which='major', labelsize=9)\n\n    # 3. ACTION RATES BY METHOD - STACKED BAR CHART\n    # Calculate percentages for each method\n    method_action_rates = pd.crosstab(df['method'], df['action_category'], normalize='index') * 100\n\n    # Order columns for stacking\n    action_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\n    existing_cols = [col for col in action_order if col in method_action_rates.columns]\n    method_action_rates = method_action_rates[existing_cols]\n\n    # Sort by total annotations (most common first)\n    method_action_rates = method_action_rates.loc[method_counts.index]\n\n    # Create stacked bar chart\n    x = np.arange(len(method_action_rates))\n    width = 0.7\n\n    # Define colors for each action category\n    action_colors = {\n        'Accept': 'green',\n        'Modify': 'orange', \n        'Remove': 'red',\n        'Non-Core/Over-Annotated': 'purple',\n        'Other': 'gray'\n    }\n\n    # Plot stacked bars\n    bottom = np.zeros(len(method_action_rates))\n    for action in existing_cols:\n        values = method_action_rates[action].values\n        color = action_colors.get(action, 'gray')\n        axes[1, 0].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n        bottom += values\n\n    axes[1, 0].set_xticks(x)\n    axes[1, 0].set_xticklabels(method_action_rates.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 0].set_ylabel('Percentage (%)')\n    axes[1, 0].set_title('Action Rates by Method', fontweight='bold', fontsize=12)\n    axes[1, 0].legend(loc='upper right')\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    axes[1, 0].set_ylim(0, 100)\n\n    # Add sample sizes above bars\n    for i, method in enumerate(method_action_rates.index):\n        count = method_counts[method]\n        axes[1, 0].text(i, 102, f'n={count}', ha='center', fontsize=8, color='black')\n\n    # 4. Method distribution bar chart\n    colors_dist = sns.color_palette(\"viridis\", len(method_counts))\n    bars = axes[1, 1].bar(range(len(method_counts)), method_counts.values, color=colors_dist)\n    axes[1, 1].set_xticks(range(len(method_counts)))\n    axes[1, 1].set_xticklabels(method_counts.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 1].set_ylabel('Number of Annotations')\n    axes[1, 1].set_title('Distribution of Methods', fontweight='bold', fontsize=12)\n    axes[1, 1].grid(axis='y', alpha=0.3)\n\n    # Add count labels\n    for bar, value in zip(bars, method_counts.values):\n        height = bar.get_height()\n        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 5,\n                        f'{int(value)}', ha='center', va='bottom', fontsize=9)\n\n    plt.suptitle('Method Analysis Overview', fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n\n    # Print detailed summary\n    print(\"\\n\ud83d\udcca Method Analysis Summary:\")\n    print(\"=\" * 60)\n\n    # Create summary DataFrame\n    method_summary = pd.DataFrame({\n        'Count': df.groupby('method').size(),\n        'Accepted': df[df['review_action'] == 'ACCEPT'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Accept_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'ACCEPT').mean() * 100),\n        'Removed': df[df['review_action'] == 'REMOVE'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Remove_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'REMOVE').mean() * 100),\n        'Non-Core/Over': df[df['review_action'].isin(['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED'])].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n    }).sort_values('Count', ascending=False)\n\n    print(f\"\\n{'Method':&amp;lt;20} {'Count':&amp;gt;6} {'Accept':&amp;gt;8} {'Accept%':&amp;gt;8} {'Remove':&amp;gt;8} {'Remove%':&amp;gt;8} {'NonCore':&amp;gt;8}\")\n    print(\"-\" * 75)\n    for method, row in method_summary.iterrows():\n        print(f\"{method:&amp;lt;20} {int(row['Count']):6d} {int(row['Accepted']):8d} {row['Accept_Rate']:7.1f}% {int(row['Removed']):8d} {row['Remove_Rate']:7.1f}% {int(row['Non-Core/Over']):8d}\")\n\n    print(\"\\n\ud83d\udcc8 Key Insights:\")\n    print(f\"  \u2022 Total methods: {df['method'].nunique()}\")\n    print(f\"  \u2022 Most common: {method_counts.index[0]} ({method_counts.iloc[0]} annotations, {method_counts.iloc[0]/len(df)*100:.1f}%)\")\n\n    # Report on ARBA specifically\n    if 'ARBA' in method_summary.index:\n        arba_row = method_summary.loc['ARBA']\n        print(\"\\n\ud83d\udd0d ARBA Analysis:\")\n        print(f\"  \u2022 Total: {int(arba_row['Count'])} annotations\")\n        print(f\"  \u2022 Accepted: {int(arba_row['Accepted'])} ({arba_row['Accept_Rate']:.1f}%)\")\n        print(f\"  \u2022 Removed: {int(arba_row['Removed'])} ({arba_row['Remove_Rate']:.1f}%)\")\n        print(f\"  \u2022 Non-Core/Over-Annotated: {int(arba_row['Non-Core/Over'])}\")\nelse:\n    print(\"\u26a0\ufe0f Method column not found in data. Please re-export annotations to include the new method field.\")\n</code></pre> <pre><code># Evidence type distribution with action rates\nevidence_counts = df['evidence_type'].value_counts()\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# 1. Overall evidence type distribution\ncolors = sns.color_palette(\"viridis\", len(evidence_counts))\nbars = axes[0, 0].bar(range(len(evidence_counts)), evidence_counts.values, color=colors)\naxes[0, 0].set_xticks(range(len(evidence_counts)))\naxes[0, 0].set_xticklabels(evidence_counts.index, rotation=45, ha='right')\naxes[0, 0].set_ylabel('Number of Annotations')\naxes[0, 0].set_title('Distribution of Evidence Types', fontweight='bold')\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# Add count labels\nfor bar, value in zip(bars, evidence_counts.values):\n    height = bar.get_height()\n    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n                    f'{int(value)}', ha='center', va='bottom')\n\n# 2. Evidence type vs Review action heatmap\nevidence_action = pd.crosstab(df['evidence_type'], df['review_action'])\nsns.heatmap(evidence_action, annot=True, fmt='d', cmap='coolwarm', ax=axes[0, 1],\n            cbar_kws={'label': 'Count'})\naxes[0, 1].set_title('Evidence Type vs Review Action', fontweight='bold')\naxes[0, 1].set_xlabel('Review Action')\naxes[0, 1].set_ylabel('Evidence Type')\n\n# 3. Acceptance rate by evidence type\nevidence_accept_rate = pd.crosstab(df['evidence_type'], \n                                   df['review_action'] == 'ACCEPT', \n                                   normalize='index')[True] * 100\nevidence_accept_rate = evidence_accept_rate.sort_values(ascending=False)\n\nbars = axes[1, 0].barh(range(len(evidence_accept_rate)), \n                       evidence_accept_rate.values,\n                       color=sns.color_palette(\"RdYlGn\", len(evidence_accept_rate))[::-1])\naxes[1, 0].set_yticks(range(len(evidence_accept_rate)))\naxes[1, 0].set_yticklabels(evidence_accept_rate.index)\naxes[1, 0].set_xlabel('Acceptance Rate (%)')\naxes[1, 0].set_title('Acceptance Rate by Evidence Type', fontweight='bold')\naxes[1, 0].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor bar, value in zip(bars, evidence_accept_rate.values):\n    width = bar.get_width()\n    axes[1, 0].text(width + 1, bar.get_y() + bar.get_height()/2.,\n                    f'{value:.1f}%', ha='left', va='center')\n\n# 4. ACTION RATES BY EVIDENCE TYPE - STACKED BAR CHART\n# Group actions into categories\ndef categorize_action(action):\n    if action == 'ACCEPT':\n        return 'Accept'\n    elif action == 'MODIFY':\n        return 'Modify'\n    elif action == 'REMOVE':\n        return 'Remove'\n    elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n        return 'Non-Core/Over-Annotated'\n    else:\n        return 'Other'\n\ndf['action_category'] = df['review_action'].apply(categorize_action)\n\n# Calculate percentages for each evidence type\nevidence_action_rates = pd.crosstab(df['evidence_type'], df['action_category'], normalize='index') * 100\n\n# Order columns for stacking\naction_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\nexisting_cols = [col for col in action_order if col in evidence_action_rates.columns]\nevidence_action_rates = evidence_action_rates[existing_cols]\n\n# Sort by total annotations (most common first)\nevidence_action_rates = evidence_action_rates.loc[evidence_counts.index]\n\n# Create stacked bar chart\nx = np.arange(len(evidence_action_rates))\nwidth = 0.6\n\n# Define colors for each action category\naction_colors = {\n    'Accept': 'green',\n    'Modify': 'orange', \n    'Remove': 'red',\n    'Non-Core/Over-Annotated': 'purple',\n    'Other': 'gray'\n}\n\n# Plot stacked bars\nbottom = np.zeros(len(evidence_action_rates))\nfor action in existing_cols:\n    values = evidence_action_rates[action].values\n    color = action_colors.get(action, 'gray')\n    axes[1, 1].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n    bottom += values\n\naxes[1, 1].set_xticks(x)\naxes[1, 1].set_xticklabels(evidence_action_rates.index, rotation=45, ha='right')\naxes[1, 1].set_ylabel('Percentage (%)')\naxes[1, 1].set_title('Action Rates by Evidence Type', fontweight='bold')\naxes[1, 1].legend(loc='upper right')\naxes[1, 1].grid(axis='y', alpha=0.3)\naxes[1, 1].set_ylim(0, 100)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Compare Method (consolidated) vs Evidence (raw) views\nif 'method' in df.columns:\n    fig = plt.figure(figsize=(18, 12))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n    # 1. Side-by-side pie charts: Method vs Evidence\n    ax1 = fig.add_subplot(gs[0, 0])\n    method_top = df['method'].value_counts().head(8)\n    colors1 = sns.color_palette(\"Set2\", len(method_top))\n    wedges, texts, autotexts = ax1.pie(method_top.values, labels=method_top.index, \n                                        autopct='%1.1f%%', colors=colors1, startangle=90)\n    ax1.set_title('Top Methods (Consolidated)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('white')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n\n    ax2 = fig.add_subplot(gs[0, 1])\n    evidence_top = df['evidence_type'].value_counts().head(8)\n    colors2 = sns.color_palette(\"Set3\", len(evidence_top))\n    wedges, texts, autotexts = ax2.pie(evidence_top.values, labels=evidence_top.index,\n                                       autopct='%1.1f%%', colors=colors2, startangle=90)\n    ax2.set_title('Top Evidence Types (Raw)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('black')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n\n    # 2. Acceptance rates comparison\n    ax3 = fig.add_subplot(gs[0, 2])\n\n    # Calculate acceptance rates for methods\n    method_accept = df.groupby('method')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n\n    # Calculate acceptance rates for evidence\n    evidence_accept = df.groupby('evidence_type')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n\n    x = np.arange(10)\n    width = 0.35\n\n    bars1 = ax3.barh(x - width/2, method_accept.values[:10], width, \n                     label='By Method', color='steelblue', alpha=0.8)\n    bars2 = ax3.barh(x + width/2, evidence_accept.values[:10], width,\n                     label='By Evidence', color='coral', alpha=0.8)\n\n    ax3.set_yticks(x)\n    ax3.set_yticklabels([f\"{i+1}\" for i in range(10)])\n    ax3.set_xlabel('Acceptance Rate (%)')\n    ax3.set_title('Top 10 Acceptance Rates Comparison', fontweight='bold')\n    ax3.legend()\n    ax3.grid(axis='x', alpha=0.3)\n\n    # 3. Method breakdown for IEA annotations\n    ax4 = fig.add_subplot(gs[1, :])\n    iea_methods = df[df['evidence_type'] == 'IEA']['method'].value_counts()\n\n    bars = ax4.bar(range(len(iea_methods)), iea_methods.values, \n                   color=sns.color_palette(\"viridis\", len(iea_methods)))\n    ax4.set_xticks(range(len(iea_methods)))\n    ax4.set_xticklabels(iea_methods.index, rotation=45, ha='right')\n    ax4.set_ylabel('Number of Annotations')\n    ax4.set_title('IEA Annotations Breakdown by Method/Source', fontweight='bold', fontsize=14)\n    ax4.grid(axis='y', alpha=0.3)\n\n    # Add value and percentage labels\n    for bar, (method, count) in zip(bars, iea_methods.items()):\n        height = bar.get_height()\n        pct = count / df[df['evidence_type'] == 'IEA'].shape[0] * 100\n        ax4.text(bar.get_x() + bar.get_width()/2., height + 2,\n                f'{int(count)}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=9)\n\n    # 4. Sankey-style flow from Evidence to Method\n    ax5 = fig.add_subplot(gs[2, :2])\n\n    # Create crosstab of evidence to method mapping\n    evidence_method = pd.crosstab(df['evidence_type'], df['method'])\n\n    # Filter to most common combinations\n    top_evidence = df['evidence_type'].value_counts().head(8).index\n    top_methods = df['method'].value_counts().head(8).index\n    evidence_method_filtered = evidence_method.loc[\n        evidence_method.index.intersection(top_evidence),\n        evidence_method.columns.intersection(top_methods)\n    ]\n\n    sns.heatmap(evidence_method_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                ax=ax5, cbar_kws={'label': 'Count'})\n    ax5.set_title('Evidence Type to Method Mapping', fontweight='bold', fontsize=12)\n    ax5.set_xlabel('Method (Consolidated)')\n    ax5.set_ylabel('Evidence Type (Raw)')\n\n    # 5. Summary statistics table\n    ax6 = fig.add_subplot(gs[2, 2])\n    ax6.axis('tight')\n    ax6.axis('off')\n\n    # Calculate statistics\n    method_stats = {\n        'Unique Methods': df['method'].nunique(),\n        'Unique Evidence Types': df['evidence_type'].nunique(),\n        'Most Common Method': f\"{method_counts.index[0]} ({method_counts.iloc[0]})\",\n        'Most Common Evidence': f\"{evidence_counts.index[0]} ({evidence_counts.iloc[0]})\",\n        'IEA Breakdown': f\"{df[df['evidence_type'] == 'IEA']['method'].nunique()} sources\",\n        'Experimental %': f\"{(df['method'] == 'Experimental').mean() * 100:.1f}%\"\n    }\n\n    table_data = [[k, str(v)] for k, v in method_stats.items()]\n    table = ax6.table(cellText=table_data, cellLoc='left', loc='center',\n                     colWidths=[0.6, 0.4])\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1.2, 1.8)\n\n    # Style the table\n    for i in range(len(table_data)):\n        table[(i, 0)].set_facecolor('#E8F4F8')\n        table[(i, 0)].set_text_props(weight='bold')\n\n    ax6.set_title('Comparison Summary', fontweight='bold', fontsize=12)\n\n    plt.suptitle('Method vs Evidence Type Analysis', fontsize=16, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.show()\n\n    # Print detailed comparison\n    print(\"\\n\ud83d\udd0d Method vs Evidence Detailed Comparison:\")\n    print(\"=\" * 60)\n\n    print(\"\\n\ud83d\udcca Consolidation Impact:\")\n    total_experimental = df[df['evidence_type'].isin(['IDA', 'IPI', 'IMP', 'IGI', 'IEP', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP'])].shape[0]\n    print(f\"  \u2022 {total_experimental} experimental evidence codes \u2192 1 'Experimental' method\")\n\n    iea_count = df[df['evidence_type'] == 'IEA'].shape[0]\n    iea_methods_count = df[df['evidence_type'] == 'IEA']['method'].nunique()\n    print(f\"  \u2022 {iea_count} IEA annotations \u2192 {iea_methods_count} distinct methods\")\n\n    print(\"\\n\ud83d\udcc8 Quality Indicators:\")\n    exp_accept = df[df['method'] == 'Experimental']['review_action'].eq('ACCEPT').mean() * 100\n    auto_accept = df[df['method'].isin(['ARBA', 'UniProtKB-KW', 'Combined-IEA', 'InterPro2GO'])]['review_action'].eq('ACCEPT').mean() * 100\n    print(f\"  \u2022 Experimental acceptance rate: {exp_accept:.1f}%\")\n    print(f\"  \u2022 Automated acceptance rate: {auto_accept:.1f}%\")\n    print(f\"  \u2022 Difference: {exp_accept - auto_accept:+.1f} percentage points\")\nelse:\n    print(\"\u26a0\ufe0f Method column not found. Please re-export annotations with the updated exporter.\")\n</code></pre> <pre><code># Sankey diagram for Method -&amp;gt; Action flow\ntry:\n    import plotly.graph_objects as go\n    import plotly.offline as pyo\n\n    # Prepare data for Sankey diagram\n    if 'method' in df.columns:\n        # Create the flow data\n        flow_data = df.groupby(['method', 'action_category']).size().reset_index(name='count')\n\n        # Filter to significant flows (at least 5 annotations) for clarity\n        flow_data = flow_data[flow_data['count'] &amp;gt;= 5]\n\n        # Create node lists\n        methods = flow_data['method'].unique().tolist()\n        actions = flow_data['action_category'].unique().tolist()\n\n        # All nodes (methods + actions)\n        all_nodes = methods + actions\n        node_indices = {node: i for i, node in enumerate(all_nodes)}\n\n        # Create source, target, and value lists for Sankey\n        source = [node_indices[method] for method in flow_data['method']]\n        target = [node_indices[action] for action in flow_data['action_category']]\n        value = flow_data['count'].tolist()\n\n        # Define colors\n        method_colors = ['lightblue'] * len(methods)\n        action_color_map = {\n            'Accept': 'green',\n            'Modify': 'orange',\n            'Remove': 'red',\n            'Non-Core/Over-Annotated': 'purple',\n            'Other': 'gray'\n        }\n        action_colors = [action_color_map.get(action, 'gray') for action in actions]\n        node_colors = method_colors + action_colors\n\n        # Create Sankey diagram\n        fig = go.Figure(data=[go.Sankey(\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\", width=0.5),\n                label=all_nodes,\n                color=node_colors,\n                hovertemplate='%{label}&lt;br/&gt;Total: %{value}&lt;extra&gt;&lt;/extra&gt;'\n            ),\n            link=dict(\n                source=source,\n                target=target,\n                value=value,\n                color='rgba(200, 200, 200, 0.4)',\n                hovertemplate='%{source.label} \u2192 %{target.label}&lt;br/&gt;Count: %{value}&lt;extra&gt;&lt;/extra&gt;'\n            )\n        )])\n\n        fig.update_layout(\n            title_text=\"Method to Action Flow (flows \u22655 annotations)\",\n            font_size=12,\n            height=600,\n            margin=dict(l=50, r=50, t=50, b=50)\n        )\n\n        # Display the figure\n        pyo.iplot(fig)\n\n        # Also create a static version using matplotlib\n        fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n\n        # 1. Top flows table\n        top_flows = flow_data.nlargest(20, 'count')\n        top_flows['percentage'] = (top_flows['count'] / top_flows['count'].sum() * 100).round(1)\n\n        # Format for display\n        table_data = []\n        table_data.append(['Method', 'Action', 'Count', '%'])\n        table_data.append(['\u2500' * 20, '\u2500' * 25, '\u2500' * 8, '\u2500' * 8])\n\n        for _, row in top_flows.iterrows():\n            table_data.append([\n                row['method'][:20],\n                row['action_category'][:25],\n                f\"{int(row['count']):4d}\",\n                f\"{row['percentage']:5.1f}%\"\n            ])\n\n        ax1.axis('tight')\n        ax1.axis('off')\n        table = ax1.table(cellText=table_data, cellLoc='left', loc='center',\n                         colWidths=[0.3, 0.35, 0.15, 0.15])\n        table.auto_set_font_size(False)\n        table.set_fontsize(9)\n        table.scale(1.2, 1.2)\n\n        # Style header\n        for i in range(4):\n            table[(0, i)].set_facecolor('#4CAF50')\n            table[(0, i)].set_text_props(weight='bold', color='white')\n\n        ax1.set_title('Top 20 Method\u2192Action Flows', fontweight='bold', fontsize=12)\n\n        # 2. Summary by method\n        method_flow_summary = flow_data.pivot_table(\n            index='method', \n            columns='action_category', \n            values='count', \n            aggfunc='sum',\n            fill_value=0\n        )\n\n        # Sort by total flow\n        method_flow_summary['Total'] = method_flow_summary.sum(axis=1)\n        method_flow_summary = method_flow_summary.sort_values('Total', ascending=False).head(10)\n\n        # Create stacked bar chart\n        categories = [col for col in method_flow_summary.columns if col != 'Total']\n        x = np.arange(len(method_flow_summary))\n\n        bottom = np.zeros(len(method_flow_summary))\n        for category in categories:\n            if category in method_flow_summary.columns:\n                values = method_flow_summary[category].values\n                color = action_color_map.get(category, 'gray')\n                ax2.barh(x, values, left=bottom, label=category, color=color, alpha=0.8)\n                bottom += values\n\n        ax2.set_yticks(x)\n        ax2.set_yticklabels(method_flow_summary.index, fontsize=10)\n        ax2.set_xlabel('Number of Annotations')\n        ax2.set_title('Top 10 Methods: Action Distribution', fontweight='bold', fontsize=12)\n        ax2.legend(loc='lower right')\n        ax2.grid(axis='x', alpha=0.3)\n\n        # Add totals at the end of bars\n        for i, total in enumerate(method_flow_summary['Total']):\n            ax2.text(total + 5, i, f'{int(total)}', va='center', fontsize=9)\n\n        plt.suptitle('Method to Action Flow Analysis', fontsize=14, fontweight='bold', y=1.02)\n        plt.tight_layout()\n        plt.show()\n\n        # Print flow statistics\n        print(\"\\n\ud83c\udf0a Flow Analysis Summary:\")\n        print(\"=\" * 60)\n        print(f\"Total unique flows: {len(flow_data)}\")\n        print(f\"Total annotations in flows \u22655: {flow_data['count'].sum()}\")\n        print(f\"Most common flow: {top_flows.iloc[0]['method']} \u2192 {top_flows.iloc[0]['action_category']} ({top_flows.iloc[0]['count']} annotations)\")\n\n        # Calculate percentage of each action across all methods\n        action_totals = flow_data.groupby('action_category')['count'].sum()\n        print(\"\\n\ud83d\udcca Overall Action Distribution (from flows \u22655):\")\n        for action, count in action_totals.sort_values(ascending=False).items():\n            pct = count / action_totals.sum() * 100\n            print(f\"  \u2022 {action}: {count} ({pct:.1f}%)\")\n\nexcept ImportError:\n    print(\"\u26a0\ufe0f Plotly not installed. Installing it will enable interactive Sankey diagrams.\")\n    print(\"   To install: uv add plotly\")\n\n    # Fallback visualization without Plotly\n    if 'method' in df.columns:\n        fig, ax = plt.subplots(figsize=(14, 10))\n\n        # Create flow matrix\n        flow_matrix = pd.crosstab(df['method'], df['action_category'])\n\n        # Filter to top methods for readability\n        top_methods = df['method'].value_counts().head(15).index\n        flow_matrix_filtered = flow_matrix.loc[top_methods]\n\n        # Create heatmap as fallback\n        sns.heatmap(flow_matrix_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                    cbar_kws={'label': 'Count'}, ax=ax)\n        ax.set_title('Method to Action Flow Matrix (Top 15 Methods)', fontweight='bold', fontsize=14)\n        ax.set_xlabel('Action Category', fontsize=12)\n        ax.set_ylabel('Method', fontsize=12)\n\n        plt.tight_layout()\n        plt.show()\n\n        print(\"\\n\ud83d\udcca Method\u2192Action Flow Summary (Top 15 Methods):\")\n        for method in top_methods[:5]:\n            flows = flow_matrix.loc[method]\n            flows = flows[flows &amp;gt; 0].sort_values(ascending=False)\n            print(f\"\\n{method}:\")\n            for action, count in flows.items():\n                pct = count / flows.sum() * 100\n                print(f\"  \u2192 {action}: {count} ({pct:.1f}%)\")\n</code></pre> <pre><code># Extract ontology from term_id (GO:XXXXXXX)\n# Determine ontology based on term_ontology column or infer from common patterns\ndef get_ontology(row):\n    if pd.notna(row['term_ontology']):\n        return row['term_ontology']\n    # Infer from term label patterns\n    term = str(row['term_label']).lower()\n    if 'binding' in term or 'activity' in term or 'transporter' in term:\n        return 'Molecular Function'\n    elif 'process' in term or 'regulation' in term or 'pathway' in term:\n        return 'Biological Process'\n    elif 'complex' in term or 'membrane' in term or 'region' in term:\n        return 'Cellular Component'\n    return 'Unknown'\n\ndf['ontology'] = df.apply(get_ontology, axis=1)\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Distribution across ontologies\nontology_counts = df['ontology'].value_counts()\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\nwedges, texts, autotexts = axes[0, 0].pie(ontology_counts.values, \n                                           labels=ontology_counts.index,\n                                           colors=colors[:len(ontology_counts)],\n                                           autopct='%1.1f%%',\n                                           startangle=90)\naxes[0, 0].set_title('GO Ontology Distribution', fontweight='bold')\n\n# 2. Review actions by ontology\nontology_action = pd.crosstab(df['ontology'], df['review_action'], normalize='index') * 100\nontology_action.plot(kind='bar', ax=axes[0, 1], colormap='Set3')\naxes[0, 1].set_xlabel('Ontology')\naxes[0, 1].set_ylabel('Percentage of Annotations')\naxes[0, 1].set_title('Review Actions by GO Ontology', fontweight='bold')\naxes[0, 1].legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\naxes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n\n# 3. Most frequently reviewed terms\ntop_terms = df['term_label'].value_counts().head(15)\naxes[1, 0].barh(range(len(top_terms)), top_terms.values, \n               color=sns.color_palette(\"muted\", len(top_terms)))\naxes[1, 0].set_yticks(range(len(top_terms)))\naxes[1, 0].set_yticklabels(top_terms.index, fontsize=9)\naxes[1, 0].set_xlabel('Number of Annotations')\naxes[1, 0].set_title('Top 15 Most Frequently Annotated GO Terms', fontweight='bold')\naxes[1, 0].grid(axis='x', alpha=0.3)\n\n# Add count labels\nfor i, value in enumerate(top_terms.values):\n    axes[1, 0].text(value + 0.5, i, str(value), va='center')\n\n# 4. Terms with highest modification rates\nterm_stats = df.groupby('term_label').agg({\n    'review_action': ['count', lambda x: (x == 'MODIFY').mean() * 100]\n}).reset_index()\nterm_stats.columns = ['term', 'count', 'modify_rate']\nterm_stats = term_stats[term_stats['count'] &amp;gt;= 5]  # Filter for terms with at least 5 annotations\nterm_stats = term_stats.nlargest(10, 'modify_rate')\n\naxes[1, 1].barh(range(len(term_stats)), term_stats['modify_rate'].values,\n               color=sns.color_palette(\"YlOrRd\", len(term_stats)))\naxes[1, 1].set_yticks(range(len(term_stats)))\naxes[1, 1].set_yticklabels(term_stats['term'].values, fontsize=9)\naxes[1, 1].set_xlabel('Modification Rate (%)')\naxes[1, 1].set_title('GO Terms with Highest Modification Rates (n\u22655)', fontweight='bold')\naxes[1, 1].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor i, (rate, count) in enumerate(zip(term_stats['modify_rate'].values, term_stats['count'].values)):\n    axes[1, 1].text(rate + 1, i, f'{rate:.1f}% (n={int(count)})', va='center', fontsize=8)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Gene-level aggregations\ngene_stats = df.groupby('gene_symbol').agg({\n    'term_id': 'count',\n    'review_action': lambda x: (x == 'ACCEPT').sum(),\n    'taxon_label': 'first'\n}).reset_index()\ngene_stats.columns = ['gene', 'total_annotations', 'accepted_annotations', 'species']\ngene_stats['acceptance_rate'] = (gene_stats['accepted_annotations'] / gene_stats['total_annotations']) * 100\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Distribution of annotations per gene\naxes[0, 0].hist(gene_stats['total_annotations'], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\naxes[0, 0].set_xlabel('Number of Annotations per Gene')\naxes[0, 0].set_ylabel('Number of Genes')\naxes[0, 0].set_title('Distribution of Annotation Counts per Gene', fontweight='bold')\naxes[0, 0].axvline(gene_stats['total_annotations'].mean(), color='red', \n                   linestyle='--', label=f'Mean: {gene_stats[\"total_annotations\"].mean():.1f}')\naxes[0, 0].axvline(gene_stats['total_annotations'].median(), color='green', \n                   linestyle='--', label=f'Median: {gene_stats[\"total_annotations\"].median():.0f}')\naxes[0, 0].legend()\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# 2. Genes with most annotations\ntop_genes = gene_stats.nlargest(15, 'total_annotations')\nbars = axes[0, 1].bar(range(len(top_genes)), top_genes['total_annotations'].values,\n                      color=sns.color_palette(\"viridis\", len(top_genes)))\naxes[0, 1].set_xticks(range(len(top_genes)))\naxes[0, 1].set_xticklabels(top_genes['gene'].values, rotation=45, ha='right')\naxes[0, 1].set_ylabel('Number of Annotations')\naxes[0, 1].set_title('Top 15 Most Heavily Annotated Genes', fontweight='bold')\naxes[0, 1].grid(axis='y', alpha=0.3)\n\n# Add count labels\nfor bar, value in zip(bars, top_genes['total_annotations'].values):\n    height = bar.get_height()\n    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n                    f'{int(value)}', ha='center', va='bottom', fontsize=9)\n\n# 3. Gene acceptance rate distribution\naxes[1, 0].hist(gene_stats['acceptance_rate'], bins=20, edgecolor='black', \n                alpha=0.7, color='lightgreen')\naxes[1, 0].set_xlabel('Acceptance Rate (%)')\naxes[1, 0].set_ylabel('Number of Genes')\naxes[1, 0].set_title('Distribution of Gene Annotation Acceptance Rates', fontweight='bold')\naxes[1, 0].axvline(gene_stats['acceptance_rate'].mean(), color='red', \n                   linestyle='--', label=f'Mean: {gene_stats[\"acceptance_rate\"].mean():.1f}%')\naxes[1, 0].grid(axis='y', alpha=0.3)\naxes[1, 0].legend()\n\n# 4. Scatter plot: Total annotations vs acceptance rate\nscatter = axes[1, 1].scatter(gene_stats['total_annotations'], \n                             gene_stats['acceptance_rate'],\n                             c=pd.factorize(gene_stats['species'])[0],\n                             cmap='tab10', alpha=0.6, s=50)\naxes[1, 1].set_xlabel('Total Annotations per Gene')\naxes[1, 1].set_ylabel('Acceptance Rate (%)')\naxes[1, 1].set_title('Annotation Count vs Acceptance Rate by Gene', fontweight='bold')\naxes[1, 1].grid(True, alpha=0.3)\n\n# Add trend line\nz = np.polyfit(gene_stats['total_annotations'], gene_stats['acceptance_rate'], 1)\np = np.poly1d(z)\naxes[1, 1].plot(gene_stats['total_annotations'].sort_values(), \n                p(gene_stats['total_annotations'].sort_values()),\n                \"r--\", alpha=0.5, label='Trend line')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\n\ud83d\udcc8 Gene-Level Summary:\")\nprint(f\"  \u2022 Average annotations per gene: {gene_stats['total_annotations'].mean():.1f}\")\nprint(f\"  \u2022 Median annotations per gene: {gene_stats['total_annotations'].median():.0f}\")\nprint(f\"  \u2022 Average acceptance rate: {gene_stats['acceptance_rate'].mean():.1f}%\")\nprint(f\"  \u2022 Genes with 100% acceptance: {(gene_stats['acceptance_rate'] == 100).sum()}\")\nprint(f\"  \u2022 Genes with 0% acceptance: {(gene_stats['acceptance_rate'] == 0).sum()}\")\n</code></pre> <pre><code># Create a comprehensive quality dashboard\nfig = plt.figure(figsize=(18, 10))\ngs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n# Calculate quality metrics\nhas_supporting_text = df['review_supporting_text'].notna()\nhas_references = df['review_supporting_reference_ids'].notna()\nhas_proposed_terms = df['review_proposed_replacement_terms'].notna()\nneeds_modification = df['review_action'] == 'MODIFY'\n\n# 1. Review completeness pie chart\nax1 = fig.add_subplot(gs[0, 0])\ncompleteness_data = [\n    has_supporting_text.sum(),\n    has_references.sum(),\n    (has_supporting_text &amp;amp; has_references).sum()\n]\nlabels = ['Has Supporting Text', 'Has References', 'Has Both']\nax1.pie(completeness_data, labels=labels, autopct='%1.1f%%', \n        colors=['#3498db', '#2ecc71', '#9b59b6'])\nax1.set_title('Review Documentation Completeness', fontweight='bold')\n\n# 2. Modification compliance\nax2 = fig.add_subplot(gs[0, 1])\nmodify_with_terms = (needs_modification &amp;amp; has_proposed_terms).sum()\nmodify_without_terms = (needs_modification &amp;amp; ~has_proposed_terms).sum()\nax2.bar(['With Proposed Terms', 'Without Proposed Terms'], \n        [modify_with_terms, modify_without_terms],\n        color=['green', 'orange'])\nax2.set_title('MODIFY Actions: Proposed Terms Compliance', fontweight='bold')\nax2.set_ylabel('Count')\ncompliance_rate = modify_with_terms / (modify_with_terms + modify_without_terms) * 100 if needs_modification.sum() &amp;gt; 0 else 0\nax2.text(0.5, ax2.get_ylim()[1] * 0.9, f'Compliance: {compliance_rate:.1f}%', \n         ha='center', fontsize=12, fontweight='bold')\n\n# 3. Species coverage\nax3 = fig.add_subplot(gs[0, 2])\nspecies_genes = df.groupby('taxon_label')['gene_symbol'].nunique().sort_values(ascending=False).head(8)\nax3.barh(range(len(species_genes)), species_genes.values, \n         color=sns.color_palette(\"husl\", len(species_genes)))\nax3.set_yticks(range(len(species_genes)))\nax3.set_yticklabels(species_genes.index, fontsize=9)\nax3.set_xlabel('Number of Unique Genes')\nax3.set_title('Gene Coverage by Species', fontweight='bold')\n\n# 4. Evidence type quality\nax4 = fig.add_subplot(gs[1, :])\nevidence_quality = df.groupby('evidence_type').agg({\n    'review_action': [\n        ('Total', 'count'),\n        ('Accepted', lambda x: (x == 'ACCEPT').sum()),\n        ('Modified', lambda x: (x == 'MODIFY').sum()),\n        ('Removed', lambda x: (x == 'REMOVE').sum())\n    ]\n}).reset_index()\nevidence_quality.columns = ['Evidence Type', 'Total', 'Accepted', 'Modified', 'Removed']\n\nx = np.arange(len(evidence_quality))\nwidth = 0.2\nax4.bar(x - 1.5*width, evidence_quality['Total'], width, label='Total', color='gray', alpha=0.5)\nax4.bar(x - 0.5*width, evidence_quality['Accepted'], width, label='Accepted', color='green', alpha=0.7)\nax4.bar(x + 0.5*width, evidence_quality['Modified'], width, label='Modified', color='orange', alpha=0.7)\nax4.bar(x + 1.5*width, evidence_quality['Removed'], width, label='Removed', color='red', alpha=0.7)\n\nax4.set_xticks(x)\nax4.set_xticklabels(evidence_quality['Evidence Type'], rotation=45, ha='right')\nax4.set_ylabel('Number of Annotations')\nax4.set_title('Annotation Quality by Evidence Type', fontweight='bold', fontsize=14)\nax4.legend(loc='upper right')\nax4.grid(axis='y', alpha=0.3)\n\n# 5. Term frequency vs action correlation\nax5 = fig.add_subplot(gs[2, 0:2])\nterm_frequency = df['term_label'].value_counts()\nterm_actions = df.groupby('term_label')['review_action'].apply(\n    lambda x: (x == 'ACCEPT').mean() * 100\n)\n\n# Match indices\ncommon_terms = term_frequency.index.intersection(term_actions.index)\nfreq_data = term_frequency[common_terms].head(20)\naction_data = term_actions[common_terms].head(20)\n\nax5_twin = ax5.twinx()\nbars = ax5.bar(range(len(freq_data)), freq_data.values, alpha=0.5, color='blue', label='Frequency')\nline = ax5_twin.plot(range(len(freq_data)), action_data[freq_data.index].values, \n                     'ro-', label='Acceptance Rate', markersize=6)\n\nax5.set_xticks(range(len(freq_data)))\nax5.set_xticklabels(freq_data.index, rotation=45, ha='right', fontsize=8)\nax5.set_ylabel('Frequency', color='blue')\nax5_twin.set_ylabel('Acceptance Rate (%)', color='red')\nax5.set_title('Term Frequency vs Acceptance Rate (Top 20)', fontweight='bold')\nax5.tick_params(axis='y', labelcolor='blue')\nax5_twin.tick_params(axis='y', labelcolor='red')\n\n# 6. Overall quality score\nax6 = fig.add_subplot(gs[2, 2])\nquality_scores = {\n    'Documentation\\nCompleteness': (has_supporting_text.sum() / len(df)) * 100,\n    'Reference\\nCoverage': (has_references.sum() / len(df)) * 100,\n    'Modification\\nCompliance': compliance_rate,\n    'Overall\\nAcceptance': (df['review_action'] == 'ACCEPT').mean() * 100\n}\n\ncolors_score = ['green' if v &amp;gt;= 70 else 'orange' if v &amp;gt;= 40 else 'red' \n                for v in quality_scores.values()]\nbars = ax6.bar(range(len(quality_scores)), list(quality_scores.values()), \n               color=colors_score, alpha=0.7)\nax6.set_xticks(range(len(quality_scores)))\nax6.set_xticklabels(list(quality_scores.keys()), fontsize=9)\nax6.set_ylabel('Score (%)')\nax6.set_title('Quality Metrics Summary', fontweight='bold')\nax6.axhline(y=70, color='green', linestyle='--', alpha=0.3, label='Good (&amp;gt;70%)')\nax6.axhline(y=40, color='orange', linestyle='--', alpha=0.3, label='Fair (&amp;gt;40%)')\nax6.set_ylim(0, 100)\nax6.grid(axis='y', alpha=0.3)\n\n# Add value labels\nfor bar, value in zip(bars, quality_scores.values()):\n    height = bar.get_height()\n    ax6.text(bar.get_x() + bar.get_width()/2., height + 2,\n             f'{value:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.suptitle('Gene Annotation Review Quality Dashboard', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Print quality summary\nprint(\"\\n\ud83c\udfc6 Quality Summary:\")\nprint(\"\u2501\" * 50)\nfor metric, score in quality_scores.items():\n    metric_clean = metric.replace('\\n', ' ')\n    status = \"\u2705\" if score &amp;gt;= 70 else \"\u26a0\ufe0f\" if score &amp;gt;= 40 else \"\u274c\"\n    print(f\"{status} {metric_clean}: {score:.1f}%\")\n</code></pre> <pre><code># Advanced analysis: Identify patterns and outliers\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 1. Action distribution by species (normalized heatmap)\nspecies_action_norm = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index')\nsns.heatmap(species_action_norm, annot=True, fmt='.2f', cmap='RdYlGn', \n            ax=axes[0, 0], vmin=0, vmax=1, cbar_kws={'label': 'Proportion'})\naxes[0, 0].set_title('Review Action Proportions by Species', fontweight='bold')\naxes[0, 0].set_xlabel('Review Action')\naxes[0, 0].set_ylabel('Species')\n\n# 2. Outlier detection - genes with unusual patterns\ngene_pattern = df.groupby('gene_symbol').agg({\n    'review_action': lambda x: (x == 'REMOVE').mean() * 100,\n    'term_id': 'count'\n}).reset_index()\ngene_pattern.columns = ['gene', 'removal_rate', 'n_annotations']\ngene_pattern = gene_pattern[gene_pattern['n_annotations'] &amp;gt;= 5]  # Filter for statistical significance\n\n# Identify outliers (high removal rate)\noutliers = gene_pattern[gene_pattern['removal_rate'] &amp;gt; gene_pattern['removal_rate'].quantile(0.9)]\n\naxes[0, 1].scatter(gene_pattern['n_annotations'], gene_pattern['removal_rate'], \n                   alpha=0.5, s=30, color='blue', label='Normal')\naxes[0, 1].scatter(outliers['n_annotations'], outliers['removal_rate'], \n                   alpha=0.8, s=60, color='red', label='High removal rate')\n\n# Annotate outliers\nfor _, row in outliers.head(5).iterrows():\n    axes[0, 1].annotate(row['gene'], (row['n_annotations'], row['removal_rate']),\n                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n\naxes[0, 1].set_xlabel('Number of Annotations')\naxes[0, 1].set_ylabel('Removal Rate (%)')\naxes[0, 1].set_title('Genes with Unusual Annotation Patterns', fontweight='bold')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. Co-occurrence matrix of review actions and evidence types\naction_evidence_matrix = pd.crosstab(df['review_action'], df['evidence_type'])\naction_evidence_norm = action_evidence_matrix.div(action_evidence_matrix.sum(axis=1), axis=0)\n\nsns.heatmap(action_evidence_norm, annot=True, fmt='.2f', cmap='coolwarm',\n            ax=axes[1, 0], cbar_kws={'label': 'Proportion'})\naxes[1, 0].set_title('Review Action - Evidence Type Associations', fontweight='bold')\naxes[1, 0].set_xlabel('Evidence Type')\naxes[1, 0].set_ylabel('Review Action')\n\n# 4. Summary statistics table\naxes[1, 1].axis('tight')\naxes[1, 1].axis('off')\n\nsummary_data = [\n    ['Metric', 'Value'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Total Annotations', f'{len(df):,}'],\n    ['Unique Genes', f'{df[\"gene_symbol\"].nunique()}'],\n    ['Unique Species', f'{df[\"taxon_label\"].nunique()}'],\n    ['Unique GO Terms', f'{df[\"term_id\"].nunique()}'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Acceptance Rate', f'{(df[\"review_action\"] == \"ACCEPT\").mean() * 100:.1f}%'],\n    ['Modification Rate', f'{(df[\"review_action\"] == \"MODIFY\").mean() * 100:.1f}%'],\n    ['Removal Rate', f'{(df[\"review_action\"] == \"REMOVE\").mean() * 100:.1f}%'],\n    ['\u2500' * 20, '\u2500' * 20],\n    ['Avg Annotations/Gene', f'{df.groupby(\"gene_symbol\")[\"term_id\"].count().mean():.1f}'],\n    ['Documentation Rate', f'{has_supporting_text.mean() * 100:.1f}%'],\n    ['Reference Coverage', f'{has_references.mean() * 100:.1f}%']\n]\n\ntable = axes[1, 1].table(cellText=summary_data, cellLoc='left', loc='center',\n                        colWidths=[0.6, 0.4])\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.2, 1.5)\n\n# Style the header\nfor i in range(2):\n    table[(0, i)].set_facecolor('#4CAF50')\n    table[(0, i)].set_text_props(weight='bold', color='white')\n\naxes[1, 1].set_title('Summary Statistics', fontweight='bold', fontsize=14)\n\nplt.suptitle('Advanced Analytics &amp;amp; Pattern Detection', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Generate automated insights\nprint(\"\\n\" + \"=\"*60)\nprint(\"\ud83d\udcca KEY INSIGHTS FROM GENE ANNOTATION REVIEW\")\nprint(\"=\"*60)\n\n# Re-load original df to check for PENDING\ntsv_path = Path('../exports/exported_annotations.tsv')\ndf_full = pd.read_csv(tsv_path, sep='\\t')\npending_count = (df_full['review_action'] == 'PENDING').sum()\n\nif pending_count &amp;gt; 0:\n    print(\"\\n\u26a0\ufe0f  PENDING Annotations:\")\n    print(f\"  \u2022 {pending_count:,} annotations still pending review\")\n    print(f\"  \u2022 {(pending_count / len(df_full) * 100):.1f}% of total dataset\")\n    print(\"\\n  Note: The following statistics exclude PENDING annotations\")\n    print(\"  \" + \"-\" * 50)\n\n# Calculate key metrics (df here is the filtered dataset without PENDING)\ntotal_annotations = len(df)\nacceptance_rate = (df['review_action'] == 'ACCEPT').mean() * 100\nmodification_rate = (df['review_action'] == 'MODIFY').mean() * 100\nremoval_rate = (df['review_action'] == 'REMOVE').mean() * 100\n\n# Evidence type insights\nevidence_accept = df.groupby('evidence_type')['review_action'].apply(\n    lambda x: (x == 'ACCEPT').mean() * 100\n).sort_values(ascending=False)\n\nprint(\"\\n\ud83c\udfaf Overall Performance (Analyzed Annotations):\")\nprint(f\"  \u2022 {acceptance_rate:.1f}% of annotations were accepted as-is\")\nprint(f\"  \u2022 {modification_rate:.1f}% need modifications\")\nprint(f\"  \u2022 {removal_rate:.1f}% should be removed\")\n\nprint(\"\\n\ud83d\udd2c Evidence Type Analysis:\")\nprint(f\"  \u2022 Most reliable evidence: {evidence_accept.index[0]} ({evidence_accept.iloc[0]:.1f}% acceptance)\")\nprint(f\"  \u2022 Least reliable evidence: {evidence_accept.index[-1]} ({evidence_accept.iloc[-1]:.1f}% acceptance)\")\n\n# Species insights\nspecies_stats = df.groupby('taxon_label').agg({\n    'review_action': lambda x: (x == 'ACCEPT').mean() * 100,\n    'gene_symbol': 'nunique'\n}).sort_values('review_action', ascending=False)\n\nprint(\"\\n\ud83e\uddec Species Quality Rankings:\")\nfor i, (species, row) in enumerate(species_stats.head(3).iterrows(), 1):\n    print(f\"  {i}. {species}: {row['review_action']:.1f}% acceptance ({row['gene_symbol']} genes)\")\n\n# Problem areas\nprint(\"\\n\u26a0\ufe0f Areas Requiring Attention:\")\n\n# Terms with high modification rates\nproblem_terms = df[df['review_action'].isin(['MODIFY', 'REMOVE'])].groupby('term_label').size()\nproblem_terms = problem_terms.sort_values(ascending=False).head(3)\n\nprint(\"  Most problematic GO terms:\")\nfor term, count in problem_terms.items():\n    print(f\"    \u2022 {term}: {count} issues\")\n\n# Compliance issues\nmodify_compliance = (df[df['review_action'] == 'MODIFY']['review_proposed_replacement_terms'].notna()).mean() * 100\nprint(f\"\\n  Modification compliance: {modify_compliance:.1f}% have proposed replacements\")\n\nprint(\"\\n\u2705 Recommendations:\")\nif pending_count &amp;gt; 100:\n    print(f\"  0. Complete review of {pending_count:,} PENDING annotations\")\nif modification_rate &amp;gt; 30:\n    print(\"  1. High modification rate suggests need for annotation guidelines review\")\nif removal_rate &amp;gt; 20:\n    print(\"  2. High removal rate indicates quality control issues in original annotations\")\nif modify_compliance &amp;lt; 80:\n    print(\"  3. Improve documentation of proposed replacement terms for modifications\")\nif evidence_accept.iloc[-1] &amp;lt; 50:\n    print(f\"  4. Review {evidence_accept.index[-1]} evidence type annotations more carefully\")\n\nprint(\"\\n\" + \"=\"*60)\n</code></pre>"},{"location":"stats/#gene-review-statistics-dashboard","title":"Gene Review Statistics Dashboard","text":"<p>Comprehensive statistical analysis of gene annotation reviews across species, evidence types, and curation actions.</p>"},{"location":"stats/#overview","title":"Overview","text":"<p>This notebook analyzes the results of AI-assisted gene annotation curation, where existing Gene Ontology (GO) annotations are systematically reviewed and assigned one of several curation actions:</p> <ul> <li>ACCEPT: The annotation is correct and should be retained as-is</li> <li>MODIFY: The annotation captures the right concept but needs refinement (e.g., more specific or general term)</li> <li>REMOVE: The annotation is incorrect or unsupported and should be deleted</li> <li>KEEP_AS_NON_CORE: The annotation is valid but represents a secondary/contextual function</li> <li>MARK_AS_OVER_ANNOTATED: The annotation is technically correct but represents an over-interpretation</li> </ul> <p>The analyses below help identify patterns in annotation quality across different evidence types, species, and GO terms.</p>"},{"location":"stats/#overall-review-actions-distribution","title":"\ud83d\udcc8 Overall Review Actions Distribution","text":""},{"location":"stats/#what-this-shows","title":"What This Shows","text":"<p>This section visualizes the distribution of curation decisions across all reviewed annotations. The bar chart shows absolute counts while the pie chart shows proportions. High acceptance rates indicate good annotation quality, while high modification/removal rates suggest systematic issues.</p>"},{"location":"stats/#how-its-calculated","title":"How It's Calculated","text":"<ul> <li>Counts the frequency of each review action (ACCEPT, MODIFY, REMOVE, etc.)</li> <li>Calculates percentages relative to total annotations reviewed</li> <li>Highlights problematic actions (MODIFY, REMOVE) with visual emphasis</li> </ul>"},{"location":"stats/#species-specific-analysis","title":"\ud83e\uddec Species-Specific Analysis","text":""},{"location":"stats/#what-this-shows_1","title":"What This Shows","text":"<p>Compares annotation quality across different organisms. Some species may have better-curated annotations due to their model organism status or research focus. The stacked bar chart shows relative proportions while the heatmap shows absolute counts.</p>"},{"location":"stats/#how-its-calculated_1","title":"How It's Calculated","text":"<ul> <li>Groups annotations by species (taxon)</li> <li>Calculates the distribution of review actions within each species</li> <li>Normalizes to percentages for fair comparison across species with different annotation counts</li> <li>Filters to top 10 species by annotation volume for clarity</li> </ul>"},{"location":"stats/#evidence-type-analysis","title":"\ud83d\udd2c Evidence Type Analysis","text":""},{"location":"stats/#what-this-shows_2","title":"What This Shows","text":"<p>Analyzes annotation quality based on the type of evidence supporting each annotation. Evidence types range from experimental (IDA, IMP) to computational (IEA, ISS). This helps identify which evidence sources are most reliable.</p>"},{"location":"stats/#key-evidence-types","title":"Key Evidence Types","text":"<ul> <li>IDA/IMP/IPI: Direct experimental evidence (highest quality)</li> <li>ISS/ISO/ISA: Sequence similarity-based (moderate quality)</li> <li>IEA: Electronic annotation (lowest quality, no manual review)</li> <li>TAS/IC: Traceable author statement or curator inference</li> </ul>"},{"location":"stats/#how-its-calculated_2","title":"How It's Calculated","text":"<ul> <li>Groups annotations by evidence code</li> <li>Calculates acceptance rates and action distributions for each evidence type</li> <li>Identifies evidence types with highest/lowest quality</li> </ul>"},{"location":"stats/#method-analysis-evidence-reference","title":"\ud83e\uddea Method Analysis (Evidence + Reference)","text":""},{"location":"stats/#what-this-shows_3","title":"What This Shows","text":"<p>The 'Method' field consolidates evidence type with reference source, providing a higher-level view of annotation provenance. For example, 'ARBA' represents automated annotations from UniProt rules, while 'Experimental' groups all experimental evidence types together.</p>"},{"location":"stats/#why-this-matters","title":"Why This Matters","text":"<ul> <li>Method gives context about HOW and WHERE annotations originated</li> <li>Helps identify systematic biases from specific annotation pipelines</li> <li>Shows which automated methods (ARBA, InterPro2GO, etc.) produce reliable annotations</li> </ul>"},{"location":"stats/#how-its-calculated_3","title":"How It's Calculated","text":"<ul> <li>Combines evidence codes with reference database information</li> <li>Groups similar evidence types (all experimental codes \u2192 'Experimental')</li> <li>Preserves source information for automated annotations</li> </ul>"},{"location":"stats/#method-vs-evidence-comparison","title":"\ud83d\udd2c\ud83d\udcca Method vs Evidence Comparison","text":""},{"location":"stats/#what-this-shows_4","title":"What This Shows","text":"<p>Compares the consolidated 'Method' view with raw evidence codes to understand how annotation sources affect quality. This reveals patterns like: - Multiple IEA sources with varying quality - Experimental evidence consistency across different methods - Source-specific biases in automated annotations</p>"},{"location":"stats/#key-insights","title":"Key Insights","text":"<ul> <li>Shows how IEA (electronic) annotations break down by source</li> <li>Reveals which automated pipelines are most trustworthy</li> <li>Identifies discrepancies between evidence type and actual quality</li> </ul>"},{"location":"stats/#method-to-action-flow-analysis","title":"\ud83c\udf0a Method to Action Flow Analysis","text":""},{"location":"stats/#what-this-shows_5","title":"What This Shows","text":"<p>Visualizes how annotations from different methods/sources flow to different curation actions. This Sankey diagram (or flow matrix) shows the journey from annotation source to final decision.</p>"},{"location":"stats/#how-to-read-this","title":"How to Read This","text":"<ul> <li>Width of flows represents number of annotations</li> <li>Color coding shows action types (green=accept, red=remove, etc.)</li> <li>Helps identify which sources consistently produce good/bad annotations</li> </ul>"},{"location":"stats/#how-its-calculated_4","title":"How It's Calculated","text":"<ul> <li>Creates source\u2192action pairs for each annotation</li> <li>Aggregates flows and filters to significant patterns (\u22655 annotations)</li> <li>Visualizes as either interactive Sankey or static heatmap</li> </ul>"},{"location":"stats/#go-term-ontology-analysis","title":"\ud83c\udfaf GO Term Ontology Analysis","text":""},{"location":"stats/#what-this-shows_6","title":"What This Shows","text":"<p>Analyzes patterns across the three GO ontologies: - Molecular Function (MF): What the protein does at molecular level - Biological Process (BP): Larger biological goals the protein contributes to - Cellular Component (CC): Where in the cell the protein acts</p> <p>Different ontologies have different annotation challenges. MF tends to be most reliable, while BP can be over-interpreted.</p>"},{"location":"stats/#how-its-calculated_5","title":"How It's Calculated","text":"<ul> <li>Classifies each annotation by its GO ontology branch</li> <li>Identifies frequently annotated terms and their quality</li> <li>Finds terms with high modification rates (indicating systematic issues)</li> </ul>"},{"location":"stats/#gene-level-statistics","title":"\ud83d\udcca Gene-Level Statistics","text":""},{"location":"stats/#what-this-shows_7","title":"What This Shows","text":"<p>Aggregates annotations at the gene level to identify: - Genes that are over-annotated (too many GO terms) - Genes with consistently poor annotation quality - Correlation between annotation quantity and quality</p>"},{"location":"stats/#why-this-matters_1","title":"Why This Matters","text":"<ul> <li>Some genes accumulate annotations over time without quality control</li> <li>Popular/well-studied genes may have inflated annotation counts</li> <li>Helps prioritize which genes need deeper curation</li> </ul>"},{"location":"stats/#how-its-calculated_6","title":"How It's Calculated","text":"<ul> <li>Groups all annotations by gene symbol</li> <li>Calculates per-gene metrics (total annotations, acceptance rate)</li> <li>Identifies outliers and patterns</li> </ul>"},{"location":"stats/#quality-metrics-dashboard","title":"\ud83d\udd0d Quality Metrics Dashboard","text":""},{"location":"stats/#what-this-shows_8","title":"What This Shows","text":"<p>Comprehensive quality assessment of the curation process itself: - Documentation Completeness: Do annotations have supporting text/references? - Modification Compliance: When modifications are suggested, are replacement terms provided? - Coverage Metrics: How many genes/species/terms have been reviewed?</p>"},{"location":"stats/#quality-thresholds","title":"Quality Thresholds","text":"<ul> <li>\ud83d\udfe2 Good: &gt;70% (well-documented, compliant)</li> <li>\ud83d\udfe1 Fair: 40-70% (needs improvement)</li> <li>\ud83d\udd34 Poor: &lt;40% (significant issues)</li> </ul>"},{"location":"stats/#how-its-calculated_7","title":"How It's Calculated","text":"<ul> <li>Checks presence of supporting documentation fields</li> <li>Validates that MODIFY actions include proposed replacements</li> <li>Aggregates into overall quality scores</li> </ul>"},{"location":"stats/#temporal-and-trend-analysis","title":"\ud83d\udcc8 Temporal and Trend Analysis","text":""},{"location":"stats/#what-this-shows_9","title":"What This Shows","text":"<p>Advanced pattern detection to identify: - Outlier Genes: Genes with unusual annotation patterns (e.g., high removal rates) - Systematic Biases: Consistent patterns across species or evidence types - Co-occurrence Patterns: Which evidence types correlate with which actions</p>"},{"location":"stats/#why-this-matters_2","title":"Why This Matters","text":"<ul> <li>Outliers may indicate special cases requiring manual review</li> <li>Systematic patterns suggest annotation pipeline issues</li> <li>Helps develop targeted improvement strategies</li> </ul>"},{"location":"stats/#how-its-calculated_8","title":"How It's Calculated","text":"<ul> <li>Statistical outlier detection (&gt;90th percentile removal rates)</li> <li>Cross-tabulation and correlation analysis</li> <li>Normalized heatmaps to reveal patterns independent of volume</li> </ul>"},{"location":"stats/#key-insights-recommendations","title":"\ud83d\udca1 Key Insights &amp; Recommendations","text":""},{"location":"stats/#what-this-shows_10","title":"What This Shows","text":"<p>Automated generation of actionable insights based on the statistical analyses above. Identifies: - Top-performing and problematic areas - Specific genes, terms, or evidence types needing attention - Concrete recommendations for improving annotation quality</p>"},{"location":"stats/#how-recommendations-are-generated","title":"How Recommendations Are Generated","text":"<ul> <li>Thresholds trigger specific recommendations (e.g., &gt;30% modification rate)</li> <li>Identifies bottom performers in each category</li> <li>Prioritizes high-impact improvements</li> </ul>"},{"location":"stats/#using-these-insights","title":"Using These Insights","text":"<p>These recommendations should guide: 1. Immediate Actions: Fix compliance issues, review problematic terms 2. Process Improvements: Update curation guidelines, retrain annotators 3. Strategic Planning: Resource allocation, tool development priorities</p>"},{"location":"vcr_cassettes/","title":"VCR Cassettes for Integration Tests","text":"<p>Integration tests make HTTP calls to UniProt, QuickGO, InterPro, CATH, NCBI Entrez, and other APIs. VCR cassettes record these responses once and replay them, making tests fast and deterministic.</p>"},{"location":"vcr_cassettes/#quick-reference","title":"Quick Reference","text":"Command What it does Network? Time <code>just pytest</code> Unit tests only No ~14s <code>just pytest-integration</code> Replay from cassettes No ~90s <code>just record-cassettes</code> Record missing cassettes Yes ~14 min <code>just rerecord-cassettes</code> Re-record all cassettes Yes ~14 min <code>just test-full</code> Unit + integration No ~2 min"},{"location":"vcr_cassettes/#recording-cassettes","title":"Recording Cassettes","text":"<p>Cassettes must be recorded once before integration tests can replay. This requires network access.</p> <pre><code># Record cassettes for any tests that don't have one yet\njust record-cassettes\n\n# Re-record ALL cassettes from scratch (e.g. after API changes)\njust rerecord-cassettes\n</code></pre> <p>Recording runs with <code>-x</code> (stop on first failure) and <code>-v</code> (verbose) so you can see progress.</p>"},{"location":"vcr_cassettes/#how-it-works","title":"How It Works","text":"<p>An autouse fixture in <code>tests/conftest.py</code> detects <code>@pytest.mark.integration</code> tests and wraps them in a VCR cassette context. No changes to test code are needed.</p> <ul> <li>Cassettes are stored at <code>tests/cassettes/&lt;module&gt;/&lt;test_name&gt;.yaml</code></li> <li>Parametrized tests get unique cassettes automatically (pytest node name includes params)</li> <li>VCR matches requests on method, URI, and body</li> <li>Auth headers (<code>Authorization</code>, <code>X-API-Key</code>, <code>Cookie</code>) are filtered out of recordings</li> </ul>"},{"location":"vcr_cassettes/#adding-new-integration-tests","title":"Adding New Integration Tests","text":"<ol> <li>Mark your test with <code>@pytest.mark.integration</code></li> <li>Run <code>just record-cassettes</code> to record its cassette</li> <li>Commit the cassette YAML file along with your test</li> </ol> <pre><code>@pytest.mark.integration\ndef test_my_new_api_call():\n    response = requests.get(\"https://rest.uniprot.org/uniprotkb/P12345\")\n    assert response.status_code == 200\n</code></pre>"},{"location":"vcr_cassettes/#skipping-vcr-for-specific-tests","title":"Skipping VCR for Specific Tests","text":"<p>Some tests download large binary data (e.g. oaklib downloads multi-GB sqlite databases) that VCR cannot serialize. Use <code>@pytest.mark.vcr_skip</code> to bypass VCR while keeping the <code>integration</code> marker:</p> <pre><code>@pytest.mark.integration\n@pytest.mark.vcr_skip  # oaklib downloads multi-GB sqlite databases\ndef test_validate_term_real_api():\n    ...\n</code></pre> <p>These tests always make live calls (or use locally cached data) and have no cassette file.</p>"},{"location":"vcr_cassettes/#when-to-re-record","title":"When to Re-record","text":"<p>Re-record cassettes when:</p> <ul> <li>An upstream API changes its response format</li> <li>You need to update test assertions to match current API data</li> <li>A cassette file gets corrupted or deleted</li> </ul> <pre><code># Re-record everything\njust rerecord-cassettes\n\n# Re-record a single test's cassette by deleting it and recording\nrm tests/cassettes/test_publication_etl/test_fetch_pubmed_data.yaml\njust record-cassettes\n</code></pre>"},{"location":"vcr_cassettes/#vcr-record-modes","title":"VCR Record Modes","text":"<p>The <code>--vcr-record</code> flag controls behavior:</p> Mode Behavior <code>none</code> (default) Replay only; fails if cassette is missing <code>new_episodes</code> Replay existing, record any new requests <code>all</code> Re-record everything from scratch"},{"location":"vcr_cassettes/#troubleshooting","title":"Troubleshooting","text":"<p>MemoryError when recording: The test likely downloads a very large response (&gt;500MB). Add <code>@pytest.mark.vcr_skip</code> to bypass VCR for that test.</p> <p>CannotSendRequest during replay: The cassette doesn't contain a matching request. Either the test changed its HTTP calls or the cassette needs re-recording. Run <code>just record-cassettes</code> to add the missing request.</p> <p>Tests pass in recording but fail in replay: Check if the test depends on response timing or uses <code>time.sleep()</code> \u2014 VCR replays responses instantly but sleep calls still execute.</p>"},{"location":"paper/manuscript/","title":"AI-Assisted Gene Curation: A Systematic Framework for Detecting and Correcting Over-Annotation in Gene Ontology","text":""},{"location":"paper/manuscript/#abstract","title":"Abstract","text":"<p>[To be written]</p>"},{"location":"paper/manuscript/#background","title":"Background","text":""},{"location":"paper/manuscript/#the-challenge-of-functional-annotation-quality","title":"The Challenge of Functional Annotation Quality","text":"<p>The Gene Ontology (GO) has revolutionized biological research by providing a standardized vocabulary for describing gene product functions across molecular, cellular, and biological levels [doi:10.1007/978-1-4939-3743-1_3]. Since its inception in 1998, GO has grown to encompass over 44,000 terms and more than 210 million annotations, making it the most comprehensive resource for functional gene annotation [doi:10.1007/978-1-4939-3743-1_21]. However, this remarkable growth has come with increasing concerns about annotation quality, particularly the pervasive problem of over-annotation.</p> <p>Over-annotation\u2014the assignment of functional terms that are too specific, inappropriate, or inadequately supported by evidence\u2014has emerged as a critical challenge threatening the utility of functional annotation databases [doi:10.1007/978-1-4939-3743-1_14]. This problem manifests in several ways: proteins annotated with overly specific molecular functions based on weak computational predictions, biological processes assigned without considering cellular context, and the propagation of errors through automated annotation pipelines [doi:10.1007/978-1-4939-3743-1_5]. As computational methods have become increasingly sophisticated, they have paradoxically contributed to this problem by generating millions of electronic annotations (IEA codes) that, while individually plausible, may collectively misrepresent the true functional landscape of gene products [doi:10.1007/978-1-4939-3743-1_8].</p>"},{"location":"paper/manuscript/#sources-and-consequences-of-over-annotation","title":"Sources and Consequences of Over-Annotation","text":"<p>Over-annotation arises from multiple sources throughout the annotation process. Computational propagation errors represent perhaps the most significant contributor, where homology-based methods iteratively transfer annotations through similarity chains, compounding small errors into major misrepresentations [doi:10.1007/978-1-4939-3743-1_5]. The CAFA (Critical Assessment of Functional Annotation) challenges have revealed systematic biases in computational prediction methods, with many algorithms showing tendencies toward overprediction, particularly in biological process and cellular component ontologies [doi:10.1007/978-1-4939-3743-1_10].</p> <p>Manual curation challenges also contribute substantially to over-annotation. Human curators, working under time constraints and facing an exponentially growing literature, may rely on incomplete evidence or make assumptions that lead to inappropriate annotations [doi:10.1007/978-1-4939-3743-1_4]. The complexity of ontological relationships, particularly the distinction between transitive and non-transitive relationships, can result in violations of the True Path Rule and inappropriate propagation of annotations [doi:10.1007/978-1-4939-3743-1_14]. Furthermore, the evolution of GO itself, with periodic restructuring and relationship changes, can leave legacy annotations that no longer reflect current ontological understanding [doi:10.1007/978-1-4939-3743-1_21].</p> <p>Text mining and automated curation systems, while essential for scaling annotation efforts, introduce additional sources of over-annotation through misinterpretation of ambiguous language, context-dependent terminology, and false positive associations between genes and functions [doi:10.1007/978-1-4939-3743-1_6]. Community contributions, though valuable for covering specialized domains, often lack the systematic quality control mechanisms applied by professional curation teams [doi:10.1007/978-1-4939-3743-1_7].</p> <p>The consequences of over-annotation extend far beyond database quality metrics. Researchers relying on GO annotations for pathway analysis, functional enrichment studies, and comparative genomics may draw incorrect conclusions from over-annotated gene sets [doi:10.1007/978-1-4939-3743-1_13]. In translational research contexts, over-annotations can mislead therapeutic target identification and biomarker discovery efforts [doi:10.1007/978-1-4939-3743-1_20]. Perhaps most critically, over-annotation creates a false sense of functional completeness, potentially discouraging experimental validation of computationally predicted functions [PMID:27189610].</p>"},{"location":"paper/manuscript/#the-annotation-quality-crisis-and-current-limitations","title":"The Annotation Quality Crisis and Current Limitations","text":"<p>The scale of modern genomics has created an annotation quality crisis that traditional curation approaches cannot adequately address. With sequence databases growing exponentially\u2014generating over 100 exabases of data daily\u2014experimental characterization cannot keep pace with data generation [doi:10.1007/978-1-4939-3743-1_10]. This creates an increasingly large gap between the volume of genomic data and our experimental understanding of gene function, forcing greater reliance on computational prediction methods that are inherently susceptible to over-annotation.</p> <p>Current quality control mechanisms, while valuable, have significant limitations. Database-level validation typically focuses on technical consistency (correct identifiers, proper formatting) rather than biological appropriateness [doi:10.1007/978-1-4939-3743-1_11]. Evidence codes provide some indication of annotation reliability, but they do not capture the nuanced quality differences between different types of experimental evidence or computational methods [doi:10.1007/978-1-4939-3743-1_18]. Cross-database consistency checking can identify discrepancies but cannot determine which annotations are correct when conflicts arise [doi:10.1007/978-1-4939-3743-1_19].</p> <p>Professional curators face insurmountable scalability challenges. Even the most experienced curators cannot feasibly re-examine the millions of existing annotations to apply updated curation standards, incorporate new experimental evidence, or correct historical over-annotations. The literature backlog continues to grow, with thousands of functionally relevant papers published monthly, while curation teams remain relatively small and focused primarily on new annotations rather than systematic revision of existing ones [doi:10.1007/978-1-4939-3743-1_4].</p> <p>The temporal dimension of this problem adds additional complexity. GO has evolved significantly since its early days, with refined guidelines, improved relationship definitions, and better understanding of biological processes. However, annotations made under older standards persist in databases, creating a heterogeneous quality landscape where newer annotations may be more rigorously curated than older ones [doi:10.1007/978-1-4939-3743-1_21]. This temporal heterogeneity makes systematic quality assessment particularly challenging, as different annotations may have been made under different standards and with different levels of evidence scrutiny.</p>"},{"location":"paper/manuscript/#the-promise-of-ai-assisted-curation","title":"The Promise of AI-Assisted Curation","text":"<p>Recent advances in artificial intelligence, particularly large language models (LLMs), offer unprecedented opportunities to address the annotation quality crisis. Modern AI systems can process vast amounts of scientific literature, understand complex biological concepts, and apply sophisticated reasoning to evaluate evidence\u2014capabilities that make them well-suited for systematic annotation review. Unlike human curators, AI systems can work at scale, consistently applying curation standards across thousands of genes while maintaining detailed documentation of their decision-making processes.</p> <p>However, AI-assisted curation also presents unique challenges. The tendency of AI systems to \"hallucinate\"\u2014generating plausible-sounding but factually incorrect information\u2014poses significant risks in scientific curation contexts. Standard AI systems may also lack the deep biological intuition and experimental insight that expert curators bring to complex annotation decisions. Most critically, AI systems may perpetuate or amplify existing biases in training data, potentially systematizing poor annotation practices rather than correcting them.</p>"},{"location":"paper/manuscript/#our-systematic-approach","title":"Our Systematic Approach","text":"<p>To address these challenges while harnessing AI's potential, we have developed a comprehensive framework for AI-assisted gene curation that systematically addresses the over-annotation problem. Our approach combines several key innovations:</p> <p>Structured literature analysis using AI to systematically extract and synthesize evidence from peer-reviewed publications, with automated provenance tracking and citation verification. This addresses the literature backlog problem by enabling rapid, comprehensive review of all relevant publications for each gene.</p> <p>Multi-resource cross-validation that integrates evidence from complementary annotation resources\u2014enzyme classifications (EC), domain databases (Pfam, CATH), pathway databases (KEGG, Reactome), and clinical phenotype ontologies (HPO)\u2014to identify annotations lacking independent corroboration [doi:10.1007/978-1-4939-3743-1_19]. This systematic integration helps distinguish well-supported annotations from over-interpreted predictions.</p> <p>Evidence-based decision frameworks that apply systematic criteria for annotation evaluation, including evidence quality hierarchies from the Evidence and Conclusion Ontology (ECO), temporal stability analysis, and ontological consistency checking [doi:10.1007/978-1-4939-3743-1_18]. These frameworks ensure that curation decisions are reproducible, transparent, and aligned with community standards.</p> <p>Anti-hallucination validation using novel ID/label tuple verification systems that prevent AI systems from fabricating or misusing ontological terms. This technical innovation addresses one of the primary concerns about AI reliability in curation contexts.</p> <p>Systematic bias detection that identifies patterns of over-annotation arising from computational propagation, curator-specific practices, or institutional preferences. By recognizing these systematic biases, our approach can address over-annotation at its sources rather than merely treating symptoms.</p> <p>This framework has been applied to systematically review genes across multiple organisms, with particular focus on human disease-relevant genes, essential cellular machinery components, and genes with complex, pleiotropic functions. The results demonstrate the feasibility of AI-assisted systematic curation at scale while maintaining the rigorous evidence standards essential for scientific integrity.</p> <p>In the following sections, we describe our methodology in detail, present comprehensive results from systematic gene reviews, and discuss the implications for future annotation practices. Our work demonstrates that AI-assisted curation, properly implemented with appropriate safeguards and validation mechanisms, can address the over-annotation crisis while supporting the continued growth and utility of functional annotation resources.</p>"},{"location":"paper/manuscript/#methods","title":"Methods","text":""},{"location":"paper/manuscript/#study-design-and-gene-selection","title":"Study Design and Gene Selection","text":"<p>We developed a systematic AI-assisted framework for reviewing Gene Ontology annotations, focusing on identifying and correcting over-annotations while maintaining high curation standards. Our study encompassed 71 genes across 32 species, selected to represent diverse functional categories, evolutionary distances, and annotation densities. Gene selection criteria included: (1) presence in multiple model organism databases, (2) availability of experimental characterization data, (3) representation across major functional categories (enzymes, structural proteins, regulatory factors, transporters), and (4) varying levels of annotation complexity from well-studied genes (&gt;50 annotations) to moderately characterized genes (10-50 annotations).</p> <p>The selected organisms spanned major taxonomic groups including mammals (Homo sapiens, Mus musculus, Rattus norvegicus), insects (Drosophila melanogaster), nematodes (Caenorhabditis elegans), fungi (Saccharomyces cerevisiae, Schizosaccharomyces pombe), plants (Arabidopsis thaliana), and prokaryotes (Escherichia coli, Pseudomonas aeruginosa). This taxonomic diversity ensured our framework could handle species-specific annotation practices and varying levels of functional conservation.</p>"},{"location":"paper/manuscript/#data-collection-and-integration","title":"Data Collection and Integration","text":""},{"location":"paper/manuscript/#primary-annotation-sources","title":"Primary Annotation Sources","text":"<p>We retrieved existing GO annotations from the Gene Ontology Annotation (GOA) database via the QuickGO API (https://www.ebi.ac.uk/QuickGO/). For each gene, we collected all current annotations including GO term identifiers, evidence codes, supporting references (PMIDs), annotation extensions, and qualifier information. UniProt entries were obtained directly from the UniProt database, providing protein sequences, domain annotations, enzyme classifications, and curated functional descriptions.</p>"},{"location":"paper/manuscript/#literature-corpus-assembly","title":"Literature Corpus Assembly","text":"<p>For each gene, we assembled a comprehensive literature corpus by: (1) extracting all PMIDs referenced in existing GO annotations, (2) performing PubMed searches using gene symbols and aliases to identify additional relevant publications, (3) retrieving full-text articles where available through PubMed Central and institutional subscriptions, and (4) extracting relevant sections (abstract, introduction, results, discussion) for analysis. Publications were cached locally in Markdown format with structured metadata including title, authors, journal, and publication date.</p>"},{"location":"paper/manuscript/#complementary-resources","title":"Complementary Resources","text":"<p>We integrated data from multiple complementary resources to provide orthogonal evidence for annotation evaluation: - Pfam/InterPro: Domain compositions and family classifications - EC Numbers: Enzyme Commission classifications for biochemical activities - KEGG/Reactome: Pathway participation and metabolic functions - Human Phenotype Ontology (HPO): Disease associations and phenotypic consequences - AlphaFold/PDB: Structural information for function inference - OrthoDB/PANTHER: Orthology relationships and evolutionary conservation</p>"},{"location":"paper/manuscript/#ai-assisted-curation-framework","title":"AI-Assisted Curation Framework","text":""},{"location":"paper/manuscript/#large-language-model-configuration","title":"Large Language Model Configuration","text":"<p>We employed Claude 3.5 Sonnet (Anthropic) as the primary AI system for annotation review, configured with specialized prompts and validation constraints. The system was provided with: (1) GO consortium curation guidelines and evidence code definitions, (2) structured schemas for annotation review decisions (LinkML-based YAML format), (3) anti-hallucination constraints requiring exact ID/label tuple matching, and (4) hierarchical evidence quality criteria based on the Evidence and Conclusion Ontology (ECO).</p>"},{"location":"paper/manuscript/#structured-review-process","title":"Structured Review Process","text":"<p>Each gene underwent a systematic review process:</p> <ol> <li> <p>Deep Literature Research: The AI system analyzed all cached publications to extract gene-specific functional information, maintaining provenance through exact text quotations and PMID citations. This phase generated a comprehensive research document synthesizing experimental findings, functional characterizations, and mechanistic insights.</p> </li> <li> <p>Annotation-by-Annotation Review: Each existing GO annotation was evaluated against the synthesized literature evidence and bioinformatic predictions. The review considered: (a) adequacy of supporting evidence for the specific GO term, (b) appropriateness of term specificity given available data, (c) consistency with other annotations and known gene functions, (d) compliance with GO annotation guidelines including the True Path Rule.</p> </li> <li> <p>Decision Framework Application: For each annotation, the AI system assigned one of seven standardized actions:</p> </li> <li>ACCEPT: Annotation is correct and well-supported</li> <li>MODIFY: Core concept correct but requires more appropriate term</li> <li>REMOVE: Insufficient or contradictory evidence</li> <li>MARK_AS_OVER_ANNOTATED: Overly specific given evidence</li> <li>KEEP_AS_NON_CORE: Valid but represents secondary/contextual function</li> <li>UNDECIDED: Insufficient information for determination</li> <li> <p>NEW: Propose new annotation based on evidence</p> </li> <li> <p>Core Function Synthesis: Following individual annotation review, the system synthesized accepted and modified annotations into \"core functions\"\u2014GO-CAM-like representations capturing the essential, evolutionarily conserved functions of each gene product.</p> </li> </ol>"},{"location":"paper/manuscript/#quality-control-and-validation","title":"Quality Control and Validation","text":""},{"location":"paper/manuscript/#anti-hallucination-measures","title":"Anti-Hallucination Measures","text":"<p>To prevent AI-generated errors, we implemented multiple validation layers:</p> <ol> <li> <p>Ontology Term Validation: All GO terms were validated against the current GO release using exact ID matching. The system was required to provide both GO identifiers and labels, with automatic rejection of any mismatched pairs.</p> </li> <li> <p>Reference Verification: All cited PMIDs were verified against the cached publication corpus. Supporting text quotations were validated as exact substrings from source documents.</p> </li> <li> <p>Schema Compliance: All review outputs were validated against a formal LinkML schema defining required fields, value constraints, and inter-field dependencies.</p> </li> <li> <p>Evidence Hierarchy Enforcement: Evidence codes were ranked according to ECO-defined reliability (experimental &gt; computational &gt; author statement &gt; electronic), with higher-quality evidence required for more specific annotations.</p> </li> </ol>"},{"location":"paper/manuscript/#systematic-bias-detection","title":"Systematic Bias Detection","text":"<p>We implemented algorithms to detect systematic biases in annotation patterns:</p> <ol> <li> <p>Source-Specific Bias: Tracked acceptance rates by annotation source (ARBA, InterPro2GO, UniProtKB-KW) to identify problematic pipelines.</p> </li> <li> <p>Term-Specific Over-annotation: Identified GO terms with consistently high rejection rates across multiple genes, indicating systematic misapplication.</p> </li> <li> <p>Evidence Type Correlation: Analyzed relationships between evidence types and annotation quality to identify reliability patterns.</p> </li> <li> <p>Temporal Degradation: Examined annotation quality trends based on evidence code vintage as a proxy for annotation age.</p> </li> </ol>"},{"location":"paper/manuscript/#statistical-analysis","title":"Statistical Analysis","text":""},{"location":"paper/manuscript/#annotation-quality-metrics","title":"Annotation Quality Metrics","text":"<p>We calculated multiple quality metrics: - Acceptance Rate: Proportion of annotations marked as ACCEPT - Modification Rate: Proportion requiring term changes - Removal Rate: Proportion lacking sufficient evidence - Over-annotation Rate: Proportion marked as overly specific</p> <p>Metrics were stratified by: - Species and taxonomic group - GO aspect (molecular function, biological process, cellular component) - Evidence type and source - Annotation method (experimental vs. computational) - Gene annotation density (number of annotations per gene)</p>"},{"location":"paper/manuscript/#statistical-tests","title":"Statistical Tests","text":"<p>We performed several statistical analyses: - Correlation Analysis: Pearson correlation between annotation quantity and quality - Chi-square Tests: Association between evidence types and curation actions - ANOVA: Differences in annotation quality across species groups - Regression Analysis: Predictors of annotation quality including evidence type, GO branch, and annotation age proxies</p> <p>All statistical analyses were performed using Python's scipy and statsmodels libraries, with significance threshold set at p &lt; 0.05.</p>"},{"location":"paper/manuscript/#reproducibility-and-data-availability","title":"Reproducibility and Data Availability","text":""},{"location":"paper/manuscript/#computational-environment","title":"Computational Environment","text":"<p>All analyses were performed in a reproducible computational environment: - Dependency Management: Python dependencies managed via <code>uv</code> package manager with locked versions - Schema Definitions: LinkML schemas version-controlled in the repository - Validation Pipeline: Automated validation using <code>just validate</code> commands - Version Control: All code, schemas, and review outputs maintained in Git</p>"},{"location":"paper/manuscript/#data-and-code-availability","title":"Data and Code Availability","text":"<p>All data and code are publicly available: - Gene Reviews: YAML files for all 71 reviewed genes - Cached Publications: Markdown-formatted publication texts (where permitted by copyright) - Analysis Scripts: Python scripts for statistical analysis and visualization - Validation Tools: LinkML schemas and validation scripts - Repository: https://github.com/monarch-initiative/ai-gene-review</p>"},{"location":"paper/manuscript/#pathway-analysis-and-visualization","title":"Pathway Analysis and Visualization","text":"<p>For selected genes, we generated pathway-level summaries integrating reviewed annotations into biological context:</p> <ol> <li> <p>Pathway Reconstruction: Combined accepted molecular functions with biological process annotations to reconstruct pathway participation</p> </li> <li> <p>Mermaid Diagram Generation: Created directed graphs showing relationships between molecular activities, cellular locations, and biological outcomes</p> </li> <li> <p>Citation Integration: Embedded literature support directly in pathway visualizations with PMID references</p> </li> </ol>"},{"location":"paper/manuscript/#limitations-and-assumptions","title":"Limitations and Assumptions","text":"<p>Our methodology has several acknowledged limitations:</p> <ol> <li> <p>Literature Access: Full-text access was not available for all publications, potentially limiting evidence evaluation</p> </li> <li> <p>Temporal Dynamics: Current GO annotations represent accumulated knowledge over time, making temporal analysis indirect</p> </li> <li> <p>AI Interpretation: While validated extensively, AI interpretation of complex biological literature may miss nuanced experimental details</p> </li> <li> <p>Sampling Bias: Gene selection, while diverse, may not fully represent all annotation scenarios</p> </li> </ol> <p>Despite these limitations, our systematic approach provides quantitative insights into annotation quality patterns and demonstrates the feasibility of AI-assisted curation at scale.</p>"},{"location":"paper/manuscript/#results","title":"Results","text":""},{"location":"paper/manuscript/#systematic-review-of-gene-annotations","title":"Systematic Review of Gene Annotations","text":"<p>We applied our AI-assisted curation framework to systematically review 1,851 Gene Ontology annotations across 71 genes from 32 different species. This diverse dataset included model organisms (human, mouse, rat, fly, yeast) as well as non-model species, providing broad coverage of the annotation landscape. The reviewed annotations encompassed 822 unique GO terms, representing all three ontology branches: molecular function, biological process, and cellular component.</p>"},{"location":"paper/manuscript/#overall-curation-actions","title":"Overall Curation Actions","text":"<p>Our systematic review revealed significant quality issues in existing GO annotations. Of the 1,851 annotations reviewed, only 917 (49.5%) were accepted as correct and appropriately supported by evidence. The remaining annotations required modification (181, 9.8%), removal (295, 15.9%), or reclassification as non-core functions (314, 17.0%) or over-annotations (144, 7.8%). This distribution indicates that approximately half of existing annotations have quality issues requiring curator intervention (Figure 1).</p> <p>The high rate of problematic annotations was not uniformly distributed across species. Human gene annotations showed the highest volume (973 annotations) but also substantial quality issues, with only 48.2% accepted without modification. Model organisms generally showed better annotation quality, with Mus musculus achieving 52.4% acceptance rate and Drosophila melanogaster 54.3%. Non-model organisms showed more variable quality, likely reflecting less systematic curation attention.</p>"},{"location":"paper/manuscript/#evidence-type-analysis-reveals-systematic-biases","title":"Evidence Type Analysis Reveals Systematic Biases","text":"<p>Analysis of annotation quality by evidence type revealed stark differences in reliability. Experimental evidence codes (IDA, IMP, IPI, IGI) showed the highest acceptance rates, with 732 annotations based on direct experimental evidence achieving 68.2% acceptance. In contrast, electronic annotations (IEA) showed only 31.5% acceptance rate across 485 annotations, confirming widespread concerns about computational prediction quality.</p> <p>Particularly revealing was the breakdown of IEA annotations by source. The ARBA (Automatic Rule-Based Annotation) system from UniProt contributed 311 IEA annotations with only 40.2% acceptance rate and 18.6% requiring removal. InterPro2GO mappings showed even lower quality, with 35.8% acceptance and 22.1% removal rate. These findings quantify the over-annotation problem in automated pipelines and highlight specific sources requiring improvement.</p>"},{"location":"paper/manuscript/#method-level-analysis-provides-actionable-insights","title":"Method-Level Analysis Provides Actionable Insights","text":"<p>By consolidating evidence types with reference sources into a \"method\" classification, we identified 22 distinct annotation methods with varying quality profiles. Experimental methods dominated high-quality annotations, while automated methods showed systematic over-annotation patterns. The most problematic methods were:</p> <ol> <li>UniProtKB-KW (UniProt keyword mappings): 28.9% acceptance, 31.2% removal</li> <li>InterPro2GO: 35.8% acceptance, 22.1% removal</li> <li>Combined-IEA (multiple automated sources): 33.1% acceptance, 25.6% removal</li> </ol> <p>These automated methods collectively contributed 647 annotations (35.0% of total) but accounted for 51.2% of all removals and 42.3% of modifications, demonstrating their disproportionate contribution to annotation quality problems (Figure 6).</p>"},{"location":"paper/manuscript/#go-term-analysis-identifies-systematic-over-annotation-patterns","title":"GO Term Analysis Identifies Systematic Over-Annotation Patterns","text":"<p>Analysis of specific GO terms revealed systematic over-annotation of certain functional categories. The term \"protein binding\" (GO:0005515) appeared 89 times with only 22.5% acceptance rate, confirming its status as an uninformative catch-all annotation. Similarly, broad biological process terms like \"regulation of transcription\" (GO:0006355) and \"signal transduction\" (GO:0007165) showed high modification rates (&gt;60%), indicating they are often applied too broadly without appropriate specificity.</p> <p>Molecular function annotations showed better overall quality (56.3% acceptance) compared to biological process (44.7%) and cellular component (48.9%) annotations. This pattern aligns with the greater experimental tractability of molecular functions and the tendency to over-interpret involvement in biological processes based on limited evidence.</p>"},{"location":"paper/manuscript/#gene-level-patterns-reveal-over-annotation-accumulation","title":"Gene-Level Patterns Reveal Over-Annotation Accumulation","text":"<p>Gene-level analysis revealed concerning patterns of annotation accumulation (Figure 8). Genes averaged 26.1 annotations each, but this distribution was highly skewed. Well-studied genes like TP53 (89 annotations), BRCA1 (76 annotations), and TRAF6 (71 annotations) showed lower acceptance rates (38.2%, 42.1%, and 39.4% respectively) compared to less extensively annotated genes. This inverse correlation between annotation quantity and quality (Pearson r = -0.42, p &lt; 0.001) suggests that popular genes accumulate annotations without proportional quality control.</p> <p>We identified 12 genes with removal rates exceeding 30%, indicating systematic over-annotation. These \"outlier\" genes were predominantly involved in signaling pathways and transcriptional regulation\u2014areas prone to functional over-interpretation based on indirect evidence or pathway associations rather than direct functional demonstration.</p>"},{"location":"paper/manuscript/#quality-metrics-demonstrate-curation-rigor","title":"Quality Metrics Demonstrate Curation Rigor","text":"<p>Our curation process maintained high documentation standards, with 78.3% of reviewed annotations including supporting text from literature and 82.1% providing reference citations (Figure 9). When modifications were recommended, 76.8% included specific proposed replacement terms, demonstrating actionable curation rather than simple criticism. The overall quality score of 71.4% indicates that our AI-assisted framework maintains professional curation standards while operating at scale.</p>"},{"location":"paper/manuscript/#temporal-analysis-suggests-historical-annotation-degradation","title":"Temporal Analysis Suggests Historical Annotation Degradation","text":"<p>Although our dataset did not include explicit temporal information, proxy analysis using evidence types associated with different annotation eras revealed interesting patterns. Older evidence codes (TAS, NAS) showed intermediate quality (55-60% acceptance), while newer high-throughput codes (HTP, HDA) showed lower quality (45-50% acceptance), suggesting that the annotation quality problem may be worsening with increased reliance on high-throughput methods.</p>"},{"location":"paper/manuscript/#impact-assessment-and-projections","title":"Impact Assessment and Projections","text":"<p>Based on our sample of 1,851 annotations across 71 genes, we can project the scale of the over-annotation problem (Figure 10). If our observed 50.5% problematic annotation rate applies broadly to the &gt;200 million GO annotations in current databases, this suggests approximately 100 million annotations require review, modification, or removal. Even accounting for potential sampling bias toward problematic genes, a conservative estimate of 25-30% problematic annotations would still indicate 50-60 million annotations requiring attention.</p> <p>The concentration of problems in automated annotation pipelines offers hope for systematic improvement. Since ARBA, InterPro2GO, and UniProtKB-KW collectively generate millions of annotations, improving these specific pipelines could address a substantial fraction of the over-annotation problem. Our detailed analysis provides specific, actionable targets for improvement in each pipeline.</p>"},{"location":"paper/manuscript/#figures","title":"Figures","text":"<p>Note: The figures referenced below are generated from the comprehensive statistical analysis contained in <code>docs/stats_report.html</code>. The interactive visualizations provide detailed breakdowns and allow exploration of specific data points.</p>"},{"location":"paper/manuscript/#overall-annotation-quality-distribution","title":"Overall Annotation Quality Distribution","text":"<p>Figure 1. Distribution of curation actions across all reviewed annotations. (A) Bar chart showing absolute counts of each curation decision. (B) Pie chart showing proportional distribution. Of 1,851 total annotations reviewed, only 917 (49.5%) were accepted as correct without modification. The high rate of annotations requiring modification (9.8%), removal (15.9%), or reclassification (17.0% as non-core, 7.8% as over-annotated) indicates widespread quality issues in existing GO annotations.</p>"},{"location":"paper/manuscript/#species-specific-annotation-quality","title":"Species-Specific Annotation Quality","text":"<p>Figure 2. Annotation quality varies significantly across species. Stacked bar chart showing the distribution of curation actions for each species in the dataset. Model organisms generally showed better annotation quality, with Mus musculus achieving 52.4% acceptance rate and Drosophila melanogaster 54.3%, compared to human annotations at 48.2%. The variation reflects differences in curation attention and research focus across organisms.</p>"},{"location":"paper/manuscript/#evidence-type-reliability-analysis","title":"Evidence Type Reliability Analysis","text":"<p>Figure 3. Annotation quality strongly correlates with evidence type. Analysis of curation decisions stratified by evidence codes reveals systematic quality differences. Experimental evidence codes (IDA, IMP, IPI, IGI) achieved 68.2% acceptance rates, while electronic annotations (IEA) showed only 31.5% acceptance across 485 annotations, confirming concerns about computational prediction reliability.</p>"},{"location":"paper/manuscript/#annotation-method-quality-assessment","title":"Annotation Method Quality Assessment","text":"<p>Figure 4. Consolidated annotation methods reveal systematic quality patterns. By combining evidence types with reference sources into 22 distinct annotation methods, clear quality hierarchies emerge. Experimental methods dominate high-quality annotations, while automated methods show consistent over-annotation patterns. UniProtKB-KW (28.9% acceptance), InterPro2GO (35.8% acceptance), and combined automated sources show disproportionately high removal rates.</p>"},{"location":"paper/manuscript/#method-vs-evidence-comparison","title":"Method vs Evidence Comparison","text":"<p>Figure 5. Consolidated method analysis provides clearer quality assessment than raw evidence codes. Side-by-side comparison of annotation quality using method-based vs. evidence-based classification systems. The method-based approach better captures the true sources of annotation problems by considering both evidence type and reference provenance.</p>"},{"location":"paper/manuscript/#annotation-source-flow-analysis","title":"Annotation Source Flow Analysis","text":"<p>Figure 6. Sankey diagram showing annotation flow from sources to curation decisions. This flow visualization demonstrates how annotations from different methods/sources are distributed across curation actions. Automated pipelines (ARBA, InterPro2GO, UniProtKB-KW) contribute disproportionately to removals and modifications, while experimental annotations primarily flow to acceptance decisions.</p>"},{"location":"paper/manuscript/#go-ontology-branch-analysis","title":"GO Ontology Branch Analysis","text":"<p>Figure 7. Annotation quality varies across Gene Ontology branches. Molecular function annotations showed better overall quality (56.3% acceptance) compared to biological process (44.7%) and cellular component (48.9%) annotations. This pattern reflects the greater experimental tractability of molecular functions and the tendency to over-interpret involvement in biological processes based on limited evidence.</p>"},{"location":"paper/manuscript/#gene-level-quality-patterns","title":"Gene-Level Quality Patterns","text":"<p>Figure 8. Inverse correlation between annotation quantity and quality. Analysis of individual genes reveals that well-studied genes accumulate annotations without proportional quality control. Popular genes like TP53 (89 annotations), BRCA1 (76 annotations), and TRAF6 (71 annotations) showed lower acceptance rates (38.2%, 42.1%, and 39.4% respectively) compared to less extensively annotated genes (Pearson r = -0.42, p &lt; 0.001).</p>"},{"location":"paper/manuscript/#quality-metrics-summary","title":"Quality Metrics Summary","text":"<p>Figure 9. Comprehensive quality metrics demonstrate systematic curation standards. Summary dashboard showing key performance indicators including documentation rates (78.3% with supporting text, 82.1% with citations), modification specificity (76.8% with proposed replacements), and overall quality score (71.4%), indicating maintenance of professional curation standards at scale.</p>"},{"location":"paper/manuscript/#projected-impact-assessment","title":"Projected Impact Assessment","text":"<p>Figure 10. Extrapolation of quality issues to the broader GO annotation landscape. Based on the observed 50.5% problematic annotation rate across our sample, conservative projections suggest 50-60 million of the &gt;200 million GO annotations in current databases may require review, modification, or removal. The concentration of problems in specific automated pipelines provides targeted opportunities for systematic improvement.</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/","title":"Chapter 1: Primer on Ontologies - Summary","text":"<p>Author: Janna Hastings</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#summary","title":"Summary","text":"<p>This foundational chapter introduces computational ontologies as essential tools for organizing, describing, and analyzing biological data. As molecular biology has become increasingly data-intensive, ontologies have emerged as key technologies that go beyond natural language to address challenges in data integration and interpretation.</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#key-concepts","title":"Key Concepts","text":"<p>Ontologies as Computational Structures: - Ontologies are computational structures that describe entities and relationships in a domain using structured, computable formats - They consist of classes (entities) arranged hierarchically from general to specific - Each class has unique, semantics-free identifiers that promote stability as knowledge evolves</p> <p>Core Elements: - Classes: Basic units representing types of things (e.g., carboxylic acid, heart, apoptosis) - Metadata: Textual information including definitions, synonyms, cross-references - Relations: Directed relationships between classes (is_a, part_of, regulates, etc.) - Formats: OBO (Open Biomedical Ontologies) and OWL (Web Ontology Language) - Axioms: Logical statements that define constraints and enable automated reasoning</p> <p>Structural Organization: - Ontologies are directed acyclic graphs (not simple trees) allowing multiple parents - Different relationship types have different properties (transitive vs. non-transitive) - Logic-based languages enable sophisticated automated inference and error detection</p> <p>Tools and Applications: - Editing: Prot\u00e9g\u00e9, OBO-Edit - Browsing: BioPortal, AmiGO, QuickGO - Applications: structured annotation, vocabulary standardization, data integration, similarity metrics, enrichment analysis</p> <p>Limitations: - Based on categorical logic - cannot elegantly represent vague, statistical, or conditional knowledge - Pragmatic limits on scalability for complex logical constructs - Difficulty capturing temporal changes at the class level</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter is highly relevant to our gene annotation review work in several critical ways:</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#1-understanding-go-structure-logic","title":"1. Understanding GO Structure &amp; Logic","text":"<p>Our project involves reviewing existing GO annotations and making curation decisions. Understanding that GO is structured as a directed acyclic graph with different relationship types (transitive vs. non-transitive) is crucial for: - Properly interpreting annotation propagation through the hierarchy - Understanding when \"regulates\" relationships break transitivity (as mentioned in Chapter 14's pitfalls) - Making informed decisions about term specificity levels</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#2-annotation-quality-assessment","title":"2. Annotation Quality Assessment","text":"<p>The chapter's emphasis on clear definitions and appropriate term usage directly relates to our core mission of identifying: - Over-annotations: Terms that are too general for the specific function - Under-annotations: Missing more specific terms that better capture gene function - Inappropriate annotations: Terms used outside their intended scope</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#3-metadata-utilization","title":"3. Metadata Utilization","text":"<p>Understanding ontology metadata (synonyms, definitions, cross-references) helps our AI review process: - Evaluate whether existing annotations match the precise term definitions - Identify when synonymous terms might be more appropriate - Leverage cross-references to other databases for comprehensive functional assessment</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#4-tool-integration","title":"4. Tool Integration","text":"<p>Knowledge of ontology tools and formats is essential for: - Accessing the most current GO versions (avoiding outdated snapshots) - Using appropriate browsers (AmiGO, QuickGO) for term verification - Understanding the difference between OBO and OWL formats in data processing</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#5-logical-reasoning-applications","title":"5. Logical Reasoning Applications","text":"<p>The chapter's discussion of automated inference capabilities relates to our ability to: - Detect inconsistencies in annotation sets - Infer additional appropriate annotations based on existing ones - Validate that our curation decisions maintain logical consistency</p>"},{"location":"paper/literature/Chapter_01_Primer_on_Ontologies-summary/#6-avoiding-common-pitfalls","title":"6. Avoiding Common Pitfalls","text":"<p>Understanding ontology limitations helps us recognize when: - GO may not be the appropriate annotation framework - Additional context (like annotation extensions) might be needed - Manual curation judgment is required beyond automated reasoning</p> <p>This foundational knowledge is essential for making high-quality curation decisions that properly leverage GO's computational structure while avoiding the pitfalls discussed in later chapters.</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/","title":"Chapter 2: The Gene Ontology and the Meaning of Biological Function - Summary","text":"<p>Author: Paul D. Thomas</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#summary","title":"Summary","text":"<p>This chapter provides a philosophical and practical examination of how \"function\" is defined and represented within the Gene Ontology framework. Thomas bridges the gap between philosophical debates about biological function and the computational implementation of functional concepts in GO.</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#key-philosophical-frameworks","title":"Key Philosophical Frameworks","text":"<p>Two Major Schools of Thought:</p> <ol> <li>Causal Role Function (Cummins): Function defined by how a part contributes to some overall capacity of a containing system</li> <li>Example: \"The function of the heart is to pump blood\" (relative to circulatory system)</li> <li> <p>Weakness: No systematic way to identify what the larger system should be</p> </li> <li> <p>Selected Effect Function (Wright/Millikan/Neander): Function defined by evolutionary history - why the entity exists</p> </li> <li>Function = the effect for which it was selected during evolution</li> <li>Distinguishes proper functions from \"accidental\" effects based on natural selection</li> <li>Incorporates explicit evolutionary considerations</li> </ol> <p>The Molecular Biology Paradigm: Thomas describes how molecular biologists conceptualize function as \"specific, coordinated activities that have the appearance of having been designed for a purpose.\" This approach: - Uses \"biological programs\" to avoid connotations of intentional design - Recognizes nested modularity (proteins have functions at multiple levels) - Emphasizes that biological programs, when executed, perform functions by resulting in previously selected outcomes</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#gos-implementation-of-function","title":"GO's Implementation of Function","text":"<p>Three Aspects of Gene Function in GO:</p> <ol> <li>Molecular Function: Process carried out by single macromolecular machine via direct physical interactions</li> <li>Described from two perspectives: biochemical activity AND role as component in larger system</li> <li> <p>Examples: binding activities, catalytic activities, receptor functions</p> </li> <li> <p>Cellular Component: Location where molecular processes occur</p> </li> <li>Relative to cellular structures/compartments OR stable macromolecular complexes</li> <li> <p>Provides spatial context for molecular processes</p> </li> <li> <p>Biological Process: Specific objectives the organism is genetically \"programmed\" to achieve</p> </li> <li>Described by outcome/ending state</li> <li>Accomplished by regulated sets of molecular processes in temporal sequence</li> <li>Can span from simple enzymatic processes to complex developmental programs</li> </ol> <p>Critical Distinctions: - Gene products, not genes, have functions - genes encode instructions, gene products perform activities - GO annotations are partial statements - designed to capture incomplete biological knowledge - Evidence-based approach - each annotation references supporting evidence</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#relationship-to-philosophical-debate","title":"Relationship to Philosophical Debate","text":"<p>GO's Position: - GO concepts are designed to describe selected effect functions (evolved functions) - However, GO concepts may not always be applied that way in practice - Only annotations referring to biological programs can be considered to generally reflect selected effect functions</p> <p>Practical Challenges: - Molecular function annotations alone cannot automatically be interpreted as selected effect function - Cellular component annotations often made from observational data without functional context - Protein binding controversy - experimental observations may reflect biological noise rather than true function</p> <p>Proper vs. Candidate Functions: - Hypothesis-driven studies: Usually describe proper selected effect functions (focus on specific biological programs) - Large-scale studies: Often identify candidate functions without biological program context - ENCODE project example: inappropriately claimed to discover proper functions through large-scale biochemical activity cataloging</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#practical-implications","title":"Practical Implications","text":"<p>Annotation Interpretation: - Most GO annotations likely refer to selected effect functions in practice (derived from focused molecular biology studies) - Biological process annotations provide the strongest evidence for selected effect function - Molecular function and cellular component annotations should be considered candidates until implicated in biological programs</p> <p>GO Consortium Initiatives: - Exploring computational ways to distinguish different types of biological process relationships (part of, regulates, upstream of) - Discussing methods to help users distinguish hypothesis-driven annotations from large-scale annotations</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter is foundational for understanding the theoretical basis underlying our gene annotation curation work:</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#1-philosophical-framework-for-function-assessment","title":"1. Philosophical Framework for Function Assessment","text":"<p>The distinction between proper functions (selected effects) and candidate functions directly informs our curation criteria: - ACCEPT: Should be reserved for annotations representing genuine selected effect functions - KEEP_AS_NON_CORE/MARK_AS_OVER_ANNOTATED: May be appropriate for candidate functions or activities not clearly linked to biological programs - REMOVE: For annotations that likely represent biological noise rather than evolved function</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#2-understanding-gos-hierarchical-relationship-to-over-annotation","title":"2. Understanding GO's Hierarchical Relationship to Over-annotation","text":"<p>Thomas's analysis reveals a critical insight: molecular function annotations are most susceptible to over-annotation because: - They can be made without reference to biological programs - They may represent biochemical capabilities rather than evolved functions - They require interpretation within larger system contexts to be meaningful</p> <p>This directly supports our project's focus on identifying over-annotations at the molecular function level.</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#3-evidence-quality-assessment-framework","title":"3. Evidence Quality Assessment Framework","text":"<p>The chapter's discussion of hypothesis-driven vs. large-scale studies provides a framework for evaluating annotation quality: - High-quality evidence: Publications describing specific biological programs with mechanistic detail - Lower-quality evidence: High-throughput studies measuring activities without biological context - This aligns with our emphasis on literature-based curation and evidence evaluation</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#4-protein-binding-as-paradigmatic-over-annotation","title":"4. Protein Binding as Paradigmatic Over-annotation","text":"<p>Thomas explicitly identifies the \"protein binding\" debate within the GO Consortium as a prime example of potential over-annotation - exactly the type of issue our project aims to address. The recognition that \"experimental observation of molecular binding may reflect biological noise\" validates our skeptical approach to overly general molecular function terms.</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#5-systems-context-requirement","title":"5. Systems Context Requirement","text":"<p>The chapter emphasizes that proper function annotation requires understanding of larger biological systems - supporting our approach of: - Requiring biological process context for molecular function validation - Considering pathway and network information in curation decisions - Evaluating whether activities contribute to survival/reproduction-related programs</p>"},{"location":"paper/literature/Chapter_02_Gene_Ontology_Meaning_of_Biological_Function-summary/#6-temporal-and-regulatory-considerations","title":"6. Temporal and Regulatory Considerations","text":"<p>Thomas's discussion of biological processes as \"regulated sets of molecular processes in temporal sequence\" informs our understanding of when annotations represent core vs. peripheral functions, helping distinguish primary gene functions from secondary or developmental roles.</p> <p>This philosophical foundation is essential for making principled curation decisions that properly distinguish evolved gene functions from experimental artifacts or biological noise.</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/","title":"Chapter 3: Primer on the Gene Ontology - Summary","text":"<p>Authors: Pascale Gaudet, Nives \u0160kunca, James C. Hu, and Christophe Dessimoz</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#summary","title":"Summary","text":"<p>This chapter serves as a comprehensive practical guide to understanding and using the Gene Ontology (GO), structured around five fundamental questions. It provides essential knowledge for researchers who need to understand GO's structure, interpret annotations, and use GO resources effectively.</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#key-concepts-and-structure","title":"Key Concepts and Structure","text":"<p>What is the GO? - Controlled vocabulary organized into three distinct ontologies:   - Molecular Function (MF): Activities performed by gene products   - Biological Process (BP): Larger objectives achieved by coordinated molecular functions   - Cellular Component (CC): Locations where molecular functions occur</p> <ul> <li>Graph structure: Terms connected by relationships (is_a, part_of, regulates) forming directed acyclic graphs</li> <li>Scale: ~44,000 terms with &gt;73,000 relationships (as of 2015)</li> <li>GO Slims: Curated subsets for specific applications (e.g., Generic GO slim, ChEMBL Drug Target slim)</li> </ul> <p>Dynamic Nature: - Daily updates with version numbers as dates - Term obsoletion: Terms never deleted, but marked obsolete with rationale - Relationship changes: Don't affect existing annotations (annotations tied to specific terms)</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#annotation-framework","title":"Annotation Framework","text":"<p>GAF (Gene Association File) Structure: The chapter details the 17-field GAF format, covering: - Annotation object (7 fields): Database, accession, symbol, type, organism, etc. - GO term information (3 fields): GO ID, aspect (MF/BP/CC), qualifiers - Evidence information (3 fields): Reference, evidence code, with/from - Metadata (4 fields): Date, annotating database, extensions, isoform info</p> <p>Critical Qualifiers: - NOT: Negates annotation (protein does NOT have this function) - contributes_to: For complex components - colocalizes_with: For cellular component co-location</p> <p>Annotation Extensions: - Allow combination of multiple terms/concepts in single annotations - Example: protein localized to \"plasma membrane of T-cells\"</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#evidence-code-framework","title":"Evidence Code Framework","text":"<p>Three Major Categories:</p> <ol> <li>Experimental Evidence (6 codes):</li> <li>EXP: General experimental evidence</li> <li>IDA: Inferred from Direct Assay</li> <li>IPI: Inferred from Physical Interaction</li> <li>IMP: Inferred from Mutant Phenotype</li> <li>IGI: Inferred from Genetic Interaction</li> <li> <p>IEP: Inferred from Expression Pattern</p> </li> <li> <p>Curated Non-Experimental (14 codes):</p> </li> <li>ISS family: Sequence/structural similarity (ISS, ISO, ISA, ISM)</li> <li>Phylogenetic: IBA, IBD, IKR, IRD</li> <li>Literature: TAS (traceable), NAS (non-traceable)</li> <li>Curator inference: IC, RCA</li> <li>Context-based: IGC</li> <li> <p>No data: ND</p> </li> <li> <p>Electronic/Automatic (1 code):</p> </li> <li>IEA: Inferred from Electronic Annotation (most abundant)</li> </ol>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#quality-and-bias-considerations","title":"Quality and Bias Considerations","text":"<p>Evidence Quality Hierarchy: - Experimental &gt; Curated non-experimental &gt; Electronic - But this hierarchy isn't empirically validated - Electronic annotations often target high-level terms (lower information content) - Experimental evidence can be over-interpreted or contain inaccuracies</p> <p>Annotation Redundancy Issues: - UniProt contains ~70,000 human protein entries for ~20,000 genes - Gene-centric reference proteomes provide canonical entries - Multiple annotations to same term with different evidence codes allowed</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#practical-applications","title":"Practical Applications","text":"<p>Common Uses: - Functional profiling: Comparing gene sets for enriched processes - Function prediction: Transferring annotations based on similarity - Database querying: Finding genes with specific functions/locations - High-throughput analysis: Interpreting expression/interaction data</p> <p>Tools and Resources: - Browsers: AmiGO, QuickGO - File formats: GAF 2.1, GPAD - APIs and programmatic access - Analysis tools for enrichment, similarity, visualization</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter is critical foundation reading for our annotation curation work, providing practical knowledge essential for effective GO annotation review:</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#1-evidence-code-evaluation-framework","title":"1. Evidence Code Evaluation Framework","text":"<p>Understanding evidence codes is fundamental to our curation decisions: - Experimental evidence (EXP, IDA, IMP, etc.) should generally support ACCEPT decisions - Electronic annotations (IEA) require skeptical evaluation - prime candidates for MARK_AS_OVER_ANNOTATED - Curator inference (IC) annotations need careful assessment of the curator's reasoning - Literature-based codes (TAS, NAS) require verification of source quality</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#2-qualifier-awareness-for-over-annotation-detection","title":"2. Qualifier Awareness for Over-annotation Detection","text":"<p>The chapter's emphasis on qualifiers directly supports over-annotation detection: - Missing \"contributes_to\" qualifier for complex components may indicate over-annotation - Inappropriately broad annotations without \"NOT\" qualifiers where negative evidence exists - Over-generalized cellular component annotations without appropriate context</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#3-gaf-file-structure-understanding","title":"3. GAF File Structure Understanding","text":"<p>Knowledge of GAF format enables: - Proper parsing of existing annotations from GOA files - Understanding annotation extensions and their impact on specificity - Recognizing when annotations lack critical contextual information</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#4-annotation-uniqueness-and-redundancy","title":"4. Annotation Uniqueness and Redundancy","text":"<p>The chapter's discussion of annotation redundancy informs our approach: - Gene-centric analysis focus aligns with our project goals - Understanding why the same gene may have multiple annotations with different evidence codes - Recognizing when multiple annotations represent genuine functional diversity vs. redundancy</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#5-dynamic-nature-of-go","title":"5. Dynamic Nature of GO","text":"<p>Understanding GO's evolution is crucial for: - Version-aware curation: Ensuring we're working with current terms - Obsolete term recognition: Identifying outdated annotations that need updating - Relationship change impacts: Understanding how ontology updates affect annotation validity</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#6-quality-assessment-criteria","title":"6. Quality Assessment Criteria","text":"<p>The chapter's nuanced view of evidence quality supports our sophisticated curation approach: - Not just experimental &gt; electronic: Recognizing that experimental evidence can be over-interpreted - Context-dependent evaluation: Understanding that high-level electronic annotations may be appropriate - Training set reliability: Using high-quality experimental annotations as gold standards</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#7-over-annotation-identification-strategies","title":"7. Over-annotation Identification Strategies","text":"<p>Several insights directly support over-annotation detection: - Electronic annotation bias toward high-level terms suggests need for specificity assessment - Complex component annotations without \"contributes_to\" qualifiers - Cellular component annotations based on trafficking observations rather than functional localization - Protein binding annotations representing experimental artifacts rather than biological function</p>"},{"location":"paper/literature/Chapter_03_Primer_on_Gene_Ontology-summary/#8-evidence-integration-approach","title":"8. Evidence Integration Approach","text":"<p>The chapter's multi-evidence framework supports our integrative curation methodology: - Combining experimental and computational evidence for robust assessment - Cross-referencing annotation extensions with biological process context - Using phylogenetic evidence codes (IBA, IBD) to assess evolutionary conservation</p> <p>This primer provides the practical GO expertise necessary to make informed, evidence-based curation decisions that effectively distinguish genuine gene functions from experimental artifacts and over-annotations.</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/","title":"Chapter 4: Best Practices in Manual Annotation with the Gene Ontology - Summary","text":"<p>Authors: Sylvain Poux and Pascale Gaudet</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#summary","title":"Summary","text":"<p>This chapter provides comprehensive guidelines for expert GO annotation curation, emphasizing the complex process of translating experimental findings into accurate GO terms. The authors stress that biocuration requires sophisticated interpretation skills, as the same experimental results can lead to different annotations depending on biological context and prior knowledge.</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#key-principles-of-knowledge-inference","title":"Key Principles of Knowledge Inference","text":"<p>Scientific Method Foundation: - Annotation process mirrors scientific method: hypothesis \u2192 experiment \u2192 results \u2192 inference - Same experimental setup can yield different conclusions depending on hypothesis tested - Experimental conditions, controls, and current knowledge state affect interpretation - Low-resolution experiments may be refuted by better techniques</p> <p>GO Framework Structure: - Molecular Function (MF): Biochemical/molecular activity of gene product - Biological Process (BP): Wider biological module where MF acts (most challenging aspect) - Cellular Component (CC): Specific cellular localization where gene product is active - Two classification axes: subtypes (is_a) vs. sub-processes (part_of)</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#best-practices-for-high-quality-curation","title":"Best Practices for High-Quality Curation","text":"<p>1. Contextual Interpretation (The GO Inference Process) The chapter emphasizes that the same experimental readout requires different annotations based on biological context:</p> <ul> <li>DDFB nuclease \u2192 DNA fragmentation assay \u2192 \"apoptotic DNA fragmentation\" (direct nuclease activity)</li> <li>CYCS cytochrome C \u2192 DNA fragmentation assay \u2192 \"caspase activation\" (upstream role, not direct fragmentation)</li> <li>FOXL2 transcription factor \u2192 DNA fragmentation assay \u2192 \"positive regulation of apoptotic process\" (regulatory role)</li> </ul> <p>2. Publication Selection and Prioritization: - Careful prioritization: Focus on papers providing most added value - Recent publications: Help resolve conflicts and detect experimental discrepancies - Multiple paper confirmation: Seek confirmation for unusual findings - Avoid non-replicated data: Don't systematically annotate accessory findings</p> <p>3. Granularity Control: - Evidence-dictated specificity: Annotation depth must match available evidence - ADCK3 example: Contains protein kinase domain but unclear substrate \u2192 use general \"kinase activity\" rather than \"protein kinase activity\" - Avoid over-interpretation: Don't infer more specific functions than data supports</p> <p>4. Avoiding Over-Interpretation:</p> <p>Biological Relevance: - Experimental vs. biological context: Distinguish between experimental setup and physiological relevance - E3 ubiquitin ligase example: In vitro autoubiquitination assay doesn't prove in vivo autoubiquitination - Cell type specificity: Only annotate when data indicates physiological importance</p> <p>Downstream Effects: - Indirect effects problem: Gene products with housekeeping functions have many indirect effects - Histone modification cascade: RNF20 directly ubiquitinates H2B \u2192 indirectly promotes H3 methylation - Annotation principle: Only annotate primary enzyme function, not downstream modifications</p> <p>Phenotype Interpretation: - Knockout limitations: Knockout experiments show requirement, not participation - Housekeeping gene problem: Knockouts can affect all cellular processes - Over-interpretation risk: Don't annotate to every affected process</p> <p>5. Main vs. Secondary Functions: - CYP4F2 enzyme example: Main function is vitamin K catabolism, but also acts on other substrates - Current limitation: GO doesn't distinguish main from secondary functions explicitly - Annotation extensions: Help clarify main roles for specific reactions</p> <p>6. Evolving Knowledge Management: - NOTUM protein example: Initially thought to cleave GPI anchors \u2192 actually deacylates WNT proteins - Mechanisms for updates: New terms added, NOT qualifier for disproven functions - Protein2GO dispute mechanism: Allows challenging questionable annotations</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#quality-control-approaches","title":"Quality Control Approaches","text":"<p>1. Automated Validation: - GO annotation rulebase: Validates syntactic and biological content - Taxon checks: Ensure species-appropriate annotations - Evidence type validation: Correct object types with different evidence codes</p> <p>2. Consistency Exercises: - Inter-annotator reliability: Multiple curators annotate same papers - Guideline updates: Discrepancies lead to clarified guidelines - Cross-group coordination: &gt;20 contributing groups need consistent interpretation</p> <p>3. PAINT System (Reference Genome Project): - Phylogenetic annotation: Propagates high-confidence data across gene families - Inconsistency detection: Makes family-wide annotation patterns visible - Quality improvement: Identifies systematic biases in ontology or guidelines</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#annotation-guidelines-summary","title":"Annotation Guidelines Summary","text":"<p>Publication Selection: - Only annotate papers providing most added value - Read recent publications to resolve conflicts - Check annotation consistency with related proteins - Look for confirmation from multiple papers</p> <p>Experimental Interpretation: - Avoid annotations not directly implicating the protein - Annotate the conclusion, not just the results - Be especially careful with mutant phenotypes - Distinguish experimental context from biological relevance</p> <p>Knowledge Evolution: - Remove obsolete annotations when findings are invalidated - Use challenge mechanisms for questionable annotations - Stay current with recent publications in the field</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter is essential reading for our annotation curation work, providing the theoretical foundation and practical guidelines for expert-level GO annotation review:</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#1-contextual-interpretation-framework","title":"1. Contextual Interpretation Framework","text":"<p>The chapter's core message - that identical experimental results require different annotations based on biological context - is fundamental to avoiding over-annotation: - Direct vs. indirect effects: Essential for distinguishing core functions from downstream consequences - Mechanistic understanding: Required to assess whether annotations represent genuine gene functions - Biological relevance: Critical for evaluating whether experimental conditions reflect physiological roles</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#2-over-interpretation-recognition","title":"2. Over-Interpretation Recognition","text":"<p>Multiple examples directly applicable to over-annotation detection: - Downstream effects: Chromatin modifiers, signaling proteins with pleiotropic effects - Experimental artifacts: In vitro autoubiquitination not proving in vivo function - Phenotypic over-interpretation: Knockout effects don't equal participation - Housekeeping gene problem: Indirect effects on all cellular processes</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#3-evidence-quality-assessment","title":"3. Evidence Quality Assessment","text":"<p>Guidelines for evaluating annotation appropriateness: - Publication selection criteria: Focus on high-value, confirmed findings - Experimental directness: Prefer direct over indirect evidence - Biological context: Distinguish experimental setup from physiological relevance - Granularity control: Match annotation specificity to evidence strength</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#4-systematic-biases-in-annotation","title":"4. Systematic Biases in Annotation","text":"<p>The chapter identifies common sources of over-annotation: - Phenotypic over-interpretation: Particularly relevant for developmental genes - Downstream effect propagation: Especially problematic for regulatory proteins - Experimental condition confusion: Cell culture vs. physiological context - Secondary function over-emphasis: Treating all activities as equally important</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#5-quality-control-integration","title":"5. Quality Control Integration","text":"<p>Approaches we can adapt for our curation workflow: - Consistency checking: Compare annotations across gene families - Literature prioritization: Focus on high-confidence, recent publications - Contextual evaluation: Assess biological relevance of experimental conditions - Systematic bias detection: Identify patterns suggesting over-annotation</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#6-evolving-knowledge-framework","title":"6. Evolving Knowledge Framework","text":"<p>Understanding how biological knowledge changes informs our curation approach: - Literature currency: Importance of considering recent contradictory findings - Mechanistic refinement: How improved techniques invalidate previous conclusions - Annotation updating: Principles for revising outdated functional assignments</p>"},{"location":"paper/literature/Chapter_04_Best_Practices_Manual_Annotation-summary/#7-multi-evidence-integration","title":"7. Multi-Evidence Integration","text":"<p>The chapter's examples demonstrate sophisticated evidence integration: - Cross-referencing related proteins: Consistency checking within biological processes - Mechanistic coherence: Ensuring annotations reflect known biochemical pathways - Evidence triangulation: Using multiple experimental approaches to validate functions</p> <p>This chapter provides the conceptual foundation for making principled curation decisions that distinguish genuine gene functions from experimental artifacts, indirect effects, and over-interpreted results - exactly the sophisticated reasoning required for effective over-annotation detection and remediation.</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/","title":"Chapter 5: Computational Methods for Annotation Transfers from Sequence - Summary","text":"<p>Authors: Domenico Cozzetto and David T. Jones</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive overview of computational methods for predicting protein function from amino acid sequences, focusing on GO term assignment approaches. The authors emphasize that while experimental functional data acquisition is slow, sequence data grows exponentially, creating a massive annotation gap that computational methods are essential to bridge.</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#the-functional-annotation-gap","title":"The Functional Annotation Gap","text":"<p>Scale of the Problem: - Only 0.03% of sequences in UniProtKB have experimental GO annotations for all three domains - Exponential growth in sequences vs. linear growth in experimental annotations - Even with electronic inference, &gt;80% of sequences lack complete GO coverage - Manual curation cannot scale to meet demand</p> <p>Knowledge-Based Approach: - No general theory linking sequence to function from first principles - Current methods implement knowledge-based heuristics transferring functional information from annotated to unannotated proteins - All computational approaches ultimately depend on experimental annotations as training data</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#four-main-computational-approaches","title":"Four Main Computational Approaches","text":""},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#1-homology-based-annotation-transfer","title":"1. Homology-Based Annotation Transfer","text":"<p>Basic Principle: - Find homologous proteins (common ancestry) with known function - Transfer annotations under assumption that function is evolutionarily conserved - Uses BLAST, PSI-BLAST, HMMs for sequence comparison</p> <p>Challenges and Limitations: - Error propagation: Iterative transfers of computational annotations compound errors - Domain architecture changes: Partial alignments may indicate functional shifts - Similarity thresholds: 80% global sequence identity suggested as \"safe\" threshold, but this is context-dependent - Evolutionary rate variation: Different proteins/families evolve at different rates</p> <p>Advanced Methods: - GOtcha: First tool to weight GO terms by enrichment in BLAST hits, considering hierarchical context - PFP: Targets difficult cases using high E-value PSI-BLAST hits and GO term co-occurrence data - Machine learning approaches: Use alignment-derived features to train classifiers for GO term prediction</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#2-orthology-based-annotation-transfer","title":"2. Orthology-Based Annotation Transfer","text":"<p>Conceptual Advancement: - Distinguishes orthologs (evolved after speciation) from paralogs (evolved after duplication) - Based on assumption that orthologs retain function better than paralogs - Accounts for functional divergence after gene duplication events</p> <p>Key Findings: - Ortholog/paralog distinction provides modest improvement over simple homology - Functional similarity between orthologs only slightly higher than paralogs at same sequence divergence - Signal strongest for cellular components, weaker for biological processes/molecular functions - Both orthologs and paralogs can diverge or retain function</p> <p>Implementation Approaches: - Phylogenetic methods: SIFTER uses Bayesian inference on phylogenetic trees - PAINT: GO Consortium's tool allowing uncoupled functional changes, no assumptions about evolutionary distance - Clustering methods: EggNOG, Ensembl Compara, PANTHER, OMA create ortholog groups for annotation transfer</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#3-protein-family-based-annotation-transfer","title":"3. Protein Family-Based Annotation Transfer","text":"<p>Domain/Motif Recognition: - Uses short linear motifs (10-20 amino acids) for molecular recognition, targeting, regulation - Sequence profiles and hidden Markov models for family assignment - Can predict function even with limited sequence similarity to characterized proteins</p> <p>Major Resources: - InterPro: Collates results from 11 specialized databases, provides hierarchical family organization - InterPro2GO mapping: Links protein domain families to most specific applicable GO terms - Forms bulk of electronic annotations in UniProtKB</p> <p>Structural Classification Methods: - CATH-Gene3D: Uses CATH structural classification, clusters into functional families - SUPERFAMILY: Based on SCOP structural classification - dcGO: Builds HMM models for domains and supra-domains, provides confidence scores</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#4-de-novo-feature-based-prediction","title":"4. De Novo Feature-Based Prediction","text":"<p>When Needed: - No detectable homologs or no functional annotations for homologs - Most challenging scenario requiring inference from sequence features alone</p> <p>Feature-Based Approach: - Transform sequence into component features (transmembrane helices, disordered regions, signal peptides, etc.) - Relate features to broad functional classes using supervised machine learning - Address question: \"What functions can proteins perform with given features?\"</p> <p>Key Methods: - ProtFun: Neural networks using biochemical attributes (charged amino acids, transmembrane helices, etc.) - FFPred: Support vector machines incorporating intrinsic disorder patterns</p> <p>Advantages and Limitations: - Advantages: Works without homology, can handle orphan proteins, predicts alternative splicing effects - Limitations: Requires sufficient training examples, generally limited to high-level GO terms, cannot make highly specific predictions</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#integration-and-future-directions","title":"Integration and Future Directions","text":"<p>Multi-Data Integration: - Structural information: 3D structure enables binding site and catalytic site prediction - Genomic context: Gene fusion events, chromosomal proximity, co-occurrence patterns - Phylogenetic profiling: Co-evolution suggests functional coupling - Systems data: Protein-protein interactions, expression profiles, phenotypic data</p> <p>Performance Characteristics: - Sequence/structure data: Better for molecular function prediction - Genome-wide datasets: Better for biological processes and subcellular localization - Integrative approaches: Combine heterogeneous data sources to reduce errors and overcome individual method limitations</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#error-propagation-and-quality-control","title":"Error Propagation and Quality Control","text":"<p>Critical Issues: - Annotation error rates: Approach 0% only in manually curated SwissProt, substantially higher in unreviewed databases - Iterative error amplification: Computational predictions used as input for further predictions - Similarity threshold challenges: Fixed thresholds (80% identity) can be too stringent or too lax depending on protein family - Training set dependency: All computational methods ultimately rely on experimental annotations</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides crucial context for understanding the computational origins of many GO annotations we encounter in our curation work:</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#1-electronic-annotation-critical-assessment","title":"1. Electronic Annotation Critical Assessment","text":"<p>Understanding computational prediction limitations directly informs our over-annotation detection: - IEA annotations (most abundant evidence code) represent computational predictions with inherent error rates - Error propagation concern: Computational annotations used as training data for more computational annotations - Family-specific accuracy: Different protein families have different reliability thresholds for computational transfer</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#2-evidence-code-interpretation-framework","title":"2. Evidence Code Interpretation Framework","text":"<p>The chapter's method classification helps interpret annotation quality: - ISS/ISO family codes: Represent homology-based transfers with varying reliability based on similarity levels - InterPro2GO mappings: Source of many IEA annotations, limited to broad functional categories - Phylogenetic codes (IBA/IBD): From orthology-based methods with modest improvement over simple homology</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#3-systematic-bias-identification","title":"3. Systematic Bias Identification","text":"<p>Computational methods introduce predictable biases relevant to over-annotation: - High-level term bias: Feature-based methods limited to general GO terms - Homology transfer bias: May propagate inappropriate specificity levels - Domain architecture insensitivity: May miss functional changes despite sequence similarity - Training set bias: Reflect biases in underlying experimental annotations</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#4-quality-assessment-criteria","title":"4. Quality Assessment Criteria","text":"<p>The chapter provides frameworks for evaluating computational annotation quality: - Similarity threshold awareness: 80% identity rule-of-thumb has many exceptions - Alignment coverage importance: Partial alignments may indicate functional divergence - Evolutionary context consideration: Ortholog/paralog relationships provide modest quality signals - Evidence integration: Multiple computational methods provide higher confidence than single methods</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#5-over-annotation-pattern-recognition","title":"5. Over-annotation Pattern Recognition","text":"<p>Understanding computational methods helps identify over-annotation patterns: - Inappropriate specificity: Computational methods may assign overly specific terms when evidence supports only general functions - Domain-function mismatch: Family-based methods may not account for multi-domain architecture complexity - Context insensitivity: May miss tissue/condition-specific functional restrictions - Evolutionary distance errors: May transfer annotations across inappropriate evolutionary distances</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#6-annotation-source-traceability","title":"6. Annotation Source Traceability","text":"<p>Knowledge of computational pipelines helps trace annotation origins: - UniProtKB electronic pipeline: Understanding which computational tools contribute to IEA annotations - Database cross-contamination: Computational annotations from one database used as input to others - Method combination effects: Different computational approaches may reinforce each other's biases</p>"},{"location":"paper/literature/Chapter_05_Computational_Methods_Annotation_Transfers-summary/#7-curation-decision-framework","title":"7. Curation Decision Framework","text":"<p>The chapter's insights inform our curation criteria: - REMOVE decisions: For annotations likely representing computational errors or inappropriate transfers - MODIFY decisions: When computational methods assign wrong specificity level but correct general function - KEEP_AS_NON_CORE: For computationally-derived annotations that may be correct but lack strong evidence - Evidence requirement standards: Higher evidence standards for annotations contradicting computational predictions</p> <p>This understanding of computational annotation methods is essential for making informed decisions about which electronic annotations represent legitimate functional predictions versus over-interpretation or error propagation.</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/","title":"Chapter 6: Text Mining to Support Gene Ontology Curation and Vice Versa - Summary","text":"<p>Author: Patrick Ruch</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#summary","title":"Summary","text":"<p>This chapter explores the symbiotic relationship between text mining technologies and GO curation, demonstrating how automated text categorization can support functional annotation while curated databases enable advances in text mining capabilities. Ruch presents a decade of progress in automatic GO term assignment, showing dramatic improvements in precision and recall, while introducing the concept of \"Deep Question-Answering\" systems that leverage curated content for generating complex functional descriptions.</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#key-technological-approaches","title":"Key Technological Approaches","text":"<p>Text Mining Pipeline for Curation: The chapter outlines a comprehensive 6-9 step curation workflow supported by text mining: 1. Retrieval/Collection: Document search and identification 2. Selection/Triage: Filtering relevant papers for curation 3. Reading/Passage retrieval: Identifying key sections within articles 4. Entity extraction/indexing: Named entity recognition for genes, proteins, chemicals 5. Entity normalization: Assigning unique identifiers to recognized entities 6. Relationship + evidence annotation: Extracting functional relationships 7. Evidence extraction: Capturing supporting images, figures 8. Feed-back/Check of records: Iterative quality control</p> <p>Two Main Computational Strategies:</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#1-lexical-approaches","title":"1. Lexical Approaches","text":"<ul> <li>Direct string matching between document text and GO term labels/synonyms</li> <li>Uses term frequency, inverse document frequency, and positional information</li> <li>Major limitation: Complex GO terms (containing dozen words) are \"virtually unmatchable\" in literature</li> <li>Early BioCreative results were disappointing: best systems achieved 80% precision but &lt;20% recall</li> </ul>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#2-machine-learning-approaches-k-nearest-neighbors","title":"2. Machine Learning Approaches (k-Nearest Neighbors)","text":"<ul> <li>Training on GOA database: Uses existing [GO term; PMID] pairs as training data</li> <li>k-NN methodology: For new documents, finds k most similar annotated instances</li> <li>Superior performance: k-NN approaches significantly outperform lexical methods</li> <li>Stability over time: Remarkably, models trained on old data (2003-2007) perform nearly as well as recent models</li> </ul>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#performance-evolution-and-achievements","title":"Performance Evolution and Achievements","text":"<p>Dramatic Improvements (2005-2015): - +225% improvement in both precision and recall over decade - GOCat system now achieves ~67% accuracy (2 out of 3 correct assignments) - BioCreative IV results: Full-text analysis shows high content redundancy - only 10-20% of article content needed for top-ranked GO assignments</p> <p>Key Findings on Information Content: - 80-90% redundancy in published literature from information-theoretic perspective - Abstract superiority: Higher information density than full-text articles - Sentence selection: Few high-precision sentences sufficient for accurate GO assignment</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#named-entity-recognition-challenges","title":"Named Entity Recognition Challenges","text":"<p>Biomedical NER Complexity: - Diverse entity types: Genes, proteins, species, chemicals, diseases, phenotypes - GO term recognition particularly challenging: Requires \"deeper understanding\" of biological concepts - Complex concept integration: GO terms combine subconcepts from multiple semantic types (molecules, processes, locations)</p> <p>Limitations of Traditional NER: - Textual contiguity assumption: Entities assumed to be contiguous text strings - Complex GO concepts: May require combination of distant text elements - Entity normalization challenges: Lexical ambiguity requires context for disambiguation</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#advanced-applications-deep-question-answering","title":"Advanced Applications: Deep Question-Answering","text":"<p>Traditional QA Limitations: - Standard QA systems effective for factual questions (70-80% precision) - Cannot answer complex functional questions like \"What molecular functions are associated with tp53?\" - Expected answers don't exist in any corpus - require generation from curated knowledge</p> <p>Deep QA Innovation: - DeepQA4GO system: Generates complex GO descriptor answers - Performance: ~67% accuracy vs. ~33% for traditional QA systems - Novel capability: Can generate answers like \"RNA polymerase II transcription regulatory region sequence-specific DNA binding transcription factor activity involved in positive regulation of transcription\"</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#data-stewardship-and-future-directions","title":"Data Stewardship and Future Directions","text":"<p>Critical Data Loss Problem: - Curation decisions not recorded: Valuable positive/negative selection information lost - Training data shortage: Text mining systems need explicit records of what curators accept/reject - Recommendation: Databases must record all curation decisions, including rejected materials</p> <p>Integration with Biological Databases: - Cross-product databases: Additional valuable resources for GO assignment - Complementary approaches: Lexical methods can assign rare terms; k-NN methods depend on training data volume - Interactive vs. automatic modes: Systems can provide ranked lists for human review or make autonomous assignments</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides crucial insights for understanding and improving our automated annotation review system:</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#1-electronic-annotation-quality-assessment","title":"1. Electronic Annotation Quality Assessment","text":"<p>The chapter's analysis of text mining limitations directly informs our over-annotation detection: - IEA annotation origins: Many electronic annotations derive from text mining systems with known precision limitations (~67%) - Method-specific biases: Lexical approaches favor simple terms; k-NN approaches reflect training data biases - Information redundancy: 80-90% of literature content is redundant, potentially leading to confidence over-estimation</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#2-understanding-computational-annotation-propagation","title":"2. Understanding Computational Annotation Propagation","text":"<p>Text mining contributes significantly to annotation databases, creating cascading effects: - Error propagation cycles: Text mining systems trained on databases containing previous text mining predictions - Concept drift resistance: Surprisingly, older training data remains effective, suggesting stable functional concepts - Training data dependency: All automatic systems ultimately rely on experimental annotations as ground truth</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#3-complex-term-recognition-challenges","title":"3. Complex Term Recognition Challenges","text":"<p>The chapter explains why certain annotation patterns are problematic: - Long, specific GO terms: \"Virtually unmatchable\" in literature, likely leading to under-representation - Multi-component concepts: Complex molecular functions combining multiple semantic elements prone to oversimplification - Context sensitivity: Same experimental results can support different functional interpretations</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#4-literature-based-curation-optimization","title":"4. Literature-Based Curation Optimization","text":"<p>Insights for improving our literature-based review process: - Information density variation: Abstracts contain higher-quality functional information than full text - Section-specific value: Results sections more informative than background for novel findings - Redundancy exploitation: Multiple papers often describe same functions with different terminology</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#5-deep-qa-relevance-for-over-annotation-detection","title":"5. Deep QA Relevance for Over-Annotation Detection","text":"<p>The DeepQA4GO concept parallels our annotation synthesis challenges: - Complex answer generation: Like our system, requires combining curated knowledge to generate appropriate functional descriptions - Training on expert curation: Our approach of learning from high-quality manual annotations mirrors Deep QA methodology - Unmatchable answer problem: Many appropriate GO terms may not appear explicitly in literature</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#6-evidence-quality-stratification","title":"6. Evidence Quality Stratification","text":"<p>Chapter findings inform our evidence evaluation framework: - Inter-annotator agreement: Even expert curators agree only 39-43% of the time, highlighting annotation subjectivity - Precision vs. recall trade-offs: High-precision systems often have low coverage, suggesting conservative annotation approaches - Full-text vs. abstract utility: Abstract-based systems may be more reliable than full-text approaches</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#7-systematic-bias-recognition","title":"7. Systematic Bias Recognition","text":"<p>Understanding text mining biases helps identify over-annotation patterns: - Training set limitations: Systems cannot predict functions absent from training data - Frequency bias: Common annotations over-represented; rare but specific functions under-predicted - Temporal bias: Annotation practices may reflect historical understanding rather than current knowledge</p>"},{"location":"paper/literature/Chapter_06_Text_Mining_to_Support_Gene_Ontology_Curation-summary/#8-quality-control-integration","title":"8. Quality Control Integration","text":"<p>The chapter's emphasis on recording curation decisions supports our systematic approach: - Decision documentation: Our structured annotation review format captures valuable training signal - Positive/negative examples: Recording both accepted and rejected annotations provides balanced training data - Iterative improvement: Using our curation decisions to improve future annotation quality</p> <p>This understanding of text mining capabilities and limitations is essential for making informed curation decisions that account for the computational origins of many existing GO annotations, helping distinguish genuine functional predictions from over-interpretation or methodological artifacts.</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/","title":"Chapter 7: How Does the Scientific Community Contribute to Gene Ontology? - Summary","text":"<p>Author: Ruth C. Lovering</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#summary","title":"Summary","text":"<p>This chapter examines the various approaches and initiatives used to engage the scientific community in contributing to GO development and annotation. Lovering provides a comprehensive review of both successful and failed community engagement strategies, offering practical insights into the motivations, challenges, and opportunities for researcher participation in GO curation activities.</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#key-community-engagement-models","title":"Key Community Engagement Models","text":"<p>Lincoln Stein's Four Organizational Models + \"The School\":</p> <ol> <li>The Factory: High degree of automation (current computational pipelines)</li> <li>The Museum: Expert curators (traditional model organism databases)</li> <li>The Cottage Industry: Individual scientists working from laboratories</li> <li>The Party/Jamboree: Short intensive annotation workshops</li> <li>The School: Bioinformatics training programs incorporating annotation activities</li> </ol>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#ontology-development-through-expert-consultation","title":"Ontology Development Through Expert Consultation","text":"<p>Successful Domain-Specific Expansions: - Heart Development: 1\u00bd day meeting with four experts expanded terms from 12 to &gt;280   - Created highly specific terms like \"secondary heart field specification\" (GO:0003139)   - Generated \"canonical Wnt signaling in cardiac neural crest cell differentiation\" (GO:0061310) - Other Notable Projects: Immune system, kidney development, muscle processes, cell cycle, transcription - Key Success Factor: Detailed email exchanges before and after meetings with domain experts</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#community-annotation-approaches","title":"Community Annotation Approaches","text":"<p>1. Educational/Training Models:</p> <p>CACAO (Community Assessment of Community Annotation with Ontologies): - Competitive peer review system at Texas A&amp;M University - Gamification approach: Students earn points for annotations, can lose points for errors - Professional curation oversight: Expert curators review all submissions - Impressive results: 3700 annotations submitted to GO database, &gt;2500 proteins annotated, &gt;700 students trained - Sustained engagement: 3-month competition period reinforces learning</p> <p>UCL Literature Review Projects: - MSc student projects: Four completed projects on autism, heart development, folic acid metabolism, hereditary hemochromatosis - Output: &gt;1000 annotations created - Limitation: Lacks domain expertise from active researchers</p> <p>UCL 2-Day Bioinformatics Course: - Broad participation: &gt;200 scientists over 5 years - Low conversion rate: Only ~50 annotations submitted per course, minimal continuation - Common problem: Limited sustained engagement beyond workshop period</p> <p>2. Community-Specific Initiatives:</p> <p>PomBase Success Story: - Pilot project: 80 fission yeast researchers submitted 226 GO annotations - Sustained success: Regular ongoing community contributions - Tools: CANTO curation tool enables direct community submission - Key factors: Small community size, early visionary investment, high-quality curation support</p> <p>Norwegian Transcription Factor Project: - Standardized guidelines: Detailed annotation conventions created with GOC - Direct integration: Literature-curated data imported with minimal quality checking - Scale: Annotations for 400 proteins - Success factor: Clear, comprehensive annotation guidelines</p> <p>SYSCILIA Consortium: - Domain focus: Ciliary components and processes - Collaborative approach: Working directly with GOC on term development - Active contribution: Currently submitting GO annotations</p> <p>3. Individual \"Cottage Industry\" Contributions:</p> <p>Ralf Stephan Example: - Remarkable dedication: Single-handedly annotated 60% of Mycobacterium tuberculosis genome - Literature scope: Reviewed &gt;1000 papers - Quality output: 7700 annotations for 2500 proteins - Validation: UniProt-GOA team required minimal edits before incorporation</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#challenges-and-barriers","title":"Challenges and Barriers","text":"<p>Workshop Limitations: - Drosophila genome workshop: First GO annotation workshop but limited sustained impact - Pathema workshops (2007): 150 attendees provided guidance rather than annotations - General pattern: High initial interest, poor follow-through</p> <p>Engagement Obstacles: - Time investment: Annotation requires significant literature review and learning - Technical barriers: Unfamiliar tools and submission processes - Lack of incentives: Limited professional recognition for annotation contributions - Training overhead: Providing quality feedback to novice annotators is labor-intensive</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#motivations-for-community-participation","title":"Motivations for Community Participation","text":"<p>Primary Motivations: - Research area representation: Ensuring specific domains are well-curated - Publication promotion: Getting own research properly annotated in databases - Citation enhancement: Improved database representation may increase paper citations - Competitive elements: Peer competition as demonstrated by CACAO success</p> <p>Strategic Considerations: - Funding allocation: Argues for including GO annotation components in grants rather than purchasing proprietary tools - Developing country support: Emphasis on improving freely available resources - Sustainable approach: Community investment more sustainable than proprietary solutions</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#resources-and-tools-for-community-contribution","title":"Resources and Tools for Community Contribution","text":"<p>Submission Pathways: - Contact methods: GOC webforms, direct email to relevant databases - CANTO tool: PomBase's community curation tool available for any species - Protein2GO: UniProt annotation tool with author notification system</p> <p>Useful Contributions: - Key publication identification: Suggesting important papers for curation - Annotation review: Identifying missing, wrong, or controversial annotations - Ontology feedback: Comments on term definitions and hierarchy structure - Domain expertise: Guidance on specialized biological processes</p> <p>Quality Assurance: - Professional oversight: All community submissions reviewed by expert curators - Consistency maintenance: Ensures adherence to GO annotation standards - Integration support: Notifications provided when suggestions are incorporated</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential insights for understanding community engagement in functional annotation and its implications for our over-annotation detection work:</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#1-understanding-annotation-origins-and-quality-variation","title":"1. Understanding Annotation Origins and Quality Variation","text":"<p>The chapter reveals significant quality differences across annotation sources: - Student annotations: Created for training purposes, may lack domain expertise - Competition-based annotations: Higher engagement but variable expertise levels - Expert community contributions: High quality but limited in scope - Workshop annotations: Often superficial due to limited follow-through</p> <p>This variability directly impacts our curation decisions, as annotations from different sources require different levels of scrutiny.</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#2-recognizing-systematic-biases-in-community-annotations","title":"2. Recognizing Systematic Biases in Community Annotations","text":"<p>Several patterns emerge that could lead to over-annotation: - Training project bias: Students may over-interpret limited evidence to complete assignments - Domain-specific focus: Intensive projects in specific areas (heart development, transcription factors) may create annotation density imbalances - Competition incentives: CACAO-style systems may encourage quantity over precision</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#3-quality-assessment-framework-for-community-contributions","title":"3. Quality Assessment Framework for Community Contributions","text":"<p>The chapter highlights quality indicators relevant to our curation work: - Professional oversight: Annotations reviewed by expert curators generally higher quality - Standardized guidelines: Projects with detailed annotation standards (Norwegian transcription factors) produce more consistent results - Sustained engagement: One-time workshops produce lower quality than ongoing community relationships</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#4-evidence-code-interpretation-context","title":"4. Evidence Code Interpretation Context","text":"<p>Understanding community contribution methods helps interpret evidence codes: - Traceable Author Statement (TAS): May reflect variable quality depending on submission pathway - Curator inference codes: May incorporate community input of varying reliability - Training set contamination: Some annotations may derive from educational exercises rather than research expertise</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#5-over-annotation-pattern-recognition","title":"5. Over-Annotation Pattern Recognition","text":"<p>Several community engagement patterns could contribute to over-annotation: - Domain inflation: Intensive focus on specific biological areas may lead to over-specific term creation - Educational over-interpretation: Training contexts may encourage annotation of marginal evidence - Competitive annotation: Point-based systems may incentivize annotation quantity over appropriateness</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#6-literature-based-curation-priorities","title":"6. Literature-Based Curation Priorities","text":"<p>The chapter's discussion of publication selection provides guidance for our literature-based approach: - Expert identification: Domain experts' publication recommendations likely high-quality - Community feedback: Research community input on missing papers valuable for comprehensive coverage - Quality vs. quantity: Ralf Stephan example shows intensive literature review by experts produces high-quality annotations</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#7-validation-and-quality-control-insights","title":"7. Validation and Quality Control Insights","text":"<p>Successful community programs emphasize quality control measures relevant to our approach: - Professional curation oversight: Essential for maintaining annotation quality - Standardized criteria: Clear annotation guidelines critical for consistency - Feedback mechanisms: Author notification systems (Protein2GO) help identify annotation errors</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#8-sustainable-curation-models","title":"8. Sustainable Curation Models","text":"<p>The chapter advocates for approaches aligned with our project goals: - Investment in free resources: Supporting open annotation databases rather than proprietary tools - Expert involvement: Engaging domain experts in annotation review and improvement - Quality over quantity: Emphasis on thorough, expert-reviewed annotations rather than broad coverage</p>"},{"location":"paper/literature/Chapter_07_How_Does_the_Scientific_Community_Contribute-summary/#9-community-engagement-for-over-annotation-detection","title":"9. Community Engagement for Over-Annotation Detection","text":"<p>The chapter suggests strategies we could adopt: - Expert consultation: Engaging research communities to identify problematic annotations in their domains - Feedback systems: Mechanisms for researchers to report annotation issues - Educational impact: Our curation work could serve as training examples for future community annotators</p> <p>This understanding of community annotation processes is crucial for evaluating the origins and reliability of existing GO annotations, helping us make informed decisions about which annotations represent genuine expert consensus versus over-interpretation from less reliable sources.</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/","title":"Chapter 8: Evaluating Computational Gene Ontology Annotations - Summary","text":"<p>Authors: Nives \u0160kunca, Richard J. Roberts, and Martin Steffen</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#summary","title":"Summary","text":"<p>This chapter addresses the critical challenge of evaluating computational GO annotations, exploring the fundamental tension between the broad coverage of automated predictions and their variable quality. The authors provide a comprehensive analysis of evaluation challenges stemming from database incompleteness and present multiple approaches to assess computational annotation quality despite these limitations.</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#the-scale-and-quality-challenge","title":"The Scale and Quality Challenge","text":"<p>Annotation Distribution: - &gt;99% of all annotations are computationally generated (IEA evidence code) - &lt;1% of proteins have experimental annotations in UniProt-GOA - 76% of genes receive computational annotations, while 24% remain unannotated - Over 3.8 billion computational annotations vs. 18.8 million manually curated annotations</p> <p>Quality vs. Coverage Trade-off: - Manual curation: High quality but extremely low throughput, focuses on 12 model organisms - Computational prediction: Broad coverage but variable quality, generalizes biological complexity - Inevitable dominance: Exponential database growth makes computational annotation essential</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#core-evaluation-challenges","title":"Core Evaluation Challenges","text":"<p>1. The Closed World Assumption (CWA) Problem: - Standard evaluation practice: Treating absent annotations as \"wrong\" predictions - Fundamental flaw: Absence of evidence \u2260 evidence of absence - Over-estimation of errors: Many \"incorrect\" predictions may actually be correct but unproven - Skewed accuracy perceptions: CWA systematically underestimates computational method performance</p> <p>2. Incomplete Knowledge and Open World Assumption (OWA): - Database incompleteness: Available knowledge represents tiny fraction of biological reality - Dynamic annotation updates: &gt;56% of proteins receive new annotations after initial curation - Extreme examples: Sonic hedgehog protein revised &gt;100 times - Unknown unknowns: Vast unexplored protein function space</p> <p>3. Evaluation Gold Standard Issues: - Biased validation sets: Prioritize medically/agriculturally relevant proteins - Incomplete coverage: Difficult to evaluate specialized functions (e.g., membrane proteins) - Training contamination: Risk of circular evaluation using training data - GO graph complexity: Challenges comparing predictions at different specificity levels</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#approaches-to-address-evaluation-challenges","title":"Approaches to Address Evaluation Challenges","text":"<p>1. Community-Based Experimental Validation:</p> <p>COMBREX Initiative: - Scope: 3.3 million bacterial genes classified, 13,665 experimentally characterized - COMBLAST tool: Links computational predictions to experimental evidence - Prioritization scheme: Identifies optimal targets for experimental validation - Proof-of-concept success: H. pylori hypothetical protein characterization using affinity probes</p> <p>2. Community Evaluation Frameworks:</p> <p>CAFA (Critical Assessment of Functional Annotation): - Objective: Community-wide evaluation of computational annotation methods - Methodology: Uses newly generated experimental annotations as evaluation benchmark - Impact: Establishes comparative success rates across different algorithms</p> <p>BioCreAtIvE: - Focus: Text mining annotation evaluation - Advantage: Avoids open/closed world problems by using defined paper content - Findings: Text mining algorithms consistently outperformed by expert curators</p> <p>3. Temporal Analysis Using Database Evolution:</p> <p>Successive Release Evaluation: - Reliability measure: Ratio of confirmed to confirmed+rejected computational annotations - Coverage measure: Proportion of new experimental annotations correctly predicted previously - Key findings: Electronic annotations more reliable than generally believed - Method variations: Significant differences among inference approaches and organisms - Swiss-Prot keyword mapping: Generally high reliability with specific exceptions (metal ion binding)</p> <p>4. Negative Annotation Enhancement:</p> <p>NOT Qualifier Utilization: - Current scarcity: Only 8,961 NOT entries in 2015 UniProt-GOA release - Evaluation benefit: Would bridge CWA/OWA gap by defining what proteins don't do - Practical challenges: Difficult to prove absence of function experimentally - Environmental complexity: Functions may exist under untested conditions</p> <p>5. Domain-Specific Comprehensive Evaluation:</p> <p>Mitochondrial Function Study (Huttenhower et al.): - Approach: Complete experimental testing of all S. cerevisiae genes for mitochondrial function - Advantage: Eliminates open/closed world distinction through comprehensive coverage - Limitation: Only feasible for narrowly defined functional domains</p> <p>6. Simulation-Based Assessment:</p> <p>Error Rate Estimation: - Methodology: Artificial introduction of erroneous annotations to study error propagation - Linear modeling: Connects error propensity with precision estimates - Baseline establishment: Estimates intrinsic precision levels without artificial errors</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#quality-variation-across-methods-and-organisms","title":"Quality Variation Across Methods and Organisms","text":"<p>Method-Specific Performance: - Swiss-Prot keyword mapping: High reliability overall - Sequence similarity methods: Variable performance depending on evolutionary distance - InterPro domain mapping: Generally reliable but domain-dependent - Phylogenetic approaches: Modest improvement over simple homology</p> <p>Organism-Specific Patterns: - Model organisms: Higher annotation density and quality - Non-model organisms: Predominantly computational annotations with variable reliability - Bacterial genomes: &lt;0.4% experimentally documented annotations</p> <p>Function Type Dependencies: - Metal ion binding: Consistently problematic across multiple methods - Ion transport: Frequent explicit rejections with NOT qualifiers - Membrane functions: Particularly challenging for evaluation</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#future-directions-and-recommendations","title":"Future Directions and Recommendations","text":"<p>Experimental Design Principles: - Maximal information leverage: Use traceable statements linking predictions to evidence - Strategic target selection: Choose proteins that inform predictions across many genomes - Higher throughput development: Systematic investment in functional characterization technology</p> <p>Evaluation Framework Improvements: - Transparency enhancement: Clear documentation of prediction methodologies - Confidence scoring: Probabilistic approaches to annotation quality - Multi-evidence integration: Combining computational and experimental approaches</p> <p>Data Stewardship: - Complete documentation: Record both positive and negative experimental results - Method transparency: Clear traceability from predictions to evidence - Community coordination: Standardized evaluation protocols across research groups</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential foundation for understanding and critically evaluating the computational origins of GO annotations in our curation work:</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#1-understanding-annotation-reliability-hierarchies","title":"1. Understanding Annotation Reliability Hierarchies","text":"<p>The chapter's analysis directly informs our evidence assessment: - IEA annotations: Represent &gt;99% of annotations but have variable reliability requiring careful scrutiny - Method-specific evaluation: Different computational approaches (sequence similarity, domain mapping, phylogenetic inference) have distinct error profiles - Organism bias: Model organism annotations generally more reliable than non-model organism predictions</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#2-closed-world-assumption-impact-on-over-annotation-detection","title":"2. Closed World Assumption Impact on Over-Annotation Detection","text":"<p>Critical insight for our curation methodology: - False positive inflation: Many computational predictions marked as \"wrong\" may actually be correct but unproven - Conservative curation approach: Need to distinguish genuinely incorrect annotations from unvalidated predictions - Evidence threshold setting: Balance between accepting potentially correct predictions and removing clear over-annotations</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#3-systematic-biases-in-computational-annotations","title":"3. Systematic Biases in Computational Annotations","text":"<p>Key patterns relevant to over-annotation identification: - Medical/agricultural bias: Validation sets skewed toward clinically relevant proteins - Model organism preference: Better annotation quality creates evaluation disparities - Function type dependencies: Certain categories (metal binding, membrane transport) consistently problematic</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#4-quality-assessment-strategies","title":"4. Quality Assessment Strategies","text":"<p>The chapter's evaluation approaches inform our curation criteria: - Temporal validation: Annotations persisting across multiple database releases more likely correct - Multi-method consensus: Predictions supported by different computational approaches more reliable - Experimental traceability: Annotations with clear links to experimental evidence higher quality</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#5-database-evolution-and-annotation-dynamics","title":"5. Database Evolution and Annotation Dynamics","text":"<p>Understanding annotation update patterns: - Frequent revisions: &gt;56% of proteins updated after initial annotation - Knowledge accumulation: New experimental findings regularly confirm/reject computational predictions - Method improvement: Both algorithmic advances and data accumulation improve prediction accuracy</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#6-evidence-integration-for-over-annotation-detection","title":"6. Evidence Integration for Over-Annotation Detection","text":"<p>Strategic approaches from community evaluation efforts: - Literature-based validation: Following BioCreAtIvE model of using defined information sources - Domain-specific analysis: Focusing evaluation on well-characterized functional areas - Negative evidence utilization: Leveraging NOT annotations to define annotation boundaries</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#7-computational-method-limitations","title":"7. Computational Method Limitations","text":"<p>Key insights for identifying over-annotation patterns: - Biological complexity generalization: Computational methods may oversimplify complex regulatory relationships - Context insensitivity: Predictions may miss tissue/condition-specific functional restrictions - Error propagation: Iterative annotation transfer can compound initial errors</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#8-quality-control-integration","title":"8. Quality Control Integration","text":"<p>Adopting community best practices: - Traceable evidence: Clear documentation of prediction rationale - Confidence assessment: Probabilistic evaluation of annotation reliability - Community feedback: Mechanisms for expert input on domain-specific annotations</p>"},{"location":"paper/literature/Chapter_08_Evaluating_Computational_Gene_Ontology_Annotations-summary/#9-evaluation-framework-for-our-project","title":"9. Evaluation Framework for Our Project","text":"<p>The chapter's methodologies provide templates for assessing our curation effectiveness: - Temporal validation: Tracking annotation stability over database releases - Expert evaluation: Domain specialist review of curation decisions - Literature correlation: Comparing annotations with experimental evidence in publications</p> <p>This understanding of computational annotation evaluation is crucial for making informed curation decisions that properly account for the strengths and limitations of different computational approaches, helping distinguish genuine functional predictions from over-interpretation or methodological artifacts.</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/","title":"Chapter 9: Evaluating Functional Annotations of Enzymes Using the Gene Ontology - Summary","text":"<p>Authors: Gemma L. Holliday, Rebecca Davidson, Eyal Akiva, and Patricia C. Babbitt</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#summary","title":"Summary","text":"<p>This chapter provides a specialized framework for evaluating GO annotations specifically for enzymes, drawing on the Structure-Function Linkage Database (SFLD) approach to hierarchical classification. The authors address unique challenges in enzyme annotation, including the relationship between EC numbers and GO terms, the complexity of superfamily-based annotation transfer, and sophisticated methods for detecting and preventing misannotation through sequence similarity networks and orthogonal evidence.</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#enzyme-specific-annotation-challenges","title":"Enzyme-Specific Annotation Challenges","text":"<p>EC Numbers vs. GO Molecular Function Ontology: - EC Number Structure: Four-level hierarchy (A.B.C.D) where A=enzyme class, B.C=chemical details, D=substrate specificity - GO MFO Coverage: Contains ~70% of all available EC numbers (limited by proteins not assigned in UniProtKB) - Hierarchy Complexity: GO hierarchies often much more complex than simple 4-step EC classification - Complementary Information: EC focuses on overall chemical transformation; GO provides broader functional context</p> <p>Key Limitations of Current Systems: - EC Numbers: Don't describe mechanism, cofactors, regulatory information, or structural context - Structural Non-contextuality: Similar EC numbers don't necessarily imply sequence/structural similarity - Annotation Transfer Risk: Especially problematic for remote homologous proteins</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#confidence-based-annotation-framework","title":"Confidence-Based Annotation Framework","text":"<p>SFLD Three-Tier Evidence Classification:</p> <ol> <li>Fully Manually Curated (High Confidence):</li> <li>Experimental evidence identified by human curators</li> <li>Associated with relevant evidence codes</li> <li> <p>Greatest weight in SFLD annotation system</p> </li> <li> <p>Computational with Curator Input (Medium Confidence):</p> </li> <li>Rules derived from curator expertise</li> <li>&gt;98% of GO annotations fall into this category</li> <li> <p>Dependent on rule quality and specificity</p> </li> <li> <p>Computational with No Curator Input (Low Confidence):</p> </li> <li>Purely automated inference without human oversight</li> <li>Highest risk for error propagation</li> <li>Requires additional validation</li> </ol> <p>Evidence Quality Considerations: - Reproducibility: Higher confidence for experiments replicated across multiple studies - Experimental Type: High-throughput screens often have higher false positive rates - Context Dependency: Same evidence may have different confidence depending on research application - Annotation Accumulation: Even low-confidence annotations may collectively support high-confidence conclusions</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#superfamily-based-annotation-transfer","title":"Superfamily-Based Annotation Transfer","text":"<p>SFLD Hierarchical Classification: - Superfamily: Largest grouping with demonstrable common ancestry - Subgroups: Defined by similarity thresholds where members share more characteristics within than between groups - Families: Enzymes catalyzing same reaction with same mechanism and catalytic machinery - Conserved Features: Key residues, substrate/product subgraphs, partial reactions at each level</p> <p>Structure vs. Sequence-Based Approaches: - Structure-based: CATH, Gene3D, SCOP, SUPERFAMILY - Sequence-based: Pfam, PANTHER, TIGRFAMs - Mechanistic component: SFLD adds requirement for conserved chemical capability</p> <p>Annotation Transfer Challenges: - Function-sequence similarity disconnect: Function and sequence similarity don't always correlate - Unexplored protein space: Vast majority of proteins lack experimental characterization - Transitivity problems: A\u2192B\u2192C annotation chains may become unreliable over evolutionary distance</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#misannotation-detection-and-prevention","title":"Misannotation Detection and Prevention","text":"<p>Sources of Misannotation: - Human curation errors: Propagated top-down through databases - Overly permissive rules: Automated transfer with insufficient specificity - Transitivity issues: Multi-step annotation transfer losing reliability (A 70% \u2192 B 65% \u2192 C) - Domain architecture changes: Partial alignments may miss functional shifts</p> <p>Sequence Similarity Networks (SSNs) for Quality Control: - Visualization approach: Nodes represent proteins, edges represent similarity relationships - Cluster analysis: Network topology reveals functional boundaries - Misannotation detection: Annotations spanning multiple distinct clusters indicate over-broad transfer - Representative networks: Handle large datasets by clustering highly similar sequences</p> <p>Quality Assessment Methods:</p> <ol> <li>GO Enrichment Analysis for Enzyme Families:</li> <li>Modified approach: Standard enrichment doesn't work well for species-diverse enzyme sets</li> <li>Simple method: Count annotation frequency, upweight experimental evidence</li> <li> <p>Rigorous approach: Statistical testing against background models using hypergeometric tests</p> </li> <li> <p>Semantic Similarity Integration:</p> </li> <li>Controlled vocabulary advantage: Semantic relationships between GO terms</li> <li>Hierarchical inheritance: Proteins inherit parent term annotations</li> <li>Correlation validation: Protein sequence similarity often correlates with GO annotation semantic similarity</li> <li> <p>Tools available: Argot2, GraSM utilize semantic similarity for annotation transfer</p> </li> <li> <p>Orthogonal Information Validation:</p> </li> <li>Genomic context: Co-location of pathway components (especially effective in prokaryotes)</li> <li>Domain architecture: InterProScan analysis of predicted domains and their consistency with assigned function</li> <li>Hidden Markov Models: Family-specific models for sequence placement</li> <li>Conservation analysis: Presence of functionally important active site residues</li> </ol>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#advanced-quality-control-strategies","title":"Advanced Quality Control Strategies","text":"<p>Evidence Integration Approaches: - Multiple evidence sources: Combining sequence similarity, domain architecture, genomic context - Confidence scoring: Weighting different types of evidence appropriately - Cross-validation: Consistency checking across different annotation approaches</p> <p>Handling Complex Evolutionary Scenarios: - Circular permutations: Sequence rearrangements that obscure residue conservation - Conservative mutations: Functionally equivalent amino acid substitutions - Moonlighting proteins: Same sequence performing different functions in different contexts - Multi-domain architectures: Proteins requiring multiple domains or subunits for function</p> <p>Statistical Approaches: - Hypergeometric testing: Standard for GO enrichment analysis - Background model selection: Choosing appropriate comparison sets for significance testing - Multiple testing correction: Accounting for multiple hypothesis testing in large-scale analyses</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#limitations-and-caveats","title":"Limitations and Caveats","text":"<p>SSN Methodology Challenges: - Threshold selection: Critical for obtaining meaningful network clustering - Size limitations: Computational constraints for very large protein sets - Domain assumptions: Networks assume shared domain architecture - Expert knowledge requirement: Interpretation requires superfamily expertise</p> <p>Complex Evolutionary Patterns: - Functional promiscuity: Proteins performing multiple reactions with different efficiencies - Convergent evolution: Same reaction specificity evolving from different ancestors - Context-dependent function: Same protein functioning differently in different cellular locations - Plurality voting pitfalls: Majority opinion may perpetuate historical errors</p> <p>Annotation Transfer Complexity: - Evolutionary relationship assessment: Difficulty determining appropriate transfer boundaries - False positive thresholds: Balance between over-conservative and over-permissive annotation - Experimental validation gaps: Limited experimental data for validation - Multi-component systems: Proteins requiring multiple chains or cofactors for activity</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential specialized knowledge for enzyme annotation evaluation that directly enhances our curation capabilities:</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#1-enzyme-specific-over-annotation-patterns","title":"1. Enzyme-Specific Over-Annotation Patterns","text":"<p>Key insights for identifying problematic enzyme annotations: - EC number over-generalization: Annotations may be too broad when EC hierarchy doesn't match GO complexity - Mechanistic assumptions: GO terms may imply specific mechanisms not supported by evidence - Substrate specificity errors: Overly specific or overly general substrate assignments - Cofactor requirements: Missing or incorrect cofactor dependencies</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#2-evidence-quality-stratification-for-enzymes","title":"2. Evidence Quality Stratification for Enzymes","text":"<p>Specialized confidence assessment framework: - Experimental evidence hierarchy: Direct assays &gt; indirect assays &gt; computational predictions - Reproducibility weighting: Multiple independent studies increase confidence - Assay context evaluation: In vitro vs. in vivo evidence quality differences - High-throughput data skepticism: Screen results require additional validation</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#3-superfamily-based-validation","title":"3. Superfamily-Based Validation","text":"<p>Advanced approaches for enzyme family analysis: - Hierarchical validation: Check annotation consistency at superfamily, subgroup, and family levels - Conserved feature analysis: Verify presence of catalytically important residues - Mechanistic coherence: Ensure annotations consistent with known reaction mechanisms - Evolutionary constraint assessment: Evaluate functional conservation across phylogenetic distances</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#4-sequence-similarity-network-integration","title":"4. Sequence Similarity Network Integration","text":"<p>Powerful visualization and analysis tools: - Misannotation detection: Identify annotations spanning functionally distinct clusters - Boundary determination: Establish reliable annotation transfer thresholds - Quality assessment: Visualize annotation consistency within protein families - Systematic bias identification: Recognize patterns of over-broad annotation transfer</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#5-orthogonal-evidence-integration","title":"5. Orthogonal Evidence Integration","text":"<p>Multi-source validation strategies: - Genomic context validation: Particularly valuable for bacterial enzyme annotation - Domain architecture consistency: InterPro domain predictions supporting functional assignments - HMM family placement: Hidden Markov Model scores for family membership confidence - Active site conservation: Critical residue presence/absence analysis</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#6-statistical-rigor-for-enzyme-families","title":"6. Statistical Rigor for Enzyme Families","text":"<p>Sophisticated quantitative approaches: - Species-diverse enrichment: Modified GO enrichment approaches for taxonomically broad enzyme sets - Confidence-weighted scoring: Incorporating evidence quality into statistical tests - Background model selection: Appropriate comparison sets for enzyme family analysis - Semantic similarity metrics: Quantitative assessment of annotation relatedness</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#7-complex-annotation-scenarios","title":"7. Complex Annotation Scenarios","text":"<p>Handling challenging enzyme cases: - Multi-domain enzymes: Proteins with multiple catalytic activities requiring complex annotation - Enzyme complexes: Multi-subunit systems requiring coordinated annotation - Moonlighting enzymes: Context-dependent functional assignment - Promiscuous enzymes: Multiple substrate specificities and reaction capabilities</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#8-quality-control-pipeline-integration","title":"8. Quality Control Pipeline Integration","text":"<p>Systematic approaches for our curation workflow: - Evidence triangulation: Combining sequence, structure, and functional evidence - Annotation consistency checking: Cross-referencing within enzyme families - Literature validation: Prioritizing experimental studies over computational predictions - Systematic bias detection: Identifying patterns of computational over-annotation</p>"},{"location":"paper/literature/Chapter_09_Evaluating_Functional_Annotations_of_Enzymes-summary/#9-specialized-enzyme-databases","title":"9. Specialized Enzyme Databases","text":"<p>Understanding alternative annotation sources: - SFLD integration: Leveraging hierarchical enzyme classification - EC number validation: Cross-referencing GO terms with enzyme commission assignments - InterPro family consistency: Checking domain-function correspondence - Pathway context validation: Ensuring annotations consistent with metabolic roles</p> <p>This enzyme-specific expertise significantly enhances our ability to identify over-annotations, validate computational predictions, and make informed curation decisions for the substantial portion of genes that encode enzymes, providing both theoretical framework and practical tools for sophisticated functional annotation evaluation.</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/","title":"Chapter 10: Community-Wide Evaluation of Computational Function Prediction - Summary","text":"<p>Authors: Iddo Friedberg and Predrag Radivojac</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#summary","title":"Summary","text":"<p>This chapter describes the Critical Assessment of Functional Annotation (CAFA) challenge series, a community-wide initiative designed to evaluate computational protein function prediction methods systematically. The authors present a comprehensive framework for assessing prediction algorithms using the Gene Ontology as the functional vocabulary, addressing the fundamental challenge of evaluating computational methods in an era where experimental validation cannot keep pace with sequence data generation.</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#the-cafa-challenge-framework","title":"The CAFA Challenge Framework","text":"<p>Scale and Motivation: - Sequence data explosion: 100 exabases per day generation rate vastly exceeds experimental characterization capacity - Function prediction necessity: Computational methods essential for gaining insights into biological macromolecule activity - Community evaluation need: Standardized, unbiased assessment required to advance the field</p> <p>Organizational Structure: The CAFA challenge involves five distinct participant groups:</p> <ol> <li>Organizers: Coordinate activities, establish challenges, manage website and data compilation</li> <li>Assessors: Develop assessment rules, write evaluation software, present results to community</li> <li>Biocurators: Provide additional functional annotations (introduced in CAFA2)</li> <li>Steering Committee: Provide oversight, advice, and ensure experimental integrity</li> <li>Predictors: Research groups developing and submitting prediction methods for evaluation</li> </ol> <p>Timeline Structure: - t\u2080: Release of experimentally unannotated target proteins to community - t\u2081: Prediction submission deadline (several months after t\u2080) - t\u2082: Collection of newly accumulated experimental annotations (several months after t\u2081) - t\u2083: Assessment completion and results presentation</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#assessment-methodology","title":"Assessment Methodology","text":"<p>Gold Standard Development: - Time-based evaluation: Exploits natural growth of annotation databases over time - CAFA1 results: 866 benchmark proteins from 50,000 targets (1.7% success rate) - CAFA2 expansion: 3,681 benchmark proteins from 100,000 targets (3.7% success rate) - Swiss-Prot and UniProt-GOA: Primary sources for experimental annotations</p> <p>Key Evaluation Challenges: 1. Incomplete Knowledge Problem: Proteins may have additional unknown functions, leading to false positive assessments for correct but unvalidated predictions 2. Biased Experimental Annotations: High-throughput assays favor shallow terms; biomedical research bias toward health-related functions 3. Limited Experimental Window: Scientists minimize time between discovery and publication, creating small validation windows</p> <p>Assessment Metrics:</p> <ol> <li>Precision-Recall Framework (Primary Metric):</li> <li>Precision (pr): |P \u2229 T| / |P| (fraction of predicted terms that are correct)</li> <li>Recall (rc): |P \u2229 T| / |T| (fraction of true terms recovered by predictor)</li> <li>F\u2081-measure (F\u2098\u2090\u2093): Maximum harmonic mean of precision and recall</li> <li> <p>Equal weighting rationale: Balances avoiding overprediction with achieving adequate coverage</p> </li> <li> <p>Information-Theoretic Metrics (CAFA2):</p> </li> <li>Misinformation (mi): Information content of incorrectly predicted nodes</li> <li>Remaining Uncertainty (ru): Information content of true annotations not predicted</li> <li>Semantic Distance (S\u2098\u1d62\u2099): Minimum Euclidean distance from origin on ru-mi curve</li> <li>Advantage: Accounts for hierarchical term relationships and information content</li> </ol>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#key-findings-and-insights","title":"Key Findings and Insights","text":"<p>Performance Trends: - Molecular Function: Most reliable predictions, showing consistent progress over time - Biological Process and Cellular Component: Performance below expectations, likely requiring high-quality systems data rather than sequence information alone - Method diversity: Successful approaches combine machine learning expertise with biological insights</p> <p>Algorithm Superiority: - Computational methods outperform simple sequence alignment: CAFA demonstrated that sophisticated function prediction algorithms exceed straightforward homology-based transfer - Multi-data integration advantage: Methods combining multiple data types (sequence, structure, expression, interactions) typically perform better</p> <p>Community Growth: - CAFA1: 23 groups, 14 countries, 54 methods - CAFA2: 56 groups, 126 methods - Substantial growth: Indicates strong community interest and investment in computational function prediction</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#future-directions","title":"Future Directions","text":"<p>CAFA3 Improvements: - Unbiased evaluation: Genome-wide experimental evidence collection for specific biological terms - Expanded scope: Additional evaluation criteria and assessment approaches - Community feedback integration: Evolution based on participant needs and requests</p> <p>Methodological Advances: - Multiple data type exploitation: Integration of diverse biological data sources - Machine learning sophistication: Advanced computational approaches combined with biological insight - Systems-level approaches: Higher-quality data integration for biological process and cellular component predictions</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential methodological foundation for understanding computational function prediction evaluation and its implications for our annotation curation work:</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#1-understanding-computational-prediction-limitations","title":"1. Understanding Computational Prediction Limitations","text":"<p>CAFA results directly inform our evaluation of IEA (Inferred from Electronic Annotation) codes: - Variable algorithm performance: Different computational methods have distinct accuracy profiles and failure modes - Ontology-specific reliability: Molecular function predictions generally more reliable than biological process or cellular component - Training data dependency: All computational methods ultimately rely on experimental annotations as ground truth</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#2-assessment-framework-for-electronic-annotations","title":"2. Assessment Framework for Electronic Annotations","text":"<p>The CAFA evaluation methodology provides templates for our annotation quality assessment: - Precision-recall considerations: Balance between avoiding over-annotation and maintaining functional coverage - Hierarchical consistency: Importance of True Path Rule compliance in GO predictions - Information content weighting: More specific terms should receive greater weight in quality assessments</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#3-temporal-validation-approaches","title":"3. Temporal Validation Approaches","text":"<p>CAFA's time-based evaluation strategy offers insights for our curation work: - Database evolution tracking: Annotations persisting across multiple releases likely more reliable - Experimental accumulation patterns: Understanding how new evidence emerges over time - Prediction validation timescales: Realistic expectations for computational prediction confirmation</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#4-community-standards-and-best-practices","title":"4. Community Standards and Best Practices","text":"<p>The chapter's discussion of evaluation challenges informs our curation criteria: - Incomplete knowledge acknowledgment: Recognition that annotation absence doesn't imply functional absence - Bias recognition: Systematic biases in experimental validation toward medically relevant functions - Multi-metric evaluation: Need for multiple assessment approaches to capture different aspects of annotation quality</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#5-algorithm-specific-over-annotation-patterns","title":"5. Algorithm-Specific Over-Annotation Patterns","text":"<p>CAFA findings help identify potential computational over-annotation sources: - Overprediction tendency: Recall-focused algorithms may generate many incorrect specific predictions - Shallow term bias: Precision-focused methods may favor less informative general terms - Training set limitations: Algorithms cannot predict functions absent from training data</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#6-evidence-quality-stratification","title":"6. Evidence Quality Stratification","text":"<p>The chapter's analysis of experimental evidence informs our curation decisions: - Experimental evidence hierarchy: Direct experimental validation superior to computational inference - High-throughput skepticism: Large-scale studies often provide lower information content annotations - Publication timing effects: Recently published experimental results may be higher quality</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#7-systematic-evaluation-methodologies","title":"7. Systematic Evaluation Methodologies","text":"<p>CAFA's systematic approach provides models for our quality control: - Standardized assessment: Consistent evaluation criteria across different genes and annotation types - Multiple evaluation metrics: Different measures capture distinct aspects of prediction quality - Community feedback integration: Mechanisms for expert input on evaluation approaches</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#8-computational-method-evolution","title":"8. Computational Method Evolution","text":"<p>Understanding CAFA's longitudinal perspective helps assess annotation reliability: - Performance improvements: Methods showing progress over multiple CAFA rounds likely more reliable - Method stability: Approaches with consistent performance across evaluations more trustworthy - Community validation: Methods evaluated through CAFA have undergone peer assessment</p>"},{"location":"paper/literature/Chapter_10_Community-Wide_Evaluation_of_Computational_Function_Prediction-summary/#9-future-assessment-integration","title":"9. Future Assessment Integration","text":"<p>The chapter's forward-looking perspective suggests opportunities for our project: - Unbiased evaluation development: Our manual curation could contribute to more balanced assessment datasets - Expert annotation contribution: Our detailed literature-based curation provides high-quality training/evaluation data - Method feedback: Our identification of over-annotations could inform computational method improvement</p> <p>This understanding of computational function prediction evaluation is crucial for making informed curation decisions that appropriately account for the strengths and limitations of different algorithmic approaches, helping distinguish reliable predictions from over-interpretation while contributing to community-wide improvement in functional annotation quality.</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/","title":"Chapter 11: Get GO! Retrieving GO Data Using AmiGO, QuickGO, API, Files, and Tools - Summary","text":"<p>Authors: Monica Munoz-Torres and Seth Carbon</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive practical guide to accessing and utilizing Gene Ontology Consortium (GOC) resources through various interfaces and methods. The authors systematically cover web-based interfaces, file formats, programmatic access methods, and tools for retrieving, manipulating, and analyzing GO data, serving as both a tutorial and reference for researchers working with GO resources.</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#web-interfaces-for-go-data-access","title":"Web Interfaces for GO Data Access","text":"<p>Primary Web Browsers:</p> <ol> <li>AmiGO (http://amigo.geneontology.org):</li> <li>Official GOC browser: Open-source tool for querying, browsing, and visualizing GO data</li> <li>Key features: Basic searching, custom dataset downloads, \"wizard\" interface for common questions</li> <li>Recent improvements: Enhanced speed, multiple search modes, annotation extensions display, protein forms visualization</li> <li>Data sources: MODs (model organism databases), UniProtKB, and other consortium members</li> <li> <p>Funding: NHGRI-NIH supported, official channel for GO data dissemination</p> </li> <li> <p>QuickGO (http://www.ebi.ac.uk/QuickGO):</p> </li> <li>EMBL-EBI developed: Web-based tool for browsing GO and annotations</li> <li>Advanced features: Extensive search/filter capabilities, integrated subset/slim interface, historical term views</li> <li>Data consumption: Broad-ranging web services, cart functionality for persistence</li> <li>Management: EMBL-EBI funded and managed, team members also participate in GOC</li> </ol> <p>Third-Party Browsers: - OntoBee: Semantic web community focused, linked data platform - EMBL-EBI OLS: Ontology Lookup Service for general ontology browsing - OLSVis: Visualization-oriented interface - BioPortal: General ontology repository - Limitation: None currently provide access to GO annotations</p> <p>Enrichment Analysis Integration: - PANTHER Classification System: Direct connection from GO website for term enrichment analysis - Supported features: Overrepresentation/underrepresentation analysis, up-to-date GO annotations - Gene ID support: Comprehensive list available from PANTHER website</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#go-file-formats-and-data-structure","title":"GO File Formats and Data Structure","text":"<p>Ontology File Editions (increasing complexity):</p> <ol> <li>go-basic:</li> <li>Filtered version: Supports annotation propagation up the graph</li> <li>Relations included: is_a, part_of, regulates, negatively_regulates, positively_regulates</li> <li>Limitation: Excludes cross-hierarchy relationships</li> <li>Format: OBO only</li> <li> <p>Use case: Legacy tool compatibility</p> </li> <li> <p>go:</p> </li> <li>Core edition: Additional relationship types spanning GO hierarchies</li> <li>Cross-hierarchy relations: has_part, occurs_in connecting disjoint hierarchies</li> <li>Formats: OBO and OWL-RDF/XML</li> <li> <p>Enhanced connectivity: Links otherwise separate hierarchical structures</p> </li> <li> <p>go-plus:</p> </li> <li>Most expressive edition: Maximum relationship complexity and external ontology connections</li> <li>External integrations: ChEBI (chemical entities), Uberon (anatomy), Plant Ontology (PO)</li> <li>Advanced features: Import modules, cross-ontology queries, biological constraint rules</li> <li>Validation capabilities: Spatial exclusivity constraints, automated consistency checking</li> <li>Format: OWL-RDF/XML only</li> </ol> <p>Technical Implementation: - Official language: Web Ontology Language (OWL), W3C standard - Scale: ~41,000 GO terms + 10,000 imported classes, ~27 million associations, ~470,000 species - Axiomatization: Complete logical definitions (OWL axioms) for systematic reasoning - Tool support: Prot\u00e9g\u00e9 editor, Java OWL API, OWLTools framework</p> <p>Association File Formats:</p> <ol> <li>GAF (Gene Association Files):</li> <li>Primary format: Tab-delimited plain text, version 2.1 current</li> <li>Structure: One line per gene product-GO term association</li> <li>Information included: Evidence codes, references, qualifier information</li> <li> <p>Standardization: Consortium-wide submission format</p> </li> <li> <p>GPAD/GPI Files:</p> </li> <li>Normalized version: Separated gene product information from associations</li> <li>Future prominence: Expected to replace GAF format</li> <li>Advantages: Cleaner data structure, reduced redundancy</li> </ol>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#programmatic-access-and-tool-development","title":"Programmatic Access and Tool Development","text":"<p>Java/JVM Ecosystem: - OWLTools: Primary library for GO data manipulation and analysis   - Core operations: Graph walking, closures, OBO-specific field access   - Advanced features: Ontology reasoning, validation, taxon checks, link prediction - OWL API: Standard Java library for OWL ontology processing - Standard reasoners: Full compatibility with OWL tool stack</p> <p>JavaScript Development: - AmiGO APIs: Client and server-side JavaScript interfaces - Widget system: Reusable components for GO data integration - Core components: Manager and response interfaces for external site integration - External linking: Methods for producing incoming searches and relevantinformation linking</p> <p>Database Access: - GOOSE (GO Online SQL/Solr Environment): Legacy SQL database access - MySQL builds: Regular conversions for legacy application support - Remote querying: Available for applications requiring SQL interface - Schema information: Comprehensive documentation for database structure</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#ontology-subsets-and-customization","title":"Ontology Subsets and Customization","text":"<p>GO Slims/Subsets: - Purpose: Cut-down versions with reduced term numbers for broad classification - Use cases: Genome annotation summaries, microarray analysis, cDNA collection classification - Types: Species-specific subsets, generic \"useful\" term collections - Benefits: Overview without fine-grained detail complexity</p> <p>Community Contribution Mechanisms: - TermGenie: Web-based tool for requesting new GO classes with automated review - GitHub tracker: Free-text ontology update and request submissions - AmiGO browser: Term existence searching and validation - Feedback integration: Systematic incorporation of user suggestions and corrections</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#additional-resources-and-support","title":"Additional Resources and Support","text":"<p>Cross-System Mappings: - Available mappings: Enzyme Commission numbers, KEGG pathways - Limitations: Neither complete nor exact, require cautious usage - Documentation: Complete listing available on GO website</p> <p>Help and Support Infrastructure: - GO Helpdesk: User query addressing for data, software, and analysis issues - Contact methods: Site forms with automatic internal tracking - Response system: Queries directed to appropriate consortium personnel - Issue tracking: Systematic responsiveness assurance</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential practical knowledge for effectively accessing and utilizing GO resources in our annotation curation workflow:</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#1-data-source-understanding-and-quality-assessment","title":"1. Data Source Understanding and Quality Assessment","text":"<p>The chapter's coverage of different GO browsers and their origins directly informs our data evaluation: - AmiGO vs. QuickGO differences: Understanding that both use same datasets but with different implementations helps assess annotation consistency - Official vs. third-party sources: Prioritizing GOC-official resources (AmiGO) for authoritative annotation information - Data provenance tracking: Recognizing MOD and UniProtKB contribution patterns for source reliability assessment</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#2-file-format-expertise-for-systematic-analysis","title":"2. File Format Expertise for Systematic Analysis","text":"<p>Detailed understanding of GO file formats enables sophisticated annotation analysis: - GAF format mastery: Essential for parsing and analyzing existing annotations in our gene review workflow - GPAD/GPI transition awareness: Preparing for future format changes and understanding normalization benefits - Ontology edition selection: Choosing appropriate complexity level (go-basic vs. go vs. go-plus) for specific analysis needs</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#3-programmatic-access-for-large-scale-curation","title":"3. Programmatic Access for Large-Scale Curation","text":"<p>The chapter's programming interface documentation supports scalable annotation processing: - OWLTools integration: Leveraging advanced reasoning capabilities for annotation validation and consistency checking - Batch processing capabilities: Utilizing file-based access for systematic annotation review across multiple genes - API utilization: Implementing automated quality checks and cross-referencing in our curation pipeline</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#4-cross-hierarchy-relationship-understanding","title":"4. Cross-Hierarchy Relationship Understanding","text":"<p>Knowledge of ontology structure complexity informs curation decisions: - go-basic limitations: Understanding when cross-hierarchy relationships are excluded affects annotation interpretation - go-plus advantages: Recognizing enhanced relationship types helps identify more sophisticated functional connections - External ontology integration: Leveraging ChEBI, Uberon, and PO connections for comprehensive functional understanding</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#5-quality-control-through-multiple-access-methods","title":"5. Quality Control Through Multiple Access Methods","text":"<p>Utilizing different interfaces provides validation opportunities: - Cross-browser verification: Checking annotations across AmiGO and QuickGO for consistency - Historical tracking: Using QuickGO's historical views to understand annotation evolution and stability - Search methodology diversity: Employing different search approaches to identify potential annotation gaps or inconsistencies</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#6-subset-and-slim-analysis-for-over-annotation-detection","title":"6. Subset and Slim Analysis for Over-Annotation Detection","text":"<p>Understanding GO slims supports systematic annotation evaluation: - Broad classification perspective: Using slims to identify genes with excessive fine-grained annotations - Summary-level consistency: Checking whether detailed annotations align with expected broad functional categories - Species-specific validation: Leveraging organism-specific subsets for contextual annotation appropriateness</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#7-community-contribution-and-feedback-integration","title":"7. Community Contribution and Feedback Integration","text":"<p>The chapter's coverage of contribution mechanisms supports our project's broader impact: - Systematic improvement: Using GitHub tracker and TermGenie to contribute annotation quality feedback - Error reporting: Implementing systematic feedback mechanisms for identified over-annotations or inconsistencies - Community engagement: Connecting our findings with broader GO improvement efforts</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#8-tool-development-for-specialized-needs","title":"8. Tool Development for Specialized Needs","text":"<p>Programming interface documentation enables custom tool development: - Automated validation tools: Creating specialized scripts for systematic over-annotation detection - Integration pipelines: Building workflows that combine multiple data sources and validation approaches - Quality metrics development: Implementing quantitative measures for annotation appropriateness assessment</p>"},{"location":"paper/literature/Chapter_11_Get_GO_Retrieving_Data-summary/#9-historical-and-temporal-analysis-capabilities","title":"9. Historical and Temporal Analysis Capabilities","text":"<p>Understanding data evolution features supports longitudinal analysis: - Annotation stability tracking: Using historical views to assess annotation persistence and reliability - Change pattern analysis: Identifying systematic trends in annotation modifications over time - Version control awareness: Understanding how ontology and annotation changes affect our curation decisions</p> <p>This comprehensive understanding of GO data access and manipulation is crucial for implementing sophisticated, scalable approaches to annotation curation that can systematically identify over-annotations while leveraging the full power of GO resources for informed decision-making.</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/","title":"Chapter 12: Semantic Similarity in the Gene Ontology - Summary","text":"<p>Author: Catia Pesquita</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive overview of semantic similarity (SS) measures applied to the Gene Ontology, exploring how the hierarchical structure and annotation corpora can be leveraged to quantitatively assess functional relationships between GO terms and gene products. The author presents a systematic framework for understanding, selecting, and evaluating SS measures, addressing both theoretical foundations and practical applications in biomedical research.</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#fundamentals-of-semantic-similarity","title":"Fundamentals of Semantic Similarity","text":"<p>Core Concept: Semantic similarity assesses the likeness in meaning between concepts, enabling comparison of GO terms and GO-annotated gene products by exploiting ontology structure and annotation data. This supports crucial inference tasks including protein-protein interaction prediction, disease gene prioritization, and functional coherence evaluation.</p> <p>Terminology Distinctions: - Semantic Similarity (SS): Limited to hierarchical relations (is-a, synonymy) - Semantic Relatedness: Encompasses broader relations (hyponymic, hypernymic, meronymic, antonymic, functional) - Semantic Distance: Generally considered opposite of similarity, though sometimes used as opposite of relatedness</p> <p>Application Levels: 1. Term Similarity: Comparison between individual GO terms 2. Gene Product Similarity: Comparison between proteins annotated with GO term sets</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#term-similarity-approaches","title":"Term Similarity Approaches","text":"<p>1. Structural/Internal Methods:</p> <p>Simple Distance-Based: - Edge counting: Number of edges in path between terms - Limitations: Assumes uniform edge weights, disregards hierarchical depth - Problem: Equal-length paths at different ontology depths considered equivalent</p> <p>Enhanced Structural Approaches: - Depth weighting: Edges assigned different weights reflecting hierarchical depth - Node density consideration: Accounting for varying ontology region density - Advanced metrics: Lowest common ancestor (LCA) depth, distance to nearest leaf node, distinct GO subgraph depth</p> <p>2. External/Information-Theoretic Methods:</p> <p>Information Content (IC) Based: - Foundation: IC(c) = -log p(c), where p(c) is occurrence probability in annotation corpus - Advantages: Less sensitive to link density variability and ontology imbalances - Normalized IC: Scaled values [0,1] for easier interpretation</p> <p>Common Ancestor Approaches: - MICA (Most Informative Common Ancestor): Uses highest IC common ancestor - DCA (Disjoint Common Ancestors): Considers all disjoint common ancestors - Resnik's measure: Simplest IC-based approach using MICA IC as similarity</p> <p>Hybrid Measures: - Combined strategies: Edge-based and IC-based approaches - Corpus-independent IC: Based on descendants, depth, or entropy - Recent advances: SSDD (semantic totipotency), SORA (structural IC), TCSS (subgraph-based)</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#gene-product-similarity-strategies","title":"Gene Product Similarity Strategies","text":"<p>1. Pairwise Approaches: - Method: Individual term similarities combined into global functional similarity measure - Combination strategies: Average, maximum, sum of pairwise term comparisons - Scope options: All-vs-all term combinations or best-matching pairs only</p> <p>2. Groupwise Approaches:</p> <p>Set-based Methods: - Direct annotations only: Using set similarity techniques - Limitation: Ignores shared ancestry between GO terms</p> <p>Graph-based Methods: - Comprehensive representation: Subgraphs including direct and inherited annotations - Similarity calculation: Graph-matching techniques or set similarity on expanded annotations</p> <p>Vector-based Methods: - Vector space representation: Each term as dimension, functional similarity via vector measures - IC weighting: Terms weighted by information content in vector calculations</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#issues-and-challenges-in-semantic-similarity","title":"Issues and Challenges in Semantic Similarity","text":"<p>External Issues (Annotation Corpus-Related):</p> <ol> <li>Shallow Annotation Problem:</li> <li>Issue: Many proteins annotated only to general GO terms</li> <li>Impact: High term overlap between dissimilar proteins</li> <li> <p>Relevance: Particularly problematic for electronic annotations (IEA)</p> </li> <li> <p>Annotation Length Bias:</p> </li> <li>Issue: Positive correlation between similarity scores and annotation number</li> <li>Cause: Non-uniform annotation distribution among proteins</li> <li> <p>Impact: Well-annotated proteins appear more similar to everything</p> </li> <li> <p>Evidence Code Effects:</p> </li> <li>IEA annotation impact: Generally positive or null effect on performance</li> <li>Specific problems: Maximum combination approaches with IEA can decrease similarity detection</li> <li>Quality trends: Electronic annotation specificity improving over time</li> </ol> <p>Internal Issues (Measure Design-Related):</p> <ol> <li>Term Specificity Level:</li> <li>IC measures: Corpus bias effect - rare generic terms may have high IC</li> <li> <p>Depth measures: Independent of corpus but insensitive to biological specificity variation</p> </li> <li> <p>Term Similarity Level:</p> </li> <li>Distance measures: Same issues as depth-based specificity</li> <li> <p>Ancestor selection: Choice between single MICA vs. multiple ancestors affects performance</p> </li> <li> <p>Gene Product Similarity Level:</p> </li> <li>Maximum approach: Focuses only on most similar aspect, missing global similarity</li> <li>Average approach: Counterintuitive results for multi-functional proteins</li> <li>Best-match approach: Generally superior performance by considering significant matches only</li> </ol>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#evaluation-and-performance-assessment","title":"Evaluation and Performance Assessment","text":"<p>Evaluation Challenge: No gold standard exists for functional similarity, making measure comparison inherently subjective. Each measure formalizes functional similarity differently.</p> <p>Comparison Proxies: - Sequence similarity: Positive correlation generally found, particularly with binned data - Family similarity: Pfam-based functional groupings - Protein-protein interactions: SS measures generally good PPI predictors - Expression profiles: Co-expression as functional similarity proxy - Functional modules/complexes: Known functional groupings</p> <p>Top-Performing Measures by Application:</p> Application Best Measures Sequence similarity SSDD, SimGIC, HRSS Pfam similarity SORA, SSDD, SimGIC ECC similarity SSDD, HRSS, SORA Expression similarity TCSS, SimGIC, SimIC, Best-Match-Avg (Resnik) Protein-protein interaction TCSS, SimIC, Max(Resnik) <p>Performance Trends: - Classic measures: Resnik still competitive in some settings - New generation dominance: Structural and hybrid measures (SSDD, SORA, TCSS) now leading - Historical shift: From pure IC-based measures to complex structural approaches - GO evolution impact: Measure performance affected by ontology growth and complexity changes</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#tools-and-implementation","title":"Tools and Implementation","text":"<p>Web Servers: - ProteInOn: Multi-measure platform with easy interface - FunSimMat: Comprehensive functional similarity database - GOssToWeb: Web-based semantic similarity calculation - Limitations: Fixed ontology/annotation versions, limited parametrization</p> <p>Software Packages: - GoSemSim (R): Flexible parametrization and programmatic access - GOssTo: Standalone application with version control - Java library: 50+ measures, multiple input formats (OWL, OBO, RDF), high-performance (100M+ comparisons/hour)</p> <p>Selection Criteria: - Web tools: Check update frequency for current GO versions - Software packages: Better for large datasets and custom analyses - Performance needs: Consider computational requirements for large-scale applications</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#future-challenges-and-opportunities","title":"Future Challenges and Opportunities","text":"<p>GO Evolution Integration: - Unexplored features: Regulatory relationships, evidence code categorization, logical definitions - Cross-products: Internal and external ontology connections - Axiomatization: GO's OWL structure underutilized by current measures</p> <p>Computational Efficiency: - Current limitation: Most applications offline, speed not prioritized - Emerging needs: Real-time similarity search, genomic-scale datasets - Solution approaches: Parallel computation, efficiency-accuracy balance</p> <p>Semantic Sophistication: - OWL axiom utilization: Moving beyond simple DAG representation - Disjointness exploration: Recently proposed for ChEBI, applicable to GO - Enhanced accuracy: More semantically sound measures needed</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential quantitative tools for assessing functional relationships and annotation quality in our curation workflow:</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#1-annotation-consistency-assessment","title":"1. Annotation Consistency Assessment","text":"<p>Semantic similarity measures offer sophisticated methods for evaluating annotation quality: - Term coherence analysis: Using SS to identify annotations that don't fit with gene's primary functional profile - Cross-validation approaches: Comparing our curated annotations with SS-predicted functional relationships - Outlier detection: Identifying potentially over-annotated terms that show low similarity to core function set</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#2-evidence-quality-stratification-using-ss","title":"2. Evidence Quality Stratification Using SS","text":"<p>Different SS measure performance characteristics inform evidence evaluation: - IC-based measure limitations: Understanding corpus bias effects helps interpret annotation frequency as quality indicator - Shallow annotation problem: Directly relevant to identifying over-general annotations requiring REMOVE actions - Electronic annotation effects: SS findings about IEA impact support our evidence code-based curation decisions</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#3-functional-coherence-validation","title":"3. Functional Coherence Validation","text":"<p>SS measures provide quantitative frameworks for assessing functional annotation sets: - Multi-functional protein handling: Best-match approaches align with our understanding that proteins may have distinct functional aspects - Core vs. peripheral function distinction: SS clustering approaches can help distinguish ACCEPT from KEEP_AS_NON_CORE annotations - Global similarity assessment: Groupwise approaches relevant for evaluating overall annotation set appropriateness</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#4-over-annotation-detection-through-ss-analysis","title":"4. Over-Annotation Detection Through SS Analysis","text":"<p>Several chapter insights directly support over-annotation identification: - Maximum combination problems: Awareness that single high-similarity aspects can mask overall functional mismatch - Annotation length bias: Understanding that similarity scores increase with annotation number helps identify annotation inflation - Corpus-independent measures: Useful for validating annotations without dependency on potentially biased annotation databases</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#5-literature-based-curation-enhancement","title":"5. Literature-Based Curation Enhancement","text":"<p>SS measures can augment our literature-based approach: - Publication relevance scoring: Using SS between paper-derived functions and existing annotations to assess literature quality - Functional prediction validation: Cross-checking computationally predicted functions against literature-derived evidence using SS measures - Citation analysis: Applying SS to assess consistency between different publications' functional claims</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#6-systematic-bias-recognition","title":"6. Systematic Bias Recognition","text":"<p>Understanding SS measure limitations helps identify annotation biases: - Depth vs. specificity issues: Recognizing that ontology depth doesn't always correlate with biological specificity - Link density problems: Understanding that GO's uneven structure affects annotation reliability assessment - Common ancestor artifacts: Awareness that MICA-based approaches may miss functionally relevant relationships</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#7-quality-control-integration","title":"7. Quality Control Integration","text":"<p>SS evaluation frameworks provide templates for our curation assessment: - Multiple validation proxies: Using sequence, domain, interaction, and expression data as orthogonal validation approaches - Comparative measure assessment: Applying multiple SS measures to build confidence in curation decisions - Performance benchmarking: Using established SS evaluation approaches to assess our curation effectiveness</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#8-tool-integration-for-scalable-analysis","title":"8. Tool Integration for Scalable Analysis","text":"<p>Software and computational approaches support systematic curation: - High-performance libraries: For large-scale annotation consistency analysis across multiple genes - Programmatic access: Enabling automated quality checks and systematic over-annotation detection - Custom measure development: Framework for developing domain-specific similarity measures for our curation needs</p>"},{"location":"paper/literature/Chapter_12_Semantic_Similarity_in_Gene_Ontology-summary/#9-advanced-curation-strategies","title":"9. Advanced Curation Strategies","text":"<p>Emerging SS approaches suggest future opportunities: - OWL axiom utilization: Leveraging GO's logical structure for more sophisticated over-annotation detection - Disjointness constraints: Using semantic exclusion principles to identify incompatible annotation combinations - Hybrid evidence integration: Combining structural and information-theoretic approaches for robust quality assessment</p> <p>This comprehensive understanding of semantic similarity provides both theoretical foundation and practical tools for implementing quantitative approaches to annotation curation that can systematically identify over-annotations while maintaining sensitivity to genuine functional complexity.</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/","title":"Chapter 13: Gene-Category Analysis - Summary","text":"<p>Author: Sebastian Bauer</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive overview of gene-category analysis (also known as enrichment analysis), a critical knowledge integration approach that combines ontological knowledge bases like Gene Ontology with gene lists from high-throughput experiments. The author systematically describes the standard Fisher's exact test approach, identifies its key limitations in the context of hierarchical ontologies, and presents several advanced algorithms designed to address these shortcomings.</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#fundamentals-of-gene-category-analysis","title":"Fundamentals of Gene-Category Analysis","text":"<p>Core Problem: High-throughput biological experiments typically generate lists of hundreds of biological entities (genes/proteins), making direct interpretation difficult for humans. Gene-category analysis addresses the fundamental question: \"Do these responder genes share biological features that distinguish them from all genes tested in the experiment?\"</p> <p>Basic Framework: - Population set (M): All items a study could select (e.g., all genes on microarray chip) with cardinality m - Study set (N): Actual experimental outcome (e.g., differentially expressed genes) with cardinality n - Gene categories: Groupings of genes with similar features (GO terms, KEGG pathways, etc.) - Statistical method: Approach for identifying significantly enriched categories</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#fishers-exact-test-standard-approach","title":"Fisher's Exact Test - Standard Approach","text":"<p>Statistical Foundation: The standard approach casts gene-category analysis as a statistical test using the hypergeometric distribution:</p> <p>Hypergeometric Model: - Population M is dichotomic: items either annotated to term t or not - Mt contains all items annotated to t (cardinality mt) - Xt follows hypergeometric distribution: Xt ~ h(k|m; mt; n) - P(Xt = k) = (mt choose k)(m-mt choose n-k)/(m choose n)</p> <p>Hypothesis Testing: - Null hypothesis (H0): No positive association between study set occurrence and term t annotation - Alternative hypothesis (H1): Study set enriched for term t - One-tailed test: P(Xt \u2265 nt | H0) where nt is observed annotated items in study set</p> <p>P-value calculation: ptft = \u03a3(k=nt to min(n,mt)) [(mt choose k)(m-mt choose n-k)/(m choose n)]</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#multiple-testing-problem","title":"Multiple Testing Problem","text":"<p>Core Issue: Hypothesis-generating studies test many terms simultaneously (often all GO terms), leading to high false-positive rates.</p> <p>Expected false positives: \u03b1 \u00d7 T tests under null hypothesis - Example: Testing 10,000 true null hypotheses at \u03b1=0.05 \u2192 ~500 false positives</p> <p>Correction Methods:</p> <ol> <li>Bonferroni Correction:</li> <li>Method: Multiply each p-value by number of tests (saturated at 1.0)</li> <li>Controls: Family-wise error rate</li> <li> <p>Limitation: Very conservative, assumes independence (rarely true for ontology terms)</p> </li> <li> <p>Westfall-Young Procedure:</p> </li> <li>Method: Resampling-based approach accounting for dependencies</li> <li>Process: Random study sets of same size, compute null distributions</li> <li>Advantage: Considers term correlations</li> <li> <p>Limitation: Computationally expensive</p> </li> <li> <p>Benjamini-Hochberg (FDR):</p> </li> <li>Method: Controls false discovery rate rather than family-wise error rate</li> <li>Advantage: Higher statistical power at expense of less strict false discovery control</li> <li>Recommendation: American Physiological Society calls it \"best practical solution\"</li> </ol>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#gene-propagation-problem","title":"Gene Propagation Problem","text":"<p>Structural Issue: Ontology design creates systematic gene sharing between terms through hierarchical relationships (particularly is-a relationships).</p> <p>Problem Manifestation: - If term T1 is related to T2 by is-a relationship and gene annotated to T1 - Then gene implicitly annotated to T2 (true path rule) - If T1 is overrepresented, T2 likely also appears overrepresented - Creates cascading false positives up hierarchy</p> <p>Synthetic Experiment Results: - Artificially overrepresenting \"localization\" term (1542 genes, \u03b2=0.2, \u03b1=0.1) - Result: 275 additional significantly enriched terms - 6/6 children terms significant - 172/681 descendant terms significant - Demonstrates extensive false positive propagation</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#advanced-algorithms","title":"Advanced Algorithms","text":"<p>1. Parent-Child Approach:</p> <p>Core Idea: Condition overrepresentation probability on parental term properties rather than entire population.</p> <p>Method: - Instead of drawing from population M, draw from Mpa(t) (items annotated to parents of t) - For single parent s: P(Xt = k | pa(t)) uses mpa(t) as population size - Effect: Changes population underlying Fisher's exact test to parent-annotated items</p> <p>Advantages: - Accounts for hierarchical structure - Reduces false positives from gene propagation - More conservative p-values for child terms when parent already enriched</p> <p>2. Topology-Based Algorithms (elim and weight):</p> <p>elim Algorithm: - Traversal: Bottom-up depth-first search through ontology - Gene removal: If term t significant, remove all t-annotated genes from ancestor calculations - Effect: Strictly favors most specific terms, eliminates redundant parent terms - Philosophy: Children terms more biologically informative due to higher specificity</p> <p>weight Algorithm: - Approach: Compares significance scores within term families (parent-child) - Method: Identifies locally most significant terms, down-weights genes in less significant neighbors - Effect: Decorrelates p-values while maintaining existence of significant terms - Advantage: Less restrictive than elim, allows multiple significant levels</p> <p>3. Model-Based Gene Set Analysis (MGSA):</p> <p>Bayesian Network Architecture: - Term layer: Boolean nodes for m ontology terms (active/inactive) - Hidden layer: Boolean nodes for n gene hidden states - Observed layer: Boolean nodes for experimentally observed gene states</p> <p>Model Relationships: - Prior probability p: Term activation probability (typically &lt;&lt; 0.5) - Gene state rule: Gene \"on\" if \u22651 annotated term active, otherwise \"off\" - Observation noise: False-positive rate \u03b1, false-negative rate \u03b2</p> <p>Inference Process: - Goal: Find term configuration explaining observed gene pattern - Method: Sampling from state space (optimization is NP-hard) - Output: Marginal probabilities for each term (0-1 scale) - Advantage: All terms compete simultaneously, accounts for dependencies</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#gene-set-enrichment-analysis-gsea","title":"Gene Set Enrichment Analysis (GSEA)","text":"<p>Alternative Approach: Uses continuous gene measurements rather than discrete study sets.</p> <p>Method: - Gene ranking: Order genes by interesting feature (e.g., expression difference) - Score calculation: Normalized Kolmogorov-Smirnov test statistic - ES(Nt) formula: Maximum of running sum (increased for annotated genes, decreased for non-annotated) - Significance testing: Compare score to randomly chosen gene sets of same size</p> <p>Advantages: - No arbitrary cutoffs: Eliminates need to define study set threshold - Utilizes all data: Incorporates continuous measurements rather than binary classification - Ranking-based: Focuses on gene ordering rather than absolute expression levels</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#software-implementations","title":"Software Implementations","text":"<p>Available Tools: - Web interfaces: Gene Ontology Consortium website (direct Fisher's exact test access) - Integrated tools: BiNGO (Cytoscape plugin), Ontologizer (standalone GUI) - R/Bioconductor packages: topGo, mgsa, gCMAP - Multiple approaches: Most tools implement several algorithms for comparison</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides critical insights for understanding and evaluating enrichment analysis results that frequently appear in gene function literature:</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#1-literature-based-evidence-evaluation","title":"1. Literature-Based Evidence Evaluation","text":"<p>Understanding enrichment analysis limitations helps assess publication quality: - Gene propagation awareness: Recognizing when papers report artificially inflated numbers of significant terms - Multiple testing evaluation: Assessing whether appropriate corrections were applied - Method selection critique: Understanding when standard Fisher's test may be inadequate</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#2-over-annotation-pattern-recognition","title":"2. Over-Annotation Pattern Recognition","text":"<p>Enrichment analysis biases directly parallel over-annotation issues: - Hierarchical propagation: Same mechanism that causes false positive enrichment can lead to over-annotation up ontology hierarchies - Parent-child relationships: Understanding that child term significance may be consequence of parent term significance - Specificity assessment: Recognizing when more general terms are flagged due to specific term activity</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#3-evidence-quality-stratification","title":"3. Evidence Quality Stratification","text":"<p>Different enrichment approaches provide templates for annotation confidence assessment: - Standard approach limitations: High false positive rates parallel issues with computational annotation pipelines - Advanced method advantages: Parent-child and topology-based approaches offer models for more sophisticated annotation validation - Model-based competition: MGSA's competitive framework mirrors need to evaluate annotations in context of all possible functions</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#4-statistical-rigor-in-curation-decisions","title":"4. Statistical Rigor in Curation Decisions","text":"<p>The chapter's statistical frameworks inform our systematic curation approach: - Multiple comparison awareness: Understanding that testing many annotations simultaneously increases false positive probability - Conditional independence: Recognizing that annotation decisions shouldn't be made independently when terms are hierarchically related - Bayesian integration: MGSA's approach suggests ways to integrate multiple evidence sources for annotation decisions</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#5-functional-coherence-validation","title":"5. Functional Coherence Validation","text":"<p>Enrichment analysis concepts support systematic gene function assessment: - Study set analogy: Our curated annotation sets can be viewed as \"study sets\" for validation - Population definition: Understanding how background gene sets affect enrichment detection - Significance thresholds: Applying appropriate statistical rigor to annotation validation decisions</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#6-literature-mining-enhancement","title":"6. Literature Mining Enhancement","text":"<p>Enrichment analysis understanding improves literature-based curation: - Method recognition: Identifying which enrichment approaches authors used and their reliability implications - Result interpretation: Understanding when enrichment results support specific functional annotations vs. general pathway involvement - Critical evaluation: Recognizing common pitfalls in enrichment analysis that may lead to over-interpretation</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#7-systematic-bias-detection","title":"7. Systematic Bias Detection","text":"<p>The chapter's discussion of algorithmic biases informs annotation quality assessment: - Topology bias: Understanding how ontology structure affects both enrichment detection and annotation practices - Coverage bias: Recognizing that well-studied terms/pathways may appear artificially enriched - Method dependence: Appreciating how different computational approaches can yield different conclusions</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#8-quality-control-integration","title":"8. Quality Control Integration","text":"<p>Advanced enrichment methods provide models for sophisticated curation approaches: - Parent-child conditioning: Evaluating child term annotations in context of parent term evidence - Competitive assessment: Considering annotations in competitive framework where evidence supports most appropriate terms - Topology awareness: Accounting for ontological structure in annotation evaluation decisions</p>"},{"location":"paper/literature/Chapter_13_Gene_Category_Analysis-summary/#9-meta-analysis-capabilities","title":"9. Meta-Analysis Capabilities","text":"<p>Understanding enrichment analysis enables systematic evaluation of annotation literature: - Cross-study comparison: Evaluating consistency of functional assignments across different publications - Method bias recognition: Identifying when computational method artifacts may influence functional conclusions - Evidence synthesis: Integrating enrichment results with other evidence types for robust annotation decisions</p> <p>This comprehensive understanding of gene-category analysis provides both methodological foundation and practical tools for critically evaluating functional evidence in literature, helping distinguish genuine biological insights from computational artifacts or statistical anomalies.</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/","title":"Chapter 14: Gene Ontology: Pitfalls, Biases, and Remedies - Summary","text":"<p>Authors: Pascale Gaudet and Christophe Dessimoz</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive guide to understanding and mitigating the various pitfalls and biases inherent in Gene Ontology (GO) data and analyses. The authors systematically examine how GO's heterogeneous nature, despite efforts at normalization, can introduce considerable biases in large-scale analyses, and they provide practical solutions for addressing these challenges.</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#core-perspective-observational-vs-experimental-data","title":"Core Perspective: Observational vs. Experimental Data","text":"<p>Fundamental Distinction: The chapter establishes GO annotations as observational data rather than experimental data, with critical implications: - Experimental data: Controlled conditions where case and control groups differ only in the factor of interest - Observational data: Readily available data with potential unknown confounding factors - Critical implication: Testing and controlling for potential confounders becomes paramount</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#simpsons-paradox-and-data-aggregation-perils","title":"Simpson's Paradox and Data Aggregation Perils","text":"<p>Classic Example - Berkeley Gender Bias Case: - Aggregate data: 44% men admitted vs. 35% women (appeared discriminatory) - Department-level analysis: Similar admission rates for both sexes, even favoring women in most departments - True confounder: Women tended to apply to more competitive departments with lower admission rates - GO relevance: Heterogeneous GO data can manifest similar paradoxes, emphasizing need for confounder recognition</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#open-world-assumption-and-data-incompleteness","title":"Open World Assumption and Data Incompleteness","text":"<p>Core Principle: - Fundamental assumption: Absence of evidence \u2260 absence of function - Database scale: Over 210 million annotations currently, but incompleteness remains pervasive - Uneven distribution: More comprehensively annotated parts can present contradictory information - Evaluation impact: Can lead to inflated false positive rates in computational method assessment - Mitigation strategies: Annotation thinning, successive database release analysis</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#ontology-structure-pitfalls","title":"Ontology Structure Pitfalls","text":"<p>1. Relationship Transitivity Issues:</p> <p>Transitive relationships: - \"is a\" and \"part of\": Proteins annotated to specific terms implicitly annotated to all parents - Example: \"serine/threonine protein kinase activity\" \u2192 \"protein kinase activity\"</p> <p>Non-transitive relationships: - \"regulates\" relations: Semantics don't propagate to parents - Critical example: \"peptidase inhibitor activity\" connects to \"proteolysis\" via non-transitive \"negatively regulates\" - the protein does NOT mediate proteolysis</p> <p>2. Inter-ontology Links and Enrichment Impact: - Automatic annotation generation: \"part of\" relations across ontology aspects trigger additional annotations - Massive scale: 12 million annotations to 7 million proteins from these links - Volatility example: November 2011 loss of ~2,500 annotations to \"transcription, DNA-dependent\" due to single link removal - Analysis sensitivity: Can dramatically affect GO enrichment analyses and background distributions</p> <p>3. GO File Versions: - GO-basic: Completely acyclic, for applications requiring graph traversal - GO: Includes cross-hierarchy relationships (\"has part\", \"occurs in\") - GO-plus: Most complex, with external ontology connections and biological constraints</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#annotation-qualifiers-and-semantic-nuances","title":"Annotation Qualifiers and Semantic Nuances","text":"<p>Three Critical Qualifiers:</p> <p>1. \"NOT\" Qualifier: - Function: Indicates evidence that gene product lacks expected function - Usage cases: Missing active site residues, negative experimental results - Propagation pattern: Propagates to children terms, not parents (opposite of positive annotations) - Impact example: STRADA pseudokinase annotated as \"NOT protein kinase activity\"</p> <p>2. \"contributes to\" Qualifier: - Primary use: Molecular function distributed across complex subunits - Permissive usage: Sometimes applied to all complex subunits regardless of direct contribution - Interpretation challenge: May seem counterintuitive (e.g., cyclin with kinase activity annotation)</p> <p>3. \"co-localizes with\" Qualifier: - Dual meaning problem: Transient association OR experimental resolution limitation - Current limitation: Cannot distinguish between the two meanings in existing annotations</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#evidence-code-biases-and-reliability","title":"Evidence Code Biases and Reliability","text":"<p>Evidence Code Hierarchy by Reliability:</p> <p>1. Direct Evidence (IDA - Inferred from Direct Assay): - Highest reliability: Most direct protein-function implication - Limitation: Still doesn't guarantee specific mechanistic details</p> <p>2. Mutant Phenotype Evidence (IMP, IGI): - Utility: Excellent for pathway/process implication - Weakness: Inherently derivative, difficult to assess exact involvement mechanism - Same limitation: Genetic interaction evidence (IGI)</p> <p>3. Physical Interaction Evidence (IPI): - Strong for: Protein binding annotations, cellular component assignments - Weak for: Molecular functions and biological processes (\"guilt by association\") - Low confidence: Expression pattern evidence (IEP)</p> <p>4. High-throughput Experiment Biases: - Term bias: Tend toward high-level GO terms with limited functional diversity - Information content distortion: Artificial decrease due to frequent annotation - Database impact: ~25% of annotations from high-throughput papers - Current limitation: GO doesn't record high-throughput vs. focused study origin</p> <p>5. Electronic Annotation Methods: - Method diversity: InterPro domains, Enzyme Commission numbers, BLAST, orthology - Reference code tracking: Available but not integrated into standard evidence codes - Disproportionate impact: Large numbers can skew analyses - Normalization challenges: Multiple annotations to same term with different evidence</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#species-specific-and-systematic-biases","title":"Species-Specific and Systematic Biases","text":"<p>1. Species Research Focus Bias: - Zebrafish: Heavily developmental biology focused - Rat: Standard toxicology model - Implication: GO term frequencies vary dramatically across species - Solution: Use species-specific backgrounds for enrichment analyses</p> <p>2. Authorship Bias: - Striking finding: Annotations from same paper ~50\u00d7 more similar than different papers - Impact on evolution studies: Same-species paralogs appeared more functionally conserved than orthologs due to annotation source bias - Controlled analysis: Bias elimination revealed orthologs actually more conserved - Partial effect: Even different papers with common authors show increased similarity</p> <p>3. Annotator/Database Bias: - Example comparison: MGI vs. UniProt mouse annotations - Evidence code distribution: Similar overall (IMP most common), but different term focus - Specific divergences: MGI emphasizes \"in utero embryonic development\" (1,170 annotations); UniProt focuses on \"regulation of circadian rhythm\" - Implication: Annotations biased toward specific biological aspects, not uniform representation</p> <p>4. Propagation Bias (Electronic vs. Experimental): - Observation: Electronic annotations show higher similarity between homologs than experimental annotations - Explanation: Electronic methods infer annotations among homologous sequences, artificially inflating functional similarity - Analysis caution: Problematic when comparing model organisms (experimental-rich) with non-model organisms (electronic-rich)</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#advanced-bias-categories","title":"Advanced Bias Categories","text":"<p>1. Annotation Extensions: - New mechanism: Increased expressivity through contextual information - Examples: Location specificity (retinal ganglion cells), dynamic localization (mitotic anaphase), enzyme substrates - Current challenges: Inconsistent implementation across databases, guidelines still developing - Analysis impact: Creates \"virtual\" GO classes, substantial annotation inflation potential</p> <p>2. Positive/Negative Annotation Imbalance: - Scale: &lt;1% of experimental annotations are negative in UniProt-GOA - Publication bias: Negative results less publishable, harder to establish experimentally - Machine learning impact: Class imbalance problems, metric reliability issues - Evaluation effects: Particularly problematic under Open World Assumption</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#remedies-and-best-practices-framework","title":"Remedies and Best Practices Framework","text":"<p>1. Data Completeness Management: - Acknowledge incompleteness: Don't assume absence of annotation implies absence of function - Impact assessment: Use annotation thinning or successive database releases to gauge incompleteness effects - Open World Assumption: Always consider in evaluation frameworks</p> <p>2. Structural Relationship Handling: - Transitivity awareness: Understand which relationships propagate annotations (\"is a\", \"part of\") vs. which don't (\"regulates\") - Graph file selection: Use GO-basic for acyclic requirements, GO-plus for full expressivity - Inter-ontology link tracking: Monitor database releases for structural changes affecting analyses</p> <p>3. Enrichment Analysis Robustness: - Background specification: Use appropriate, consistent background distributions - Multiple release validation: Ensure conclusions hold across recent database versions - Tool currency: Avoid outdated tools (example: DAVID not updated since 2009) - Current recommendation: PantherDB GO analysis service for up-to-date analyses</p> <p>4. Evidence Code Stratification: - Code-aware analysis: Consider evidence type distribution in statistical analyses - Bias control: Account for high-throughput vs. focused study differences - Multiple evidence integration: Appropriately normalize when genes have multiple evidence types for same term</p> <p>5. Species and Systematic Bias Control: - Species-specific analysis: Use organism-appropriate backgrounds and term frequencies - Authorship bias mitigation: Control for publication source in analyses with varying paper origin distributions - Annotator bias awareness: Understand database-specific annotation focus patterns</p> <p>6. Qualifier Integration: - Mandatory consideration: Always account for NOT, \"contributes to\", and \"co-localizes with\" qualifiers - Tool verification: Ensure analysis software properly handles qualifiers - Semantic precision: Understand qualifier-specific propagation patterns</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#comprehensive-pitfall-summary-table","title":"Comprehensive Pitfall Summary Table","text":"<p>The chapter provides an extensive table of 13 major pitfalls with specific remedies:</p> <ol> <li>Open World Assumption violations \u2192 Impact assessment and incompleteness acknowledgment</li> <li>Transitivity misunderstanding \u2192 Relationship-aware reasoning</li> <li>Background distribution errors \u2192 Consistent database versions and appropriate backgrounds</li> <li>Inter-ontology link volatility \u2192 Database release tracking</li> <li>Qualifier ignorance \u2192 Mandatory qualifier consideration</li> <li>Evidence code bias \u2192 Stratified analysis approaches</li> <li>Species research bias \u2192 Species-specific frequency usage</li> <li>Authorship bias \u2192 Publication source control</li> <li>Propagation bias \u2192 Experimental annotation restriction for evolution studies</li> <li>Positive/negative imbalance \u2192 Separate rate consideration and focused subset analysis</li> </ol>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides fundamental guidance for understanding and addressing the systematic biases that contribute to over-annotation problems in our gene curation workflow:</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#1-over-annotation-source-identification","title":"1. Over-Annotation Source Identification","text":"<p>The chapter's bias catalog directly maps to over-annotation mechanisms: - Electronic annotation propagation bias: Explains why electronic annotations (IEA) often appear inflated among homologs - High-throughput experiment bias: Identifies why certain terms become over-represented in databases - Authorship bias: Explains clustering of similar annotations from same research groups, leading to apparent functional convergence</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#2-evidence-quality-assessment-framework","title":"2. Evidence Quality Assessment Framework","text":"<p>The evidence code hierarchy provides structured approach to annotation evaluation: - IDA (Direct Assay): Highest confidence, ACCEPT unless contradicted - IMP/IGI (Phenotype/Interaction): Moderate confidence, require mechanistic validation - IPI (Physical Interaction): Context-dependent, strong for binding/localization, weak for molecular functions - IEP (Expression Pattern): Low confidence, often suitable for REMOVE actions - Electronic methods: Systematic over-annotation risk, requiring careful evaluation</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#3-systematic-bias-recognition-in-literature","title":"3. Systematic Bias Recognition in Literature","text":"<p>Understanding systematic biases helps identify over-annotation patterns in publications: - Same-paper bias: Multiple annotations from single publication may reflect methodological artifacts rather than true functional diversity - Species research focus: Over-representation of certain functional categories due to model organism specializations - High-throughput study bias: Shallow, broad annotations rather than specific, mechanistic insights</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#4-qualifier-based-curation-precision","title":"4. Qualifier-Based Curation Precision","text":"<p>The chapter's qualifier analysis directly supports sophisticated curation decisions: - \"NOT\" annotations: Critical for identifying proteins that lack expected homolog functions (STRADA pseudokinase example) - \"contributes to\": Helps distinguish direct catalytic activity from regulatory/structural roles - \"co-localizes with\": Enables recognition of transient vs. permanent associations</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#5-open-world-assumption-application","title":"5. Open World Assumption Application","text":"<p>Critical for avoiding over-interpretation of database completeness: - Annotation absence interpretation: Cannot conclude functional absence from annotation absence - Comparative analysis caution: Different annotation coverage across genes may reflect curation history rather than functional differences - Negative annotation scarcity: &lt;1% negative annotations suggests systematic under-representation of negative results</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#6-enrichment-analysis-sophistication","title":"6. Enrichment Analysis Sophistication","text":"<p>Insights for evaluating functional coherence in gene annotation sets: - Background distribution criticality: Inappropriate backgrounds can create false functional enrichments - Inter-ontology link awareness: Automatic annotation generation can inflate apparent functional complexity - Species-specific analysis: Essential for appropriate functional characterization</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#7-transitivity-aware-annotation-evaluation","title":"7. Transitivity-Aware Annotation Evaluation","text":"<p>Structural relationship understanding prevents logical errors: - \"is a\"/\"part of\" transitivity: Specific annotations imply general annotations - \"regulates\" non-transitivity: Regulatory relationships don't propagate through hierarchies (peptidase inhibitor \u2260 proteolysis mediator) - Cross-ontology propagation: Molecular function annotations can automatically generate process annotations</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#8-electronic-annotation-skepticism-framework","title":"8. Electronic Annotation Skepticism Framework","text":"<p>Systematic approach to IEA evaluation based on propagation bias understanding: - Homology inference bias: Electronic annotations artificially inflate similarity between related genes - Method-specific evaluation: Different electronic methods (InterPro, orthology, BLAST) have distinct error profiles - Model vs. non-model organism considerations: Electronic annotation proportion varies dramatically</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#9-multi-evidence-integration","title":"9. Multi-Evidence Integration","text":"<p>Framework for handling conflicting or redundant evidence: - Evidence code weighting: Appropriate confidence assignment based on experimental directness - Contradictory result interpretation: Understanding when conflicts reflect genuine biological complexity vs. methodological differences - Multiple annotation normalization: Avoiding artificial inflation when same function supported by multiple evidence types</p>"},{"location":"paper/literature/Chapter_14_GO_Pitfalls_Biases_Remedies-summary/#10-temporal-and-database-evolution-awareness","title":"10. Temporal and Database Evolution Awareness","text":"<p>Understanding how annotation landscapes change over time: - Database release sensitivity: Major structural changes can affect annotation sets dramatically - Annotation accumulation patterns: New experimental evidence tends to confirm rather than contradict existing annotations - Tool currency requirements: Outdated analysis tools can provide misleading results due to structural changes</p> <p>This comprehensive understanding of GO biases and pitfalls provides essential foundation for implementing sophisticated over-annotation detection that distinguishes genuine biological complexity from systematic artifacts, methodological biases, and database incompleteness effects. The chapter's remedies directly inform our curation decision framework and quality control approaches.</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/","title":"Chapter 15: Visualizing GO Annotations - Summary","text":"<p>Authors: Fran Supek and Nives \u0160kunca</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive survey of methods and tools for visualizing large lists of Gene Ontology (GO) terms, addressing the critical challenge of interpreting complex functional annotation data from high-throughput biological experiments. The authors systematically catalog available visualization approaches, demonstrate their practical applications, and provide guidance for selecting appropriate methods based on analytical goals.</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#core-challenge-making-sense-of-go-enrichment-results","title":"Core Challenge: Making Sense of GO Enrichment Results","text":"<p>The Fundamental Problem: High-throughput experiments (RNA-Seq, microarrays, comparative genomics) generate large gene lists that require functional interpretation through GO enrichment analysis. However, these analyses typically produce flat lists of significant GO terms that fail to capture: - Hierarchical relationships between terms - Functional redundancy among related terms - Relative importance of different biological themes - Systematic patterns across related functions</p> <p>Scale and Complexity Issues: - GO contains thousands of terms in complex hierarchical structure - Enrichment analyses often yield dozens to hundreds of significant terms - Inherent redundancy due to GO's exhaustive functional description design - Coordinated biological responses involve multiple overlapping subsystems</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#systematic-tool-classification","title":"Systematic Tool Classification","text":"<p>1. Interactive GO Browsers: - Purpose: General GO browsing and gene annotation exploration - Limitation: No integration of user-supplied experimental data - Examples: AmiGO, QuickGO, OLSVis - Use case: Background GO exploration, not results visualization</p> <p>2. Network Visualization Tools: - Purpose: General graph display capable of showing GO structure - Advantage: Highly configurable visualization options - Limitation: Not GO-specific, more complex to use - Examples: Cytoscape, Gephi, Pajek - Specialized plugins: EnrichmentMap, BINGO (Cytoscape-specific)</p> <p>3. GO Visual Overlays: - Purpose: Display GO subset with experimental data overlays - Method: Color terms by enrichment p-values, show parent-child relationships - Layout: Tree-like arrangement reflecting hierarchy - Examples: GOrilla, GRYFUN, GOFFA, SimCT - Related approaches: KEGG pathway highlighting, FuncTree hierarchy</p> <p>4. Semantic Similarity Analysis: - Purpose: Address redundancy through term clustering and filtering - Method: Group similar terms, remove redundant ones, prioritize by significance - Key insight: Some GO terms are functionally similar despite not being directly connected - Examples: REVIGO, RedundancyMiner - Related tools: g:Profiler (collapses similar terms), Ontologizer (parent-child statistical tests)</p> <p>5. Emerging Methods: - Tag clouds: Text-based visualization with size/color indicating importance - Tree maps: Hierarchical colored tiles for interactive exploration - Multi-experiment displays: Side-by-side comparison capabilities - Examples: REVIGO (multiple visualizations), GOSummaries, BACA</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#detailed-case-studies","title":"Detailed Case Studies","text":"<p>GOrilla Analysis Pipeline: - Input: Ranked gene list or target/background gene sets - Method: Statistical test for position-dependent enrichment in ranked lists - Output: Hierarchical display with color-coded significance - Example dataset: Human blood cell response to Staphylococcus aureus - Results: Tree visualization showing enriched immune response terms</p> <p>REVIGO Redundancy Reduction: - Input: GO terms with p-values from enrichment analysis - Process: Semantic similarity clustering, representative term selection - Output styles:   - Scatterplot: 2D semantic similarity space with bubble sizes   - Interactive graph: Connected terms showing GO hierarchy   - TreeMap: Hierarchical colored tiles for exploration   - Word cloud: Frequent keywords from term names/descriptions - Integration: Direct import from GOrilla results</p> <p>RedundancyMiner Statistical Approach: - Method: Fisher's exact tests between all term pairs - Analysis: Gene set overlap significance testing - Output: Clustered Image Map (CIM) showing term independence - Process: GOminer input \u2192 RedundancyMiner analysis \u2192 CIMminer visualization - Focus: Most independent, least redundant term sets</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#visualization-method-categories","title":"Visualization Method Categories","text":"<p>1. Graphs/Networks: - Structure: Nodes (terms) connected by edges (relationships) - Attributes: Node colors (enrichment), edge types (is_a, part_of) - Layout importance: Spatial arrangement suggests functional clustering - Tree-like displays: Emphasize hierarchical levels and parent-child relationships - Depth limitation: GO levels may not reflect biological generality - Recommendation: Use Information Content (IC) rather than graph depth</p> <p>2. Semantic Similarity Space: - Method: Mathematical similarity measures between term pairs (SimRel, others) - Processing: Principal Components Analysis (PCA) or multidimensional scaling - Result: 2D projection preserving pairwise distances - Implementation: REVIGO scatterplot visualization - Advantage: Reveals functional relationships beyond direct hierarchical connections</p> <p>3. TreeMaps: - Structure: Hierarchical tiles subdivided into smaller tiles - Interaction: Click-to-zoom revealing finer subdivisions - Mapping: Tiles = GO terms, subdivisions = child terms - Size encoding: Term importance (enrichment, p-values) - Example: REVIGO TreeMap implementation</p> <p>4. Word Clouds: - Display: Text in various sizes and colors - Content: GO term names or associated keywords - Encoding: Size/color reflects importance or generality - Information Content application: Can encode term specificity - Implementations: GOSummaries, REVIGO</p> <p>5. Clustered Heatmaps: - Structure: 2D grids with clustered rows/columns - Application: Show term similarity based on shared genes or semantic relationships - Advantage: Reveals block structure in similarity data - Implementation: RedundancyMiner CIM approach - Biological relevance: Rare application to GO terms specifically</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#best-practices-and-selection-guidance","title":"Best Practices and Selection Guidance","text":"<p>Avoiding Interpretation Bias: - Problem: Researchers may cherry-pick familiar terms that \"make sense\" - Solution: Systematic visualization reveals complete functional landscape - Benefit: Unbiased algorithmic organization prevents expectation-driven selection</p> <p>Communication and Discovery: - Scientific communication: Effective for papers, presentations, posters - Pattern recognition: Helps identify dominant biological themes - Hypothesis generation: Reveals unexpected functional connections</p> <p>Tool Selection Criteria: - Data complexity: Simple lists vs. hierarchical relationships - Redundancy issues: Need for similarity-based filtering - Interaction requirements: Static display vs. interactive exploration - Integration needs: Single experiment vs. multi-experiment comparison</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#future-directions-and-challenges","title":"Future Directions and Challenges","text":"<p>Anticipated Developments: 1. Larger datasets: Increased statistical power will generate longer significant term lists 2. Multi-experiment integration: Tools needed for cross-experiment pattern extraction 3. Ontology expansion: Over 100 biomedical ontologies beyond GO requiring similar approaches 4. Refinement needs: Better redundancy reduction methods for massive term lists</p> <p>Technical Evolution: - Real-time analysis: Integration with high-throughput experimental pipelines - Cross-ontology visualization: Environmental, phenotype, chemical entity ontologies - Machine learning integration: Automated pattern recognition in functional landscapes</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential guidance for developing sophisticated approaches to visualize and interpret functional annotation patterns, directly supporting our over-annotation detection and curation efforts:</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#1-over-annotation-pattern-visualization","title":"1. Over-Annotation Pattern Visualization","text":"<p>The chapter's approaches directly apply to identifying over-annotation patterns: - Semantic similarity clustering: Can reveal groups of highly similar annotations that may represent over-annotation of the same underlying function - Hierarchical displays: Help identify inappropriate annotation at multiple hierarchy levels (shallow annotation problem) - Redundancy detection: REVIGO and RedundancyMiner approaches can systematically identify functionally redundant annotation sets</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#2-systematic-bias-recognition-through-visualization","title":"2. Systematic Bias Recognition Through Visualization","text":"<p>Visualization methods enable detection of systematic annotation biases: - Clustering analysis: Can reveal whether annotations cluster around specific functional themes vs. being appropriately distributed - Information content analysis: Helps identify whether annotations are appropriately specific vs. overly general or overly specific - Multi-experiment comparison: Techniques for side-by-side analysis can identify annotation consistency across different evidence sources</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#3-evidence-quality-assessment-integration","title":"3. Evidence Quality Assessment Integration","text":"<p>Visualization approaches support evidence-based curation decisions: - Color-coding by evidence type: Adapting enrichment visualization to show evidence codes can reveal over-annotation patterns in IEA vs. experimental annotations - Hierarchical evidence display: Showing how different evidence types distribute across GO hierarchy levels - Temporal analysis: Visualizing annotation changes over time to identify systematic addition patterns</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#4-functional-coherence-evaluation","title":"4. Functional Coherence Evaluation","text":"<p>The chapter's methods support assessment of annotation set appropriateness: - Semantic similarity assessment: Quantitative approaches to measure whether a gene's annotation set shows appropriate functional coherence - Outlier detection: Visual identification of annotations that don't fit with a gene's primary functional profile - Specificity analysis: Information content-based approaches to ensure annotation specificity is appropriate</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#5-curation-decision-support","title":"5. Curation Decision Support","text":"<p>Visualization techniques can enhance systematic curation workflows: - Interactive exploration: Tools like REVIGO's multiple visualization modes support detailed annotation examination - Comparative analysis: Side-by-side visualization of different annotation sources (literature vs. computational) to identify discrepancies - Quality control dashboards: Adapting enrichment visualization approaches for systematic curation monitoring</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#6-literature-based-annotation-integration","title":"6. Literature-Based Annotation Integration","text":"<p>Visualization methods support integration of literature-derived functional insights: - Publication-based clustering: Adapting authorship bias visualization (from Chapter 14) to identify literature-derived functional themes - Evidence source comparison: Visualizing how literature-based annotations compare with existing database annotations - Citation network analysis: Applying network visualization to understand functional annotation provenance</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#7-gene-family-and-ortholog-analysis","title":"7. Gene Family and Ortholog Analysis","text":"<p>The chapter's approaches support comparative functional analysis: - Cross-species visualization: Adapting tools to show functional annotation conservation and divergence - Family-level analysis: Using clustering approaches to identify functional annotation consistency within gene families - Evolutionary annotation patterns: Visualizing how annotations change across evolutionary distances</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#8-quality-metrics-development","title":"8. Quality Metrics Development","text":"<p>Visualization approaches inform quantitative quality assessment: - Redundancy metrics: REVIGO's semantic similarity measures can be adapted for annotation quality scoring - Specificity assessment: Information content calculations can provide objective measures of annotation appropriateness - Coherence scoring: Cluster analysis approaches can quantify functional annotation set coherence</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#9-automated-over-annotation-detection","title":"9. Automated Over-Annotation Detection","text":"<p>The chapter's systematic approaches enable automated quality control: - Clustering-based detection: Identifying genes with unusually high annotation clustering in specific functional areas - Similarity-based filtering: Using semantic similarity to identify potentially redundant annotations - Statistical significance testing: Adapting enrichment analysis methods to identify statistically unusual annotation patterns</p>"},{"location":"paper/literature/Chapter_15_Visualizing_GO_Annotations-summary/#10-communication-and-validation","title":"10. Communication and Validation","text":"<p>Visualization methods support curation workflow communication: - Decision documentation: Visual summaries of curation decisions showing before/after annotation landscapes - Expert consultation: Tools for presenting complex annotation patterns to domain experts for validation - Training and education: Visual approaches for demonstrating over-annotation concepts to new curators</p> <p>This comprehensive understanding of GO visualization methods provides essential tools for implementing sophisticated, visually-informed approaches to annotation quality assessment that can systematically identify over-annotations while supporting evidence-based curation decisions through clear, interpretable displays of complex functional relationships.</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/","title":"Chapter 16: A Gene Ontology Tutorial in Python - Summary","text":"<p>Authors: Alex Warwick Vesztrocy and Christophe Dessimoz</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#summary","title":"Summary","text":"<p>This chapter provides a comprehensive hands-on tutorial for working with Gene Ontology (GO) resources in Python, covering fundamental operations including GO graph querying, annotation retrieval, enrichment analysis, and semantic similarity computation. The tutorial demonstrates practical programming approaches using established Python libraries, particularly GOATOOLS and BioPython, with concrete examples and exercises.</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#core-programming-infrastructure","title":"Core Programming Infrastructure","text":"<p>GOATOOLS Library: - Primary tool: Python package for GO structure manipulation and analysis - Installation: Available via PyPI (<code>pip install goatools</code>) - Key capabilities: Parse OBO format files, query GO structure, visualize ontology graphs - Version specificity: Tutorial uses version 0.6.4 for consistency</p> <p>Alternative Access Methods: - Web services: QuickGO API for individual term queries - File formats: Direct OBO file processing vs. HTTP requests - Trade-offs: Bulk analysis (file-based) vs. targeted queries (web-based)</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#go-structure-querying-and-navigation","title":"GO Structure Querying and Navigation","text":"<p>GOTerm Class Attributes: - name: Textual definition of the term - namespace: Ontology category (MF, BP, CC) - parents: List of immediate parent terms - children: List of immediate child terms - level: Shortest distance to root node</p> <p>Programming Operations: - Recursive traversal: Finding all ancestors and descendants - Search functionality: Term identification by name patterns - Relationship analysis: Understanding \"is_a\" vs. regulatory relationships - Visualization: Lineage plotting using GOTerm.draw_lineage()</p> <p>Advanced Features: - Relationship loading: Optional attributes for complex relationships - Common ancestor identification: Deepest common ancestor calculations - Regulatory term finding: Identifying regulation relationships</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#alternative-data-access-quickgo-web-services","title":"Alternative Data Access: QuickGO Web Services","text":"<p>HTTP-Based Queries: - URL format: <code>http://www.ebi.ac.uk/QuickGO/GTerm?id=&lt;GO_ID&gt;&amp;format=oboxml</code> - Response format: OBO-XML structure - Python implementation: Using urllib and xmltodict libraries - Advantages: No local file storage, always current data - Disadvantages: Network dependency, slower for bulk operations</p> <p>Data Structure: - Hierarchical dictionary: Parsed XML provides nested access - Variable content: Information richness depends on term complexity - Visualization: Dictionary structure can be mapped for understanding</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#go-annotations-processing","title":"GO Annotations Processing","text":"<p>Gene Association File (GAF) Handling: - BioPython integration: Bio.UniProt.GOA.gafiterator - Standard format: GAF 2.1 with 17 tab-delimited fields - Key fields:   - DB: Protein database identifier   - DB_Object_ID: Protein ID   - Qualifier: Annotation qualifiers (NOT, etc.)   - GO_ID: Associated GO term   - Evidence: Evidence code</p> <p>Practical Applications: - Data extraction: Iterating through annotation files - Filtering operations: Finding specific annotations or evidence types - Statistical analysis: Counting annotations by various criteria - Quality assessment: Analyzing NOT qualifiers and evidence code distributions</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#enrichment-analysis-implementation","title":"Enrichment Analysis Implementation","text":"<p>GOEnrichmentStudy Function Parameters: 1. Background set: Population terms for statistical comparison 2. Associations: Dictionary mapping protein IDs to GO term sets 3. GO structure: Parsed ontology from obo_parser() 4. Propagation settings: Boolean for parent term propagation 5. Significance level: Alpha cutoff (default 0.05) 6. Study set: Foreground terms for comparison 7. Statistical methods: Multiple correction approaches available</p> <p>Multiple Testing Corrections: - bonferroni: Conservative family-wise error rate control - sidak: \u0160id\u00e1k correction for multiple testing - holm: Step-down Holm-Bonferroni method - fdr: False discovery rate control (Benjamini-Hochberg)</p> <p>Output Analysis: - Over-represented terms: Statistically enriched GO categories - Under-represented terms: Statistically depleted categories - Significance assessment: P-values with multiple correction options</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#semantic-similarity-computation","title":"Semantic Similarity Computation","text":"<p>Graph-Based Measures: - Distance calculation: Minimum edges between terms via deepest common ancestor - Formula: <code>min_distance(t1, t2) = depth(t1) + depth(t2) - 2 \u00d7 depth(tDCA)</code> - Inverse similarity: 1/distance as similarity measure - Structural dependency: Based only on ontology graph structure</p> <p>Information-Theoretic Measures: - Resnik similarity: Information content of most informative common ancestor - Information content: <code>-log(probability)</code> based on annotation frequency - Database dependency: Requires annotation corpus for probability estimation - Enhanced accuracy: Accounts for term usage patterns beyond structure</p> <p>Computational Implementation: - Common ancestor finding: Algorithmic identification of shared parents - Depth calculations: Graph traversal for distance measurements - Probability estimation: Frequency analysis from annotation databases - Comparative analysis: Multiple similarity measures for validation</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#practical-exercise-framework","title":"Practical Exercise Framework","text":"<p>Structured Learning Path: 1. Basic querying: Term lookup and relationship exploration 2. Visualization: Graph plotting and structure understanding 3. Annotation analysis: File processing and statistical summaries 4. Enrichment testing: Hypothesis testing with multiple corrections 5. Similarity computation: Quantitative functional relationship assessment</p> <p>Real Data Integration: - Arabidopsis thaliana: Model organism with comprehensive annotations - UniProt-GOA: Standard annotation database for examples - GO basic file: Simplified ontology structure for learning</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential technical foundation for implementing sophisticated computational approaches to GO annotation analysis and quality assessment:</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#1-automated-quality-control-infrastructure","title":"1. Automated Quality Control Infrastructure","text":"<p>The tutorial's programming approaches directly support systematic annotation analysis: - Bulk processing capabilities: GOATOOLS enables analysis of entire annotation sets for systematic over-annotation detection - Relationship traversal: Recursive parent/child finding supports identification of annotation redundancy across hierarchy levels - Statistical framework: Enrichment analysis methods provide quantitative approaches to assess annotation appropriateness</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#2-evidence-code-analysis-integration","title":"2. Evidence Code Analysis Integration","text":"<p>Programming techniques support systematic evidence evaluation: - GAF parsing: BioPython integration enables systematic analysis of evidence code patterns across genes - NOT qualifier analysis: Tools for identifying and quantifying negative annotations that contradict over-annotation patterns - Evidence stratification: Programmatic approaches to separate experimental vs. computational annotations for quality assessment</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#3-semantic-similarity-for-over-annotation-detection","title":"3. Semantic Similarity for Over-Annotation Detection","text":"<p>Similarity computation methods directly support redundancy identification: - Graph-based measures: Distance calculations can identify annotations that are too similar (potential redundancy) - Information-theoretic approaches: IC-based measures help distinguish genuinely specific annotations from inappropriately general ones - Comparative analysis: Multiple similarity measures enable robust assessment of functional annotation coherence</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#4-enrichment-analysis-for-functional-coherence","title":"4. Enrichment Analysis for Functional Coherence","text":"<p>Statistical methods support systematic annotation set evaluation: - Background comparison: Using species-specific annotation sets as backgrounds for assessing individual gene annotation appropriateness - Multiple testing awareness: Understanding correction methods crucial for avoiding false discovery in over-annotation detection - Study set definition: Techniques for defining appropriate comparison groups for annotation quality assessment</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#5-programmatic-literature-integration","title":"5. Programmatic Literature Integration","text":"<p>Web service integration supports dynamic annotation validation: - QuickGO integration: Real-time access to current GO term information for validation against literature findings - API-based validation: HTTP requests enable checking annotation currency and accuracy - Cross-reference validation: Web services provide additional metadata for annotation assessment</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#6-systematic-bias-detection","title":"6. Systematic Bias Detection","text":"<p>Programming approaches enable identification of systematic annotation problems: - Pattern recognition: Bulk processing enables identification of genes with unusual annotation patterns - Statistical outliers: Enrichment methods can identify genes with statistically unusual functional annotation profiles - Hierarchy analysis: Relationship traversal enables detection of inappropriate annotation at multiple ontology levels</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#7-quality-metrics-development","title":"7. Quality Metrics Development","text":"<p>Technical infrastructure supports quantitative quality assessment: - Similarity scoring: Semantic similarity measures provide objective metrics for annotation set coherence - Statistical significance: Enrichment analysis provides p-values for annotation appropriateness - Evidence integration: Multi-source data integration enables comprehensive quality scoring</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#8-scalable-curation-support","title":"8. Scalable Curation Support","text":"<p>Programming infrastructure enables large-scale curation workflows: - Batch processing: File-based approaches support analysis of hundreds of genes systematically - Automated flagging: Statistical methods enable automatic identification of genes requiring manual review - Priority ranking: Quantitative measures enable prioritization of curation efforts</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#9-interactive-validation-tools","title":"9. Interactive Validation Tools","text":"<p>Tutorial approaches support development of curation interfaces: - Visualization integration: Graph plotting capabilities support interactive annotation exploration - Real-time analysis: Web service integration enables dynamic annotation checking during curation - Comparative display: Multiple data source integration supports side-by-side evidence evaluation</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#10-integration-with-bioinformatics-workflows","title":"10. Integration with Bioinformatics Workflows","text":"<p>Python infrastructure enables integration with broader analysis pipelines: - Domain analysis integration: GO analysis can be combined with protein domain analysis for comprehensive functional assessment - Expression data integration: Enrichment analysis methods can incorporate expression data for functional validation - Evolutionary analysis: Similarity measures support comparative functional analysis across species</p>"},{"location":"paper/literature/Chapter_16_GO_Tutorial_Python-summary/#11-educational-and-training-applications","title":"11. Educational and Training Applications","text":"<p>Tutorial approaches support curation training and quality control: - Systematic examples: Structured exercises provide templates for training new curators - Quality benchmarks: Statistical measures provide objective standards for annotation quality - Best practices demonstration: Code examples illustrate proper approaches to annotation analysis</p> <p>This comprehensive programming foundation enables development of sophisticated, scalable approaches to annotation quality assessment that can systematically identify over-annotations while supporting evidence-based curation decisions through quantitative analysis of functional relationships, statistical significance, and semantic coherence.</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/","title":"Chapter 17: Annotation Extensions - Summary","text":"<p>Authors: Rachael P. Huntley and Ruth C. Lovering</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#summary","title":"Summary","text":"<p>This chapter describes annotation extensions, a significant advancement in Gene Ontology annotation expressivity that enables curators to capture contextual information beyond the basic gene product-GO term pairing. The authors present the technical framework, practical applications, and analytical benefits of this enhanced annotation model, which addresses a major limitation of traditional GO annotations by incorporating physiologically relevant contextual detail.</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#core-problem-limited-expressivity-of-basic-go-annotations","title":"Core Problem: Limited Expressivity of Basic GO Annotations","text":"<p>Historical Limitations: The original GO annotation format was intentionally designed for simplicity to encourage adoption, but this created significant constraints: - Basic model: Simple gene product \u2194 GO term pairs treated independently - Lost contextual information: No mechanism to capture experimental context, targets, or physiological conditions - Analysis limitations: Vast amounts of correlated functional data omitted from basic annotations - Network analysis gaps: Inability to identify condition-specific or tissue-specific gene product roles</p> <p>Real-World Impact: - Tissue-specific function: LEF1 transcription factor shows different functional associations in blood vessels (angiogenesis) vs. hypothalamus (hypothalamus development) - Conditional activity: Gene products performing roles only under specific conditions cannot be distinguished from constitutively active ones - Pathway connectivity: Missing directional information prevents accurate network reconstruction</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#technical-implementation-virtual-term-creation","title":"Technical Implementation: Virtual Term Creation","text":"<p>Core Concept: Annotation extensions enable dynamic creation of \"virtual\" GO terms by combining: - Primary term: Base GO term from standard ontology - Contextual relationships: Additional relationships to other ontology classes - Computational interpretation: Reproducible, logically equivalent to creating new ontology terms</p> <p>Example Transformation: - Basic: \"core RNA polymerase binding transcription factor activity\" - Extended: \"core RNA polymerase binding transcription factor in hypothalamus\" - Result: Virtual subclass with specific locational context</p> <p>Technical Advantages: - Immediate availability: No waiting for new terms to be added to ontology - Flexibility: On-demand creation of complex, compound child terms - Integration: Previously independent annotation and ontology development processes now unified - Efficiency: Eliminates need to return and update annotations after term creation</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#annotation-extension-format-and-structure","title":"Annotation Extension Format and Structure","text":"<p>Basic Syntax: - Format: Relation(Entity) - Example: part_of(GO:0005634) where GO:0005634 = \"nucleus\" - Components: Relation label + Entity identifier</p> <p>Relation Categories:</p> <p>1. Molecular Relations: - Entities: Genes, gene products, complexes, chemicals - Examples: has_direct_input, has_regulation_target, has_input - Applications: Enzyme targets, regulatory relationships, substrate specification</p> <p>2. Contextual Relations: - Entities: Cell types, anatomy terms, developmental stages, GO terms - Examples: part_of, occurs_in, happens_during, exists_during - Applications: Location specification, temporal context, developmental stage</p> <p>Validation Rules: - Controlled vocabularies: Specific ontologies required for different relation types - Cell Type Ontology (CL): For cellular context - Uber Anatomy Ontology (Uberon): For anatomical features - Plant Ontology (PO): For plant-specific contexts - ChEBI: For chemical entities - Curation tool integration: Rules prevent invalid annotation creation</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#practical-applications-and-examples","title":"Practical Applications and Examples","text":"<p>1. Enzyme Target Specification: - Problem: Basic annotation cannot capture enzyme-substrate relationships - Solution: has_direct_input relation specifies molecular targets - Example: MAPKAP-K2 protein serine/threonine kinase \u2192 has_direct_input(CapZIP) - Impact: Enables directional network analysis and pathway reconstruction</p> <p>2. Anatomical Context: - Problem: Basic annotations lack tissue/cell-type specificity - Solution: occurs_in relation specifies functional location - Example: Dhfr dihydrofolate reductase activity \u2192 occurs_in(neuron) - Impact: Enables tissue-specific functional analysis</p> <p>3. Temporal Specification: - Problem: Basic annotations cannot capture developmental timing - Solution: exists_during relation specifies developmental stages - Example: PAXT-1 nucleus localization \u2192 exists_during(embryo) - Impact: Enables stage-specific functional analysis</p> <p>4. Complex Multi-Relational Statements: - Comma separation (AND): Co-occurring conditions - Pipe separation (OR): Independent conditions - Example: miR-145 mRNA binding \u2192 has_direct_input(POU5F1), occurs_in(embryonic stem cell), part_of(negative regulation of somatic stem cell division) - Impact: Captures complete functional context in single annotation</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#analytical-benefits-and-use-cases","title":"Analytical Benefits and Use Cases","text":"<p>Advanced Query Capabilities: - Cell-type filtering: Find gene products active in specific tissues - Regulatory network construction: Identify transcription factor targets in specific contexts - Pathway analysis: Determine active components in particular cell types - Temporal analysis: Examine stage-specific functional roles</p> <p>Network Analysis Enhancement: - Directional relationships: has_input and has_direct_input enable pathway directionality - Context-specific networks: Different cell types show different active pathway components - Substrate specification: Enzyme-substrate relationships enable metabolic network reconstruction</p> <p>Bias Reduction: - Context awareness: Distinguish active vs. inactive gene products in specific conditions - Complete data representation: Include previously omitted contextual information - Analysis accuracy: Reduce interpretation bias from incomplete functional data</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#data-access-and-integration","title":"Data Access and Integration","text":"<p>File Format Integration: - GAF 2.0: Column 16 contains annotation extensions - GPAD: Column 11 contains extension data - Availability: GOC and GOA websites provide updated files</p> <p>Browser Integration: - QuickGO: Filtering and display of extended annotations - AmiGO 2: Advanced search with extension-based filtering - PomBase: Specialized display for model organism data</p> <p>Computational Analysis: - Plain text format: Compatible with computational analysis - Programmatic access: API integration for automated processing - Tool development: Foundation for enhanced analysis software</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#implementation-status-and-evolution","title":"Implementation Status and Evolution","text":"<p>Current State: - Manual curation: Extensions currently limited to manually curated annotations - Electronic annotation: IEA pipelines do not yet populate extension fields - Community adoption: Growing use across major annotation databases</p> <p>Future Development: - Community feedback: Ongoing evolution based on user needs - Extended vocabularies: Addition of new relation types as required - Tool enhancement: Improved software support for extension-based analysis</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides crucial insights for enhancing the specificity and context-awareness of our annotation curation and over-annotation detection efforts:</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#1-enhanced-annotation-quality-assessment","title":"1. Enhanced Annotation Quality Assessment","text":"<p>Annotation extensions provide new dimensions for evaluating annotation appropriateness: - Context validation: Extensions can help validate whether annotations are physiologically relevant in specific contexts - Specificity assessment: Extended annotations provide more specific functional descriptions that can be compared against literature evidence - Relationship verification: Molecular relations (has_direct_input, etc.) enable verification of functional relationships described in literature</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#2-over-annotation-detection-through-context-analysis","title":"2. Over-Annotation Detection Through Context Analysis","text":"<p>Extension data offers new approaches to identify inappropriate annotations: - Context mismatch: Annotations lacking appropriate contextual extensions may indicate over-generalization - Relationship gaps: Missing molecular target relationships may suggest incomplete or over-simplified annotations - Temporal inconsistencies: Annotations without appropriate developmental or conditional context may be over-broad</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#3-literature-integration-enhancement","title":"3. Literature Integration Enhancement","text":"<p>Extensions provide framework for capturing detailed literature-derived context: - Experimental condition capture: Literature often describes context-specific functions that can be represented through extensions - Target relationship documentation: Publications frequently describe molecular targets that can be captured through has_direct_input relations - Tissue-specific evidence: Literature evidence for tissue-specific functions can be systematically captured</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#4-systematic-curation-decision-framework","title":"4. Systematic Curation Decision Framework","text":"<p>Extension patterns inform curation action decisions: - ACCEPT with extensions: High-quality annotations may warrant extension addition rather than simple acceptance - MODIFY to include context: Basic annotations may be enhanced through contextual extensions - REMOVE for lack of context: Annotations that cannot be appropriately contextualized may be inappropriate</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#5-quality-control-through-relationship-validation","title":"5. Quality Control Through Relationship Validation","text":"<p>Extensions enable sophisticated validation approaches: - Molecular target verification: has_direct_input relationships can be verified against literature evidence - Anatomical context validation: occurs_in relations can be confirmed through expression and functional data - Temporal consistency: exists_during and happens_during relations enable developmental appropriateness validation</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#6-bioinformatics-analysis-enhancement","title":"6. Bioinformatics Analysis Enhancement","text":"<p>Extension-aware analysis improves functional assessment: - Context-specific enrichment: Enrichment analyses can incorporate tissue/cell-type specificity - Network reconstruction: Molecular relations enable more accurate pathway and network modeling - Comparative analysis: Context-specific annotations enable more sophisticated cross-species functional comparisons</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#7-evidence-integration-framework","title":"7. Evidence Integration Framework","text":"<p>Extensions provide structure for integrating diverse evidence types: - Multi-source validation: Different evidence sources can support different aspects of extended annotations - Experimental vs. computational: Extensions can help distinguish high-confidence experimental relationships from computational predictions - Literature synthesis: Multiple publications can contribute different contextual aspects to comprehensive extended annotations</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#8-automated-quality-assessment","title":"8. Automated Quality Assessment","text":"<p>Extension patterns enable algorithmic quality evaluation: - Completeness scoring: Annotations lacking expected extensions may indicate incomplete curation - Context consistency: Extension patterns can be validated against known biological constraints - Relationship verification: Molecular relations can be cross-validated against protein interaction and pathway databases</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#9-training-and-educational-applications","title":"9. Training and Educational Applications","text":"<p>Extensions provide examples of sophisticated annotation practices: - Best practice demonstration: Extended annotations illustrate appropriate level of functional detail - Context awareness training: Examples demonstrate importance of physiological relevance in annotation - Relationship documentation: Extension examples show how to capture molecular and contextual relationships</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#10-future-proofing-curation-approaches","title":"10. Future-Proofing Curation Approaches","text":"<p>Understanding extensions prepares for enhanced annotation requirements: - Increased specificity demands: Research increasingly requires context-specific functional information - Integration capabilities: Extensions enable integration with pathway, network, and systems biology analyses - Computational compatibility: Extension format supports both human interpretation and computational processing</p>"},{"location":"paper/literature/Chapter_17_Annotation_Extensions-summary/#11-cross-database-integration","title":"11. Cross-Database Integration","text":"<p>Extensions facilitate integration with external resources: - Pathway databases: Molecular relations enable connection with KEGG, Reactome, etc. - Expression databases: Tissue-specific contexts can be linked with expression atlas data - Interaction databases: has_direct_input relations can be validated against protein interaction data</p> <p>This comprehensive understanding of annotation extensions provides essential foundation for implementing context-aware approaches to annotation curation that can systematically identify over-annotations while enabling capture of physiologically relevant functional detail that supports sophisticated biological analysis and interpretation.</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/","title":"Chapter 18: The Evidence and Conclusion Ontology (ECO): Supporting GO Annotations - Summary","text":"<p>Authors: Marcus C. Chibucos, Deborah A. Siegele, James C. Hu, and Michelle Giglio</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#summary","title":"Summary","text":"<p>This chapter describes the Evidence and Conclusion Ontology (ECO), a community resource that provides structured vocabulary for describing the diverse types of evidence used to support scientific assertions in biological databases. ECO addresses the critical need for systematic evidence documentation in biocuration by offering a hierarchical ontology that captures both the types of evidence (experimental, computational, author statements, and curator inferences) and the methods by which annotations are made (manual vs. automatic).</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#the-critical-need-for-evidence-documentation","title":"The Critical Need for Evidence Documentation","text":"<p>Scientific Foundation: - Evidence diversity: Scientific investigations generate data from diverse methodologies using wide-ranging tools and techniques - Assertion support: Evidence forms the basis for conclusions and assertions about biological function - Biocuration goal: Extract both assertions and supporting evidence from literature in structured format - Database integration: Structured evidence representation enables automated quality control and selective data retrieval</p> <p>Essential Benefits of Evidence Documentation: 1. Methodological transparency: Understanding what methodologies were used is central to scientific method and impacts data evaluation 2. Query capability: Structured evidence allows selective data queries and retrieval from large databases 3. Quality control: Automated quality control becomes possible with structured evidence representation</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#eco-ontological-framework","title":"ECO Ontological Framework","text":"<p>Dual Root Structure: ECO comprises two main hierarchical branches:</p> <p>1. Evidence Hierarchy: - Root class: \"evidence\" - defined as \"a type of information that is used to support an assertion\" - Major categories:   - Experimental evidence: Laboratory and field experiment results (e.g., \"chromatography evidence\")   - Computational evidence: In silico analysis results (e.g., \"sequence similarity evidence\")   - Author statements: Direct statements made by authors in publications   - Curator inferences: Conclusions drawn during literature curation process</p> <p>2. Assertion Method Hierarchy: - Root class: \"assertion method\" - defined as \"a means by which a statement is made about an entity\" - Two branches:   - Manual assertion: Human-performed annotation process   - Automatic assertion: Computer-performed annotation process (equivalent to GO's IEA code)</p> <p>Cross-Product Architecture: - Current version: 630 terms describing evidence, assertion method, or \"evidence \u00d7 assertion method\" cross products - Granular specificity: Leaf nodes represent most specific evidence types (e.g., \"thin layer chromatography evidence\") - Hierarchical organization: Child terms are more specific than parents, enabling hierarchical queries</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#evolution-from-go-evidence-codes","title":"Evolution from GO Evidence Codes","text":"<p>Historical Development: - Origin: Evolved from original GO evidence codes created for systematic evidence documentation - Model organism contribution: Terms from FlyBase and TAIR incorporated into first ECO version - Name change: \"Evidence Code Ontology\" \u2192 \"Evidence and Conclusion Ontology\" to reflect broader scope - GO integration: GO remains active user and participant in ECO development</p> <p>Advantages over Traditional GO Codes: 1. Formal ontology structure: Hierarchical relationships vs. shallow controlled vocabulary 2. Comprehensive coverage: Broader range of evidence types than GO codes alone 3. Future-proof naming: Avoids limitations of three-letter acronym system 4. Enhanced expressivity: More detailed evidence descriptions than simple codes</p> <p>Transition Strategy: - One-to-one mapping: Most GO evidence codes map directly to ECO terms - Complex mappings: Some codes (IEA, IGC, ISS) map to specific ECO terms based on context - GAF format evolution: Future transition from \"evidence code\" to \"ECO term\" in GAF format - Backward compatibility: Filtering by previous codes remains possible</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#practical-applications-in-go-annotation","title":"Practical Applications in GO Annotation","text":"<p>1. Hierarchical Data Querying: - Selective queries: Search for specific evidence types (e.g., \"thin layer chromatography evidence\") - Grouped queries: Search for broad categories that include all specific subtypes (e.g., \"chromatography evidence\") - Scale: Over 365 million GO annotations currently linked to evidence terms</p> <p>2. Phylogenetic Annotation Support: - Tree-based approach: GO Consortium uses phylogenetic methodology for homology-based annotations - New evidence terms: Specialized terms created for inference processes - Current scale: Over 150,000 annotations associated with phylogenetic evidence terms</p> <p>3. Quality Control Mechanisms: - Computable rules: Evidence requirements enforce annotation consistency - Protein alignment rules: Annotations based on protein alignment must include matching protein identity - Ontology restrictions: Expression pattern evidence restricted to biological process ontology - Circular annotation prevention: Evidence chains evaluated to ensure experimental foundation</p> <p>4. Enhanced Integration: - UniProt-GOA project: ECO terms replace original UniProtKB evidence types - GPAD format: Gene Product Association Data format includes ECO terms - Cross-referencing: ECO terms cross-referenced to GO codes for seamless mapping - Multiple resource adoption: Over 30 resources now use ECO for evidence representation</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#technical-implementation-benefits","title":"Technical Implementation Benefits","text":"<p>Database Management: - Structured queries: Leverage hierarchical structure for sophisticated database searches - Quality control pipelines: Automated checking of evidence-annotation consistency - Rule enforcement: Computational validation of evidence requirements - Annotation grouping: Evidence hierarchy enables logical grouping of related annotations</p> <p>Integration Advantages: - Multiple format support: GAF and GPAD formats accommodate ECO terms - Cross-database compatibility: ECO enables integration across diverse annotation sources - Future extensibility: Ontological structure supports addition of new evidence types - Tool development: Structured evidence supports development of analysis software</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#future-developments","title":"Future Developments","text":"<p>Confidence and Quality Integration: - Active exploration: Work begun on incorporating quality information into ECO - Confidence assessment: Future possibility of describing evidence quality in addition to evidence type - Standalone systems: Alternative approach of creating separate confidence assessment systems</p> <p>Anticipated Applications: - Enhanced quality control: More sophisticated automated quality assessment - Confidence scoring: Quantitative assessment of annotation reliability - Evidence integration: Better integration of multiple evidence sources - Community standards: Broader adoption across biological databases</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential framework for systematic evidence evaluation and quality control in our annotation curation work, directly addressing core challenges in over-annotation detection and evidence-based decision making:</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#1-systematic-evidence-quality-assessment","title":"1. Systematic Evidence Quality Assessment","text":"<p>ECO's hierarchical structure directly supports our evidence-based curation approach: - Evidence hierarchy utilization: ECO's evidence classification enables systematic ranking of annotation reliability based on evidence type strength - Experimental vs. computational distinction: Clear separation between manual assertion and automatic assertion methods helps identify potentially over-annotated computational predictions - Evidence granularity: Specific evidence types (e.g., \"thin layer chromatography evidence\") enable fine-grained assessment of annotation support quality</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#2-over-annotation-detection-through-evidence-analysis","title":"2. Over-Annotation Detection Through Evidence Analysis","text":"<p>ECO framework provides systematic approaches to identify over-annotation patterns: - Circular annotation detection: ECO's chain-of-evidence evaluation directly applies to identifying annotations that lack experimental foundation - Computational bias recognition: Distinction between evidence types helps identify genes with disproportionate reliance on computational predictions - Evidence strength stratification: Hierarchical evidence structure enables identification of annotations supported only by weak evidence types</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#3-enhanced-curation-decision-framework","title":"3. Enhanced Curation Decision Framework","text":"<p>ECO concepts directly inform our structured curation actions: - ACCEPT decisions: Annotations supported by strong experimental evidence (direct assay, mutant phenotype) align with ECO's high-confidence categories - REMOVE decisions: Annotations based on weak computational evidence or lacking evidence chains should be flagged for removal - MODIFY decisions: ECO's specificity levels help determine when annotations are inappropriately general or specific</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#4-quality-control-pipeline-development","title":"4. Quality Control Pipeline Development","text":"<p>ECO's systematic approach provides templates for our automated quality assessment: - Evidence requirement rules: ECO's computable rules for evidence requirements can be adapted for gene-specific annotation validation - Ontology-specific restrictions: ECO's approach to restricting evidence types to appropriate ontology aspects informs our validation rules - Cross-product validation: ECO's evidence \u00d7 assertion method combinations help ensure annotation methods match evidence types</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#5-literature-integration-and-evidence-capture","title":"5. Literature Integration and Evidence Capture","text":"<p>ECO framework supports systematic literature evidence evaluation: - Author statement classification: ECO's distinction between traceable and non-traceable author statements helps evaluate literature-based evidence quality - Experimental evidence hierarchy: ECO's experimental evidence categories (chromatography, assay, phenotype analysis) provide framework for evaluating publication evidence - Manual curation support: ECO's manual assertion methods align with our literature-based annotation approach</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#6-computational-annotation-evaluation","title":"6. Computational Annotation Evaluation","text":"<p>ECO's treatment of automatic assertion directly addresses IEA annotation challenges: - Electronic annotation skepticism: ECO's automatic assertion category helps systematically evaluate computational predictions - Algorithm-specific assessment: ECO's granular computational evidence types enable method-specific reliability assessment - Propagation bias detection: ECO's sequence similarity and homology evidence categories help identify over-annotation through computational propagation</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#7-multi-source-evidence-integration","title":"7. Multi-Source Evidence Integration","text":"<p>ECO's comprehensive evidence framework supports complex curation decisions: - Evidence weight integration: ECO hierarchy enables weighted assessment when multiple evidence types support single annotations - Conflicting evidence resolution: ECO's structured approach to evidence types helps resolve contradictory annotation evidence - Evidence gap identification: ECO framework helps identify annotations lacking appropriate supporting evidence</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#8-database-integration-and-standardization","title":"8. Database Integration and Standardization","text":"<p>ECO's multi-database adoption provides foundation for our systematic approach: - Cross-database comparison: ECO standardization enables comparison of annotation quality across different sources (UniProt-GOA, model organism databases) - Evidence mapping consistency: ECO's cross-referencing to GO codes ensures consistent evidence interpretation - Quality benchmarking: ECO adoption by multiple resources provides community standards for evidence quality</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#9-automated-quality-control-implementation","title":"9. Automated Quality Control Implementation","text":"<p>ECO's computational applications directly translate to our quality control needs: - Rule-based validation: ECO's computable rules provide templates for automated annotation validation - Evidence chain analysis: ECO's circular annotation prevention methods apply directly to our over-annotation detection - Systematic flagging: ECO's quality control mechanisms enable automated identification of problematic annotations</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#10-training-and-consistency-framework","title":"10. Training and Consistency Framework","text":"<p>ECO's structured approach supports systematic curation training: - Evidence evaluation standards: ECO hierarchy provides objective framework for training consistent evidence assessment - Quality control education: ECO's systematic approach to evidence documentation provides examples of best practices - Decision consistency: ECO framework enables reproducible, systematic annotation decisions across different curators</p>"},{"location":"paper/literature/Chapter_18_Evidence_Conclusion_Ontology_Supporting_GO_Annotations-summary/#11-future-proofing-and-extension","title":"11. Future-Proofing and Extension","text":"<p>ECO's extensible framework supports evolution of our curation approaches: - Confidence integration: ECO's planned confidence assessment features align with our need for annotation reliability scoring - New evidence types: ECO's ontological structure supports addition of new evidence categories as scientific methods evolve - Community integration: ECO's broad adoption enables integration with community-wide quality control initiatives</p> <p>This comprehensive understanding of evidence ontology and systematic evidence evaluation provides essential foundation for implementing sophisticated, evidence-based approaches to over-annotation detection that can systematically distinguish well-supported functional annotations from computationally over-interpreted or inadequately supported assertions, enabling precise curation decisions that maintain high-quality functional annotation while removing inappropriate over-annotations.</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/","title":"Chapter 19: Complementary Sources of Protein Functional Information: The Far Side of GO - Summary","text":"<p>Author: Nicholas Furnham</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#summary","title":"Summary","text":"<p>This chapter explores the complementary functional annotation resources that extend beyond the Gene Ontology (GO), providing enhanced functional descriptions through specialized databases focused on enzymes, protein domains, pathways, and protein interactions. The author demonstrates how these resources can be integrated with GO to provide more comprehensive and detailed functional characterization of proteins, highlighting both the strengths and limitations of different annotation approaches.</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#the-need-for-complementary-resources","title":"The Need for Complementary Resources","text":"<p>GO Limitations: While GO provides accessible controlled vocabulary for protein function description, it has inherent limitations that other resources can address: - Enzyme specificity: GO cannot capture detailed reaction chemistry and substrate specificity - Domain granularity: GO typically annotates whole proteins rather than specific functional domains - Pathway dynamics: GO lacks explicit representation of pathway dependencies and directional information - Interaction networks: GO doesn't capture protein-protein interaction topology</p> <p>Integration Benefits: - Enhanced descriptions: Mapping between resources provides relationships not readily captured in GO alone - Automatic updates: GO consortium provides regularly updated mappings to complementary resources - Comprehensive coverage: Combined resources offer broader functional annotation landscape</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#enzyme-classification-and-function","title":"Enzyme Classification and Function","text":"<p>Enzyme Commission (E.C.) System: - Historical development: Created in 1956 to address confused enzyme naming conventions - Hierarchical structure: Four-level classification system   - Level 1: Six broad enzyme classes (Oxidoreductases, Transferases, Hydrolases, Lyases, Isomerases, Ligases)   - Level 2-3: Sub-class and sub-subclass describing reactive species and bond types   - Level 4: Serial number for specific reactions within sub-subclass - Current scale: 6,510 approved E.C. numbers, 5,560 in active use - GO mapping: Only 3,924 (70%) of active E.C. numbers have equivalent GO terms</p> <p>E.C. System Complexities: - Mass-balanced reactions: Described as balanced as possible but not necessarily charge-balanced - Multiple reactions per E.C.: One E.C. number may have multiple associated reactions - General vs. specific reactions: Broad specificity represented as generic reactions with specific alternatives - Pseudo E.C. terms: UniProt-created terms (identifiable by 'n' in fourth level, e.g., 1.1.1.n5)</p> <p>Specialized Enzyme Resources: - KEGG: Curated database of genes, enzyme reactions, metabolites, and metabolic pathways - BRENDA: Comprehensive enzyme function database with GO term integration - CSA (Catalytic Site Atlas): Catalytic residues and their functions in enzyme reactions - MACiE: Enzyme mechanism steps, bond formation/breaking order, cofactor roles - EMO (Enzyme Mechanism Ontology): Bridge between chemical and biological descriptors</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#functional-similarity-measurement-challenges","title":"Functional Similarity Measurement Challenges","text":"<p>GO vs. E.C. Similarity Measures: - GO approaches: Semantic similarity based on ontological graph (information content, Lin score, Wang score) - E.C. limitations: Cannot be used for automated quantitative comparisons between annotations - EC-Blast solution: Atom-atom mapping approach for reaction comparison   - Fingerprint generation: Describes reactions through bond changes and reaction centers   - Quantitative comparison: Enables similarity scoring based on chemical transformation details</p> <p>Divergent Results Example: - E.C. 2.1.2.9 vs. E.C. 2.1.2.11:   - EC-Blast similarity: 0.22 (low due to different bond cleavage patterns)   - GO semantic similarity: 0.73 (high due to similar ontological classification) - Chemical specificity: EC-Blast captures differences in bonds cleaved, stereochemistry, and bond order rearrangements</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#domain-centric-functional-annotation","title":"Domain-Centric Functional Annotation","text":"<p>Granularity Challenge: - Whole protein vs. domain annotation: Most genomic annotations assigned to complete gene products - Functional unit identification: Many functions attributable to specific protein domains - Multi-domain complexity: Functions often result from domain combinations rather than individual domains</p> <p>Domain Classification Resources:</p> <p>1. Pfam (Sequence-Based): - Goal: Representative collection of functionally annotated protein families - Community curation: Recent releases use Wikipedia for functional annotations - GO mapping: InterPro provides mapping between Pfam annotations and GO terms</p> <p>2. CATH (Structure-Based): - Domain definition: Uses protein structures for domain classification - FunFams: Functionally coherent clusters within superfamily divisions - GO integration: Uses GO terms associated with sequences to define functional clusters - Limitation: Annotations assigned to whole sequences, not specific domains</p> <p>3. SUPERFAMILY (SCOP-Based): - Domain-centric approach: Statistical inference of domain-specific functional annotations - Assumption: GO terms annotated to proteins sharing domains confer functional indicators - SDFO: Structural Domain Functional Ontology with reduced GO version - Phenotype integration: Incorporates mammalian phenotype ontology (MPO) and Human Phenotype Ontology (HPO)</p> <p>4. SFLD (Structure-Function Linkage Database): - Critical domains: Identifies domains essential for function (often defining superfamilies) - Direct linkage: Links functional annotations directly to domains or domain combinations</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#pathway-and-interaction-context","title":"Pathway and Interaction Context","text":"<p>GO Pathway Limitations: - Individual components: Molecular function GO terms describe pathway components - Process description: Biological process terms capture overall pathway descriptions - Missing dynamics: GO lacks representation of pathway dependencies and directional information - Limited context: Cannot represent signal transduction or metabolic pathway topology</p> <p>Specialized Pathway Resources: - KEGG: Comprehensive pathway diagrams and metabolic maps - BioCarta: Curated pathway descriptions - MetaCyc: Enzyme and pathway database - Pathway Interaction Database: Curated interaction descriptions - Reactome: Detailed pathway topology and interactions - IntAct: Molecular interaction database with high-confidence subset exported to GO</p> <p>Integration Applications: - Proteomics data analysis: Combined GO enrichment and pathway resource linking - Dynamic network construction: Gene list-based functional network organization - Interaction prediction: Semantic similarity and machine learning for protein-protein interaction prediction</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#multi-domain-architecture-complexity","title":"Multi-Domain Architecture Complexity","text":"<p>Biological Complexity: - Domain combinations: Increasing complexity of multi-domain protein architectures - Function distribution: Functions assigned to complete gene products and individual domains - Architecture diversity: Single domains combined in diverse multi-domain arrangements</p> <p>Visualization and Analysis: - Force-directed graphs: Network representation of multi-domain architectures - Functional unit identification: Distinguishing single-domain from multi-domain functions - Interactive exploration: Tools for investigating domain architecture relationships</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential perspective on the limitations of GO-only annotation and the importance of integrating multiple functional annotation sources for comprehensive gene function assessment, directly supporting our over-annotation detection and curation efforts:</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#1-multi-resource-validation-framework","title":"1. Multi-Resource Validation Framework","text":"<p>The chapter's integration approach directly supports comprehensive annotation assessment: - Cross-resource consistency: Comparing GO annotations with E.C., KEGG, and domain classifications helps identify over-annotations that lack support across multiple resources - Complementary evidence: Annotations supported by multiple independent resources (GO + E.C. + domain analysis) provide stronger evidence than GO alone - Resource-specific strengths: Understanding each resource's focus enables targeted validation (e.g., E.C. for enzyme specificity, domain databases for structural function)</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#2-enzyme-function-over-annotation-detection","title":"2. Enzyme Function Over-Annotation Detection","text":"<p>The chapter's detailed treatment of enzyme classification provides specific tools for enzyme annotation curation: - E.C.-GO mapping gaps: The 30% of E.C. numbers lacking GO equivalents may indicate areas where GO annotations are either missing or potentially over-interpreted - Chemical specificity validation: EC-Blast similarity measures can identify GO annotations that are too general or too specific compared to actual chemical transformation - Pseudo E.C. term recognition: Identifying UniProt-created \"n\" terms helps distinguish well-established from preliminary enzyme classifications</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#3-functional-similarity-assessment","title":"3. Functional Similarity Assessment","text":"<p>The chapter's comparison of GO vs. E.C. similarity measures directly informs curation decisions: - Divergent similarity scores: Cases where GO and EC-Blast measures differ significantly (like the 0.73 vs. 0.22 example) flag potential over-annotation issues - Chemical vs. ontological grouping: Understanding when GO groups functions ontologically that are chemically distinct helps identify inappropriate functional generalizations - Method selection: Choosing appropriate similarity measures based on specific functional aspects being evaluated</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#4-domain-level-annotation-precision","title":"4. Domain-Level Annotation Precision","text":"<p>The chapter's domain-centric perspective addresses a major source of over-annotation: - Whole protein vs. domain function: Many GO annotations assigned to complete proteins may actually represent domain-specific functions, leading to over-annotation of proteins with that domain - Multi-domain complexity: Proteins with multiple domains may be over-annotated when domain-specific functions are attributed to the entire protein - Domain architecture analysis: Understanding domain combinations helps identify when annotations are inappropriately broad or narrow</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#5-evidence-source-stratification","title":"5. Evidence Source Stratification","text":"<p>The chapter's resource categorization supports systematic evidence evaluation: - Resource reliability hierarchy: Understanding the curation quality and evidence basis of different resources enables weighted assessment of annotation support - Experimental vs. computational origins: Distinguishing between resources based on experimental evidence (CSA, MACiE) vs. computational inference (some domain predictions) helps prioritize evidence - Community vs. expert curation: Understanding annotation source (expert curators vs. community editing) informs confidence assessment</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#6-pathway-context-validation","title":"6. Pathway Context Validation","text":"<p>The chapter's pathway integration approach supports system-level annotation assessment: - Pathway consistency: Annotations should be consistent with known pathway roles and interactions - Directional information: Using pathway databases to validate GO biological process annotations against known pathway topology - Interaction network support: Protein-protein interaction data can validate or contradict functional annotations</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#7-over-annotation-pattern-recognition","title":"7. Over-Annotation Pattern Recognition","text":"<p>The chapter's comprehensive resource survey enables systematic bias detection: - Database-specific biases: Understanding each resource's focus and limitations helps identify systematic over-annotation patterns - Resource correlation analysis: Genes with annotations supported by multiple resources vs. those supported only by GO may indicate over-annotation - Functional coherence assessment: Using multiple resources to evaluate whether gene annotation sets show appropriate functional coherence</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#8-quality-control-through-resource-integration","title":"8. Quality Control Through Resource Integration","text":"<p>The chapter's integration strategies provide frameworks for systematic quality assessment: - Cross-validation approaches: Using multiple resources to validate individual annotations - Consensus-based curation: Requiring support from multiple resources before accepting complex functional annotations - Resource-specific quality indicators: Understanding reliability indicators specific to each resource type</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#9-specialized-function-assessment","title":"9. Specialized Function Assessment","text":"<p>The chapter's specialized resource descriptions enable targeted evaluation: - Enzyme mechanism validation: Using CSA and MACiE to validate detailed enzyme function annotations - Domain function verification: Using CATH FunFams and SUPERFAMILY to assess domain-specific annotations - Pathway role confirmation: Using Reactome and KEGG to validate biological process annotations</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#10-annotation-granularity-optimization","title":"10. Annotation Granularity Optimization","text":"<p>The chapter's discussion of annotation levels supports appropriate specificity assessment: - Function unit identification: Determining whether annotations should be applied to whole proteins, domains, or domain combinations - Specificity calibration: Using E.C. hierarchy and domain classifications to ensure GO annotations are at appropriate specificity levels - Complexity management: Understanding when multi-domain proteins warrant multiple specific annotations vs. general functional descriptions</p>"},{"location":"paper/literature/Chapter_19_Complementary_Sources_Protein_Functional_Information-summary/#11-future-proofing-curation-approaches","title":"11. Future-Proofing Curation Approaches","text":"<p>The chapter's comprehensive resource landscape prepares for evolving annotation needs: - Resource evolution tracking: Understanding how different resources develop helps anticipate new validation opportunities - Integration methodology: Systematic approaches to combining multiple resource types for comprehensive functional assessment - Technology advancement: Preparation for new tools like EC-Blast that provide novel functional comparison capabilities</p> <p>This comprehensive understanding of complementary functional annotation resources provides essential foundation for implementing sophisticated, multi-resource approaches to over-annotation detection that can systematically distinguish well-supported functional annotations from those lacking appropriate evidence across multiple independent functional classification systems, enabling precise curation decisions that maintain comprehensive functional coverage while removing inappropriately broad or insufficiently supported annotations.</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/","title":"Chapter 20: Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs to Bedside Phenotypes - Summary","text":"<p>Author: Spiros C. Denaxas</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#summary","title":"Summary","text":"<p>This chapter explores the integration of biological ontologies with controlled clinical terminologies, demonstrating how Electronic Health Records (EHR) can bridge genomic variation and clinical phenotypes through structured data capture and standardized vocabularies. The author provides a comprehensive overview of major clinical terminologies, their applications and challenges, and illustrates integration pathways through a detailed breast cancer case study that traces information flow from genetic variants to bedside phenotypes.</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#the-clinical-data-challenge","title":"The Clinical Data Challenge","text":"<p>EHR Complexity: - Data diversity: Electronic health records contain structured (clinical terminologies), semi-structured (laboratory results), and unstructured (free text) data - Multidisciplinary nature: Healthcare involves diverse specialties requiring integrated data across primary, secondary, and tertiary care settings - Scale and growth: Vast amounts of EHR data generated but lacking common structure for integration - Integration imperative: Need for standardized approaches to facilitate care across settings and enable research applications</p> <p>Transformational Potential: - Personalized medicine: EHR data considered transformational force for measuring and improving clinical care quality - Research acceleration: Potential to accelerate biomedical research across all translation stages - Data-driven approach: Movement toward evidence-based, personalized medical practice</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#controlled-clinical-terminologies","title":"Controlled Clinical Terminologies","text":"<p>Core Purpose: Like Gene Ontology for biological concepts, clinical terminologies provide systematic capture, curation, and description of healthcare-related concepts including: - Clinical entities: Diagnoses, symptoms, anatomical locations, prescribed medications, medical tests - Procedural information: Surgical procedures, interventions, investigations - Measurement data: Laboratory results, clinical observations - Integration function: Essential tools for clinical data integration across disparate sources</p> <p>Major Clinical Terminologies:</p> <p>1. SNOMED-CT (Systematized Nomenclature of Medicine-Clinical Terms): - Scale: Over 300,000 healthcare-related concepts - Structure: Four primary components (concepts, descriptions, relationships, reference sets) - Hierarchical organization: Acyclic hierarchy with multiple inheritance capability - Post-coordination: Compositional syntax allowing combination of terms for complex concepts - Implementation: Variable international adoption; UK NHS designated as standard by 2020</p> <p>2. ICD-10 (International Classification of Diseases): - Scope: Diseases, signs, symptoms, abnormal findings, social circumstances, external causes - Structure: Alphanumeric codes up to six characters long with major categorical organization - Usage: Most widely used statistical classification system globally - Applications: Clinical coding for research, official statistics, medical billing, resource planning - Variants: Country-specific extensions (e.g., ICD-9-CM in USA)</p> <p>3. Procedural Classifications: - CPT (Current Procedural Terminology): American Medical Association maintained, US-focused - OPCS-4: UK National Health Service classification for interventions and procedures - Integration: Combined with diagnosis codes for medical billing and resource allocation</p> <p>4. Laboratory Standards: - LOINC (Logical Observation Identifiers Names and Codes): Regenstrief Institute maintained - Structure: Six-part format (component, property, time, system, scale, method) - Function: Facilitates laboratory data exchange between providers, laboratories, public health agencies</p> <p>5. Medication Terminology: - RxNorm: US Library of Medicine developed for clinical drug information - Content: Normalized names, active ingredients, strengths, forms, branded versions - Applications: Health records, provider communication, medication decision support</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#applications-and-challenges","title":"Applications and Challenges","text":"<p>Opportunities: - Translational research: Larger sample sizes at higher clinical resolution through linked EHR data - Phenotyping: Accurate extraction of disease status from EHR data for research cohorts - Clinical studies: Cost-effective alternative to traditional investigator-led studies - Pragmatic trials: Real-world evidence generation through routine clinical data</p> <p>Integration Challenges: - Terminology mismatch: Different clinical settings use different terminologies (SNOMED-CT vs. ICD-10) - Granularity differences: Information recorded at varying levels of detail across sources - Mapping complexities: Not all terms have direct one-to-one mappings between systems - Resolution requirements: Manual rule creation often needed for complex integration scenarios</p> <p>Semantic Mapping Solutions: - UMLS (Unified Medical Language System): Provides relationship mapping between terminologies - Cross-referencing: Facilitates translation and integration across different clinical vocabularies - Limitation acknowledgment: Information loss possible due to insufficient resolution or mapping conflicts</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#biological-clinical-data-integration","title":"Biological-Clinical Data Integration","text":"<p>Genotype-Phenotype Challenge: - Complex associations: Even Mendelian diseases show complex genotype-phenotype relationships - Interpretation shift: Focus moving from sequence generation to efficient interpretation - Perspective differences: Clinical vs. molecular scientist viewpoints require different data organization - Data incompatibility: Phenotypic and molecular properties recorded in different, often incompatible formats</p> <p>Integration Solutions:</p> <p>Human Phenotype Ontology (HPO): - Structure: Three independent sub-ontologies covering phenotypic abnormalities, inheritance modes, onset/clinical course - Focus: Phenotypic abnormalities rather than diseases themselves - Organization: \"Is_a\" relationships with multiple parent term capability - Qualitative emphasis: Descriptions of excess/reduction rather than quantitative measurements</p> <p>Cross-System Integration: - UMLS mapping: HPO terms reference Unified Medical Language System for clinical terminology mapping - External linkages: Connections to OMIM, DECIPHER, Orphanet databases - Evidence coding: Analogous to GO evidence codes for annotation quality tracking - Metadata support: Onset, frequency, and modifier effect specifications</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#case-study-breast-cancer-integration-pathway","title":"Case Study: Breast Cancer Integration Pathway","text":"<p>Multi-Level Data Flow: The chapter demonstrates integration through a comprehensive breast cancer example tracing: 1. Genomic variation \u2192 2. Genotype \u2192 3. Transcripts \u2192 4. Phenotype \u2192 5. Clinical phenotype</p> <p>Resource Integration at Each Level:</p> <p>Genomic Level: - dbSNP: SNP rs144848 in BRCA2 gene with cancer risk association - Location data: Chromosomal position, source assays, population diversity - Risk assessment: Cumulatively significant increased breast cancer risk</p> <p>Genotype Level: - OMIM: Breast Cancer, Familial phenotype entity (#114480) with BRCA2 gene entry - Cross-references: Links to Entrez Gene ID 675, Ensembl ENSG00000139618 - Gene family: Fanconi anemia complementation group (FANC) classification</p> <p>Transcript Level: - UniProt: BRCA2_HUMAN (P51587) protein information - GO annotation: Double-strand break repair, DNA repair, cytokinesis, protease binding - Functional context: Researchers can identify related gene products sharing pathways/functions</p> <p>Phenotype Level: - HPO: Breast carcinoma term (HP:0003002) with hierarchical relationships - UMLS integration: Malignant Neoplasm of Breast (UMLS:C0006142) concept - Clinical mapping: ICD-10 C50, SNOMED-CT 254837009 terminology connections</p> <p>Clinical Phenotype Level: - Multisystem storage: Pathology, radiology, surgery, medical oncology, radiotherapy systems - Diagnostic procedures: Mammograms, ultrasounds, MRI, biopsy with PACS system storage - Treatment documentation: Pharmacy information systems for therapeutic interventions</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides crucial insights for integrating clinical and biological annotation systems, directly supporting our gene curation work through systematic approaches to evidence validation and multi-resource integration:</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#1-multi-terminology-validation-framework","title":"1. Multi-Terminology Validation Framework","text":"<p>The chapter's comprehensive terminology survey supports robust evidence evaluation: - Cross-system verification: Annotations supported across multiple terminologies (GO, HPO, SNOMED-CT, ICD-10) provide stronger evidence than single-system support - Clinical correlation: Genes with GO annotations should show consistent representation in clinical terminologies when medically relevant - Integration consistency: Discrepancies between biological and clinical terminology representations may indicate over-annotation or under-annotation issues</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#2-evidence-quality-stratification-through-clinical-context","title":"2. Evidence Quality Stratification Through Clinical Context","text":"<p>Understanding clinical terminology integration enables sophisticated evidence assessment: - Clinical relevance validation: GO annotations should align with clinical phenotype representations when medically applicable - Disease association verification: HPO connections provide independent validation of GO biological process annotations - Therapeutic context: Drug terminology (RxNorm) connections can validate GO molecular function annotations for therapeutic targets</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#3-phenotype-genotype-consistency-evaluation","title":"3. Phenotype-Genotype Consistency Evaluation","text":"<p>The chapter's integration approach supports systematic annotation coherence assessment: - HPO-GO alignment: Phenotypic abnormalities described in HPO should be consistent with GO biological process annotations - Clinical manifestation validation: GO annotations should be compatible with known clinical presentations and disease associations - Multi-level consistency: Annotations should maintain coherence across genomic variation, gene function, and clinical phenotype levels</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#4-over-annotation-detection-through-clinical-disconnects","title":"4. Over-Annotation Detection Through Clinical Disconnects","text":"<p>Integration patterns help identify inappropriate functional annotations: - Clinical relevance gaps: GO annotations lacking corresponding clinical terminology representations may indicate over-interpretation - Phenotype mismatch: Biological functions not reflected in clinical phenotype databases may suggest over-annotation - Therapeutic disconnect: Molecular functions without corresponding drug targets or clinical interventions may be over-interpreted</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#5-systematic-bias-recognition-across-domains","title":"5. Systematic Bias Recognition Across Domains","text":"<p>Understanding clinical vs. research perspectives helps identify annotation biases: - Perspective-specific emphasis: Clinical terminologies focus on diagnostically/therapeutically relevant functions vs. research emphasis on mechanistic detail - Disease-centric bias: Clinical systems emphasize pathological states, potentially missing normal physiological functions - Application-driven focus: Medical billing and clinical care priorities may not align with comprehensive functional annotation</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#6-evidence-integration-across-data-types","title":"6. Evidence Integration Across Data Types","text":"<p>The chapter's multi-resource approach enables comprehensive evidence synthesis: - Literature-clinical alignment: Published functional studies should align with clinical observations when medically relevant - Genetic association validation: GO annotations should be consistent with known disease-gene associations in clinical databases - Population-level verification: Clinical terminology frequency patterns can validate GO annotation prevalence expectations</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#7-quality-control-through-integration-patterns","title":"7. Quality Control Through Integration Patterns","text":"<p>Multi-system integration provides quality assessment opportunities: - Annotation completeness: Genes with extensive GO annotations should show corresponding representation in relevant clinical terminologies - Functional coherence: GO molecular function annotations should align with clinical procedure terminologies when therapeutically relevant - Systematic gaps: Missing connections between biological and clinical terminologies may indicate curation opportunities</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#8-translation-ready-annotation-assessment","title":"8. Translation-Ready Annotation Assessment","text":"<p>The chapter's translational focus supports clinically-relevant curation: - Translational potential: GO annotations should provide foundation for clinical application when medically relevant - Drug development relevance: Molecular function annotations should align with pharmaceutical terminology when appropriate - Diagnostic utility: GO annotations should support clinical phenotyping when diagnostically relevant</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#9-precision-medicine-integration","title":"9. Precision Medicine Integration","text":"<p>Understanding clinical data integration supports precision medicine applications: - Personalized relevance: GO annotations should contribute to individualized clinical interpretation - Biomarker potential: Molecular function annotations should align with clinical measurement terminologies - Therapeutic targeting: GO annotations should provide foundation for precision therapeutic approaches</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#10-educational-and-training-applications","title":"10. Educational and Training Applications","text":"<p>The chapter's integration examples provide training frameworks: - Multi-domain literacy: Understanding both biological and clinical terminology systems - Integration competency: Skills in cross-system validation and evidence synthesis - Translation awareness: Understanding how biological annotations relate to clinical applications</p>"},{"location":"paper/literature/Chapter_20_Integrating_Bio-ontologies_Controlled_Clinical_Terminologies-summary/#11-automated-integration-validation","title":"11. Automated Integration Validation","text":"<p>The chapter's systematic approach enables computational quality control: - Cross-system mapping: Automated validation of GO annotations against clinical terminology representations - Integration consistency: Computational checks for coherence across biological and clinical annotation systems - Gap identification: Systematic detection of missing connections between related terminologies</p> <p>This comprehensive understanding of clinical-biological integration provides essential foundation for implementing sophisticated, multi-domain approaches to annotation curation that can systematically validate GO annotations against clinical reality, ensuring functional annotations maintain both biological accuracy and clinical relevance while identifying over-annotations that lack corresponding clinical support or therapeutic relevance.</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/","title":"Chapter 21: The Vision and Challenges of the Gene Ontology - Summary","text":"<p>Author: Suzanna E. Lewis</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#summary","title":"Summary","text":"<p>This concluding chapter provides a comprehensive retrospective on the Gene Ontology (GO) project's origins, evolution, achievements, and future challenges. The author traces the development from the early recognition in the 1990s that systematic gene function description was essential, through the foundational principles established at seminal workshops, to current challenges in capturing complete biological knowledge while maintaining ontological rigor and community adoption.</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#historical-motivation-and-context","title":"Historical Motivation and Context","text":"<p>Early 1990s Recognition: - Model organism imperative: Need to connect model system insights to human health through systematic functional descriptions - Genomic data explosion: Completion of genomes like yeast demanded systematic description of voluminous microarray and other high-throughput results - Web technology advent: World Wide Web enabled new possibilities for data dissemination and exchange - Syntactic and semantic requirements: Data exchange demanded structured approaches beyond simple file transfer</p> <p>Key Pioneer Collaboration: The effort involved prominent database developers including Amos Bairoch, Jonathan Bard, David Botstein, Michelle Gwinn, Minoru Kanehisa, Stan Letovsky, and Monica Riley, with Michael Ashburner's vision of unified classification across fly, worm, mouse, human, and yeast databases driving the initiative.</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#foundational-principles-1996-1997-workshops","title":"Foundational Principles (1996-1997 Workshops)","text":"<p>Core Working Definitions:</p> <p>Gene Product: - Physical object associated with genes through transcription and translation - Includes proteins, ncRNAs, protein complexes, and other functional objects - The fundamental entities to be described by the ontology</p> <p>Essential Attributes: - Function: Capability that a gene product carries as potential, describing what it can do without specifying when or where - Process: Transformation with temporal aspect, accomplished via ordered assemblies of functions - Cellular Component: Anatomical structure within cells, locations where functions or processes occur (later expanded to include extracellular space)</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#essential-ontological-features","title":"Essential Ontological Features","text":"<p>1. Unique Identifiers: - Operational necessity: Enabled unambiguous, stable referencing across collaborating resources - Semantic independence: Meaningless numerical identifiers separated from human-readable labels - Label flexibility: Freedom to change labels without affecting annotations or breaking compatibility - Innovation: Major difference from contemporary frame-based systems that used labels as identifiers</p> <p>2. Graph Structure: - Hierarchical relationships: Graph structure rather than flat keyword lists prevalent in biology at the time - Initial simplicity: Started with only is_a and part_of relationships, recognizing more would be needed - Expandability: Architecture designed to accommodate additional relationship types as understanding grew</p> <p>3. Human-Readable Definitions: - Definition primacy: Definitions, not labels, provide definitive meaning of ontology classes - Nomenclature independence: GO divorced from gene nomenclature despite often using same words - Many-to-many relationships: Gene products can have multiple functions; functions can be performed by multiple products - User-friendly labels: Effort to use familiar terms rather than overly standardized non-intuitive labels</p> <p>4. Synonym Support: - Natural language accommodation: Multiple synonyms handle colloquialisms, community preferences, abbreviations, legacy names - Communication priority: Top priority on biological knowledge communication in researchers' particular idioms - Comprehensive coverage: Different flavors of synonyms address capitalization, chemical naming variations, community-specific terms</p> <p>5. Versioning and History: - Monthly snapshots: Comprehensive ontology and annotation snapshots since 2000 enable progress quantification and retrospective analyses - Micro-attribution: Date stamping and authorship capture for each class from outset - Change tracking: Records of modifications, additions, deletions, merges, and splits - Modern evolution: Transitioning to online editing tools with authentication and authorization</p> <p>6. Subset Management (Slims): - Community demand: Users requested subsets containing major categories or specific branches - Multiple applications: High-level classification, fine-grained sub-branches, clade-specific versions, utility subsets - Internal tagging: GO classes tagged as members of various categories for different subset purposes</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#annotation-framework-and-evidence","title":"Annotation Framework and Evidence","text":"<p>Evidence and Attribution System: - Source requirement: All functional assignments must be attributed to sources (literature references, computational analyses) - Evidence type indication: Evidence codes specify the type of supporting evidence - Initial evidence codes: Genetic interaction, protein interaction, sequence similarity, direct assay - Evolution: Evidence codes developed into autonomous Evidence and Conclusion Ontology (ECO) - Core principle: Assertions require evidence general category and published reference</p> <p>Database Integration: - Cross-reference system: References to predecessor vocabularies (Monica Riley's E. coli categories, EC numbers, SwissProt keywords) - Migration paths: Enabled users with legacy data to transition to GO - Bootstrap support: Original sources helped establish initial GO content - Interoperability enhancement: Additional cross-references (MeSH) added for broader integration</p> <p>Negation and Qualifiers: - Negative results: Qualifiers enable statements that gene products do NOT have specific functions - Experimental reality: Captures negative experimental results rather than losing information - Expressivity enhancement: Allows more complete representation of experimental findings</p> <p>Taxonomic Constraints: - Early recognition: Need for taxon-specific classes recognized from 1996 - Web service solution: Implementation of taxon-constraint resource and corresponding web services - Applicability checking: Automated verification of GO term appropriateness for specific taxa</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#current-state-and-achievements","title":"Current State and Achievements","text":"<p>Scale and Adoption: - Database content: Over 5.2 million function annotations for almost 900,000 gene products - Evidence distribution: About 660,000 experimental annotations, remainder computational predictions - Community adoption: Wide acceptance demonstrates real need fulfillment - Nomenclature alternative: GO provides systematic alternative to simple nomenclature</p> <p>Technical Evolution: - Relationship expansion: From initial two relationships (is_a, part_of) to eight relationships currently in use - Cross-ontology linking: Three branches (BP, MF, CC) now being connected - OWL implementation: Primary operational data structure evolved to OWL (Ontology Web Language)</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#ongoing-challenges-and-solutions","title":"Ongoing Challenges and Solutions","text":"<p>1. Relationship Complexity: - Historical simplification: 1999 decision to delay cross-branch relationships over-simplified biological model - Part_of conflation: Different meanings in cellular component (sub-component) vs. biological process (step/subprocess) - Relations Ontology: Ongoing work to enrich and appropriately apply relationship types - Integration progress: Most significantly, three GO branches now being linked</p> <p>2. Orthogonality Issues: - Embedded ontologies: GO contains implicit ontologies for chemicals, anatomical parts, tissues, cell types - Core ontology extraction: Work begun after 2000 to create autonomous ontologies - ChEBI integration: Chemical references replaced with explicit ChEBI classes - Cell Type Ontology: Derived from GO, now autonomous with independent applications (ENCODE, FANTOM, cancer studies) - Uberon anatomy: Species-neutral anatomical ontology extracted from GO, connects human and model organism phenotype data</p> <p>3. Contextual Annotation: - Context recognition: Importance of functional context recognized from outset (e.g., cytochrome C roles in different cellular compartments) - Operational challenge: Proving to be one of the biggest annotation challenges - Annotation extensions: Enhanced expressivity through contextual information capture - Active development: New annotation strategies and methods under development</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#future-directions","title":"Future Directions","text":"<p>1. Phylogenetic Annotation: - Evolutionary framework: Most annotations must be prediction-based, requiring explicit evolutionary context - PAINT tool: Phylogenetic Annotation and INference Tool enables curators to make precise evolutionary assertions - Evidence recording: Captures when functions gained/lost during evolution with supporting evidence - Integration plans: Incorporating PAINT into suite of integrated online annotation tools</p> <p>2. Modular Annotation: - Biological modularity: Systems modular at multiple levels (catalytic sites, protein domains, complexes, pathways) - Noctua tool: First release of modular curation tool combining annotation and ontology construction tasks - Historical disconnect: Artificial separation between annotation and ontology construction created bottlenecks - Direct biology description: Curators describe biology with known relationships and specific supporting instances</p> <p>3. Community Annotation Enhancement: - Collaborative data exchange: Partnerships with Reactome, IntAct for data incorporation - Community tools: Online community annotation tools planned for both consortium curators and community contributors - Ontology refinement: Tools will support refinement of GO itself in addition to providing annotations</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#comprehensive-vision","title":"Comprehensive Vision","text":"<p>Unchanged Fundamental Motivation: The project continues pursuing its original goal: building a realistic model of biology to enable research based on collective community evidence. The vision remains providing rigorous ways to describe gene product attributes that enable biologists to explore the universe of genomes and biology.</p> <p>Computational Model of Biological Reality: GO aims to be a computational model that researchers will contribute to and regard as the optimum means of sharing knowledge gained from research with the wider community.</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#relevance-to-ai-gene-review-project","title":"Relevance to AI Gene Review Project","text":"<p>This chapter provides essential strategic perspective on the ontological foundations, historical development, and ongoing challenges that directly inform our approaches to over-annotation detection and curation quality improvement:</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#1-historical-context-for-over-annotation-problems","title":"1. Historical Context for Over-Annotation Problems","text":"<p>Understanding GO's evolutionary trajectory illuminates sources of over-annotation issues: - Early simplification decisions: The 1999 decision to delay cross-branch relationships created over-simplified biological models that may have encouraged over-broad annotations - Part_of conflation: Different meanings of part_of relationships across branches may contribute to inappropriate annotations - Evidence code evolution: Early simple evidence categories have evolved into sophisticated ECO, suggesting early annotations may need re-evaluation with current evidence standards</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#2-foundational-principles-for-curation-quality","title":"2. Foundational Principles for Curation Quality","text":"<p>The chapter's principles directly support our curation decision framework: - Definition primacy: Definitions, not labels, define ontology classes - emphasizing the importance of understanding precise functional meaning rather than relying on familiar terms - Evidence requirement: All assertions must have evidence and published references - reinforcing our evidence-based approach to annotation validation - Synonym awareness: Multiple ways to express functions require careful evaluation to avoid annotation based on misleading labels</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#3-taxonomic-and-contextual-precision","title":"3. Taxonomic and Contextual Precision","text":"<p>The chapter's recognition of context importance directly supports over-annotation detection: - Taxon constraints: Early recognition of species-specific applicability helps identify inappropriate annotations across taxa - Contextual annotation: Recognition that same protein can have different functions in different contexts (cytochrome C example) helps identify over-generalizations - Location specificity: Understanding that functions occur in specific cellular contexts helps evaluate annotation appropriateness</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#4-evidence-evolution-and-quality-assessment","title":"4. Evidence Evolution and Quality Assessment","text":"<p>The historical development of evidence standards informs our evidence evaluation: - ECO development: Evolution from simple evidence codes to sophisticated ECO provides framework for evaluating evidence quality in historical annotations - Negative result importance: Recognition of negative experimental results suggests we should value NOT qualifiers and contradictory evidence - Source attribution: Emphasis on literature reference requirement supports our focus on publication-based validation</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#5-orthogonality-and-embedded-ontology-issues","title":"5. Orthogonality and Embedded Ontology Issues","text":"<p>The chapter's discussion of embedded ontologies directly relates to over-annotation patterns: - Chemical extraction: Work to replace implicit chemical references with explicit ChEBI classes suggests similar approaches needed for other embedded concepts - Cross-ontology consistency: Integration with cell type, anatomy, and other ontologies provides validation opportunities for GO annotations - Core ontology benefits: Understanding that elemental components enable broader network connections supports cross-resource validation approaches</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#6-community-adoption-and-quality-control","title":"6. Community Adoption and Quality Control","text":"<p>The chapter's emphasis on community needs informs our curation approach: - User-friendly requirements: Emphasis on familiar labels and community preferences suggests we should consider researcher expectations in curation decisions - Communication priority: Top priority on biological knowledge communication supports focusing on annotations that effectively convey functional information - Community feedback: History of adaptation based on community needs suggests our curation approaches should be responsive to user requirements</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#7-phylogenetic-and-evolutionary-frameworks","title":"7. Phylogenetic and Evolutionary Frameworks","text":"<p>The chapter's discussion of PAINT and evolutionary annotation informs our cross-species validation: - Evolutionary context: Most annotations are predictions requiring evolutionary framework - suggesting phylogenetic consistency as validation criterion - Function gain/loss: Explicit tracking of when functions gained/lost during evolution provides framework for evaluating annotation appropriateness across species - Family-based curation: Phylogenetic approaches to annotation provide models for systematic family-level validation</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#8-modular-biological-systems","title":"8. Modular Biological Systems","text":"<p>The chapter's recognition of biological modularity informs our functional assessment: - Multiple organization levels: Understanding modularity from catalytic sites to pathways provides framework for evaluating annotation granularity - Noctua integration: Combining annotation and ontology construction tasks provides model for integrated curation approaches - Pathway context: Recognition that molecular interactions define reusable pathways supports pathway-based validation of annotations</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#9-ongoing-challenge-recognition","title":"9. Ongoing Challenge Recognition","text":"<p>The chapter's honest assessment of remaining challenges informs realistic expectations: - Contextual annotation difficulty: Recognition that contextual annotation is one of the biggest operational challenges suggests we should expect complexity in this area - Scalability challenges: Recognition that capturing all functional data is formidable suggests we should prioritize high-impact curation efforts - Balance requirements: Need to balance ontology development with annotation capture suggests integration of these activities</p>"},{"location":"paper/literature/Chapter_21_Vision_Challenges_Gene_Ontology-summary/#10-future-oriented-curation-strategies","title":"10. Future-Oriented Curation Strategies","text":"<p>The chapter's forward-looking perspective informs our long-term approach: - Tool integration: Plans for integrated online tools suggest our curation approaches should be designed for eventual automation and community participation - Collaborative frameworks: Emphasis on partnerships with other annotation initiatives suggests our approaches should be compatible with broader community efforts - Continuous evolution: Recognition that GO is ongoing enterprise suggests our curation approaches should be adaptable to evolving standards</p> <p>This comprehensive historical and strategic perspective provides essential foundation for understanding GO's trajectory and remaining challenges, enabling our over-annotation detection efforts to align with the ontology's fundamental principles while addressing recognized limitations and building toward improved community-wide functional annotation quality.</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/","title":"Gene Ontology Handbook Full","text":"<p>The Gene Ontology Handbook</p> <p>Editors. Christophe Dessimoz, Nives \u0160kunca</p> <p>Methods in Molecular Biology   1446</p> <p>Christophe Dessimoz Nives \u0160kunca  Editors</p> <p>The Gene Ontology Handbook</p> <p>METHODS IN MOLECULAR BIOLOGY       Series EditorJohn M. WalkerSchool of Life and Medical SciencesUniversity of HertfordshireHatfield, Hertfordshire, AL10 9AB, UK For further volumes:   http://www.springer.com/series/7651    \f    The Gene Ontology Handbook  Edited by     Christophe   DessimozDepartment of Genetics, Evolution &amp; Environment, University College London, London, UK; Swiss Institute of Bioinformatics, Lausanne, Switzerland; Department of Ecology and Evolution, University of Lausanne, Lausanne, Switzerland; Center of Integrative Genomics, University of Lausanne, Lausanne, Switzerland; Department of Computer Science, University College London, London, UK         Nives   \u0160kuncaDepartment of Computer Science, ETH Zurich, Zurich, Switzerland; SIB Swiss Institute of Bioinformatics, Zurich, Switzerland; University College London, London, UK                              \f       ISSN 1064-3745            ISSN 1940-6029 (electronic)    Methods in Molecular Biology   ISBN 978-1-4939-3741-7      ISBN 978-1-4939-3743-1 (eBook)  DOI 10.1007/978-1-4939-3743-1  Library of Congress Control Number: 2016943478  \u00a9 The Editor(s) (if applicable) and The Author(s)   2017 . This book is published open access. Open Access This book is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated. The images or other third party material in this book are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speci\ufb01 c statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.  The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made.  Printed on acid-free paper    This Humana Press imprint is published by Springer Nature   The registered company is Springer Science+Business Media LLC New York  Editors    Christophe   Dessimoz      Department of Genetics  Evolution and EnvironmentUniversity College London   London ,  UK   Swiss Institute of BioinformaticsLausanne, SwitzerlandDepartment of Ecology and EvolutionUniversity of LausanneLausanne, SwitzerlandCenter of Integrative GenomicsUniversity of LausanneLausanne, SwitzerlandDepartment of Computer ScienceUniversity College LondonLondon, UK   Nives   \u0160kunca      Department of Computer Science ETH Zurich    Zurich ,  Switzerland   SIB Swiss Institute of BioinformaticsZurich, SwitzerlandUniversity College LondonLondon, UK\fv The Gene Ontology (GO) is the leading project to organize biological knowledge on genes and their products in a formal and consistent way across genomic resources. This has had a profound impact at several levels. First, such standardization has made possible the integra-tion of multiple resources and sources of knowledge, thereby increasing their discoverabil-ity and simplifying their usage. Second, it has greatly facilitated\u2014some might say  exceedingly so \u2014data mining, aggregate analyses, and other forms of automated knowledge extraction. Third, it has led to an increase in the overall quality of the resources by enforcing minimum requirements across all of them.  Even considering these advantages, the rapid adoption of the GO in the community has been remarkable. In the 15 years since the publication of its introductory article [  1    ], over 100,000 scienti\ufb01 c articles containing the keyword \u201cGene Ontology\u201d have been published and the rate is still increasing (Google Scholar).  However, despite this popularity and widespread use, many aspects of the Gene Ontology remain poorly understood [  2    ], at times even by experts [  3    ]. For instance, unbe-knownst to most users, routine procedures such as GO term enrichment analyses remain subject to biases and simplifying assumptions that can lead to spurious conclusions [  4    ].  The objective of this book is to provide a practical, self-contained overview of the GO for biologists and bioinformaticians. After reading this book, we would like the reader to be equipped with the essential knowledge to use the GO and correctly interpret results derived from it. In particular, the book will cover the state of the art of how GO annotations are made, how they are evaluated, and what sort of analyses can and cannot be done with the GO. In the spirit of the  Methods in Molecular Biology  book series in which it appears, there is an emphasis on providing practical guidance and troubleshooting advice.  The book is intended for a wide scienti\ufb01 c audience and makes few assumptions about prior knowledge. While the primary target is the nonexpert, we also hope that seasoned GO users and contributors will \ufb01 nd it informative and useful. Indeed, we are the \ufb01 rst to admit that working with the GO occasionally brings to mind the aphorism \u201cthe more we know, the less we understand.\u201d  The book is structured in six main parts. Part I introduces the reader to the fundamen-tal concepts underlying the Gene Ontology project, with primers on ontologies in general (Chapter   1    ), on gene function (Chapter   2    ), and on the Gene Ontology itself (Chapter   3    ).  To become pro\ufb01 cient GO users, we need to know where the GO data comes from. Part II reviews how the GO annotations are made, be it via manual curation of the primary lit-erature (Chapter   4    ), via computational methods of function inference (Chapter   5    ), via lit-erature text mining (Chapter   6    ), or via crowdsourcing and other contributions from the community (Chapter   7    ).  But can we trust these annotations? In Part III, we consider the problem of evaluating GO annotations. We \ufb01 rst provide an overview of the different approaches, the challenges associated with them, but also some successful initiatives (Chapter   8    ). We then focus on the more speci\ufb01 c problem of evaluating enzyme function predictions (Chapter   9    ). Last, we   Pref ace    \fvire\ufb02 ect on the achievements of the Critical Assessment of protein Function Annotation (CAFA) community experiment (Chapter   10    ).  Having made and validated GO annotations, we proceed in Part IV to use the GO resource. We consider the various ways of retrieving GO data (Chapter   11    ), how to  quantify the functional similarity of GO terms and genes (Chapter   12    ), or perform GO enrichment analyses (Chapter   13    )\u2014all the while avoiding common biases and pitfalls (Chapter   14    ). The part ends with a chapter on visualizing GO data (Chapter   15    ) as well as a tutorial on GO analyses in the programming language Python (Chapter   16    ).  Part V covers two advanced topics: annotation extensions, which make it possible to express relationships involving multiple terms (Chapter   17    ), and the evidence code ontol-ogy, which provides a more precise and expressive speci\ufb01 cation of supporting evidence than the traditional GO annotation evidence codes (Chapter   18    ).  Part VI goes beyond the GO, by considering complementary sources of functional infor-mation such as KEGG and Enzyme Commission numbers (Chapter   19    ), and by considering the potential of integrating GO with controlled clinical nomenclatures (Chapter   20    ).  The \ufb01 nal part concludes the book with a perspective by Suzi Lewis on the past, present, and future of the GO (Chapter   21    ).     London, UK     Christophe     Dessimoz     Zurich, Switzerland    Nives     \u0160kunca           References      1.    Ashburner M, Ball CA, Blake JA et al (2000) Gene ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Consortium. Nat Genet 25:25\u201329      2.    Thomas PD, Wood V, Mungall CJ et al (2012) On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report. PLoS Comput Biol 8:e1002386      3.    Dessimoz C, \u0160kunca N, Thomas PD (2013) CAFA and the open world of protein function predictions. Trends Genet 29:609\u2013610      4.    Tipney H, Hunter L (2010) An introduction to effective use of enrichment analysis software. Hum Genomics 4:202\u2013206       Preface \fvii We thank all chapter authors for their contributions to the book. We are particularly indebted to Pascale Gaudet and Ruth Lovering for contributing multiple chapters and demonstrating unabated enthusiasm throughout the process. All chapters were reviewed by at least two independent peers, which represents a considerable effort. Peer reviews were mostly contributed by chapter authors, but also by the following people: Adrian Altenhoff, Natasha Glover, Debra Klopfenstein, Chris Mungall, Prudence Mutowo, Marc Robinson- Rechavi, Kimberly Van Auken, and Haibao Tang. Last but not least, we thank support by John Walker, our series editor, and Patrick Marton from Springer.  Funding for the Open Access charges was generously provided by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.    Acknowledgements  \fix   Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   v       Contributors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   xi      PART I FUNDAMENTALS        1     Primer on Ontologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   3       Janna   Hastings         2     The Gene Ontology and the Meaning of Biological Function  . . . . . . . . . . . . .   15       Paul   D.   Thomas         3     Primer on the Gene Ontology. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25       Pascale   Gaudet    ,     Nives   \u0160kunca    ,     James   C.   Hu    , and     Christophe   Dessimoz        PART II MAKING GENE ONTOLOGY ANNOTATIONS         4     Best Practices in Manual Annotation with the Gene Ontology. . . . . . . . . . . . .   41       Sylvain   Poux     and     Pascale   Gaudet         5     Computational Methods for Annotation Transfers from Sequence. . . . . . . . . .   55       Domenico   Cozzetto     and     David   T.   Jones         6     Text Mining to Support Gene Ontology Curation and Vice Versa . . . . . . . . . .   69       Patrick   Ruch         7     How Does the Scientific Community Contribute to Gene Ontology?  . . . . . . .   85       Ruth   C.   Lovering        PART III EVALUATING GENE ONTOLOGY ANNOTATIONS         8     Evaluating Computational Gene Ontology Annotations  . . . . . . . . . . . . . . . . .   97       Nives   \u0160kunca    ,     Richard   J.   Roberts    , and     Martin   Steffen         9     Evaluating Functional Annotations of Enzymes Using the Gene Ontology  . . .   111       Gemma   L.   Holliday    ,     Rebecca   Davidson    ,     Eyal   Akiva    , and     Patricia   C.   Babbitt        10     Community-Wide Evaluation of Computational Function Prediction  . . . . . . .   133       Iddo   Friedberg     and     Predrag   Radivojac        PART IV USING THE GENE ONTOLOGY        11     Get GO! Retrieving GO Data Using AmiGO, QuickGO, API, Files, and Tools  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   149       Monica   Munoz-Torres     and     Seth   Carbon        12     Semantic Similarity in the Gene Ontology. . . . . . . . . . . . . . . . . . . . . . . . . . . .   161       Catia   Pesquita      Contents \fx    13     Gene-Category Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   175       Sebastian   Bauer        14     Gene Ontology: Pitfalls, Biases, and Remedies. . . . . . . . . . . . . . . . . . . . . . . . .   189       Pascale   Gaudet     and     Christophe   Dessimoz        15     Visualizing GO Annotations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   207       Fran   Supek     and     Nives   \u0160kunca        16     A Gene Ontology Tutorial in Python  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   221       Alex   Warwick   Vesztrocy     and     Christophe   Dessimoz        PART V ADVANCED GENE ONTOLOGY TOPICS        17     Annotation Extensions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   233       Rachael   P.   Huntley     and     Ruth   C.   Lovering        18     The Evidence and Conclusion Ontology (ECO): Supporting GO Annotations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   245       Marcus   C.   Chibucos    ,     Deborah   A.   Siegele    ,     James   C.   Hu    , and     Michelle   Giglio        PART VI BEYOND THE GENE ONTOLOGY        19     Complementary Sources of Protein Functional Information: The Far Side of GO  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   263       Nicholas   Furnham        20     Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs to Bedside Phenotypes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   275       Spiros   C.   Denaxas         PART VII CONCLUSION         21     The Vision and Challenges of the Gene Ontology. . . . . . . . . . . . . . . . . . . . . .   291       Suzanna   E.   Lewis    Index. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  303 Contents\fxi     EYAL     AKIVA    (cid:129)    Department of Bioengineering and Therapeutic Sciences ,  University of California San Francisco  ,  San Francisco ,  CA ,  USA           PATRICIA     C.     BABBITT    (cid:129)    Department of Bioengineering and Therapeutic Sciences ,  University of California San Francisco  ,  San Francisco ,  CA ,  USA           SEBASTIAN     BAUER    (cid:129)    PRIVATE ,     Berlin ,  Germany           SETH     CARBON    (cid:129)    Berkeley Bioinformatics Open-Source Projects, Environmental Genomics and Systems Biology Division ,  Lawrence Berkeley National Laboratory  ,  Berkeley ,  CA ,  USA           MARCUS     C.     CHIBUCOS    (cid:129)    Department of Microbiology and Immunology, Institute for Genome Sciences ,  University of Maryland School of Medicine  ,  Baltimore ,  MD ,  USA           DOMENICO     COZZETTO    (cid:129)    Bioinformatics Group, Department of Computer Science ,  University College London  ,  London ,  UK           REBECCA     DAVIDSON    (cid:129)    Department of Bioengineering and Therapeutic Sciences ,  University of California San Francisco  ,  San Francisco ,  CA ,  USA           SPIROS     C.     DENAXAS    (cid:129)    Farr Institute of Health Informatics Research ,  University College London  ,  London ,  UK; Institute of Health Informatics, University College London, London, UK           CHRISTOPHE     DESSIMOZ    (cid:129)    Department of Genetics, Evolution &amp; Environment ,  University College London  ,  London ,  UK   ;   Swiss Institute of Bioinformatics ,  Lausanne  ,  Switzerland     ;   Department of Ecology and Evolution ,  University of Lausanne  ,  Lausanne ,  Switzerland;   Center of Integrative Genomics ,  University of Lausanne ,  Lausanne , Switzerland;  Department of Computer Science,  University College London ,  London , UK         IDDO     FRIEDBERG    (cid:129)    Department of Veterinary Microbiology and Preventive Medicine ,  Iowa State University  ,  Ames ,  IA ,  USA           NICHOLAS     FURNHAM    (cid:129)    Department of Pathogen Molecular Biology ,  London School of Hygiene and Tropical Medicine  ,  London ,  UK           PASCALE     GAUDET    (cid:129)    CALIPHO Group ,  Swiss Institute of Bioinformatics  ,  Geneva ,  Switzerland   ;   Department of Human Protein Sciences, Faculty of Medicine ,  University of Geneva  ,  Geneva ,  Switzerland           MICHELLE     GIGLIO    (cid:129)    Department of Medicine, Institute for Genome Sciences ,  University of Maryland School of Medicine  ,  Baltimore ,  MD ,  USA           JANNA     HASTINGS    (cid:129)    Cheminformatics and Metabolism, European Molecular Biology Laboratory ,  European Bioinformatics Institute (EMBL-EBI)  ,  Cambridgeshire ,  UK           GEMMA     L.     HOLLIDAY    (cid:129)    Department of Bioengineering and Therapeutic Sciences ,  University of California San Francisco  ,  San Francisco ,  CA ,  USA           JAMES     C.     HU    (cid:129)    Department of Biochemistry and Biophysics ,  Texas A&amp;M University and Texas AgriLife Research  ,  College Station ,  TX ,  USA           RACHAEL     P.     HUNTLEY    (cid:129)    Functional Gene Annotation Initiative, Centre for Cardiovascular Genetics, Institute of Cardiovascular Science ,  University College London  ,  London ,  UK           DAVID     T.     JONES    (cid:129)    Bioinformatics Group, Department of Computer Science ,  University College London  ,  London ,  UK       Contributors \fxii      SUZANNA     E.     LEWIS    (cid:129)    Lawrence Berkeley National Laboratory  ,  Berkeley ,  CA ,  USA           RUTH     C.     LOVERING    (cid:129)    Functional Gene Annotation Initiative, Centre for Cardiovascular Genetics, Institute of Cardiovascular Science ,  University College London  ,  London ,  UK           MONICA     MUNOZ-TORRES    (cid:129)    Berkeley Bioinformatics Open-Source Projects, Environmental Genomics and Systems Biology Division ,  Lawrence Berkeley National Laboratory  ,  Berkeley ,  CA ,  USA           CATIA     PESQUITA    (cid:129)    LaSIGE, Faculdade de Ci\u00eancias ,  Universidade de Lisboa  ,  Lisbon ,  Portugal           SYLVAIN     POUX    (cid:129)    Swiss-Prot Group ,  SIB Swiss Institute of Bioinformatics  ,  Centre Medical Universitaire, Geneva ,  Switzerland           PREDRAG     RADIVOJAC    (cid:129)    Department of Computer Science and Informatics ,  Indiana University  ,  Bloomington ,  IN ,  USA           RICHARD     J.     ROBERTS    (cid:129)    New England Biolabs  ,  Ipswich ,  MA ,  USA           PATRICK     RUCH    (cid:129)    SIB Text Mining, Swiss Institute of Bioinformatics ,  Geneva ,  Switzerland;  BiTeM Group, HES-SO \\HEG Gen\u00e8ve,  Carouge , Switzerland         DEBORAH     A.     SIEGELE    (cid:129)    Department of Biology ,  Texas A&amp;M University  ,  College Station ,  TX ,  USA           NIVES     \u0160KUNCA    (cid:129)    Department of Computer Science ,  ETH Zurich  ,  Zurich ,  Switzerland   ;   SIB Swiss Institute of Bioinformatics  ,  Zurich ,  Switzerland   ;   University College London  ,  London ,  UK           MARTIN     STEFFEN    (cid:129)    Department of Biomedical Engineering ,  Boston University  ,  Boston ,  MA ,  USA   ;   Department of Pathology and Laboratory Medicine ,  Boston University School of Medicine  ,  Boston ,  MA ,  USA           FRAN     SUPEK    (cid:129)    Division of Electronics ,  Ruder Boskovic Institute  ,  Zagreb ,  Croatia   ;   EMBL/CRG Systems Biology Research Unit ,  Centre for Genomic Regulation (CRG), The Barcelona Institute of Science and Technology  ,  Barcelona ,  Spain   ;   Universitat Pompeu Fabra (UPF)  ,  Barcelona ,  Spain           PAUL     D.     THOMAS    (cid:129)    Division of Bioinformatics, Department of Preventive Medicine ,  University of Southern California  ,  Los Angeles ,  CA ,  USA           ALEX     WARWICK     VESZTROCY    (cid:129)    Department of Genetics, Evolution and Environment ,  University College London  ,  London ,  UK   ;   Swiss Institute of Bioinformatics  ,  Lausanne ,  Switzerland      Contributors\f   Part I    Fundamentals        \f3Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_1, \u00a9 The Author(s) 2017     Chapter 1    Primer on Ontologies                          Janna     Hastings        Abstract    As molecular biology has increasingly become a data-intensive discipline, ontologies have emerged as an essential computational tool to assist in the organisation, description and analysis of data. Ontologies describe and classify the entities of interest in a scienti\ufb01 c domain in a computationally accessible fashion such that algorithms and tools can be developed around them. The technology that underlies ontologies has its roots in logic-based arti\ufb01 cial intelligence, allowing for sophisticated automated inference and error detection. This chapter presents a general introduction to modern computational ontologies as they are used in biology.    Key words     Ontology  ,   Knowledge representation  ,   Bioinformatics  ,   Arti\ufb01 cial intelligence  1      Introduction  Examining aspects of the world to determine the nature of the entities that exist and their causal networks is at the heart of many scienti\ufb01 c endeavours, including the modern biological sciences. Advances in technology have made it possible to perform large- scale high-throughput experiments, yielding results for thousands of genes or gene products in single experiments. The data from these experiments are growing in public repositories [ 1 ], and in many cases the bottleneck has moved from the generation of these data to the analysis thereof [ 2 ]. In addition to the sheer volume of data, as the focus has moved to the investigation of systems as a whole and their perturbations [ 3 ], it has become increasingly nec-essary to integrate data from a variety of disparate technologies, experiments, labs and even across disciplines. Natural language data description is not suf\ufb01 cient to ensure smooth data integration, as natural language allows for multiple words to mean the same thing, and single words to mean multiple things. There are many cases where the meaning of a natural language description is not fully unambiguous. Ontologies have emerged as a key technology going beyond natural language in addressing these challenges. \f4The most successful biological ontology (bio-ontology) is the Gene Ontology (GO) [ 4 ], which is the subject of this volume.  Ontologies are computational structures that describe the entities and relationships of a domain of interest in a structured computable format, which allows for their use in multiple applica-tions [ 5 ,  6 ]. At the heart of any ontology is a set of entities, also called classes, which are arranged into a hierarchy from the general to the speci\ufb01 c. Additional information may be captured such as domain-relevant relationships between entities or even complex logical axioms. These entities that are contained in ontologies are then available for use as hubs around which data can be organised, indexed, aggregated and interpreted, across multiple different ser-vices, databases and applications [ 7 ].  2    Elements of Ontologies  Ontologies consist of several distinct elements, including classes, metadata, relationships, formats and axioms.    The class is the basic unit within an ontology, representing a type of thing in a domain of interest, for example  carboxylic acid ,  heart ,  melanoma  and  apoptosis . Typically, classes are associated with a unique identi\ufb01 er within the ontology\u2019s namespace, for example (respectively) CHEBI:33575, FMA:7088, DOID:1909 and GO:0006915. Such identi\ufb01 ers are semantics free (they do not con-tain a reference to the class name or de\ufb01 nition) in order to pro-mote stability even as scienti\ufb01 c knowledge and the accompanying ontology representation evolve. Ontology providers commit to maintaining identi\ufb01 ers for the long term, so that if they are used in annotations or other application contexts the user can rely on their resolution. In some cases as the ontology evolves, multiple entries may become merged into one, but in these cases alternate identi-\ufb01 ers are still maintained as secondary identi\ufb01 ers. When a class is deemed to no longer be needed within the ontology it may be marked as obsolete, which then indicates that the ID should not be used in further annotations, although it is preserved for historical reasons. Obsolete classes may contain metadata pointing to one or more alternative classes that should be used instead.     Classes are usually associated with annotated textual information\u2014metadata. The metadata associated with classes may include any associated secondary (alternate) identi\ufb01 ers and \ufb02 ags to indicate whether the class has been marked as obsolete. It may also include one or more synonyms; for example the synonyms of  apoptotic  process  (a class in the GO) include  cell suicide ,  programmed cell death  and  apoptosis . It further may include cross references to that class in alternative databases and web resources. For example, many Chemical Entities of Biological Interest (ChEBI) [ 8 ] entries 2.1  Classes2.2  MetadataJanna Hastings\f5contain cross references to the KEGG resource [ 9 ], which repre-sents those chemicals in the context of the biological pathways they participate in. Textual comments and examples of intended usage may be annotated. It is very important that each class include a clear de\ufb01 nition, which provides enough information to pinpoint the meaning of the class and suggest its appropriate use\u2014suf\ufb01 -ciently distinguishing different classes in an ontology so that a user can determine which is the best to use for annotation. The de\ufb01 ni-tion of apoptosis offered by the Gene Ontology is as follows:  A programmed cell death process which begins when a cell receives an internal (e.g. DNA damage) or external signal (e.g. an extracellular death ligand), and proceeds through a series of biochemical events (signaling pathway phase) which trigger an execution phase. The exe-cution phase is the last step of an apoptotic process, and is typically characterized by rounding-up of the cell, retraction of pseudopodes, reduction of cellular volume (pyknosis), chromatin condensation, nuclear fragmentation (karyorrhexis), plasma membrane blebbing and fragmentation of the cell into apoptotic bodies. When the execution phase is completed, the cell has died.       Classes are arranged in a hierarchy from the general (high in the hierarchy) to the speci\ufb01 c (low in the hierarchy). For example, in ChEBI  carboxylic acid  is classi\ufb01 ed as a  carbon oxoacid , which in turn is classi\ufb01 ed as an  oxoacid , which in turn is classi\ufb01 ed as a  hydroxide , and so on up to the root  chemical entity , which is the most general term in the structure-based classi\ufb01 cation branch of the ontology.  Despite the hierarchical organisation, most ontologies are not simple trees. Rather, they are structured as  directed acyclic graphs . This is because it is possible for classes to have multiple parents in the classi\ufb01 cation hierarchy, and furthermore ontologies include additional types of relationships between entities other than hierar-chical classi\ufb01 cation (which itself is represented by  is_a  relations). All relations are directed and care must be taken by the ontology editors to ensure that the overall structure of the ontology does not contain cycles, as illustrated in Fig.  1 .2.3  Relations  Fig. 1    ( a ) A simple hierarchical tree, ( b ) a directed, acyclic graph, ( c ) a graph that contains a cycle, indicated in  red         Primer on Ontologies\f6   A common relationship type used in multiple ontologies is  part_of  or  has_part , representing composition or constitution. For example, in the Foundational Model of Anatomy (FMA) [ 10 ],  heart   has_part   aortic valve . The Relationship Ontology (RO) de\ufb01 nes sev-eral relationship types that are commonly used across multiple bio-ontologies [ 11 ], a selection of which is shown in Table  1 .   In addition, speci\ufb01 c ontologies may also include additional relationships that are particular to their domain. For example, GO includes biological process-speci\ufb01 c relations such as  regulates , while ChEBI includes chemistry-speci\ufb01 c relationships such as  is_tautomer_of  and  is_enantiomer_of .  The speci\ufb01 cation for a relationship type in an ontology includes a unique identi\ufb01 er, name and classi\ufb01 cation hierarchy, as for classes, as well as a speci\ufb01 cation whether the relationship is re\ufb02 exive (i.e. A  rel  B if and only if B  rel  A) and/or transitive (if A  rel  B and B  rel  C then A  rel  C), and the name of the inverse relationship type if it exists. The same metadata as is associated with the classes in the ontology may also be associated with relationship types: alternative identi\ufb01 ers, synonyms, a de\ufb01 nition and comments, and a \ufb02 ag to indicate if the relationship is obsolete.     Typically, ontologies are stored in \ufb01 les conforming to a speci\ufb01 c \ufb01 le format, although there are exceptions that are stored in custom- built infrastructures. Ontologies may be represented in different underlying ontology languages, and historically there has been an evolution of the capability of ontology languages towards greater logical expressivity and complexity, which is mirrored by the advances in computational capacity (hardware) and tools. Biological ontologies such as the GO have historically been represented in the 2.4  Formats   Table 1    A selection of relationship types commonly used in bio-ontologies    Relationship type  Informal meaning  Examples  part_of  The standard relation of parthood.  A brain is part_of a body.  derives_from  Derivation holds between distinct entities when one succeeds the other across a temporal divide in such a way that a biologically signi\ufb01 cant portion of the matter of the earlier entity is inherited by the latter.  A zygote derives_from a sperm and an ovum.  has_participant  A relation that links processes to the entities that participate in them.  An apoptotic process has_participant a cell.  has_function  A relation that links material entities to their functions, e.g. the biological functions of macromolecules.  An enzyme has_function to catalyse a speci\ufb01 c reaction type. Janna Hastings\f7human-readable Open Biomedical Ontologies (OBO) language, 1  which was designed speci\ufb01 cally for the structure and metadata con-tent associated with bio-ontologies, but in recent years there has been a move towards the Semantic Web standard Web Ontology Language (OWL) 2  largely due to the latter\u2019s adoption within a wider community and expansive tool support. Within OWL, spe-ci\ufb01 c standardised annotations are used to encode the metadata content of bio-ontologies as OWL annotations. However, the dis-tinction has become cosmetic to some extent, as tools have been created which are able to interconvert between these languages [ 12 ], provided that certain constraints are adhered to.     Within logic-based languages such as OWL, statements in ontolo-gies have a de\ufb01 nite logical meaning within a set-based logical the-ory. Classes have instances as members, and logical axioms de\ufb01 ne constraints on class de\ufb01 nitions that apply to all class members. For example, the statement  carboxylic acid   is_a   carbon oxoacid  has the logical meaning that all instances of carboxylic acid are also instances of carbon oxoacid:  \"()\u00ae()xCarboxylicAcidxCarbonOxoacidx:   The logical languages underlying ontology technology are collec-tively called Description Logics [ 13 ]\u2014in the plural because there are different variants with different levels of complexity. Some of the different ingredients of logical axioms that are available in the OWL language\u2014quanti\ufb01 cation, cardinality, logical connectives and negation, disjointness and class equivalence\u2014are explained in Table  2 .   Like the carboxylic acid example above, each of these axiom types can be expressed as a logical statement. With these axioms, logic-based ontology reasoners are able to check for errors in an ontology. For example, if a class relation is quanti\ufb01 ed with \u2018only\u2019 such as the hydrocarbon example given in the table, which in logi-cal language means \"\"()\u00d9()\u00ab()\u00da()xyHydrocarbonxhasPartxyHydrogenyCarbony:,  and then if a subclass of hydrocarbon in the ontology has a  has_part  relation with a target other than a hydrogen or a carbon (e.g. an oxygen):  HydrocarbonahasPartabOxygenb()\u00d9()\u00d9(),   that class will be detected as inconsistent and \ufb02 agged as such by the reasoner. 1   http://www.cs.man.ac.uk/~horrocks/obo/ 2   http://www.w3.org/TR/owl2-overview/ 2.5  AxiomsPrimer on Ontologies\f8 The end result\u2014an ontology which combines terminological knowledge with complex domain knowledge captured in logical form\u2014is thus amenable to various sophisticated tools which are able to use the captured knowledge to check for errors, derive inferences and support analyses.   3    Tools  Developing a complex computational knowledge base such as a bio-ontology (for example, the Gene Ontology includes 43,980 classes) requires tool support at multiple levels to assist the human knowledge engineers (curators) with their monumental task. For editing ontologies, a commonly used freely available platform is Prot\u00e9g\u00e9 [ 14 ]. Prot\u00e9g\u00e9 allows the editing of all aspects of an    Table 2    Logical constructs available in the OWL language    Language component  Informal meaning  Examples  Quanti\ufb01 cation: universal (only) or existential (some)  When specifying relationships between classes, it is necessary to specify a constraint on how the relationship should be interpreted: universal quanti\ufb01 cation means that for all relationships of that type the target has to belong to the speci\ufb01 ed class, while existential quanti\ufb01 cation means that at least one member of the target class must participate in a relationship of that type   molecule   has_part  some  atom    hydrocarbon   has_part  only ( hydrogen  or  carbon )  Cardinality: exact, minimum or maximum  It is possible to specify the number of relationships with a given type and target that a class must participate in, or a minimum or maximum number thereof.   human   has_part  exactly 2  leg   Logical connectives: intersection (and) or union (or)  It is possible to build complex expressions by joining together parts using the standard logical connectives and, or.   vitamin B  equivalentTo ( thiamin  or  ribo\ufb02 avin  or  niacin  or  pantothenic acid  or  pyridoxine  or  folic acid  or  vitamin B12 )  Negation (not)  In addition to building complex expressions using the logical connectives, it is possible to compose negations.  tailless equivalentTo  not ( has_part  some  tail )  Disjointness of classes  It is possible to specify that classes should not share any members.   organic  disjointFrom  inorganic   Equivalence of classes  It is possible to specify that two classes\u2014or class expressions\u2014are logically equivalent, and that they must by de\ufb01 nition thus share all their members.   melanoma  equivalentTo ( skin cancer  and  develops_from  some  melanocyte ) Janna Hastings\f9ontology including classes and relationships, logical axioms (in the OWL language) and metadata. Prot\u00e9g\u00e9 furthermore includes built-in support for the execution of automated reasoners to check for logical errors and for ontology visualisation using various different algorithms. Examples of reasoners that can be used within Prot\u00e9g\u00e9 are HermiT [ 15 ] and Fact++ [ 16 ]. For the rapid editing and con-struction of ontologies, various utilities are available, such as the creation of a large number of classes in a single \u2018wizard\u2019 step. The software is open source and has a pluggable architecture, which allows for custom modular extensions. Prot\u00e9g\u00e9 is able to open both OBO and OWL \ufb01 les, but it is designed primarily for the OWL lan-guage. An alternative editor speci\ufb01 c to the OBO language is OBO-Edit [ 17 ]. Relative to Prot\u00e9g\u00e9, OBO-Edit offers more sophisticated metadata searching and a more intuitive user interface.  To browse, search and navigate within a wide variety of bio- ontologies without installing any software or downloading any \ufb01 les, the BioPortal web platform provides an indispensable resource [ 18 ] that is especially important when using terminology from multiple ontologies. Additional browsing interfaces for multiple ontologies include the OLS [ 19 ] and OntoBee [ 20 ]. Most ontolo-gies are also supported by one or more browsing interfaces speci\ufb01 c to that single ontology, and for the Gene Ontology the most com-monly used interfaces are AmiGO [ 21 ] and QuickGO [ 22 ].  Large-scale ontologies such as the GO and ChEBI are often additionally supported by custom-built software tailored to their speci\ufb01 c use case, for example embedding the capability to create species-speci\ufb01 c \u2018slims\u2019 (subsets of terms of the greatest interest within the ontology for a speci\ufb01 c scenario) for the GO, or chemin-formatics support for ChEBI. As ontologies are shared across com-munities of users, an important part of the tool support pro\ufb01 le is tools for the community to provide feedback and to submit addi-tional entries to the ontology.  4    Applications  The purposes that are supported by modern bio-ontologies are diverse. The most straightforward application of ontologies is to support the structured annotation of data in a database. Here, ontologies are used to provide unique, stable identi\ufb01 ers\u2014associ-ated to a controlled vocabulary\u2014around which experimental data or manually captured reference information can be gathered [ 23 ]. An ontology annotation links a database entry or experimental result to an ontology class identi\ufb01 er, which, being independent of the single database or resource being annotated, is able to be shared across multiple contexts. Without such shared identi\ufb01 ers for biological entities, discrepant ways of referring to entities tend to accumulate\u2014different key words, or synonyms, or variants of Primer on Ontologies\f10identifying labels\u2014which signi\ufb01 cantly hinders reuse and integra-tion of the relevant data in different contexts.  Secondly, ontologies can serve as a rich source of vocabulary for a domain of interest, providing a dictionary of names, syn-onyms and interrelationships, thereby facilitating text mining (the automated discovery of knowledge from text) [ 24 ], intelligent searching (such as automatic query expansion and synonym search-ing, an example is described in [ 25 ]) and unambiguous identi\ufb01 ca-tion. When used in multiple independent contexts, such a common vocabulary can become additionally powerful. For example, unit-ing the representation of biological entities across different model organisms allows common annotations to be aggregated across species [ 26 ], which facilitates the translation of results from one organism into another in a fashion essential for the modern accu-mulation of knowledge in molecular biology. The use of a shared ontology also allows the comparison and translation entities from one discipline to another such as between biology and chemistry [ 27 ], enabling interdisciplinary tools that would be impossible computationally without a uni\ufb01 ed reference vocabulary.  While the above applications would be possible even if ontol-ogies consisted only of controlled vocabularies (standardised sets of vocabulary terms), the real power of ontologies comes with their hierarchical organisation and use of formal inter-entity rela-tionships. Through the hierarchy of the ontology, it is possible to annotate data to the most speci\ufb01 c applicable term but then to examine large-scale data in aggregate for patterns at the higher level categories. By centralising the hierarchical organisation in an application-independent ontology, different sources of data can be aggregated to converge as evidence for the same class-level inferences, and complex statistical tools can be built around knowledge bases of ontologies combined with their annotations, which check for over-representation or under-representation of given classes in the context of a given dataset relative to the back-ground of everything that is known [ 28 ] (for more information  see  Chap.   13     [ 29 ]). The knowledge-based relationships captured in the ontology can be used to assign quantitative measures of similarity between entities that would otherwise lack a quanti\ufb01 -able comparative metric [ 30 ] (for more information  see  Chap.   12     [ 31 ]). And the relationships between entities can be used to power sophisticated knowledge- based reasoning, such as the inference of which organs, tissues and cells belong to in anatomi-cal contexts [ 32 ].  With all these applications in mind, it is no wonder that the number and scope of bio-ontologies have been proliferating over the last decades. The OBO Foundry is a community organisation that offers a web portal in which participating ontologies are listed [ 33 ]. The web portal currently lists 137 ontologies, excluding Janna Hastings\f11obsolete records. Each of these ontologies has biological relevance and has agreed to abide by several community principles, including providing the ontology under an open license. Examples of these ontologies include ChEBI, the FMA, the Disease Ontology [ 34 ] and of course the Gene Ontology which is the topic of this book. In the context of the OBO Foundry, different ontologies are now becoming interrelated through inter-ontology relationships [ 35 ], and where there are overlaps in content they are being resolved through community workshops.  5    Limitations  Ontologies are a powerful technology for encoding domain knowl-edge in computable form in order to drive a multitude of different applications. However, they are not one-stop solutions for all knowledge representation requirements. There are certain limita-tions to the type of knowledge they can encode and the ways that applications can make use of that encoded knowledge.  Firstly, it is important to bear in mind that ontologies are based on logic. They are good at representing statements that are either true or false (categorical), but they cannot elegantly represent knowledge that is vague, statistical or conditional [ 36 ]. Classes that derive their meaning from comparison to a dynamic or condi-tional group (e.g.  the shortest person in the room , which may vary widely) are also not possible to represent well within ontologies. It can be dif\ufb01 cult to adequately capture knowledge about change over time at the class level, i.e. classes in which the members par-ticipate in relationships at one time and not at another, as  including a temporal index for each relation would require ternary relations which neither the OBO nor the OWL language support.  Furthermore, although the underlying technology for repre-sentation and automated reasoning has advanced a lot in recent years, there are still pragmatic limits to ensure the scalability of the reasoning tools. For this reason, higher order logical statements, non-binary relationships and other complex logical constructs can-not yet be represented and reasoned with in most of the modern ontology languages.       Acknowledgements  The author was supported by the European Molecular Biology Laboratory (EMBL). Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne. Primer on Ontologies\f12 Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     References     1.    Marx V (2013) Biology: the big challenges of big data. Nature 498:255\u2013260      2.    Holzinger A, Dehmer M, Jurisica I (2014) Knowledge discovery and interactive data min-ing in bioinformatics \u2013 state-of-the-art, future challenges and research directions. BMC Bioinformatics 15(Suppl 6):I1      3.    Palsson BO (2015) Systems biology: constraint- based reconstruction and analysis. Cambridge University Press, Cambridge      4.    Ashburner M, Ball CA, Blake JA et al (2000) Gene ontology: a tool for the uni\ufb01 cation of biology. Nat Genet 25:25\u201329      5.    Stevens R, Goble CA, Bechhofer S (2000) Ontology-based knowledge representation for bioinformatics. Brief Bioinform 1(4):398\u2013414      6.    Bodenreider O, Stevens R (2006) Bio- ontologies: current trends and future direc-tions. Brief Bioinform 7(3):256\u2013274      7.   Hoehdorf R, Scho\ufb01 eld PN, Gkoutos GV (2015) The role of ontologies in biological and biomedical research: a functional perspec-tive.  Brief Bioinform  (Advance Access) doi:  10.1093/bib/bbv011          8.    Hastings J, Owen G, Dekker A, Ennis M, Kale N, Muthukrishnan V, Turner S, Swainston N, Mendes P, Steinbeck C (2015) ChEBI in 2016: improved services and an expanding collection of metabolites. Nucleic Acids Res (advance online access). doi:  10.1093/nar/gkv1031          9.    Kanehisa M, Goto S, Sato Y, Kawashima M, Furumichi M, Tanabe M (2014) Data, infor-mation, knowledge and principle: back to metabolism in KEGG. Nucleic Acids Res 42:D199\u2013D205      10.    Golbreich C, Grosjean J, Darmoni SJ (2013) The foundational model of anatomy in OWL 2 and its use. Artif Intell Med 57(2):119\u2013132      11.    Smith B, Ceusters W, Klagges B, K\u00f6hler J, Kumar A, Lomax J, Mungall C, Neuhaus F, Rector AL, Rosse C (2005) Relations in bio-medical ontologies. Genome Biol 6:R46      12.    Tirmizi SH, Aitken S, Moreira DA, Mungall C, Sequeda J, Shah NH, Miranker DP (2011) Mapping between the OBO and OWL ontol-ogy languages. J Biomed Semantics 2(Suppl 1):S3      13.    Baader F, Calvanese D, McGuinness D, Nardi D, Patel-Schneider PF (2007) The description logic handbook: theory, implementation and applications, 2nd edn. Cambridge University Press, Cambridge      14.   Prot\u00e9g\u00e9 ontology editor.   http://protege.stan-ford.edu/    . Last Accessed Nov 2015      15.   Shearer R, Motik B, Horrocks I (2008) HermiT: a highly-ef\ufb01 cient OWL reasoner. In Proceedings of the 5th international workshop on owl: experiences and directions, Karlsruhe, Germany, 26\u201327 October 2008      16.   Tsarkov D, Horrocks I (2006) Fact++ descrip-tion logic reasoner: system description. In Proceedings of the third international joint conference on automated reasoning (IJCAR), pp 292\u2013297      17.    Day-Richter J, Harris M, Haendel M, The Gene Ontology OBO-Edit Working Group, Lewis S (2007) OBO-Edit\u2014an ontology edi-tor for biologists. Bioinformatics 23(16):2198\u20132200  Janna Hastings\f13    18.    Noy NF, Shah NH, Whetzel PL, Dai B et al (2009) BioPortal: ontologies and integrated data resources at the click of a mouse. Nucleic Acids Res 37(Suppl 2):W170\u2013W173      19.    C\u00f4t\u00e9 RG, Jones P, Apweiler R, Hermjakob H (2006) The Ontology Lookup Service, a lightweight cross-platform tool for controlled vocabulary queries. BMC Bioinformatics 7:97      20.   Xiang Z, Mungall C, Ruttenberg A, He Y (2011) OntoBee: a linked data server and browser for ontology terms. In Proceedings of the 2nd international conference on biomedi-cal ontologies (ICBO), 28\u201330 July, Buffalo, NY, USA, pp 279\u2013281      21.    Carbon S, Ireland A, Mungall C, Shu S, Marshall B, Lewis S, The Amigo Hub and the Web Presence Working Group (2008) AmiGO: online access to ontology and annotation data. Bioinformatics 25(2):288\u2013289      22.    Binns D, Dimmer E, Huntley R, Barrell D, O\u2019Donovan C, Apweiler R (2009) QuickGO: a web-based tool for Gene Ontology search-ing. Bioinformatics 25(22):3045\u20133046      23.    Blake J, Bult C (2006) Beyond the data del-uge: data integration and bio-ontologies. J Biomed Inform 39(3):314\u2013320      24.    Rebholz-Schuhmann D, Oellrich A, Hoehndorf R (2012) Text-mining solutions for biomedical research: enabling integrative biology. Nat Rev Genet 13:829\u2013839      25.   Imam, F, Larson, S, Bandrowski, A, Grethe, J, Gupta A, Martone MA (2012) Maturation of neuroscience information framework: an ontology driven information system for neuro-science. In Proceedings of the formal ontolo-gies in information systems conference, Frontiers in arti\ufb01 cial intelligence and applica-tions, vol 239, pp 15\u201328       26.    Huntley RP, Sawford T, Mutowo-Meullenet P, Shypitsyna A, Bonilla C, Martin MJ, O\u2019Donovan C (2015) The GOA Database: gene ontology annotation updates for 2015. Nucleic Acids Res 43(Database issue):D1057\u2013D1063      27.    Hill DP, Adams N, Bada M, Batchelor C et al (2013) Dovetailing biology and chemistry: integrating the Gene Ontology with the ChEBI chemical ontology. BMC Genomics 14:513      28.    Tipney H, Hunter L (2010) An introduction to effective use of enrichment analysis soft-ware. Hum Genomics 4(3):202\u2013206     29.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13      30.    Pesquita C, Faria D, Falcao AO, Lord P, Couto FM (2009) Semantic similarity in bio-medical ontologies. PLoS Comput Biol 5(7):e1000443      31.   Pesquita C (2016) Semantic similarity in the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12      32.    Osumi-Sutherland D, Reeve S, Mungall CJ, Neuhaus F, Ruttenberg A, Jefferis GS, Armstrong JD (2012) A strategy for building neuroanatomy ontologies. Bioinformatics 28(9):1262\u20131269      33.    Smith B, Ashburner M, Rosse C, Bard J et al (2007) The OBO Foundry: coordinated evo-lution of ontologies to support biomedical data integration. Nat Biotechnol 25:1251\u20131255      34.    Kibbe WA, Arze C, Felix V, Mitraka E et al (2015) Disease ontology 2015 update: an expanded and updated database of human dis-eases for linking biomedical knowledge through disease data. Nucleic Acids Res 43:D1071\u2013D1078      35.    Mungall CJ, Bada M, Berardini TZ, Deegan J, Ireland A, Harris MA, Hill DP, Lomax J (2011) Cross-product extensions of the gene ontology. J Biomed Inform 44(1):80\u201386      36.    Schulz S, Stenzhorn H, Boeker M, Smith B (2009) Strengths and limitations of formal ontologies in the biomedical domain. Rev Electron Comun Inf Inov Saude 3(1):31\u201345    Primer on Ontologies\f15    Chapter 2    The Gene Ontology and the Meaning of Biological Function                          Paul     D.     Thomas        Abstract    The Gene Ontology (GO) provides a framework and set of concepts for describing the functions of gene products from all organisms. It is speci\ufb01 cally designed for supporting the computational representation of biological systems. A GO annotation is an association between a speci\ufb01 c gene product and a GO concept, together making a statement pertinent to the function of that gene. However, the meaning of the term \u201cfunction\u201d is not as straightforward as it might seem, and has been discussed at length in both philosophi-cal and biological circles. Here, I \ufb01 rst review these discussions. I then present an explicit formulation of the biological model that underlies the GO and annotations, and discuss how this model relates to the broader debates on the meaning of biological function.    Key words     Genome  ,   Function  ,   Ontology  ,   Selected effects  ,   Causal role  1      What Is Biological Function?  The notion of function in biology has received a great deal of attention in the philosophical literature. At the broadest level, there are two schools of thought on how functions should be de\ufb01 ned, now most commonly referred to as \u201ccausal role function\u201d and \u201cselected effect function.\u201d Causal role function was \ufb01 rst pro-posed by Cummins [ 1 ], and it focuses on describing function in terms of how a part contributes to some overall capacity of the system that contains the part. In this formulation, the function of an entity is relative to some system to which it contributes. For example, the statement \u201cthe function of the heart is to pump blood\u201d has meaning only in the context of the larger circulatory system\u2019s capacity to deliver nutrients and remove waste products from bodily tissues. However, one of the main objections to the causal role de\ufb01 nition of function is that there is no systematic way to identify what the larger system (and the relevant capacity of that system) should be. Selected effect function, on the other hand, derives from the \u201cetiological\u201d de\ufb01 nition of function \ufb01 rst proposed by Wright [ 2 ]. In this formulation, a function of an entity is the Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_2, \u00a9 The Author(s) 2017\f16ultimate answer to the question of why the entity exists at all. In biology, as explained by Millikan [ 3 ] and Neander [ 4 ], this is tan-tamount to asking the following: For which of its effects was it selected during evolution? One obvious advantage of the selected effect de\ufb01 nition is that it explicitly incorporates evolutionary con-siderations, and demands that a function ultimately derive from its history of natural selection. On the more practical side, it has the further advantage of putting constraints on which effects, out of the myriad causal effects that a particular entity might have, could be considered as functions. Following the example above, an effect of the heart (beating) is to produce a sound, but it would not be correct to say that the function of the heart is to produce a sound. The selected effects de\ufb01 nition of function would distinguish a proper function (e.g., pumping blood) from an \u201caccidental\u201d effect (e.g., producing a sound) on the basis that natural selection more likely operated on the heart\u2019s effect of pumping blood. In the causal role de\ufb01 nition, on the other hand, there is always the poten-tial for arbitrariness and idiosyncrasy in de\ufb01 ning a containing sys-tem and capacities; thus there is no general rule for distinguishing functional from accidental effects.  Nevertheless, causal role function has been stalwartly defended by biologists in the subdiscipline of functional anatomy [ 5 ], which emphasizes how anatomical parts function as parts of larger sys-tems. They claim that the selected trait can be dif\ufb01 cult to infer, and lack of a hypothesis for such a trait should not stand in the way of an analysis of the mechanism of how an anatomical feature oper-ates. For example, one could analyze a jaw in terms of its capacity for generating a crushing force irrespective of whether it was selected for crushing seeds or defending against a predator. Indeed, the search for mechanisms of operation, or more generally just \u201cmechanism,\u201d has more recently been offered as an alternative par-adigm for molecular and neurobiology in particular [ 6 ]. Mechanism, like causal role, focuses on how parts contribute to a system. But it takes a step further in de\ufb01 ning core concepts, and how these relate to function. The core concepts are entities and activities: physical entities (such as proteins) perform activities, or actions that can have causal effects on other activities. In this view, a function is simply an activity that is carried out as part of a larger mechanism. For example, the function of the ribosome (an entity) is translation (an activity), and translation plays a role in a larger mechanism of gene expression. The subtle difference from earlier formulations of function is an emphasis on  the activity having the role of a function , rather than  the entity itself having a function . Also like causal role, no a priori constraints are put on mechanism: \u201ca function is \u2026 a component in some mechanism, that is \u2026 in a context that is taken to be important, vital, or otherwise signi\ufb01 cant.\u201d Clearly mechanism is susceptible to the same criticism as causal role function, regard-ing arbitrariness in the choice of system. Paul D. Thomas\f17 The core differences between selected effect function and causal role function derive largely from differences in what question they are trying to answer. For selected effect function, the question is about origins: Why is the entity there (i.e., what explains its selective advantage)? [ 2 ]. For causal role function, the question is about operation: How does the entity contribute to the biological capaci-ties of the organism that has the entity (and only secondarily, how do those capacities relate to natural selection)? [ 1 ]. And there is little doubt that in most biological research endeavors today, the concern is in elucidating the mechanisms by which biological systems oper-ate, rather than in explaining why the parts are there to begin with.  The notion of function, particularly in connection with molec-ular biology, has been discussed at length not only by philosophers, but also by molecular biologists themselves. As a representative sample, I will consider two publications written with very different aims in mind: a textbook chapter by Alberts entitled \u201cProtein Function\u201d [ 7 ] and a philosophical treatise by Monod,  Chance and Necessity  [ 8 ]. Alberts\u2019 treatment of \u201cfunction\u201d covers two distinct but related senses of the word. The \ufb01 rst is how an individual pro-tein  works  at the mechanistic level (its manner of functioning): \u201chow proteins bind to other selected molecules and how their activity depends on such binding.\u201d The second is to describe how a protein acts as a component in a larger system, by analogy to mechanical parts in human-designed systems (its functional role in the context of the operation of the cell): \u201cproteins \u2026 act as cata-lysts, signal receptors, switches, motors, or tiny pumps.\u201d Speci\ufb01 c molecular binding can be considered the general mechanism by which a functional role can be carried out. These uses of \u201cfunc-tion\u201d appear, at least on the face of it, to be more in line with the causal role and mechanism views in the philosophical literature.  Given its broader intended audience of scientists and laymen (and presumably philosophers),  Chance and Necessity  puts biologi-cal function in a much broader context. Monod coins the term \u201cteleonomic function\u201d to describe more precisely what he means by function. He carefully de\ufb01 nes teleonomy as the characteristic of \u201cobjects endowed with a purpose or project, which at the same time they exhibit through their structure and carry out through their performances\u201d [p. 9]. Teleonomy is also a property of human-designed \u201cartifacts,\u201d further emphasizing the view of function in terms of an apparent purpose in accomplishing a predetermined aim. But living systems owe their teleonomy to a distinct source. As he so eloquently (if also compactly) states, \u201cinvariance necessar-ily precedes teleonomy\u201d [p. 23], which he goes on to explain fur-ther as \u201cthe Darwinian idea that the initial appearance, evolution and steady re\ufb01 nement of ever more intensely teleonomic structures are due to perturbations in a structure  which already possesses the property of invariance .\u201d Thus what appears to be a future-goal-oriented action by a living organism is, in fact, only a blind The Gene Ontology and the Meaning of Biological Function\f18repetition of a genetic program that evolved in the past. Importantly, Monod notes the presence of teleonomy at all levels of a biological system, from proteins (which he calls \u201cthe essential molecular agents of teleonomic performance\u201d) to \u201csystems providing large scale coordination of the organism\u2019s performances \u2026 [such as] the endocrine and nervous systems\u201d [p. 62]. In this way, Monod\u2019s teleonomic function includes aspects of both Wright\u2019s selected effect function (the origin of apparently designed functions in prior natural selection) and Cummins\u2019s causal role function (the role of a part in a larger system).  In summary, function as conceived by molecular biologists (in what could be called the \u201cmolecular biology paradigm\u201d) refers to speci\ufb01 c, coordinated activities that have the appearance of having been designed for a purpose. That apparent purpose is their func-tion. The appearance of design derives from natural selection, so many biologists now favor the use of the term \u201cbiological pro-gram\u201d to avoid connotations of intentional design. Following this convention, biological programs, when executed, perform a func-tion; that is, they result in a particular, previously selected outcome or causal effect. Biological programs are nested modularly inside other, larger biological programs, so a protein can be said to have functions at multiple levels. The lowest level biological program is expression of a single macromolecule, e.g., a protein: the gene is transcribed into RNA, which is translated into a protein, which adopts a particular structure that performs its function simply by following physical laws that determine how it will interact with speci\ufb01 c (i.e., a small number) of other distinct types of other molecular entities. At higher levels, the functions of multiple pro-teins are executed in a coherent, controlled (\u201cregulated\u201d) manner to accomplish a larger function. Thus, simply identifying a coher-ent, regulated system of activities can be a fruitful, practical start for identifying selected effect functions. Causal role analyses can and do play such a role in functional anatomy and molecular biol-ogy. But of course they are only  candidates  for evolved biological functions until they have been related to past survival and repro-duction, the ultimate function of every biological program.  2    Function in the Gene Ontology  I now turn to a description of how function is conceived of, and represented in practice, in the Gene Ontology.    In order to understand how gene function is represented in the GO, some basic molecular biology knowledge is required. \u2013   A  gene  is a contiguous region of DNA that encodes instruc-tions for how the cell can make a large (\u201cmacro\u201d) molecule (or potentially multiple different macromolecules).  2.1  Gene Products, Not Genes, Have FunctionsPaul D. Thomas\f19 \u2013  A macromolecule is called a  gene product  (as it is produced deterministically according to the instructions from a gene), and can be of two types, a  protein  (the most common type) or a  noncoding RNA .   \u2013  A gene product can act as a molecular machine; that is, it can perform a chemical action that we call an  activity .   \u2013  Gene products from different genes can combine into a larger molecular machine, called a macromolecular  complex .     Each concept in the Gene Ontology relates to the activity of a gene product or complex, as these are the entities that carry out cellular processes. A gene encodes a gene product, so it can obvi-ously be considered the ultimate source of these activities and pro-cesses. But strictly speaking, a gene does not perform an activity itself. Thus, when the Gene Ontology refers to \u201cgene function,\u201d it is actually shorthand for \u201cgene product function.\u201d     The Gene Ontology de\ufb01 nes the \u201cuniverse\u201d of possible functions a gene might have, but it makes no claims about the function of any particular gene. Those claims are, instead, captured as \u201cGO anno-tations.\u201d A GO annotation is a statement about the function of a particular gene. But our biological knowledge is extremely incom-plete. Accordingly, the GO annotation format is designed to cap-ture partial, incomplete statements about gene function. A GO annotation typically associates only a single GO concept with a single gene. Together, these statements comprise a \u201csnapshot\u201d of current biological knowledge. Different pieces of knowledge regarding gene function may be established to different degrees, which is why each GO annotation always refers to the evidence upon which it is based.     The Gene Ontology (GO) considers three distinct aspects of how gene functions can be described:  molecular function ,  cellu-lar component , and  biological process  (note that throughout this chapter,  bold text  will denote speci\ufb01 c concepts, or classes, from the Gene Ontology). In order to understand what these aspects mean and how they relate to each other, it may be helpful to consider the biological model assumed in GO annotations. GO follows what could be called the \u201cmolecular biology paradigm,\u201d as described in the previous section. In this representation, a gene encodes a gene product, and that gene product carries out a molecular- level process or activity ( molecular function ) in a spe-ci\ufb01 c location relative to the cell  ( cellular component ), and this molecular process contributes to a larger biological objective ( bio-logical process ) comprised of multiple molecular-level processes. An example, elaborating on the example in the original GO paper [ 9 ], is shown in Fig.  1 .2.2  Assertions About Functions of Particular Genes Are Made by \u201cGO Annotations\u201d2.3  The Model of Gene Function Underlying the GOThe Gene Ontology and the Meaning of Biological Function\f20   To reiterate, GO concepts were designed to apply speci\ufb01 cally to the actions of gene products, i.e.,  macromolecular machines  comprising proteins, RNAs, and stable complexes thereof. In the GO representation, a region of DNA (e.g., a regulatory region) is treated not as carrying out a molecular process, but rather as an object that gene products can act upon in order to perform their speci\ufb01 c activities.     In the GO, a  molecular function  is a process that can be carried out by the action of a single macromolecular machine, via direct physical interactions with other molecular entities. Function in this sense denotes an action, or activity, that a gene product performs. These actions are described from the two distinct but related per-spectives commonly employed by biologists: (1) biochemical activ-ity, and (2) role as a component in a larger system/process. Biochemical activities include binding and catalytic activities, and are only functions in the broad sense, i.e., how something func-tions, the molecular mechanism of operation. Component role descriptions, on the other hand, refer to roles in larger processes, and are sometimes described by analogy to a mechanical or electri-cal system. For example, biologists may refer to a protein that func-tions (acts) as a  receptor . This is because the activity is interpreted as receiving a signal, and converting that signal into another physi-cochemical form. Unlike biochemical activities, these roles require some degree of   interpretation  that includes knowledge of the larger system context in which the gene product acts.     A cellular component is a location, relative to cellular compart-ments and structures, occupied by a macromolecular machine when it carries out a molecular function. There are two ways in which biologists describe locations of gene products: (1) relative to cellu-lar structures (e.g.,  cytoplasmic side of plasma membrane ) or compartments (e.g.,  mitochondrion   ), and (2) the stable 2.4  Molecular Functions De\ufb01 ne Molecular Processes (Activities)2.5  Cellular Components De\ufb01 ne Places Where Molecular Processes Occurcomplex(MCM2-7)DNA helicase activityNucleuscomplex(PRI1-2)DNA primase activityNucleuscomplex(RFC2-5)DNA clamp loader activityNucleusCDC9DNA ligase activityNucleuscomplex(POL3,POL31,POL32)DNA polymerase activityNucleusDNA-directed DNA replication  Fig. 1    DNA replication (in yeast) as modeled using the GO. Gene products/complexes ( white ) perform molecu-lar processes ( molecular function ,  red ) in speci\ufb01 c locations ( cellular component ,  yellow ), as part of larger biological objectives ( biological process , speci\ufb01 cally DNA-directed DNA replication)        Paul D. Thomas\f21macromolecular complexes of which they are parts (e.g., the  ribo-some ). Unlike the other aspects of GO,  cellular component  con-cepts refer not to processes but rather a cellular anatomy. Nevertheless, they are designed to be applied to the actions of gene products and complexes: a GO annotation to a cellular compo-nent provides information about where a molecular process may occur during a larger process.     In the GO, a  biological process  represents a speci\ufb01 c objective that the organism is genetically \u201cprogrammed\u201d to achieve. Each bio-logical process is often described by its outcome or ending state, e.g., the biological process of  cell division  results in the creation of two daughter cells (a divided cell) from a single parent cell. A biological process is accomplished by a particular set of molecular processes carried out by speci\ufb01 c gene products, often in a highly regulated manner and in a particular temporal sequence.  An annotation of a particular gene product to a GO biological process concept should therefore have a clear interpretation: the gene product carries out a molecular process that plays an integral role in that biological program. But a gene product can affect a biological objective even if it does not act strictly within the process, and in these cases a GO annotation aims to specify that relationship insofar as it is known. First, a gene product can control when and where the program is executed; that is, it might  regulate  the pro-gram. In this case, the gene product acts outside of the program, and controls (directly or indirectly) the activity of one or more gene products that act within the program. Second, the gene product might act in another, separate biological program that is  required for  the given program to occur. For instance, animal embryogenesis requires translation, though translation would not generally be con-sidered to be part of the embryogenesis program. Thus, currently a given  biological process  annotation could have any of these three meanings (namely a gene activity could be part of, regulate, or be upstream of but still necessary for, a biological process). The GO Consortium is currently exploring ways to  computationally repre-sent these different meanings so they can be distinguished.  Biological process is the largest of the three ontology aspects in the GO, and also the most diverse. This re\ufb02 ects the multiplicity of levels of biological organization at which genetically encoded pro-grams can be identi\ufb01 ed. Biological process concepts span the entire range of how biologists characterize biological systems. They can be as simple as a generic enzymatic process, e.g.,  protein phosphory-lation , to molecular pathways such as  glycolysis  or the  canonical Wnt signaling pathway , to complex programs like  embryo devel-opment  or  learning , and even including  reproduction , the ulti-mate function of every evolutionarily retained gene.  Because of this diversity, in practice not all biological process classes actually represent coherent, regulated biological programs. 2.6  Biological Processes De\ufb01 ne Biological Programs Comprised of Regulated Molecular ProcessesThe Gene Ontology and the Meaning of Biological Function\f22In particular, GO biological process also includes molecular-level processes that cannot always be distinguished from molecular func-tions. Taking the previous example, the process class  protein phos-phorylation  overlaps in meaning with the molecular activity class  protein kinase activity , as protein kinase activity is the enzymatic activity by which protein phosphorylation occurs. The main difference is that while a molecular function annotation has a precise semantics (e.g., the gene carries out protein kinase activity), the biological pro-cess annotation does not (e.g., the gene either carries out, regulates, or is upstream of but necessary for a particular protein kinase activity).   3    How Does the GO Relate to the Debate About the Meaning of Biological Function?  GO concepts are designed to describe aspects (molecular activity, location of the activity, and larger biological programs) of the  func-tions that a gene evolved to perform , i.e., selected effect functions. However, GO concepts may not always be applied that way. As a result, a given GO annotation may or may not be a statement about selected effect function. Note that while all biological programs are carried out by molecular activities, not all molecular activities nec-essarily contribute to a biological program. In principle, then, only those GO annotations that refer to biological programs can be considered to generally re\ufb02 ect selected effect functions.  A GO  molecular function  annotation by itself cannot be automatically interpreted as selected effect function. One of the most vigorous long-standing debates in the GO Consortium con-cerns the  protein binding  class in GO, as it is clearly appreciated by biologists that a given experimental observation of molecular binding may re\ufb02 ect biological noise and not necessarily contribu-tion to a biological objective. Even further removed,  cellular com-ponent  annotations are often made from observations of a protein in a particular compartment, irrespective of whether the protein performs a molecular activity in that location. For example, many proteins known to act extracellularly are also observed in the Golgi apparatus as they await traf\ufb01 cking to the plasma membrane. In short, if the molecular activity and  cellular  location are not yet implicated in a biological program (that is itself clearly related to survival and reproduction), they cannot be said to have selected effect function. Strictly speaking, such annotations should be con-sidered as referring to  candidate  functions, rather than  proper  functions.  Despite these theoretical considerations, most GO annotations are likely in practice to refer to selected effect functions. This is simply because most GO annotations are made from publications describing speci\ufb01 c, small-scale molecular biology studies that focus on a particular biological program. In such studies, a biological objective (usually implicitly related to survival and reproduction) Paul D. Thomas\f23has already been established in advance, and the paper describes the mechanistic activities of gene products in accomplishing that bio-logical objective. Large-scale studies, on the other hand, that mea-sure gene product activities or locations without reference to the biological program they are part of, should be considered as  candi-date  selected effect functions. This view would address the recent debate about gene function [ 10 \u2013 12 ], initiated when the ENCODE (Encyclopedia of DNA Elements) project\u2014a large- scale, hypothe-sis-free project to catalog biochemical activities across numerous regions of the human genome [ 13 ]\u2014inappropriately claimed to have discovered proper functions. The GO Consortium is discuss-ing ways to help users distinguish between hypothesis-driven anno-tations (likely proper functions) from large-scale annotations (candidate functions).  4    Conclusion  It has not generally been appreciated that the Gene Ontology con-cepts for describing aspects of gene function assume a speci\ufb01 c model of how gene products act to achieve biological objectives. My aim here has been to describe this model, which, I hope, will clarify how GO annotations should be properly used and inter-preted, as well as how the GO relates to biological function as discussed in both the philosophical and biological literature.       Acknowledgments  I want to thank Christophe Dessimoz, Pascale Gaudet, Jenna Hastings, and Ridhima Kad for helpful discussions on this topic, and for thoughtful reading and suggestions on the manuscript. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.  The Gene Ontology and the Meaning of Biological Function\f24   References      1.    Cummins R (1975) Functional analysis. J Philos 72:741\u2013765       2.    Wright L (1973) Functions. Philos Rev 82:139\u2013168      3.    Millikan RG (1989) In defense of proper func-tions. Philos Sci 56:288\u2013302      4.    Neander K (1991) The teleological notion of \u201cfunction.\u201d. Australas J Philos 69:454\u2013468      5.    Amundson R, Lauder GV (1994) Function without purpose: the uses of causal role func-tion in evolutionary biology. In: Hull DL, Ruse M (eds) Biology &amp; philosophy, vol 9. Oxford University Press, Oxford, pp 443\u2013469      6.    Machamer P, Darden L, Craver CF (2000) Thinking about mechanisms. Philos Sci 67:1\u201325      7.    Alberts B (2002) Protein function. In: Molecular biology of the cell, 4th edn. Garland Science, New York      8.    Monod J (1971) Chance and necessity. Alfred Knopf, New York      9.    Ashburner MA et al (2000) Gene ontology: tool for the uni\ufb01 cation of biology. Nat Genet 25:25\u201329      10.    Doolittle WF (2013) Is junk DNA bunk? A critique of ENCODE. Proc Natl Acad Sci U S A 110:5294\u20135300     11.    Doolittle WF et al (2014) Distinguishing between \u201cfunction\u201d and \u201ceffect\u201d in genome biology. Genome Biol Evol 6:1234\u20131237      12.    Graur D et al (2013) On the immortality of television sets: \u201cfunction\u201d in the human genome according to the evolution-free gospel of ENCODE. Genome Biol Evol 5:578\u2013590      13.    Dunham I et al (2012) An integrated encyclo-pedia of DNA elements in the human genome. Nature 489:57\u201374    Paul D. Thomas\f25    Chapter 3    Primer on the Gene Ontology                          Pascale     Gaudet     ,     Nives     \u0160kunca    ,     James     C.     Hu    , and     Christophe     Dessimoz       Abstract    The Gene Ontology (GO) project is the largest resource for cataloguing gene function. The combination of solid conceptual underpinnings and a practical set of features have made the GO a widely adopted resource in the research community and an essential resource for data analysis. In this chapter, we provide a concise primer for all users of the GO. We brie\ufb02 y introduce the structure of the ontology and explain how to interpret annotations associated with the GO.    Key words     Gene Ontology structure  ,   Evidence codes  ,   Annotations  ,   Gene association \ufb01 le (GAF)  ,   GO \ufb01 les  ,   Function  ,   Vocabulary  ,   Annotation evidence  1      Introduction  The key motivation behind the Gene Ontology (GO) was the observation that similar genes often have conserved functions in different organisms [ 1 ]. Clearly, a common vocabulary was needed to be able to compare the roles of orthologous genes (and their products) across different species. The value of comparative studies of biological function across systems predates Jacques Monod\u2019s statement that \u201canything found to be true of  E. coli  must also be true of elephants\u201d [ 2 ]. The Gene Ontology aims to produce a rig-orous shared vocabulary to describe the roles of genes across dif-ferent organisms [ 1 ]. The GO project consists of the  Gene Ontology  itself, which models biological aspects in a structured way, and  annotations , which associate genes or gene products with terms from the Gene Ontology. Combining information from all organ-isms in one central repository makes it possible to integrate knowl-edge from different databases, to infer the functionality of newly discovered genes, and to gain insight into the conservation and divergence of biological subsystems.  In this primer, we review the fundamentals of the GO project. The chapter is organised as answers to \ufb01 ve essential questions: What is the GO? Why use it? Who develops it and provides Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_3, \u00a9 The Author(s) 2017\f26 annotations? What are the elements of a GO annotation? And \ufb01 nally, how can the reader learn more about GO resources?  2    What Is the Gene Ontology?  The Gene Ontology is a controlled vocabulary of terms to repre-sent biology in a structured way. The terms are subdivided into three distinct ontologies that represent different biological aspects: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC) [ 1 ]. These ontologies are non-redundant and share a common space of identi\ufb01 ers and a well-speci\ufb01 ed syntax.  Terms are linked to each other by relations to form a hierarchical vocabulary (Chap.   1     [ 3 ]). This is often modelled as a graph in which the relationships form the directed edges, and the terms are the nodes (Fig.  1 ). Since each term can have multiple relationships to broader parent terms and to more speci\ufb01 c child terms, the structure allows for more expressivity than a simple hierarchy.GO:0031344regulation of cellprojectionorganizationGO:0060491regulation of cellprojection assemblyGO:0044085cellular componentbiogenesisGO:0022607cellular componentassemblyGO:0044087regulation ofcellular componentbiogenesisGO:0030031cell projectionassemblyGO:0008150biological_processGO:0050789regulation ofbiological processGO:0009987cellular processGO:0065007biological regulationGO:0044699single-organismprocessGO:0071840cellular componentorganization orbiogenesisGO:0051128regulation ofcellular componentorganizationGO:0050794regulation ofcellular processGO:0044763single-organismcellular processGO:0016043cellular componentorganizationGO:0030030cell projectionorganizationregulatesis_apart_of  Fig. 1    The structure of the Gene Ontology (GO) is illustrated on a subset of the paths of the term \u201cregulation of cell projection assembly\u201d, GO:0060491, to its root term. The GO is a directed graph with terms as nodes and relationships as edges; these relationships are either is_a, part_of, has_part, or regulates. In its basic repre-sentation, there should be no cycles in this graph, and we can therefore establish parent (more general) and child (more speci\ufb01 c) terms (Chap.   11     [ 4 ] for more details on the different representations). Note that it is pos-sible for a term to have multiple parents. This \ufb01 gure is based on the visualisation available from the AmiGO browser, generated on November 6, 2015 [ 5 ]        Pascale Gaudet et al.\f27   The full GO is large: in October 2015, the full ontology speci\ufb01 -cation had 43835 terms, 73776 explicitly encoded is_a relationships, 7436 explicitly encoded part_of relationships, and 8263 explicitly encoded regulates, negatively_regulates, or positively_regulates rela-tionships. This level of detail is not necessary for all applications. Many research groups who do GO annotations for speci\ufb01 c projects use the generic GO-slim \ufb01 le, which is a manually curated subset of the Gene Ontology containing general, high- level terms across all biological aspects. There are several GO slims, 1  ranging from the general Generic GO slim developed by the GO Consortium to more speci\ufb01 c ones, such as the Chembl Drug Target slim. 2   To keep up with the current state of knowledge, as well as to correct inaccuracies, the GO undergoes frequent revisions: changes of relationships between terms, addition of new terms, or term removal (obsoletion). Terms are never deleted from the ontology, but their status changes to obsolete and all relationships to the term are removed [ 6 ]. Furthermore, the name itself is preceded by the word \u201cobsolete\u201d and the rationale for the obsoletion is typi-cally found in the Comment \ufb01 eld of the term. An example of an obsolete term is GO:0000005, \u201cobsolete ribosomal chaperone activity\u201d. This MF GO term was made obsolete \u201cbecause it refers to a class of gene products and a biological process rather than a molecular function\u201d. 3  Changes to the  relationships  do not impact annotations, because annotations are associated with a given GO term regardless of its relationships to other terms within the GO. Obsoletion of terms however has an impact on  annotations  associ-ated with them: in some cases, the old term can be automatically replaced by a new or a parent one; in others, the change is so important that the annotations must be manually reviewed.  However, these changes can affect the analyses done using the ontology. In articles or reports, it is good practice to provide the version of the \ufb01 le used for a particular analysis. In GO, the version number is the date the \ufb01 le was obtained from the GO site (GO \ufb01 les are updated daily).  3    Why Use the Gene Ontology?  Because it provides a standardised vocabulary for describing gene and gene product functions and locations, the GO can be used to query a database in search of genes\u2019 function or location within the cell or to search for genes that share characteristics [ 7 ]. The hierar-chical structure of the GO allows to compare proteins annotated to different terms in the ontology, as long as the terms have 1   http://geneontology.org/page/go-slim-and-subset-guide 2   http://wwwdev.ebi.ac.uk/chembl/target/browser 3   https://www.ebi.ac.uk/QuickGO/GTerm?id=GO:0000005 Primer on the Gene Ontology\f28relationships to each other. Terms located close together in the ontology graph (i.e. with a few intermediate terms between them) tend to be semantically more similar than those further apart ( see  Chap.   12     on comparing terms [ 8 ]).  The GO is frequently used to analyse the results of high- throughput experiments. One common use is to infer common-alities in the location or function of genes that are over- or under-expressed [ 6 ,  9 ,  10 ]. In functional pro\ufb01 ling, the GO is used to determine which processes are different between sets of genes. This is done by using a likelihood-ratio test to determine if GO terms are represented differently between the two gene sets [ 6 ].  Additionally, the GO can be used to infer the function of unan-notated genes. Gene predictions with signi\ufb01 cant similarity to anno-tated genes can be assigned one or several of the functions of the characterised genes. Other methods such as the presence of speci\ufb01 c protein domains can also be used to assign GO terms [ 11 ,  12 ]. This is discussed in Chap.   5     [ 13 ].  A wealth of tools\u2014web-based services, stand-alone software, and programing interfaces\u2014has been developed for applying the GO to various tasks. Some of these are presented in Chap.   11     [ 4 ].  While Gene Ontology resources facilitate powerful inferences and analyses, researchers using the GO should familiarise them-selves with the structure of the ontology and also with the methods and assumptions behind the tools they use to ensure that their results are valid. Common pitfalls and remedies are detailed in Chap.   14     [ 14 ].  4    Who Develops the GO and Produces Annotations?  The GO Consortium consists of a number of large databases working together to de\ufb01 ne standardised ontologies and provide annotations to the GO [ 15 ]. The groups that constitute the GO consortium include UniProt [ 16 ], Mouse Genome Informatics [ 17 ],  Saccharomyces  Genome Database [ 18 ], Wormbase [ 19 ], Flybase [ 20 ], dictyBase [ 21 ], and TAIR [ 22 ]. In addition, several other groups contribute annotations, such as EcoCyc [ 23 ] and the Functional Gene Annotation group at University College London [ 24 ]. 4  Within each group, biocurators assign annota-tions according to their expertise [ 25 ]. Further, the GO Consortium has mechanisms by which members of the broader community ( see  Chap.   7     [ 26 ]) can suggest improvements to the ontology and annotations.  4   Full list at  http://geneontology.org/page/go-consortium-contributors-list Pascale Gaudet et al.\f295    What Are the Elements of a GO Annotation?  This section describes the different elements composing an anno-tation and some important considerations about each of them. The annotation process from a curator standpoint is discussed in detail in Chap.   4     [ 27 ].  Fundamentally, a GO annotation is the association of a gene product with a GO term. From its inception, the GO Consortium has recognised the importance of providing supporting infor-mation alongside this association. For instance, annotations always include information about the evidence supporting the annotation.  Over time, the GO Consortium standards for storing annota-tions have evolved to improve this representation. Annotations are now stored in one of the two formats: GAF (Gene Association File), and the more recent GPAD (Gene Product Association Data). The two formats contain the same information but there are differences in how the data is normalised and represented  (discussed in more details in Chap.   11     [ 4 ]). In this primer, we focus on the former. The representation of an annotation in the GAF \ufb01 le format 2.1 is shown in Fig.  2 . It contains 17 \ufb01 elds (also sometimes referred to as \u201ccolumns\u201d). We describe them in this section.     The annotation object is the entity associated with a GO term\u2014a gene, a protein, a non-protein-coding RNA, a macromolecular complex, or another gene product. Seven \ufb01 elds of the GAF \ufb01 le specify the annotation object. Each annotation in the GO is associ-ated with a database (\ufb01 eld 1) and a database accession number (\ufb01 eld 2) that together provide a unique identi\ufb01 er for the gene, the gene product, or the complex. For example, the protein record P00519 is a database object in the UniProtKB database (Fig.  2 ). The database object symbol (\ufb01 eld 3), the database object name (\ufb01 eld 10), and the database object synonyms (\ufb01 eld 11) provide additional information about the annotation object. The database object type speci\ufb01 es whether the object being annotated is a gene, or a gene product (e.g. protein or RNA; \ufb01 eld 12). The organism from which the annotation object is derived is captured as the NCBI taxon ID (taxon; \ufb01 eld 13); the corresponding species name can be found at the NCBI taxonomy website. 5   GO allows capturing isoform-speci\ufb01 c data when appropriate; for example UniProtKB accession numbers P00519-1 and P00519-2 are the isoform identi\ufb01 ers for isoform 1 and 2 of P00519. In this case, the database ID still refers to the main iso-form, and an isoform accession is included in the GAF \ufb01 le as \u201cGene Product Form ID\u201d (\ufb01 eld 17).  5   http://www.ncbi.nlm.nih.gov/taxonomy 5.1  Annotation ObjectPrimer on the Gene Ontology\f30   Three \ufb01 elds are used to specify the function of the annotation object. Field 5 speci\ufb01 es the GO term, while \ufb01 eld 9 denotes the sub-ontology of GO, either Molecular Function, Biological Process, or Cellular Component. While this information is also encoded in the GO hierarchy, explicitly denoting the sub-ontol-ogy allows to simplify parsing of the annotations according to the GO aspect. Field 4 denotes the quali\ufb01 er. One of the three quali-\ufb01 ers can modify the interpretation of an annotation: \u201ccontributes_to\u201d, \u201ccolocalizes_with\u201d and \u201cNOT\u201d. This \ufb01 eld is not mandatory, but if present it can profoundly change the meaning of an 5.2  GO Term, Annotation Extension, and Quali\ufb01 er(cid:129)Database from which the identi\ufb01er in column 2 is derived.1. UniProtKB  {1}(cid:129)Identi\ufb01er in the database denoted in column 1.2. P00519 {1}(cid:129)Database object symbol; whenever possible, this entry is assigned such that it is interpretable by a biologist.3. PHO3  {1}(cid:129)Flags that modify the interpretation of an annotation. 4. NOT  {}(cid:129)The GO identi\ufb01er.5. GO:0003993  {1}(cid:129)One or more identi\ufb01ers for the authority behind the annotation: e.g., PMID, GO Reference Code, or a database reference. 6. PMID:2676709      {+}(cid:129)Evidence code; one of the codes listed in Figure 2. 7. IMP  {1}(cid:129)The content depends on the evidence code used and contains more information on the annotation.8. GO:0000346  {}(cid:129)The ontology or aspect to which the GO term in column 5 belongs to. 9. F  {1}(cid:129)Name of the gene or the gene product. 10. acid    phosphatase  {?}(cid:129)Synonym for the identi\ufb01er denoted in column 2 for the database in column 1.11. YBR092C  {}(cid:129)The type of object denoted in column 2, e.g., gene, transcript, protein, or protein_structure.12. gene  {1}(cid:129)The NCBI ID of the respective organism(s).13. taxon:4932       {1,2}(cid:129)Date on which the annotation was made; note that IEA annotations are re-calculated with every database release. 14. 20010118  {1}(cid:129)The database asserting the annotation. 15. SGD  {1}Zero, one, or more of: NOT (negates the annotation), contributes_to (when the gene product is part of a complex), and colocalizes_with (only used for the CC ontology). For single-organism terms, the NCBI taxonomy ID of the respective organism. For multi-organism terms, this column is used either in conjunction with a BP term that is_amulti-organism process or CC term that is_ahost cell, in which case there are two pipe-separated NCBI taxonomy IDs: the \ufb01rst denotes the organism encoding the gene or the gene product; the second denotes the organism in the interaction. C is Cellular Component, P is Biological Process, and M is Molecular Function. Different content is possible: -GO ID is used in conjunction with evidence code Inferred by Curator (IC) to denote the GO term from which the inference is made. -Gene product ID is used in conjunction with evidence codes IEA, IGI, IPI, and ISS. For example, in conjunction with the evidence code Inferred from Sequence Similarity (ISS), it identi\ufb01es the gene product, similarity to which was the basis for the annotation. Any database in the GO consortium can makeinferences about any organism, so it is not obligatory that the field 13 corresponds to the field 15.(cid:129)Annotation extension. 16. part_of     (CL:0000084) {}Cross references to GO or other ontologies that can enhance the annotation. (cid:129)Gene Product Form ID. 17. UniProtKB:      P00519-2   {?}This field allows the annotation of specific variants of that gene or gene product.   Fig. 2    Gene Association File (GAF) 2.1 \ufb01 le format described with example elements. In the GAF \ufb01 le, each row represents an annotation, consisting of up to 17 tab-delimited \ufb01 elds (or columns). This \ufb01 gure describes these \ufb01 elds in the order in which they are found in the GAF \ufb01 le.  Light blue colour  denotes non-mandatory \ufb01 elds, and these are allowed to be empty in the GAF \ufb01 le. The cardinality\u2014the number of elements in the \ufb01 eld\u2014is denoted with the symbol(s) in curly brackets: {?} indicates cardinality of zero or one; {*} indicates that any cardinality is allowed; {+} indicates cardinality of one or more; {1} indicates that cardinality is exactly one; {1,2} indicates that cardinality is either one or two. When cardinality is greater than 1, elements in the \ufb01 eld are sepa-rated with a pipe character or with a comma; the former indicates \u201cOR\u201d and the latter indicates \u201cAND\u201d. The GO term assigned in column 5 is always the most speci\ufb01 c GO term possible        Pascale Gaudet et al.\f31annotation [ 6 ]. Thus, while the  producers  of annotations may omit quali\ufb01 ers, applications that  consume  GO annotations must take them into account. The importance of quali\ufb01 ers is discussed in more detail in Chap.   14     [ 14 ].  An additional \ufb01 eld, \ufb01 eld 16, is a recent addition to combine more than one term or concept (protein, cell type, etc.) in the same annotation. For example, 6  if a gene product Slp1 is localised to the plasma membrane of T-cells, the GAF \ufb01 le \ufb01 eld 16 would contain the information \u201cpart_of(CL:0000084 T cell)\u201d. Here, CL:0000084 is the identi\ufb01 er for T-cell in the OBO Cell Type (CL) Ontology. This is covered in details in Chap.   17     [ 28 ] on annota-tion extensions.     Three \ufb01 elds in the GAF \ufb01 le describe the evidence used to assert the annotation: the Reference (\ufb01 eld 6), the Evidence Code (\ufb01 eld 7), and the With/From (\ufb01 eld 8). The Evidence Code informs the type of experiment or analysis that supports the annotation. There are 21 evidence codes, which can be grouped in three broad catego-ries: experimental annotations, curated non-experimental annota-tions, and automatically assigned (also known as electronic) annotations (Fig.  3 ). The Reference \ufb01 eld speci\ufb01 es more details on the source of the annotation. For example, when the evidence code denotes an experimentally supported annotation, the Reference will contain the PubMed accession ID (or a DOI if no PubMed ID is available) of the journal article which underpins the annotation, or a GO_REF identi\ufb01 er that refers to a short description of the assignment method, accessible on the GO website. 7  When the evi-dence code denotes an automatically assigned annotation, i.e. IEA, the reference will contain GO_REF identi\ufb01 ers that specify more details on the automatic assignment, e.g. annotation via the InterPro resource [ 29 ].     Annotations based on direct experimental evidence found in the primary literature are denoted with the general evidence code EXP (Inferred from Experiment) or, when appropriate, the more spe-ci\ufb01 c evidence codes IDA (Inferred from Direct Assay), IPI (Inferred from Physical Interaction), IMP (Inferred from Mutant Phenotype), IGI (Inferred from Genetic Interaction), and IEP (Inferred from Expression Pattern) (Fig.  3 ). These annotations are held in high regard by the community, e.g. [ 30 ], and are often used in applica-tions such as checking the enrichment of a gene set in particular functions, \ufb01 nding genes that perform a speci\ufb01 c function, or assess-ing involvement in speci\ufb01 c pathways or processes. 6   http://wiki.geneontology.org/index.php/Annotation_Extension#The_basic_format 7   http://www.geneontology.org/cgi-bin/references.cgi 5.3  Evidence Code and Reference Field5.3.1  Experimentally Supported AnnotationsPrimer on the Gene Ontology\f32 Another important use of experimentally supported annota-tions is in providing trustworthy training sets for various computa-tional methods that infer function [ 31 ]. Used this way, the experimentally supported annotations can be ampli\ufb01 ed to under-stand more of the growing set of newly sequenced genes.     Fourteen of the 21 evidence codes are associated with manually curated non-experimental annotations. Annotations associated with these codes are curated in the sense that every annotation is reviewed by a curator, but they are non-experimental in the sense that there is no direct experimental evidence in the primary litera-ture underpinning them; instead, they are inferred by curators based on different kinds of analyses.  ISS (Inferred from Sequence or Structural Similarity) is a superclass (i.e. a parent) of ISA (Inferred from Sequence Alignment), ISO (Inferred from Sequence Orthology), and ISM (Inferred from Sequence Model) evidence codes. Each of the three subcategories of ISS should be used when only one method was used to make the inference. For example, to improve the accuracy of function propagation by sequence similarity, many methods take into account the evolutionary relationships among genes. Most of these methods rely on orthology (ISO evidence code), because the function of orthologs tends to be more conserved across species than paralogs [ 32 ,  33 ]. In a typical analysis, characterised and uncharacterised genes are clustered based on sequence similarity measures and phylogenetic relationships. The function of unknown genes is then inferred from the function of characterised genes within the same cluster (e.g. [ 34 ,  35 ]). 5.3.2  Curated Non- experimental AnnotationsExperimentalannotations (EXP)Inferred from Direct Assay (IDA)Inferred from Physical Interaction (IPI)Inferred from Mutant Phenotype (IMP)Inferred from Genetic Interaction (IGI)Inferred from Expression Pattern (IEP)Curated non-experimental annotationsInferred from Sequence or Structural Similarity (ISS)(cid:129)Inferred from Sequence Orthology (ISO) (cid:129)Inferred from Sequence Alignment (ISA)(cid:129)Inferred from Sequence Model (ISM)(cid:129)(cid:129)(cid:129)(cid:129)Inferred from Biological aspect ofAncestor (IBA)Inferred from Biological aspect ofDescendant (IBD)Inferred from Key Residues (IKR)Inferred from Rapid Divergence (IRD)Inferred from Reviewed Computational Analysis (RCA)Traceable Author Statement (TAS)Non-traceable Author Statement (NAS)Automatically assignedannotationsInferred from Electronic Annotation (IEA)Inferred from Genomic Context (IGC)Inferred by Curator (IC)No biological Data available (ND)Inferred from Phylogenetic Evidence  Fig. 3    GO Evidence Codes and their abbreviations. The type of information supporting annotations is recorded with Evidence Codes, which can be grouped into three main categories: experimental evidence codes, curated non-experimental annotations, and automatically assigned annotations. The obsolete evidence code NR (Not Recorded) is not included in the \ufb01 gure. Documentation about the different types of automatically assigned annotations can be found at   http://www.geneontology.org/doc/GO.references            Pascale Gaudet et al.\f33 Another approach to function prediction entails supervised machine learning based on features derived from protein sequence [ 36 \u2013 39 ] (ISM evidence code). Such approach uses a training set of classi\ufb01 ed sequences to learn features that can be used to infer gene functions. Although few explicit assumptions about the complex relationship between protein sequence and function are required, the results are dependent on the accuracy and completeness of the training data.  IGC (Inferred from Genomic Context) includes, but is not limited to, such things as identity of the genes neighbouring the gene product in question (i.e. synteny), operon structure, and phy-logenetic or other whole-genome analysis.  Relatively new are four evidence codes associated with phylo-genetic analyses. IBA (Inferred from Biological aspect of Ancestor) and IBD (Inferred from Biological aspect of Descendant) indicate annotations that are propagated along a gene tree. Note that the latter is only applicable to ancestral genes. The loss of an active site, a binding site, or a domain critical for a particular function can be annotated using the IKR (Inferred from Key Residues) evidence code. When this code is assigned by PAINT, GO\u2019s Phylogenetic Annotation and INference Tool [ 40 ], this means that it is a predic-tion based on evolutionary neighbours. Finally, negative annota-tions can be assigned to highly divergent sequences using the code IRD (Inferred from Rapid Divergence).  RCA (inferred from Reviewed Computational Analysis) cap-tures annotations derived from predictions based on computa-tional analyses of large-scale experimental data sets, or based on computational analyses that integrate datasets of several types, including experimental data (e.g. expression data, protein-protein interaction data, genetic interaction data), sequence data (e.g. pro-moter sequence, sequence-based structural predictions), or math-ematical models.  Next, there are two types of annotations derived from author statements. Traceable Author Statement (TAS) refers to papers where the result is cited, but not the original evidence itself, such as review papers. On the other hand a NAS (Non-traceable Author Statement) refers to a statement in a database entry or statements in papers that cannot be traced to another paper.  The \ufb01 nal two evidence codes for curated non-experimental annotations are IC (Inferred by Curator) and ND (No biological Data available). If an assignment of a GO term is made using the curator\u2019s expert knowledge, concluding from the context of the available data, but without any  direct  evidence available, the IC evidence code is used. For example, if a eukaryotic protein is anno-tated with the MF term \u201cDNA ligase activity\u201d, the curator can assign the BP term \u201cDNA ligation\u201d and CC term \u201cnucleus\u201d with the evidence code IC. Primer on the Gene Ontology\f34 The ND evidence code indicates that the function is currently unknown (i.e. that no characterisation of the gene is currently available). Such an annotation is made to the root of the respective ontology to indicate which functional aspect is unknown. Hence, the ND evidence code allows users for a subtle difference between unannotated genes (for which the literature has not been com-pletely reviewed and thus no GO annotation has been made) and uncharacterised genes (GO annotation with ND code). Note that the ND code is also different from an annotation with the \u201cNOT\u201d quali\ufb01 er (which indicates the absence of a particular function).     The evidence code IEA (Inferred from Electronic Annotation) is used for all inferences made without human supervision, regardless of the method used. IEA evidence code is by far the most abun-dantly used evidence code. The guiding idea behind computational function annotation is the notion that genes with similar sequences or structures are likely to be evolutionarily related, and thus, assuming that they largely kept their ancestral function, they might still have similar functional roles today. For an in-depth discussion of computational methods for GO function annotations, refer to Chap.   5     or  see  refs. [ 13 ,  41 ].     Biases associated with the different evidence codes are discussed in Chap.   14    . Note that there is a more extensive Evidence and Conclusion Ontology ( ECO;  [ 42 ]), formerly known as the \u201cEvidence Code Ontology\u201d, presented in Chap.   18     [ 43 ] . ECO is only partially implemented in the GO: ECOs are displayed in the AmiGO browser, but they are not in the GAF \ufb01 le. However, all Evidence Codes used by the GO are found also in ECO. There is a general assumption among the GO user community that annotations based on experi-ments are of higher quality compared to those generated electroni-cally, but this has yet to be empirically demonstrated. Generally, annotations derived from automatic methods tend to be to high-level terms, so they may have a lower  information value, but they often withstand scrutiny. Conversely, experiments are sometimes over-interpreted ( see  Chap.   4     [ 27 ]) and can also contain inaccuracies.      No two annotations can have the same combination of the follow-ing \ufb01 elds: gene/protein ID, GO term, evidence code, reference, and isoform. Thus one gene can be annotated to the same term with more than one evidence code.  Most GO analyses are gene based, and therefore it is important in such analyses to make sure that the list of genes is non- redundant. However, annotations are often made to larger protein sets that include multiple proteins from the same gene. This is particularly evident in UniProt, which can contain distinct entries from the TrEMBL (unre-viewed) portion of the database that do not necessarily represent bio-logically distinct proteins. The different entries for the same protein or gene are often annotated with identical GO terms, which can bias 5.3.3  Automatically Assigned Annotations5.3.4  Additional Considerations About Evidence Codes5.4  Uniqueness of GO Annotations (or Lack Thereof)Pascale Gaudet et al.\f35statistical analyses because some genes have many more entries than other genes. For instance, the set of human proteins in UniProt com-prises over 70,000 entries, but there are only approximately 20,000 recognised human protein-coding genes (20,187 reviewed human proteins in the UniProt release of 2015_12). The GO Consortium has worked with UniProt as well as the Quest for Orthologs Consortium to develop \u201cgene-centric\u201d reference proteome lists (  http://www.uni-prot.org/proteomes/    ) that provide a single \u201ccanonical\u201d UniProt entry for each protein- coding gene. These lists are available for many species, and we encourage users performing gene-centric GO analyses to use only the annotations for UniProt entries in these lists.   6    How Can I Learn More About Gene Ontology Resources?  Most of the topics introduced in this primer will be treated in more depth and nuance in later chapters. Part II focuses on the creation of GO function annotations\u2014we cover in depth the two main strategies of creating GO function annotations: manual extrac-tion/curation from the literature and computational prediction. Part III describes the main strategies used to evaluate their predic-tive performance. Part IV covers practical uses of the GO annota-tions: we discuss how GO terms and GO annotations can be summed and compared, how enrichment in speci\ufb01 c GO terms can be analysed, and how the GO annotations can be visualised. For the advanced GO user, Part V discusses how the context of a GO annotation is recorded and goes beyond the Evidence Codes to describe how to capture more information on the source of an annotation. We end with Part VI by going beyond GO: we present alternatives to GO for functional annotation; we show how a struc-tured vocabulary is used in the context of controlled clinical termi-nologies; and we present how information from different structured vocabularies is integrated in one overarching resource.       Acknowledgements   The authors gratefully acknowledge extensive feedback and ideas from Kimberly Van Auken, Marcus C. Chibucos, Prudence Mutowo, and Paul D. Thomas. PG acknowledges National Institutes of Health/National Human Genome Research Institute grant HG002273. CD acknowledges Swiss National Science Foundation grant 150654 and UK BBSRC grant BB/M015009/1. JH acknowl-edges National Institutes of Health/National Institute for General Medical Sciences grant U24GM088849. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne. Primer on the Gene Ontology\f36 Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     References       1.    Ashburner M, Ball CA, Blake JA et al (2000) Gene ontology: tool for the uni\ufb01 cation of biol-ogy. The Gene Ontology Consortium. Nat Genet 25:25\u201329      2.    Friedmann HC (2004) From \u201cbutyribacte-rium\u201d to \u201cE. coli\u201d: an essay on unity in bio-chemistry. Perspect Biol Med 47:47\u201366      3.   Hastings J (2016) Primer on ontologies. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1        4.   Munoz-Torres M, Carbon S (2016) Get GO! retrieving GO data using AmiGO, QuickGO, API, \ufb01 les, and tools. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 11      5.    Carbon S, Ireland A, Mungall CJ et al (2009) AmiGO: online access to ontology and anno-tation data. Bioinformatics 25:288\u2013289         6.    Rhee SY, Wood V, Dolinski K et al (2008) Use and misuse of the gene ontology annotations. Nat Rev Genet 9:509\u2013515      7.    Arnaud MB, Costanzo MC, Shah P et al (2009) Gene Ontology and the annotation of pathogen genomes: the case of Candida albi-cans. Trends Microbiol 17:295\u2013303      8.   Pesquita C (2016) Semantic similarity in the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12      9.    Lovering RC, Camon EB, Blake JA et al (2008) Access to immunology through the Gene Ontology. Immunology 125:154\u2013160      10.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13      11.   Burge S, Kelly E, Lonsdale D, et al. (2012) Manual GO annotation of predictive protein signatures: the InterPro approach to GO cura-tion. Database:bar068      12.    Pedruzzi I, Rivoire C, Auchincloss AH et al (2015) HAMAP in 2015: updates to the pro-tein family classi\ufb01 cation and annotation sys-tem. Nucleic Acids Res 43:D1064\u2013D1070       13.   Cozzetto D, Jones DT (2016) Computational methods for annotation transfers from sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 5       14.   Gaudet P, Dessimoz C (2016) Gene ontology: pitfalls, biases, and remedies. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 14      15.    Gene Ontology Consortium (2015) Gene Ontology Consortium: going forward. Nucleic Acids Res 43:D1049\u2013D1056      16.    The UniProt Consortium (2014) Activities at the Universal Protein Resource (UniProt). Nucleic Acids Res 42:D191\u2013D198      17.   Drabkin HJ, Blake JA, Mouse Genome Informatics Database (2012) Manual gene ontol-ogy annotation work\ufb02 ow at the Mouse Genome Informatics Database. Database:bas045      18.    Hong EL, Balakrishnan R, Dong Q et al (2008) Gene ontology annotations at SGD: Pascale Gaudet et al.\f37new data sources and annotation methods. Nucleic Acids Res 36:D577\u2013D581      19.   Davis P, WormBase Consortium (2009) WormBase \u2013 nematode biology and genomes.   http://precedings.nature.com/documents/3127/version/1/\ufb01 les/npre20093127-1.pdf          20.    dos Santos G, Schroeder AJ, Goodman JL et al (2015) FlyBase: introduction of the Drosophila melanogaster Release 6 reference genome assembly and large-scale migration of genome annotations. Nucleic Acids Res 43:D690\u2013D697      21.    Gaudet P, Fey P, Basu S et al (2011) dictyBase update 2011: web 2.0 functionality and the initial steps towards a genome portal for the Amoebozoa. Nucleic Acids Res 39:D620\u2013D624      22.    Lamesch P, Berardini TZ, Li D et al (2012) The Arabidopsis Information Resource (TAIR): improved gene annotation and new tools. Nucleic Acids Res 40:D1202\u2013D1210      23.    Keseler IM, Bonavides-Mart\u00ednez C, Collado- Vides J et al (2009) EcoCyc: a comprehensive view of Escherichia coli biology. Nucleic Acids Res 37:D464\u2013D470      24.    Buchan DWA, Ward SM, Lobley AE et al (2010) Protein annotation and modelling servers at University College London. Nucleic Acids Res 38:W563\u2013W568      25.   Burge S, Attwood TK, Bateman A, et al. (2012) Biocurators and biocuration: survey-ing the 21st century challenges. Database:bar059      26.   Lovering RC (2016) How does the scienti\ufb01 c community contribute to gene ontology? In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 7       27.   Poux S, Gaudet P (2016) Best practices in manual annotation with the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 4      28.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17      29.    Hunter S, Jones P, Mitchell A et al (2012) InterPro in 2011: new developments in the family and domain prediction database. Nucleic Acids Res 40:D306\u2013D312       30.    Radivojac P, Clark WT, Oron TR et al (2013) A large-scale evaluation of computational pro-tein function prediction. Nat Methods 10:221\u2013227     31.   The Reference Genome Group of the Gene Ontology Consortium (2009) The Gene Ontology\u2019s Reference Genome Project: a uni-\ufb01 ed framework for functional annotation across species. PLoS Comput Biol 5:e1000431      32.    Tatusov RL, Koonin EV, Lipman DJ (1997) A genomic perspective on protein families. Science 278:631\u2013637      33.    Altenhoff AM, Studer RA, Robinson-Rechavi M et al (2012) Resolving the ortholog conjec-ture: orthologs tend to be weakly, but signi\ufb01 -cantly, more similar in function than paralogs. PLoS Comput Biol 8:e1002514      34.    Mi H, Muruganujan A, Casagrande JT et al (2013) Large-scale gene function analysis with the PANTHER classi\ufb01 cation system. Nat Protoc 8:1551\u20131566      35.    Altenhoff AM, \u0160kunca N, Glover N et al (2015) The OMA orthology database in 2015: function predictions, better plant support,  synteny view and other improvements. Nucleic Acids Res 43:D240\u2013D249      36.    Cai C (2003) SVM-Prot: web-based support vector machine software for functional classi\ufb01 -cation of a protein from its primary sequence. Nucleic Acids Res 31:3692\u20133697     37.    Levy ED, Ouzounis CA, Gilks WR et al (2005) Probabilistic annotation of protein sequences based on functional classi\ufb01 cations. BMC Bioinformatics 6:302     38.    Shen HB, Chou KC (2007) EzyPred: a top- down approach for predicting enzyme func-tional classes and subclasses. Biochem Biophys Res Commun 364:53\u201359      39.    Lobley AE, Nugent T, Orengo CA et al (2008) FFPred: an integrated feature-based function prediction server for vertebrate proteomes. Nucleic Acids Res 36:W297\u2013W302      40.    Gaudet P, Livstone MS, Lewis SE et al (2011) Phylogenetic-based propagation of functional annotations within the Gene Ontology Consortium. Brief Bioinform 12:449\u2013462      41.    \u0160kunca N, Altenhoff A, Dessimoz C (2012) Quality of computationally inferred gene ontol-ogy annotations. PLoS Comput Biol 8:e1002533      42.   Chibucos MC, Mungall CJ, Balakrishnan R et al. (2014) Standardized description of scien-ti\ufb01 c evidence using the Evidence Ontology (ECO). Database:bau075      43.   Chibucos MC, Siegele DA, Hu JC, Giglio M (2016) The evidence and conclusion ontology (ECO): supporting GO annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 18    Primer on the Gene Ontology\f   Part II    Making Gene Ontology Annotations        \f41    Chapter 4    Best Practices in Manual Annotation with the Gene Ontology                          Sylvain     Poux     and     Pascale     Gaudet        Abstract    The Gene Ontology (GO) is a framework designed to represent biological knowledge about gene prod-ucts\u2019 biological roles and the cellular location in which they act. Biocuration is a complex process: the body of scienti\ufb01 c literature is large and selection of appropriate GO terms can be challenging. Both these issues are compounded by the fact that our understanding of biology is still incomplete; hence it is important to appreciate that GO is inherently an evolving model. In this chapter, we describe how biocurators create GO annotations from experimental \ufb01 ndings from research articles. We describe the current best practices for high-quality literature curation and how GO curators succeed in modeling biology using a relatively simple framework. We also highlight a number of dif\ufb01 culties when translating experimental assays into GO annotations.    Key words     Gene ontology  ,   Expert curation  ,   Biocuration  ,   Protein annotation  1      Background  Biological databases have become an integral part of the tools researchers use on a daily basis for their work. GO is a controlled vocabulary for the description of biological function, and is used to annotate genes in a large number of genome and protein data-bases. Its computable structure makes it one of the most widely used resources. Manual annotation with GO involves biocurators, who are trained to reading, extracting, and translating experi-mental \ufb01 ndings from publications into GO terms. Since both the scienti\ufb01 c literature and the GO are complex, novice biocurators can make errors or misinterpretations when doing annotation. Here, we present guidelines and recommendations for best prac-tices in manual annotation, to help curators avoid the most com-mon pitfalls. These recommendations should be useful not only to biocurators, but also to users of the GO, since the understand-ing of the curation process should help understand the meaning of the annotations. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_4, \u00a9 The Author(s) 2017\f42   Our understanding of the world is built by observation and exper-imentation. The overall process of the scienti\ufb01 c method involves making hypotheses, deriving predictions from them, and then carrying out experiments to test the validity of these predictions. The results of the experiments are then used to  infer  whether the prediction was true or not [ 1 ]. Hypotheses are tested, validated, or rejected, and the combination of all the experiments contrib-utes to uncovering the mechanism underlying the process being studied (Fig.  1 ).   Examples of experiments include testing an enzymatic activity in vitro using puri\ufb01 ed reagents, measuring the expression level of a protein upon a given stimulus, or observing the phenotypes of an organism in which a gene has been deleted by molecular genet-ics techniques. Different inferences can be made from the same experimental setup depending on the hypothesis being tested. Thus, the conclusions that can be derived from individual experi-ments may vary, depending on a number of factors: they depend on the current state of knowledge, on how well controlled the experiment is, on the experimental conditions, etc. It also hap-pens that the conclusions from a low-resolution experiment are partially or completely refuted when better techniques become available. These factors are inherent to empirical studies and must be taken into account to ensure correct interpretation of experimental results.  1.1  Knowledge Inference: General PrinciplesTruefunctionExperimental resultHypothesis HypothesisconfirmedHypothesis rejectedNew hypothesis  Fig. 1    How the scienti\ufb01 c method is used to test and validate hypotheses        Sylvain Poux and Pascale Gaudet\f43   GO is a framework to describe the roles of gene products across all living organisms [ 2 ] ( see  also Chap.   2    , [ 3 ]). The ontology is divided into three branches, or aspects: Molecular Function (MF) that cap-tures the biochemical or molecular activity of the gene product; Biological Process (BP), corresponding to the wider biological module in which the gene product\u2019s MF acts; and Cellular Component (CC), which is the speci\ufb01 c cellular localization in which the gene product is active.  The association of a GO term and a gene product is not explic-itly de\ufb01 ned, but implicitly means that the gene product  has  an activity or a molecular role (MF term),  directly participates  in a process (BP), and the function takes place  in a speci\ufb01 c cellular localization  (CC) [ 2 ]. Therefore, transient localizations such as endoplasmic reticulum and Golgi apparatus for secreted proteins are not in the scope of GO. Biological process is the most challeng-ing aspect of the GO to capture, in part because it models two categories of processes:  subtypes : \u201cmitotic DNA replication\u201d (GO:1902969) is a particular type of \u201cnuclear DNA replication\u201d (GO:0033260), and  sub-processes : mitotic DNA replication is a step of the \u201ccell cycle\u201d (GO:0000278). These two classi\ufb01 cation axes are distinguished by \u201cis a\u201d and \u201cpart of\u201d relations with their parents, respectively. Gene products can be annotated using as many GO terms as necessary to completely describe its function, and the GO terms can be at varying levels in the hierarchy, depending on the evidence available. If a gene product is annotated to any particular term, then the annotations also hold for all the is-a and part-of par-ent terms. Annotations to more granular terms carry more infor-mation; however the annotation cannot be any deeper than what is supported by the evidence.  The complexity of biology is re\ufb02 ected in the GO: with 40,000 different terms [ 4 ], learning to use the GO can be compared to learning a new language. As when learning a language, there are terms that are closely related to those we are familiar with, and oth-ers that have subtle but important differences in meaning. The GO de\ufb01 nes each term in two complementary ways: \ufb01 rst by a textual de\ufb01 nition intended to be human readable. Secondly, the structure of the ontology as determined by relationships of terms between each other is also a way by which terms are de\ufb01 ned these can be utilized for computational reasoning.     There are two general methods for assigning GO terms to gene products. The \ufb01 rst is based on  experimental evidence , and involves detailed reading of scienti\ufb01 c publications to capture knowledge about gene products. Biocurators browse the GO ontologies to associate appropriate GO term(s) whose de\ufb01 nition is consistent with the data published for the gene product.  See  Chaps.   3     [ 5 ] and   17     [ 6 ], for a description of the elements of an annotation. Expert curation based on experiments is considered the gold standard of 1.2  Knowledge Representation Using Ontologies1.3  Methods for Assigning GO AnnotationsBest Practices in Manual Annotation with the Gene Ontology\f44functional annotation. It is the most reliable and provides strong support for the association of a GO term with a gene product.  The second method involves making  predictions  on the pro-tein\u2019s function and subcellular localization, most often with meth-ods relying on sequence similarity. Although not detailed in this chapter, prediction methods are highly dependent on annotations based on experiments. Indeed, all methods to assign annotations based on sequence similarity are more or less directly derived from knowledge that has been acquired experimentally; that is, at least one related protein must have been tested and shown to have a given function for that information to be propagated to other pro-teins. Hence, the accurate assignment of GO classes to gene prod-ucts based on experimental results is crucial, since many further annotations depend on their accuracy.   2    Best Practices for High-Quality Manual Curation     Similar to the process by which experimental results get trans-lated into a model of the biological phenomenon being investi-gated, biocurators take the conclusions from the investigation and convert it into the GO framework. Thus, the same assay may lead to different interpretations depending on the question being tested.  As shown in Table  1 , an assay must be interpreted in the wider context of the known roles of the protein, and how directly the assay assesses the protein\u2019s role in the process under investigation. Here, several experiments are described in which the readout is DNA fragmentation upon apoptotic stimulation, but that lead to different annotations. DFFB (UniProtKB O76075) is annotated to \u201capoptotic DNA fragmentation\u201d (GO:0006309) because the pro-tein is also known to be a nuclease. CYCS (UniProtKB P99999) is annotated to caspase activation (\u201cactivation of cysteine-type endo-peptidase activity involved in apoptotic process\u201d (GO:0006919)) because a direct role has been shown using an in vitro assay. However CYCS is not annotated to \u201capoptotic DNA fragmenta-tion\u201d (GO:0006309) despite the observation that removing it from cells prevents DNA fragmentation, since the activity of CYCS occurs before DNA fragmentation. Any step that takes place after-wards will inevitably fail to happen, but this does not imply partici-pation in this downstream sequence of molecular events. Finally, the FOXL2 (UniProtKB P58012) transcription factor has a posi-tive effect on the occurrence of apoptosis, by an unknown mecha-nism, so it is annotated to \u201cpositive regulation of apoptotic process\u201d (GO:0043065). This is where the curator\u2019s knowledge is critical and provides most added value over, e.g., machine learning and text mining2.1  GO Inference ProcessSylvain Poux and Pascale Gaudet\f45      With more than 500,000 records indexed yearly in PubMed, it is not possible for the GO to comprehensively represent all the avail-able data on every protein. To address this, a careful prioritization of both articles and proteins to annotate is done. The publications from which information is drawn are selected to accurately repre-sent the current state of knowledge. Accessory \ufb01 ndings and non- replicated data are not systematically annotated; con\ufb01 rmation or at least consistency with \ufb01 ndings from several publications is invalu-able to accurately describe the function of a gene product.  Focusing on a topic allows the curator to construct a clear pic-ture of the protein\u2019s role and makes it easier to make the best deci-sions when capturing biological knowledge as annotations. Reading different publications in the \ufb01 eld helps to resolve issues and select terms with more con\ufb01 dence. Existing GO annotation in proteins that participate in the same biological process is also helpful to 2.2  Needles and Haystacks   Table 1    GO inference process, from the hypothesis in the paper to the assay and result, and to the inference of a GO function or role    Protein  Known roles  Hypothesis  Assay \u2192 Result  Conclusion \u2192 GO  Reference  DDFB (O76075)  DNase  The nuclease activity of DDFB is required for nuclear DNA fragmentation during apoptosis  Apoptotic DNA fragmentation  \u2192Increased in the presence of DDFB  DDFB  mediates  nuclear DNA fragmentation during apoptosis  \u2192Apoptotic DNA fragmentation (GO:0006309)  [ 7 ]  CYCS (P99999)  Cytochrome C; electron transport  CYCS triggers the activation of caspase-3  Apoptotic DNA fragmentation  \u2192Decreased upon immunodepletion of CYCS 7  CYCS  directly activates  caspase-3  \u2192Activation of cysteine-type endopeptidase activity involved in apoptotic process (GO:0006919)  [ 8 ]  Puri\ufb01 ed CYCS  \u2192Stimulates the auto-proteolytic activity of caspase-3  FOXL2 (P58012)  Transcription factor  Mutations in FOXL2 are known to cause premature ovarian failure, which may be due to increased apoptosis  Apoptotic DNA fragmentation  \u2192Increased in the presence of FOXL2  FOXL2 increases the rate of apoptosis  \u2192Positive regulation of apoptotic process (GO:0043065)  [ 9 ] Best Practices in Manual Annotation with the Gene Ontology\f46decide on how best to represent the experimental data with the GO. On the other hand, without the broader context of the research domain, some papers may be misleading: \ufb01 rst, as more data accu-mulate, a growing number of contradictory or even incorrect results are found in the scienti\ufb01 c literature. Second, the way knowl-edge evolves occasionally obsoletes previous \ufb01 ndings. Curators use their expertise to assess the scienti\ufb01 c content of articles and avoid these pitfalls [ 10 ].     The level of granularity of an annotation is dictated by the evidence supporting it. A good illustration is provided by ADCK3 protein in human (UniProtKB Q8NI60), an atypical kinase containing a pro-tein kinase domain involved in the biosynthesis of ubiquinone, and an essential lipid-soluble electron transporter. Although it contains a protein kinase domain, it is unclear whether it acts as a protein kinase that phosphorylates other proteins in the CoQ complex or acts as a lipid kinase that phosphorylates a prenyl lipid in the ubi-quinone biosynthesis pathway [ 11 ]. While it would be tempting to conclude that the protein has \u201cprotein kinase activity\u201d (GO:0004672) from the presence of the protein kinase domain, the more general term \u201ckinase activity\u201d (GO:0016301) with no speci\ufb01 cation of the potential substrate class (lipid or protein) is more appropriate.       Annotations focus on capturing experiments that are biologically relevant. Thus, substrates, tissue, or cell-type speci\ufb01 city are anno-tated only when the data indicates the physiological importance of these parameters. One dif\ufb01 culty is that it is not always possible to distinguish between  experimental  context and  biological  context, which can potentially result in GO terms being assigned as if they represented a speci\ufb01 c role or under speci\ufb01 c conditions, while in fact this only re\ufb02 ects the experimental setup and does not have real biological signi\ufb01 cance. For example, the activity of E3 ubiquitin protein ligases is commonly tested by an in vitro autoubiquitina-tion assay. While convenient, the assay is not conclusive with respect to the \u201cprotein autoubiquitination\u201d (GO:0051865) in vivo. In the absence of additional data, only the term \u201cubiquitin protein ligase activity\u201d (GO:0061630) should be used. Similarly, the cell type in which a function was tested does not imply that the cell type is relevant for the function; any hint that the protein is studied outside its normal physiological context (such as overex-pression) should be carefully taken into consideration.     Downstream effects, as well as readouts (discussed above in Subheading  2.1 ), can lead to incorrect annotations if they are directly assigned to a gene product playing a role many steps  further. Here we use downstream as \u201coccurring after,\u201d with no implication on the  direct  sequentiality of the events. 2.3  How Low Can You Go: Deciding on the Level of Granularity of an Annotation2.4  Less Is More: Avoiding Over- Interpretation2.4.1  Biological Relevance of Experiments2.4.2  Downstream EffectsSylvain Poux and Pascale Gaudet\f47 Gene products that play housekeeping functions or function upstream of important signaling pathways have many indirect effects and pose a challenge for annotation. This can be illustrated by proteins that mediate chromatin modi\ufb01 cation. Histone tails are posttranslationally modi\ufb01 ed by a complex set of interdependent modi\ufb01 cations. For instance, histone H2B monoubiquitination at Lys-120 (H2BK120ub) is a prerequisite for the methylation of histone H3 at Lys-4 and Lys-79 (H3K4me and H3K79me, respec-tively) (Fig.  2 ). RNF20 (UniProtKB Q5VTR2), an E3 ubiquitin ligase that mediates H2BK120ub, therefore indirectly promotes H3K4me and H3K79me methylation [ 12 ]. Thus, the annotation of enzymes that modify histone tails is limited to the primary function of the enzyme (\u201cubiquitin-protein ligase activity\u201d (GO:0004842) and \u201chistone H2B ubiquitination\u201d (GO:0033523), in this case), while the further histone modi\ufb01 cations are only anno-tated to the proteins mediating these modi\ufb01 cations.   A similar approach is taken for cases where the experimental readout is also a GO term. Examples of this include DNA fragmen-tation assays to measure apoptosis, and MAPK cascade to measure the activation of an upstream pathway. Proteins that are involved in signaling leading to apoptosis do not mediate or  participate  in DNA fragmentation, but their addition or removal causes changes in the amount of DNA fragmentation upon apoptotic stimulation. In other words, the effect of a protein on a speci\ufb01 c readout can be very indirect. Whenever possible, annotation of these very speci\ufb01 c terms (\u201capoptotic DNA fragmentation\u201d (GO:0006309), \u201cMAPK cascade\u201d (GO:0000165)) is limited to cases where there is evidence of a molecular function supporting a direct implication in the pro-cess. If that information is not available, the annotation is made to a more general term, such as \u201capoptotic process\u201d (GO:0006915) or \u201cintracellular signal transduction\u201d (GO:0035556), for instance.     One common method to determine the function or process of a gene is mutagenesis. However, interpreting the results from mutant phenotypes is very dif\ufb01 cult, as the effects caused by the absence or disruption of a gene can be very indirect. Any kind of knockout/2.4.3  PhenotypesRNF20 (E3 ubiquitin ligase)H2BK120ub  -H3 complexH3K4me H3K79me H2Bmethylases  Fig. 2    Monoubiquitination of histone H2B (H2BK120ub) promotes methylation of histone H3 (H3K4me and H3K79me)        Best Practices in Manual Annotation with the Gene Ontology\f48knockdown or \u201cadd back\u201d experiments (in which proteins are either overexpressed or added to a cellular extract) cannot demon-strate the  participation  of a protein in a process, only its require-ment for the process to occur. Inferring a participatory role would be an over-interpretation of the results. A striking illustration of this can be made with housekeeping genes, such as those involved in transcription and translation: knockouts in these proteins (when not lethal) can be pleiotropic and affect essentially all cellular pro-cesses. It would be both inaccurate and overwhelming for curators to annotate these gene products to every cellular process impacted. The more prior knowledge we have about a protein\u2019s function, in particular its biochemical activity, the more accurate we can be when interpreting a phenotype.  Phenotypes caused by gene mutations are of great interest, not only to try to understand the function of proteins, but also to pro-vide insights into mechanisms leading to disease. The scope of the GO, though, is to capture the  normal  function of proteins. There are phenotype ontologies for human\u2014HPO [ 13 ], mouse\u2014MP [ 14 ] and other species that allow capturing phenotype in a struc-ture that is more relevant to this type of data.      One limitation of the GO is that main functions and secondary roles are not explicitly encoded, so that this information is dif\ufb01 cult to \ufb01 nd. For example, enzymes may have different substrates: in some cases, the substrate speci\ufb01 city is driven by the biological con-text, but in other cases by the experimental conditions. While some activities represent the main function of the enzyme, others are secondary or can be limited to very speci\ufb01 c conditions.  A good example is provided by the CYP4F2 enzyme (UniProtKB Q9UIU8), a member of the cytochrome P450 family that oxidizes a variety of structurally unrelated compounds, including steroids, fatty acids, and xenobiotics. In vivo, the enzyme plays a key role in vitamin K catabolism by mediating omega- hydroxylation of vitamin K1 (phylloquinone), and menaquinone-4 (MK-4), a form of vitamin K2 [ 15 ,  16 ]. While hydroxylation of phylloquinone and MK-4 probably constitutes the main activity of this enzyme since this activity has been con\ufb01 rmed by several in vivo assays, CYP4F2 also shows activity towards other related sub-strates, such as arachidonic acid omega and leukotriene-B [ 10 ] omega [ 17 \u2013 21 ]. Clearly vitamin K1 and MK-4 are the main physi-ological substrates of CYP4F2, but since it is plausible that the enzyme also acts on other molecules, these different activities are also annotated. In the absence of additional evidence, it is cur-rently impossible to highlight which GO term describes the in vivo function of the enzyme. For the reactions known to be implicated in vitamin K catabolism, adding this information as an annotation extension helps clarify the main role of that speci\ufb01 c reaction ( see  Chap.   17    , [ 6 ]).  2.5  Main Functions and Secondary RolesSylvain Poux and Pascale Gaudet\f49   Our understanding of biology is dynamic, and evolves as new experiments con\ufb01 rm or contradict previous results. It is therefore essential to read several, preferably recent publications on a subject to make sure that prior working hypotheses, that have subsequently been invalidated, are not annotated. That is, sometimes it is neces-sary to remove annotations in order to limit the number of false positives. A number of mechanisms exist in GO to capture evolu-tion of knowledge. New GO terms are added to the ontology when knowledge is not covered by existing GO terms. Curators work in collaboration with the GO editors, de\ufb01 ning new terms or correcting the de\ufb01 nitions of existing terms when required. Con\ufb02 icting results can be dealt by using the \u201cNOT\u201d quali\ufb01 er, which states that a gene product is not associated with a GO term. This quali\ufb01 er is used when a positive association to this term could otherwise be expected from previous literature or automated methods (for more information read   www.geneontology.org/GO.annotation.conventions.shtml#not    ).  A good example of how GO deals with evolving knowledge as new papers are published on a protein is provided by the recent characterization of the NOTUM protein in human and  Drosophila melanogaster . Notum was \ufb01 rst characterized in  D. melanogaster  (UniProtKB Q9VUX3) as an inhibitor of Wnt signaling [ 22 ,  23 ]. Based on its sequence similarity with pectin acetylesterase family members, it was initially thought to hydrolyze glycosaminoglycan (GAG) chains of glypicans by mediating cleavage of their GPI anchor in vitro [ 24 ]. Two different articles published recently con-tradict these previous results, showing that the substrate of human NOTUM (UniProtKB Q6P988) and  D. melanogaster  Notum is not glypicans, and that human NOTUM speci\ufb01 cally mediates a palmitoleic acid modi\ufb01 cation on WNT proteins [ 25 ,  26 ]. This new data con\ufb01 rms the role of NOTUM as an inhibitor of Wnt  signaling, but with a mechanism completely different from what the initial studies had suggested. To correctly capture these \ufb01 ndings in GO, new terms describing protein depalmitoleylation were added in GO: \u201cpalmitoleyl hydrolase activity\u201d (GO:1990699) and \u201cprotein depalmitoleylation\u201d (GO:1990697). In addition, NOTUM pro-teins received negative annotations for \u201cGPI anchor release\u201d (GO:0006507) and \u201cphospholipase activity\u201d (GO:0004620) to indicate that these \ufb01 ndings had been disproven.  Although relatively infrequent, this type of situation is critical because it may affect the accuracy of the GO. Ideally, when new \ufb01 ndings invalidate previous ones, old annotations are revisited in the light of new knowledge and annotation from previous papers reevaluated to ensure that annotation was not the result of over- interpretation of data.  The most widely used manual protein annotation editor for GO, Protein2GO, has a mechanism to dispute questionable or outdated annotations that sends a request for reevaluation 2.6  Hindsight Is 20/20: Dealing with Evolving KnowledgeBest Practices in Manual Annotation with the Gene Ontology\f50of annotations [ 27 ]. Users who notice incorrect or missing  annotations are strongly encouraged to notify the GO helpdesk (  http://geneontology.org/form/contact-go    ) so that corrections can be made.   3    Importance of Annotation Consistency: Toward a Quality Control Approach  The goal of the GO project is to provide a uniform schema to describe biological processes mediated by gene products in all cel-lular organisms [ 2 ]. Annotation involves translating conclusions from biological experiments into this schema, such that we are making inferences of inferences. To avoid deriving too much from the biologically relevant conclusions of experiments, consistent annotation within the GO framework is essential.  The GO curators make every effort to ensure that annotations re\ufb02 ect the current state of knowledge. As new \ufb01 ndings are made that invalidate or re\ufb01 ne existing models there is a need for course correction; otherwise both the ontology and the annotations may drift.  Over 20 groups contribute to manual annotations to the GO project (  http://geneontology.org/page/download-annotations    ). The number of annotations by species, broken down into experi-mental versus non-experimental, is shown in Fig.  3 . Since manual annotations are so critical to the overall quality of the entire corpus of GO data, it is important that each biocurator from every con-tributing group interprets experiments consistently.  Fig. 3    Number of annotations in 12 species annotated by the GO consortium. Source:   http://geneontology.org/page/current-go-statistics            Sylvain Poux and Pascale Gaudet\f51   While the GO Consortium does not possess suf\ufb01 cient resources to review all annotations individually on an ongoing basis, several approaches are in place to ensure consistency: \u25cf   GO uses automated procedures for validating GO annotations. An automated checker runs through the GO annotation  rulebase (  http://geneontology.org/page/annotation-quality- control-checks    ), which validates the syntactic and biological content of the annotation database, and veri\ufb01 es that correct procedures are followed. Examples include taxon checks [ 28 ] and checks to ensure that the correct object type is used with different types of evidence.   \u25cf  The annotation team of the GO consortium also has regular annotation consistency exercises, where participating annota-tors independently annotate the same paper to ensure that guidelines are applied in a uniform manner, discuss any dis-crepancy, and update guidelines when these are lacking or need clari\ufb01 cation.   \u25cf  Finally, the Reference Genome Project [ 29 ] has proven to be a very useful resource to improve annotation coherence across the GO (Feuermann et al.,  in preparation ). The project uses PAINT, a Phylogenetic Annotation and INference Tool, to annotate protein families from the PantherDB resource [ 30 ]. PAINT integrates phylogenetic trees, multiple sequence align-ments, experimental GO annotations, as well as references pointing to the original data. PAINT curators select the high- con\ufb01 dence data that can be propagated across either the entire tree or speci\ufb01 c clades. By displaying different GO annotations for all members of a family, PAINT makes it easy to detect inconsistencies, thus improving the overall quality of the set of GO annotations. It also gives a mean of identifying consistent biases that usually indicate a problem in the ontology or in the annotation guidelines.     4    Summary  Expert curation of GO terms based on experimental data is a com-plex process that requires a number of skills from biocurators. In this chapter, we describe a number of guidelines to warn curators on common annotation mistakes and provide clues on how to avoid them. These simple rules, summarized in Table  2 , can be used as a checklist to ensure that GO annotations are in line with GO consortium guidelines.Best Practices in Manual Annotation with the Gene Ontology\f525       Perspective  The guidelines presented here are easy to follow and reinforce cura-tion quality without reducing curation ef\ufb01 ciency, which is a serious and valid challenge in the era of big data. In view of the amount of data to be dealt with, it has often been argued that manual curation \u201cjust doesn\u2019t scale,\u201d and an ongoing search for alternative methods is under way in the world of biocuration and bioinformatics. However, examples described in this chapter show that most pub-lications describe complex knowledge that cannot be captured by machine learning or text mining technologies. To continue having an acceptable throughput, manual curation should be able to cope with the increasing corpus of scienti\ufb01 c data. From this perspective, PAINT constitutes an excellent example of a  propagation tool based on experimental GO annotations, which ensures maximum consistency and ef\ufb01 ciency without compromising the quality of the annotations produced. Such system provides one possible answer to the concerns addressed on scalability of expert curation.  Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License    Table 2    Summary of annotation guidelines     Carefully select publications .  Only annotate papers that provide the most added value.   Read recent publications .  Research is not a straightforward process and reading recent publications helps resolving con\ufb02 icts and detecting experimental discrepancies.   Check annotation consistency .  Review the existing annotations for related proteins to see whether the annotations you are adding are consistent.   Look for con\ufb01 rmation for unusual \ufb01 ndings with multiple papers ,  if possible .  Avoid entering annotations based on experiments that do not directly implicate the protein with the GO term you annotate.   Annotate the conclusion of the experiment .  Keep in mind that this may be different from the results presented. Be especially careful of interpreting the function of proteins based on mutant phenotypes.   Remove obsolete annotations .  If you encounter an annotation that is based on an interpretation of an experiment that is no longer valid, use the Challenge mechanism or GO helpdesk to ask to have the annotation removed. Sylvain Poux and Pascale Gaudet\f53(  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.        References     1.    Popper KR (2002) Conjectures and refuta-tions: the growth of scienti\ufb01 c knowledge. Routledge, New York        2.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT et al (2000) Gene  ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Consortium. Nat Genet 25:25\u201329      3.   Thomas PD (2016) The gene ontology and the meaning of biological function. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 2      4.    Gene Consortium (2015) Gene Ontology Consortium: going forward. Nucleic Acids Res 43:D1049\u2013D1056      5.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3       6.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17      7.    Korn C, Scholz SR, Gimadutdinow O, Lurz R, Pingoud A, Meiss G (2005) Interaction of DNA fragmentation factor (DFF) with DNA reveals an unprecedented mechanism for nuclease inhibition and suggests that DFF can be activated in a DNA-bound state. J Biol Chem 280:6005\u20136015      8.    Liu X, Kim CN, Yang J, Jemmerson R, Wang X (1996) Induction of apoptotic program in cell- free extracts: requirement for dATP and cytochrome c. Cell 86:147\u2013157      9.    Lee K, Pisarska MD, Ko JJ, Kang Y, Yoon S, Ryou SM, Cha KY, Bae J (2005) Transcriptional factor FOXL2 interacts with DP103 and induces apoptosis. Biochem Biophys Res Commun 336:876\u2013881       10.   Poux S, Magrane M, Arighi CN, Bridge A, O\u2019Donovan C, Laiho K (2014) Expert cura-tion in UniProtKB: a case study on dealing with con\ufb02 icting and erroneous data. Database (Oxford):bau016      11.    Stefely JA, Reidenbach AG, Ulbrich A, Oruganty K, Floyd BJ, Jochem A, Saunders JM, Johnson IE, Minogue CE, Wrobel RL et al (2015) Mitochondrial ADCK3 employs an atypical protein kinase-like fold to enable coenzyme Q biosynthesis. Mol Cell 57:83\u201394      12.    Kim J, Hake SB, Roeder RG (2005) The human homolog of yeast BRE1 functions as a transcriptional coactivator through direct acti-vator interactions. Mol Cell 20:759\u2013770      13.    Groza T, Kohler S, Moldenhauer D, Vasilevsky N, Baynam G, Zemojtel T, Schriml LM, Kibbe WA, Scho\ufb01 eld PN, Beck T et al (2015) The human phenotype ontology: semantic uni\ufb01 ca-tion of common and rare disease. Am J Hum Genet 97(1):111\u2013124      14.    Smith CL, Eppig JT (2015) Expanding the mammalian phenotype ontology to support automated exchange of high throughput mouse phenotyping data generated by large- scale mouse knockout screens. J Biomed Semantics 6:11      15.    Edson KZ, Prasad B, Unadkat JD, Suhara Y, Okano T, Guengerich FP, Rettie AE (2013) Cytochrome P450-dependent catabolism of vitamin K: omega-hydroxylation catalyzed by human CYP4F2 and CYP4F11. Biochemistry 52:8276\u20138285  Best Practices in Manual Annotation with the Gene Ontology\f54    16.    McDonald MG, Rieder MJ, Nakano M, Hsia CK, Rettie AE (2009) CYP4F2 is a vitamin K1 oxidase: an explanation for altered warfarin dose in carriers of the V433M variant. Mol Pharmacol 75:1337\u20131346      17.    Fava C, Montagnana M, Almgren P, Rosberg L, Lippi G, Hedblad B, Engstrom G, Berglund G, Minuz P, Melander O (2008) The V433M variant of the CYP4F2 is associated with  ischemic stroke in male Swedes beyond its effect on blood pressure. Hypertension 52:373\u2013380     18.    Jin R, Koop DR, Raucy JL, Lasker JM (1998) Role of human CYP4F2 in hepatic catabolism of the proin\ufb02 ammatory agent leukotriene B4. Arch Biochem Biophys 359:89\u201398     19.    Kikuta Y, Kusunose E, Kondo T, Yamamoto S, Kinoshita H, Kusunose M (1994) Cloning and expression of a novel form of leukotriene B4 omega-hydroxylase from human liver. FEBS Lett 348:70\u201374     20.    Lasker JM, Chen WB, Wolf I, Bloswick BP, Wilson PD, Powell PK (2000) Formation of 20-hydroxyeicosatetraenoic acid, a vasoactive and natriuretic eicosanoid, in human kidney. Role of Cyp4F2 and Cyp4A11. J Biol Chem 275:4118\u20134126      21.    Stec DE, Roman RJ, Flasch A, Rieder MJ (2007) Functional polymorphism in human CYP4F2 decreases 20-HETE production. Physiol Genomics 30:74\u201381      22.    Gerlitz O, Basler K (2002) Wingful, an extra-cellular feedback inhibitor of Wingless. Genes Dev 16:1055\u20131059      23.    Giraldez AJ, Copley RR, Cohen SM (2002) HSPG modi\ufb01 cation by the secreted enzyme Notum shapes the Wingless morphogen gradi-ent. Dev Cell 2:667\u2013676      24.    Kreuger J, Perez L, Giraldez AJ, Cohen SM (2004) Opposing activities of Dally-like glypi-can at high and low levels of Wingless morpho-gen activity. Dev Cell 7:503\u2013512      25.    Kakugawa S, Langton PF, Zebisch M, Howell SA, Chang TH, Liu Y, Feizi T, Bineva G, O\u2019Reilly N, Snijders AP et al (2015) Notum deacylates Wnt proteins to suppress signalling activity. Nature 519:187\u2013192      26.    Zhang X, Cheong SM, Amado NG, Reis AH, MacDonald BT, Zebisch M, Jones EY, Abreu JG, He X (2015) Notum is required for neural and head induction via Wnt deacylation, oxi-dation, and inactivation. Dev Cell 32:719\u2013730      27.    Huntley RP, Sawford T, Mutowo-Meullenet P, Shypitsyna A, Bonilla C, Martin MJ, O\u2019Donovan C (2015) The GOA database: gene ontology annotation updates for 2015. Nucleic Acids Res 43:D1057\u2013D1063      28.    Deegan (n\u00e9e Clark) JI, Dimmer EC, Mungall CJ (2010) Formalization of taxon-based con-straints to detect inconsistencies in annotation and ontology development. BMC Bioinformatics 11:530      29.    Gaudet P, Livstone MS, Lewis SE, Thomas PD (2011) Phylogenetic-based propagation of func-tional annotations within the Gene Ontology consortium. Brief Bioinform 12:449\u2013462      30.    Mi H, Muruganujan A, Thomas PD (2013) PANTHER in 2013: modeling the evolution of gene function, and other gene attributes, in the context of phylogenetic trees. Nucleic Acids Res 41:D377\u2013D386    Sylvain Poux and Pascale Gaudet\f55    Chapter 5    Computational Methods for Annotation Transfers from Sequence                          Domenico     Cozzetto     and     David     T.     Jones        Abstract    Surveys of public sequence resources show that experimentally supported functional information is still completely missing for a considerable fraction of known proteins and is clearly incomplete for an even larger portion. Bioinformatics methods have long made use of very diverse data sources alone or in com-bination to predict protein function, with the understanding that different data types help elucidate com-plementary biological roles. This chapter focuses on methods accepting amino acid sequences as input and producing GO term assignments directly as outputs; the relevant biological and computational concepts are presented along with the advantages and limitations of individual approaches.    Key words     Protein function prediction  ,   Homology-based annotation transfers  ,   Phylogenomics  ,   Multi-domain architecture  ,   De novo function prediction  1      Introduction  For decades experimentalists have been painstakingly probing a range of functional aspects of individual proteins. This steady but slow acquisition of functional data is in stark contrast to the results of next-generation sequencing technologies, which can survey gene expression regulation, genomic organization, and variation on a large scale [ 1 ]. Similarly, parallel efforts aim to map the net-works of interactions between proteins, nucleic acids, and metabo-lites that regulate biological processes [ 2 \u2013 4 ]. Nonetheless, comprehensive studies of protein function are hindered, because the combinations of gene products, biological roles, and cellular conditions are too numerous and because many experimental pro-tocols cannot be applied to all proteins. Furthermore, the results need to be critically interpreted, integrated with existing knowl-edge, and translated into machine-readable formats\u2014such as Gene Ontology (GO) [ 5 ] terms\u2014for further analyses. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_5, \u00a9 The Author(s) 2017\f56 Manual curation requires substantial time and effort too; therefore the exponential growth in the number of sequences in UniProtKB [ 6 ] has only been matched by a linear increase in the number of entries with experimentally supported GO terms. Moreover, only 0.03 % of the sequences have received annotations for all three GO domains and the level of annotation detail can also fall far short of the maximum possible\u2014e.g., there is direct evi-dence that some  E. coli K12  proteins act as transferases with no additional information about the chemical group relocated from the donor to the acceptor. Automated protein function prediction has consequently represented the only viable way to bridge some of these gaps, and indeed UniProtKB already exploits some com-putational tools (Fig.  1 ).   Given the lack of a general theory which can link protein sequences and environmental conditions directly to biological functions from physicochemical properties, current methods for protein function prediction implement knowledge-based heuristics that transfer functional information from already annotated pro-teins to unannotated ones. This chapter reviews sequence-based approaches to GO term prediction, which are the most popular, well understood, and easily accessible to a wide range of users. The   Fig. 1    Function annotation coverage of proteins in UniprotKB. ( a ) Over the past decade, the number of amino acid chains deposited in UniProtKB has grown exponentially ( black line ), while those with experimentally sup-ported GO term assignments has only increased linearly ( green line ). This core subset however has allowed to assign GO terms to a substantial fraction of sequences ( orange line ). ( b ) Even with electronically inferred annotations, more than 80 % of sequences in UniProtKB release 2015_01 lack assignments for at least one of the molecular function, biological process, or cellular component GO sub-ontologies. Plots and statistics are based on the \ufb01 rst release of each year        Domenico Cozzetto and David T. Jones\f57focus is primarily on the underpinning concepts and assumptions, as well as on the known advantages and pitfalls, which are all applicable to other controlled vocabularies, such as those described in the Chap. 19 [ 7 ] \u201cKEGG, EC and other sources of functional data\u201d. How well current function prediction methods perform and how prediction accuracy can be measured are topics extensively covered in the Chap. 8 [ 8 ] \u201cEvaluating GO annotations\u201d, Chap. 9 [ 9 ] \u201cEvaluating functional annotations in enzymes\u201d, and Chap. 10 [ 10 ] \u201cCommunity Assessment\u201d.  2    Annotation Transfers from Homologous Proteins  The most common way to annotate uncharacterized proteins con-sists in \ufb01 nding homologues\u2014that is, proteins sharing common ancestry\u2014of known function, and inheriting the information avail-able for them under the assumption that function is evolutionarily conserved. BLAST [ 11 ] or PSI-BLAST [ 12 ] are routinely used to search for homologous sequences, and tools that compare sequences against hidden Markov models (HMMs), or pairs of pro\ufb01 les or of HMMs can be useful to extend the coverage of the protein sequence universe thanks to the increased sensitivity for remote homologues. A detailed presentation of sequence compari-son methods is beyond the scope of this chapter and is available elsewhere [ 13 ]. In the simplest case, transfers can be made from the sequence with experimentally validated annotations and the lowest  E -value\u2014and this represents a useful baseline to benchmark the effectiveness of more advanced methods. This approach can produce erroneous results when key functional residues are mutated, or when the alignment doesn\u2019t span the whole length of the proteins\u2014possibly indicating changes in domain architecture [ 14 ]. Iterative transfers of computationally generated functional assignments can lead to uncontrolled propagation of such errors; the average error rate of molecular function annotations is esti-mated to approach 0 % only in the manually curated UniProtKB/SwissProt database, while it is substantially higher in un-reviewed resources [ 15 ].  Several studies have consequently attempted to estimate sequence similarity thresholds that would generate predictions with a guaranteed level of accuracy, and have suggested that 80 % global sequence identity should be generally suf\ufb01 cient for safe annotation transfers [ 16 \u2013 20 ]. However, this rule of thumb can either be too stringent or too lax, because biological sequences evolve at differing rates due to the need to maintain physiological function on the one hand, and to avoid deregulated gene expres-sion, protein translation, folding, or physical interactions on the other [ 21 ]. Ideally, these cutoff values should be speci\ufb01 c to Computational Methods for Annotation Transfers from Sequence\f58individual families or even functional categories, but usually the number of labelled examples is not suf\ufb01 cient to allow reliable cali-bration. To circumvent these issues, it is possible to trade annota-tion  speci\ufb01 city for accuracy, because broad functional aspects\u2014e.g., about ligand binding and enzymatic or transporter activities\u2014diverge at lower rates than the \ufb01 ne details\u2014such as the speci\ufb01 c metal ions bound or the molecules and chemical groups that are recognized and processed.  GOtcha [ 22 ] was the \ufb01 rst tool to make predictions represent-ing the enrichment of the GO terms assigned to BLAST hits in the hierarchical context of GO. It \ufb01 rst calculates weights for each GO term, taking into account the number of similar sequences anno-tated with it and the statistical signi\ufb01 cance of the observed similari-ties. The program then considers the semantic relationships among the terms to update the tallies and re\ufb02 ect increasing con\ufb01 dence in more general annotations. PFP [ 23 ] follows a similar approach, but targets more dif\ufb01 cult annotation cases, too, by leveraging information from PSI-BLAST hits with unconventionally high E-values. Furthermore, the scoring scheme exploits data about the co-occurrence of GO term pairs in UniProtKB entries, which allows safer annotations to be produced. Other methods fall in this category too, and interested readers are referred to the primary literature [ 24 \u2013 27 ]. More sophisticated approaches rely on machine learning [ 28 ] rather than statistical analyses, and use experimental data to train classi\ufb01 ers that predict GO terms based on an array of alignment-derived features\u2014such as sequence similarity scores, E-values, the coverage of the sequences, or the scores that GOtcha calculates for each GO category [ 29 \u2013 31 ].  3    Annotation Transfers from Orthologous Proteins  Simple homology-based predictors are quick but error prone because they don\u2019t try to distinguish functionally equivalent rela-tives from those that have functionally diverged. In phylogenetic terms, this problem can be cast as classifying orthologues\u2014homo-logue pairs evolved after speciation\u2014and paralogues\u2014homologue pairs derived from gene duplication. It is widely accepted that duplicated genes lack selective pressure to maintain their original biological roles, so they can easily undergo nucleotide changes ulti-mately leading to functional divergence [ 32 ]. The realization that genetic diversity arises from gene losses and horizontal transfers, too, makes phylogenetic reconstruction even more complex.  In this setup, annotations can be transferred with varying levels of con\ufb01 dence depending on how many orthologues there are and how closely related they are. This can partly account for the Domenico Cozzetto and David T. Jones\f59observation that orthologues can diverge functionally, particularly over long evolutionary distances or after duplication events in at least one of the lineages [ 33 ]. However, experimental studies have also shown that paralogues can retain functional equivalence, even long after the duplication event [ 34 ,  35 ]. Recent studies have con-sequently tested how useful the distinction between orthologues and paralogues is for protein function prediction and have drawn different conclusions [ 36 \u2013 39 ]. The latest \ufb01 ndings suggest that the functional similarity between orthologues is slightly higher than that between paralogues at the same level of sequence divergence, and that the signal is stronger for cellular components than for biological processes or molecular functions [ 38 ].  The traditional approach to orthologue detection involves computationally intensive calculations to build phylogenetic trees and then identify gene duplication and loss events [ 40 ]. SIFTER [ 41 ] builds on this framework to transfer the most speci\ufb01 c experi-mentally supported molecular function terms available from the annotated sequences to all nodes in the tree using a Bayesian approach. The propagation algorithm captures the notion that functional transitions are more likely to occur after duplication than after speciation events, and when the terms are similar\u2014i.e., the corresponding nodes are close in the GO graph. In order to speed up the computation, the authors have recently suggested limiting the number of GO term annotations that can be assigned to each protein [ 42 ], and they are providing pre-calculated pre-dictions for a vast set of sequences from different species, includ-ing multi-domain proteins [ 43 ]. The semiautomated Phylogenetic Annotation and Inference Tool (PAINT) [ 44 ] recently adopted by the GO consortium provides a more \ufb02 exible framework, which tries to keep functional change events uncoupled, so that the gain of one function does not imply the loss of another and vice versa\u2014a desirable feature for annotating biological processes and for dealing with multifunctional proteins in general. Furthermore, unlike SIFTER, PAINT makes no assumption about how func-tion diverges over evolutionary distance and whether its conserva-tion is higher within orthologous groups than between them.  The increasing availability of completely sequenced genomes has promoted the development of alternative algorithms for ortho-logue detection. These \ufb01 rst categorize pairs of orthologues in any two species, and then cluster the results across organisms, which helps recognize and \ufb01 x spurious assignments [ 40 ]. The results are usually made publicly available in the form of specialized databases such as EggNOG [ 45 ], Ensembl Compara [ 46 ], Inparanoid [ 47 ], PANTHER [ 48 ], PhylomeDB [ 49 ], and OMA [ 50 ], and the clus-tering results provide the basis for GO term annotation transfers, under the assumption that the members of an orthologous group are functionally equivalent.  Computational Methods for Annotation Transfers from Sequence\f604    Annotation Transfers from Protein Families  Even when the sequence similarities between proteins of interest and those that have previously been characterized are limited to speci\ufb01 c sites, such as individual domains or motifs, they can still be useful for function prediction. Some biological activities such as molecular recognition, protein targeting, and pathway regulation have long been mechanistically linked to short linear motifs\u2014stretches of 10\u201320 consecutive amino acids exposed on protein surfaces [ 51 ]. Furthermore, some well-known protein families can be described by speci\ufb01 c arrangements of multiple, possibly discon-tinuous, linear motifs, or by more general models of their domain sequences, namely sequence pro\ufb01 les [ 52 ] or hidden Markov mod-els [ 53 ]. Many public databases now give access to groups of evo-lutionarily related proteins, coding for individual domains or multi-domain architectures. Even though these resources cannot directly assign GO terms to the input amino acid sequences, they can produce valuable assignments to know protein families.  InterPro [ 54 ] collates such results from 11 specialized and complementary resources, which differ by the types of patterns used for family assignment, by the amount of manual curation of their contents, and by the use of additional data such as 3-D struc-ture or phylogenetic trees. InterPro entries combine available data and organize them in a hierarchical way, which mirrors the biologi-cal relationships between families and subfamilies of proteins. The curators also enrich these annotations with supporting biological information from the scienti\ufb01 c literature and with links to external resources such as the PDB [ 55 ] and GO. InterPro provides func-tion predictions for the input sequences based on the InterPro2GO mapping, which links each protein domain family to the most spe-ci\ufb01 c GO terms that apply to all its members [ 56 ]. These annota-tions form a large bulk of the electronically inferred functional assignments in UniProtKB, where they are integrated with associa-tions generated from other controlled vocabularies, e.g., about subcellular localization and enzymatic activity.  CATH-Gene3D [ 57 ] and SUPERFAMILY [ 58 ] are two data-bases that store domain assignments for known protein sequences based on the CATH [ 59 ] and SCOP [ 60 ] protein structure clas-si\ufb01 cation schemes, respectively. CATH-Gene3D data are clustered into functional families which include relatives with highly similar sequences, structures, and functions, as to highlight the strong conservation of important regions such as speci\ufb01 city-determining residues. GO terms are associated probabilistically to each func-tional family based on how often they occur in the UniProtKB annotations of the whole sequences. The recent CATH FunFHMMer web server automates the search procedure for input sequences, resolves multi-domain architectures, assigns each pre-dicted domain to its functional family, and \ufb01 nally inherits the GO Domenico Cozzetto and David T. Jones\f61term annotations found in the library [ 61 ]. The dcGO\u2014short for domain centric\u2014method follows a similar route, but with some key differences [ 62 ]. HMM models are built for both individual domains and supra-domains, i.e., sets of consecutive domains that are de\ufb01 ned according to the SCOP structural de\ufb01 nition and the evolutionary one in Pfam [ 63 ]. Given the annotations in the GOA database [ 64 ] and the GO hierarchical structure, each domain and supra-domain is labelled with a set of GO terms that are associated with it in a statistically signi\ufb01 cant way. The strength of each asso-ciation is then empirically converted into a con\ufb01 dence score. To facilitate the analysis of the results by non-specialists, the predicted GO terms are divided into four classes according to how speci\ufb01 c and informative they are using their information content.  5    De Novo Function Annotation Using Biological Features  The function annotation methods described so far make use of homology to transfer GO terms to a target protein from other previously characterized proteins. In some cases, however, no use-ful functional annotations can be found for any of the detectable homologues, or in the most extreme case no homologous sequences can be found at all. In this case a de novo method is required which can infer GO terms directly from amino acid sequence in the absence of evolutionary relatedness. This is a very hard problem, and only a few tools have been developed which can handle these situations. The most successful approaches to date employ the basic idea of \ufb01 rst transforming the target sequence into a set of component features. These features are then related to particular broad functional classes by means of supervised machine learning techniques. In this way the methods address the question of what kinds of functions can proteins perform with the given set of pro-tein features. As a trivial example, proteins which are predicted to have particular numbers of transmembrane helices as component features will be more likely to have transmembrane transporter activity.  ProtFun, which makes use of neural networks, was the \ufb01 rst widely used method for transferring functional annotations between human proteins through similarity of biochemical attributes, such as the occurrence of charged amino acids, low- complexity regions, signal peptides, trans-membrane helices, and posttranslationally modi\ufb01 ed residues [ 65 ,  66 ]. In the original ProtFun method, only the broad functional classes originally compiled by Monica Riley [ 67 ] were considered, but later the authors extended their approach to predicting a representative set of GO terms. FFPred, which is based on support vector machines, has taken this approach further by considering the observed strong correlation between the lengths and positions of intrinsically disordered protein regions with certain molecular functions and biological processes [ 68 ,  69 ]. As with Computational Methods for Annotation Transfers from Sequence\f62ProtFun, FFPred was initially developed speci\ufb01 cally for annotating human proteins, but the results have been shown to extend reason-ably well to other vertebrate proteomes too.  Feature-based protein function assignment offers both advan-tages and disadvantages over sequence similarity-based approaches. The main advantage is fairly obvious: feature-based methods can work in the absence of homology to characterized proteins, and thus can even be used to assign GO terms to orphan proteins. A further advantage is that feature-based prediction is also able to provide insight into functional changes that occur after alternative splicing, as the input features are likely to re\ufb02 ect sequence dele-tions relative to the main transcript, e.g., the loss of a signal pep-tide or disordered region. Probably the main disadvantage is that classi\ufb01 cation models can only be built for GO terms where there are suf\ufb01 cient examples with experimentally validated assignments. This generally means that assignments can only be made for terms fairly high up in the overall GO graph, and thus highly speci\ufb01 c predictions are generally not possible using this kind of approach. Of course, as datasets become larger, these methods will be able to overcome such limitation.  6    Conclusions and Outlook  The widening gap between the number of known sequences and those experimentally characterized has stimulated the development and re\ufb01 nement of a wide array of computational methods for pro-tein function prediction. The scope of this survey has been limited to four classes of sequence-based approaches for GO term annota-tion transfers, but several other routes could be followed. If the 3-D structure of a protein has been solved or accurately modelled, it is possible to search for global or local structural similarities and predict binding regions and catalytic sites [ 70 ,  71 ]. Comparison of multiple complete genomes can help detect not only orthologous genes as described above, but also further patterns indicative of functional linkages between gene pairs such as fusion events, con-served chromosomal proximity, and co-occurrence/absence in a group of species [ 72 ]. Phylogenetic pro\ufb01 ling posits that coevolv-ing protein families are functionally coupled, e.g., because they encode for proteins assembling into obligate complexes or partici-pating in the same biological process. Since its inception, this \u201cguilt-by-association\u201d method has been implemented in several different ways [ 73 ], and tools able to make GO term assignments are also emerging [ 74 ]. Involvement in the same biological process or co-localization can also be inferred from the analysis of protein- protein interaction maps, gene expression pro\ufb01 les, and phenotypic variations following engineered genetic mutations [ 75 ]. Finally, integrative strategies combine all such heterogeneous data sources Domenico Cozzetto and David T. Jones\f63and hold the potential to produce more con\ufb01 dent predictions, reduce errors, and overcome the intrinsic limitations of individual algorithms [ 31 ,  76 \u2013 78 ]. For instance, protein sequence and struc-ture data appear to be better suited to predict terms in the molecu-lar function category, while genome-wide datasets can shed light on biological processes and protein subcellular localization. In the future, these methods will become increasingly valuable to gener-ate testable hypotheses about protein function as they improve in accuracy \u2013 thanks to additional experimental data and to better ways of using them \u2013 as well as in user-friendliness to experimental-ists and nonspecialists in general.       Acknowledgements  This work was partially supported by the UK Biotechnology and Biological Sciences Research Council. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not per-mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.     References     1.    Soon WW, Hariharan M, Snyder MP (2013) High-throughput sequencing for biology and medicine. Mol Syst Biol 9:640. doi:  10.1038/msb.2012.61          2.    Mitra K, Carvunis AR, Ramesh SK, Ideker T (2013) Integrative approaches for \ufb01 nding mod-ular structure in biological networks. Nat Rev Genet 14(10):719\u2013732. doi:  10.1038/nrg3552         3.   Mahony S, Pugh BF (2015) Protein-DNA binding in high-resolution. Crit Rev Biochem Mol Biol:1\u201315. doi:10.3109/10409238.2015.1051505      4.    McHugh CA, Russell P, Guttman M (2014) Methods for comprehensive experimental identi\ufb01 cation of RNA-protein interactions. Genome Biol 15(1):203. doi:  10.1186/gb4152          5.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-Tarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M, Rubin GM, Sherlock G (2000) Gene ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Computational Methods for Annotation Transfers from Sequence\f64Consortium. Nat Genet 25(1):25\u201329. doi:  10.1038/75556          6.    UniProt C (2015) UniProt: a hub for protein information. Nucleic Acids Res 43(Database issue):D204\u2013D212. doi:  10.1093/nar/gku989          7.   Furnham N (2016) Complementary sources of protein functional information: the far side of GO. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in  molecular biology, vol 1446. Humana Press. Chapter 19      8.   \u0160kunca N, Roberts RJ, Steffen M (2016) Evaluating computational gene ontology annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 8      9.   Holliday GL, Davidson R, Akiva E, Babbitt PC (2016) Evaluating functional annotations of enzymes using the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 9      10.   Friedberg I, Radivojac P (2016) Community-wide evaluation of computational function prediction. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 10      11.    Altschul SF, Gish W, Miller W, Myers EW, Lipman DJ (1990) Basic local alignment search tool. J Mol Biol 215(3):403\u2013410. doi:  10.1016/S0022-2836(05)80360-2          12.    Altschul SF, Madden TL, Schaffer AA, Zhang J, Zhang Z, Miller W, Lipman DJ (1997) Gapped BLAST and PSI-BLAST: a new gen-eration of protein database search programs. Nucleic Acids Res 25(17):3389\u20133402      13.    Soding J, Remmert M (2011) Protein sequence comparison and fold recognition: progress and good-practice benchmarking. Curr Opin Struct Biol 21(3):404\u2013411. doi:  10.1016/j.sbi.2011.03.005          14.    Rost B (2002) Enzyme function less conserved than anticipated. J Mol Biol 318(2):595\u2013608. doi:  10.1016/S0022-2836(02)00016-5          15.    Schnoes AM, Brown SD, Dodevski I, Babbitt PC (2009) Annotation error in public databases:  misannotation of molecular function in enzyme superfamilies. PLoS Comput Biol 5(12):e1000605. doi:  10.1371/journal.pcbi.1000605          16.    Devos D, Valencia A (2000) Practical limits of function prediction. Proteins 41(1):98\u2013107     17.    Wilson CA, Kreychman J, Gerstein M (2000) Assessing annotation transfer for genomics: quantifying the relations between protein sequence, structure and function through tradi-tional and probabilistic scores. J Mol Biol 297(1):233\u2013249. doi:  10.1006/jmbi.2000.3550         18.    Tian W, Skolnick J (2003) How well is enzyme function conserved as a function of pairwise sequence identity? J Mol Biol 333(4):863\u2013882     19.    Sangar V, Blankenberg DJ, Altman N, Lesk AM (2007) Quantitative sequence-function relationships in proteins based on gene ontol-ogy. BMC Bioinformatics 8:294. doi:  10.1186/1471-2105-8-294          20.    Addou S, Rentzsch R, Lee D, Orengo CA (2009) Domain-based and family-speci\ufb01 c sequence identity thresholds increase the  levels of reliable protein function transfer. J Mol Biol 387(2):416\u2013430. doi:  10.1016/j.jmb.2008.12.045          21.    Zhang J, Yang JR (2015) Determinants of the rate of protein sequence evolution. Nat Rev Genet 16(7):409\u2013420. doi:  10.1038/nrg3950          22.    Martin DM, Berriman M, Barton GJ (2004) GOtcha: a new method for prediction of pro-tein function assessed by the annotation of seven genomes. BMC Bioinformatics 5:178. doi:  10.1186/1471-2105-5-178          23.    Hawkins T, Chitale M, Luban S, Kihara D (2009) PFP: automated prediction of gene ontology functional annotations with con\ufb01 dence scores using protein sequence data. Proteins 74(3):566\u2013582. doi:  10.1002/prot.22172          24.    Chitale M, Hawkins T, Park C, Kihara D (2009) ESG: extended similarity group method for automated protein function pre-diction. Bioinformatics 25(14):1739\u20131745. doi:  10.1093/bioinformatics/btp309         25.    Vinayagam A, Konig R, Moormann J, Schubert F, Eils R, Glatting KH, Suhai S (2004) Applying support vector machines for gene ontology based gene function prediction. BMC Bioinformatics 5:116. doi:  10.1186/1471-2105-5-116         26.    Gotz S, Garcia-Gomez JM, Terol J, Williams TD, Nagaraj SH, Nueda MJ, Robles M, Talon M, Dopazo J, Conesa A (2008) High- throughput functional annotation and data mining with the Blast2GO suite. Nucleic Acids Res 36(10):3420\u20133435. doi:  10.1093/nar/gkn176          27.    Piovesan D, Martelli PL, Fariselli P, Zauli A, Rossi I, Casadio R (2011) BAR-PLUS: the Bologna Annotation Resource Plus for func-tional and structural annotation of protein sequences. Nucleic Acids Res 39(Web Server issue):W197\u2013W202. doi:  10.1093/nar/gkr292          28.    Duda RO, Hart PE, Stork DG (2012) Pattern classi\ufb01 cation. Wiley, New York      29.    Sokolov A, Ben-Hur A (2010) Hierarchical classi\ufb01 cation of gene ontology terms using the Domenico Cozzetto and David T. Jones\f65GOstruct method. J Bioinforma Comput Biol 8(02):357\u2013376     30.    Clark WT, Radivojac P (2011) Analysis of pro-tein function and its prediction from amino acid sequence. Proteins 79(7):2086\u20132096       31.    Cozzetto D, Buchan DW, Bryson K, Jones DT (2013) Protein function prediction by massive integration of evolutionary analyses and multi-ple data sources. BMC Bioinformatics 14(Suppl 3):S1. doi:  10.1186/1471-2105-14-S3-S1          32.    Gabaldon T, Koonin EV (2013) Functional and evolutionary implications of gene orthol-ogy. Nat Rev Genet 14(5):360\u2013366. doi:  10.1038/nrg3456          33.    Kachroo AH, Laurent JM, Yellman CM, Meyer AG, Wilke CO, Marcotte EM (2015) Evolution. Systematic humanization of yeast genes reveals conserved functions and genetic modularity. Science 348(6237):921\u2013925. doi:  10.1126/science.aaa0769          34.    Dean EJ, Davis JC, Davis RW, Petrov DA (2008) Pervasive and persistent redundancy among duplicated genes in yeast. PLoS Genet 4(7):e1000113. doi:  10.1371/journal.pgen.1000113          35.    Tischler J, Lehner B, Chen N, Fraser AG (2006) Combinatorial RNA interference in Caenorhabditis elegans reveals that redun-dancy between gene duplicates can be main-tained for more than 80 million years of evolution. Genome Biol 7(8):R69. doi:  10.1186/gb-2006-7-8-R69          36.    Nehrt NL, Clark WT, Radivojac P, Hahn MW (2011) Testing the ortholog conjecture with comparative functional genomic data from mammals. PLoS Comput Biol 7(6):e1002073. doi:  10.1371/journal.pcbi.1002073         37.    Chen X, Zhang J (2012) The ortholog conjec-ture is untestable by the current gene ontology but is supported by RNA sequencing data. PLoS Comput Biol 8(11):e1002784. doi:  10.1371/journal.pcbi.1002784          38.    Altenhoff AM, Studer RA, Robinson-Rechavi M, Dessimoz C (2012) Resolving the ortho-log conjecture: orthologs tend to be weakly, but signi\ufb01 cantly, more similar in function than paralogs. PLoS Comput Biol 8(5):e1002514. doi:  10.1371/journal.pcbi.1002514          39.    Rogozin IB, Managadze D, Shabalina SA, Koonin EV (2014) Gene family level compara-tive analysis of gene expression in mammals validates the ortholog conjecture. Genome Biol Evol 6(4):754\u2013762. doi:  10.1093/gbe/evu051           40.    Altenhoff AM, Dessimoz C (2012) Inferring orthology and paralogy. Methods Mol Biol 855:259\u2013279. doi:  10.1007/978-1-61779-582-4_9          41.    Engelhardt BE, Jordan MI, Muratore KE, Brenner SE (2005) Protein molecular function prediction by Bayesian phylogenomics. PLoS Comput Biol 1(5):e45. doi:  10.1371/journal.pcbi.0010045          42.    Engelhardt BE, Jordan MI, Srouji JR, Brenner SE (2011) Genome-scale phylogenetic func-tion annotation of large and diverse protein families. Genome Res 21(11):1969\u20131980. doi:  10.1101/gr.104687.109          43.    Sahraeian SM, Luo KR, Brenner SE (2015) SIFTER search: a web server for accurate phylogeny- based protein function prediction. Nucleic Acids Res. doi:  10.1093/nar/gkv461          44.    Gaudet P, Livstone MS, Lewis SE, Thomas PD (2011) Phylogenetic-based propagation of functional annotations within the Gene Ontology consortium. Brief Bioinform 12(5):449\u2013462. doi:  10.1093/bib/bbr042          45.    Huerta-Cepas J, Szklarczyk D, Forslund K, Cook H, Heller D, Walter MC, Rattei T, Mende DR, Sunagawa S, Kuhn M, Jensen LJ, von Mering C, Bork P (2016) eggNOG 4.5: a hierarchical orthology framework with improved functional annotations for eukaryotic, prokaryotic and viral sequences. Nucleic Acids Res 44(D1):D286\u2013D293. doi:  10.1093/nar/gkv1248          46.    Flicek P, Amode MR, Barrell D, Beal K, Billis K, Brent S, Carvalho-Silva D, Clapham P, Coates G, Fitzgerald S, Gil L, Giron CG, Gordon L, Hourlier T, Hunt S, Johnson N, Juettemann T, Kahari AK, Keenan S, Kulesha E, Martin FJ, Maurel T, McLaren WM, Murphy DN, Nag R, Overduin B, Pignatelli M, Pritchard B, Pritchard E, Riat HS, Ruf\ufb01 er M, Sheppard D, Taylor K, Thormann A, Trevanion SJ, Vullo A, Wilder SP, Wilson M, Zadissa A, Aken BL, Birney E, Cunningham F, Harrow J, Herrero J, Hubbard TJ, Kinsella R, Muffato M, Parker A, Spudich G, Yates A, Zerbino DR, Searle SM (2014) Ensembl 2014. Nucleic Acids Res 42(Database issue):D749\u2013D755. doi:  10.1093/nar/gkt1196          47.    Sonnhammer EL, Ostlund G (2015) InParanoid 8: orthology analysis between 273 proteomes, mostly eukaryotic. Nucleic Acids Res 43(Database issue):D234\u2013D239. doi:  10.1093/nar/gku1203          48.    Mi H, Poudel S, Muruganujan A, Casagrande JT, Thomas PD (2016) PANTHER version 10: expanded protein families and functions, and analysis tools. Nucleic Acids Res 44(D1):D336\u2013D342. doi:  10.1093/nar/gkv1194          49.    Huerta-Cepas J, Capella-Gutierrez S, Pryszcz LP, Marcet-Houben M, Gabaldon T (2014) PhylomeDB v4: zooming into the plurality of evolutionary histories of a genome. Nucleic Computational Methods for Annotation Transfers from Sequence\f66Acids Res 42(Database issue):D897\u2013D902. doi:  10.1093/nar/gkt1177          50.    Altenhoff AM, Skunca N, Glover N, Train CM, Sueki A, Pilizota I, Gori K, Tomiczek B, Muller S, Redestig H, Gonnet GH, Dessimoz C (2015) The OMA orthology database in 2015: function predictions, better plant sup-port, synteny view and other improvements. Nucleic Acids Res 43(Database issue):D240\u2013D249. doi:  10.1093/nar/gku1158          51.    Van Roey K, Uyar B, Weatheritt RJ, Dinkel H, Seiler M, Budd A, Gibson TJ, Davey NE (2014) Short linear motifs: ubiquitous and functionally diverse protein interaction mod-ules directing cell regulation. Chem Rev 114(13):6733\u20136778. doi:  10.1021/cr400585q          52.    Gribskov M, McLachlan AD, Eisenberg D (1987) Pro\ufb01 le analysis: detection of distantly related proteins. Proc Natl Acad Sci U S A 84(13):4355\u20134358      53.    Eddy SR (1998) Pro\ufb01 le hidden Markov mod-els. Bioinformatics 14(9):755\u2013763      54.    Mitchell A, Chang HY, Daugherty L, Fraser M, Hunter S, Lopez R, McAnulla C, McMenamin C, Nuka G, Pesseat S, Sangrador- Vegas A, Scheremetjew M, Rato C, Yong SY, Bateman A, Punta M, Attwood TK, Sigrist CJ, Redaschi N, Rivoire C, Xenarios I, Kahn D, Guyot D, Bork P, Letunic I, Gough J, Oates M, Haft D, Huang H, Natale DA, Wu CH, Orengo C, Sillitoe I, Mi H, Thomas PD, Finn RD (2015) The InterPro protein families database: the classi\ufb01 cation resource after 15 years. Nucleic Acids Res 43(Database issue):D213\u2013D221. doi:  10.1093/nar/gku1243          55.    Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat TN, Weissig H, Shindyalov IN, Bourne PE (2000) The Protein Data Bank. Nucleic Acids Res 28(1):235\u2013242      56.   Burge S, Kelly E, Lonsdale D, Mutowo- Muellenet P, McAnulla C, Mitchell A, Sangrador-Vegas A, Yong SY, Mulder N, Hunter S (2012) Manual GO annotation of predictive protein signatures: the InterPro approach to GO curation. Database (Oxford) 2012:bar068. doi:  10.1093/database/bar068          57.    Sillitoe I, Lewis TE, Cuff A, Das S, Ashford P, Dawson NL, Furnham N, Laskowski RA, Lee D, Lees JG, Lehtinen S, Studer RA, Thornton J, Orengo CA (2015) CATH: comprehensive structural and functional annotations for genome sequences. Nucleic Acids Res 43(Database issue):D376\u2013D381. doi:  10.1093/nar/gku947          58.    Oates ME, Stahlhacke J, Vavoulis DV, Smithers B, Rackham OJ, Sardar AJ, Zaucha J, Thurlby N, Fang H, Gough J (2015) The SUPERFAMILY 1.75 database in 2014: a dou-bling of data. Nucleic Acids Res 43(Database issue):D227\u2013D233. doi:  10.1093/nar/gku1041          59.    Orengo CA, Michie AD, Jones S, Jones DT, Swindells MB, Thornton JM (1997) CATH--a hierarchic classi\ufb01 cation of protein domain structures. Structure 5(8):1093\u20131108      60.    Murzin AG, Brenner SE, Hubbard T, Chothia C (1995) SCOP: a structural classi\ufb01 cation of proteins database for the investigation of sequences and structures. J Mol Biol 247(4):536\u2013540. doi:  10.1006/jmbi.1995.0159          61.    Das S, Sillitoe I, Lee D, Lees JG, Dawson NL, Ward J, Orengo CA (2015) CATH FunFHMMer web server: protein functional annotations using functional family assign-ments. Nucleic Acids Res. doi:  10.1093/nar/gkv488          62.    Fang H, Gough J (2013) DcGO: database of domain-centric ontologies on functions,  phenotypes, diseases and more. Nucleic Acids Res 41(Database issue):D536\u2013D544. doi:  10.1093/nar/gks1080          63.    Finn RD, Bateman A, Clements J, Coggill P, Eberhardt RY, Eddy SR, Heger A, Hetherington K, Holm L, Mistry J, Sonnhammer EL, Tate J, Punta M (2014) Pfam: the protein families database. Nucleic Acids Res 42(Database issue):D222\u2013D230. doi:  10.1093/nar/gkt1223          64.    Huntley RP, Sawford T, Mutowo-Meullenet P, Shypitsyna A, Bonilla C, Martin MJ, O\u2019Donovan C (2015) The GOA database: gene Ontology annotation updates for 2015. Nucleic Acids Res 43(Database issue):D1057\u2013D1063. doi:  10.1093/nar/gku1113          65.    Jensen LJ, Gupta R, Blom N, Devos D, Tamames J, Kesmir C, Nielsen H, Staerfeldt HH, Rapacki K, Workman C, Andersen CA, Knudsen S, Krogh A, Valencia A, Brunak S (2002) Prediction of human protein func-tion from post-translational modi\ufb01 cations and localization features. J Mol Biol 319(5):1257\u20131265. doi:  10.1016/S0022-2836(02)00379-0          66.    Jensen LJ, Gupta R, Staerfeldt HH, Brunak S (2003) Prediction of human protein function according to Gene Ontology categories. Bioinformatics 19(5):635\u2013642      67.    Riley M (1993) Functions of the gene prod-ucts of Escherichia coli. Microbiol Rev 57(4):862\u2013952      68.    Lobley A, Swindells MB, Orengo CA, Jones DT (2007) Inferring function using patterns of native disorder in proteins. PLoS Comput Biol 3(8):e162. doi:  10.1371/journal.pcbi.0030162          69.    Minneci F, Piovesan D, Cozzetto D, Jones DT (2013) FFPred 2.0: improved homology- independent prediction of gene ontology Domenico Cozzetto and David T. Jones\f67terms for eukaryotic protein sequences. PLoS One 8(5):e63754. doi:  10.1371/jour-nal.pone.0063754          70.    Jacobson MP, Kalyanaraman C, Zhao S, Tian B (2014) Leveraging structure for enzyme func-tion prediction: methods, opportunities, and challenges. Trends Biochem Sci 39(8):363\u2013371. doi:  10.1016/j.tibs.2014.05.006          71.    Petrey D, Chen TS, Deng L, Garzon JI, Hwang H, Lasso G, Lee H, Silkov A, Honig B (2015) Template-based prediction of protein function. Curr Opin Struct Biol 32C:33\u201338. doi:  10.1016/j.sbi.2015.01.007          72.    Galperin MY, Koonin EV (2014) Comparative genomics approaches to identifying function-ally related genes. In: Algorithms for computa-tional biology. Springer, Berlin, pp 1\u201324      73.    Pellegrini M (2012) Using phylogenetic pro-\ufb01 les to predict functional relationships. Methods Mol Biol 804:167\u2013177. doi:  10.1007/978-1-61779-361-5_9          74.    Skunca N, Bosnjak M, Krisko A, Panov P, Dzeroski S, Smuc T, Supek F (2013) Phyletic pro\ufb01 ling with cliques of orthologs is enhanced by signatures of paralogy relationships. PLoS Comput Biol 9(1):e1002852. doi:  10.1371/journal.pcbi.1002852          75.    Yu D, Kim M, Xiao G, Hwang TH (2013) Review of biological network data and its applications. Genomics Inform 11(4):200\u2013210. doi:  10.5808/GI.2013.11.4.200          76.    Ma X, Chen T, Sun F (2014) Integrative approaches for predicting protein function and prioritizing genes for complex phenotypes using protein interaction networks. Brief Bioinform 15(5):685\u2013698. doi:  10.1093/bib/bbt041         77.    Wass MN, Barton G, Sternberg MJ (2012) CombFunc: predicting protein function using heterogeneous data sources. Nucleic Acids Res 40(Web Server issue):W466\u2013W470. doi:  10.1093/nar/gks489          78.    Piovesan D, Giollo M, Leonardi E, Ferrari C, Tosatto SC (2015) INGA: protein function prediction combining interaction networks, domain assignments and sequence similarity. Nucleic Acids Res. doi:  10.1093/nar/gkv523        Computational Methods for Annotation Transfers from Sequence\f69    Chapter 6    Text Mining to Support Gene Ontology Curation and Vice Versa                          Patrick     Ruch        Abstract    In this chapter, we explain how text mining can support the curation of molecular biology databases deal-ing with protein functions. We also show how curated data can play a disruptive role in the developments of text mining methods. We review a decade of efforts to improve the automatic assignment of Gene Ontology (GO) descriptors, the reference ontology for the characterization of genes and gene products. To illustrate the high potential of this approach, we compare the performances of an automatic text cate-gorizer and show a large improvement of +225 % in both precision and recall on benchmarked data. We argue that automatic text categorization functions can ultimately be embedded into a Question-Answering (QA) system to answer questions related to protein functions. Because GO descriptors can be relatively long and speci\ufb01 c, traditional QA systems cannot answer such questions. A new type of QA system, so- called Deep QA which uses machine learning methods trained with curated contents, is thus emerging. Finally, future advances of text mining instruments are directly dependent on the availability of high- quality annotated contents at every curation step. Databases work\ufb02 ows must start recording explicitly all the data they curate and ideally also some of the data they do not curate.    Key words     Automatic text categorization  ,   Gene ontology  ,   Data curation  ,   Databases  ,   Data steward-ship  ,   Information storage and retrieval  1      Introduction  This chapter attempts to concisely describes the role played by text mining in literature-based curation tasks concerned with the descrip-tion of protein functions. More speci\ufb01 cally, the chapter explores the relationships between the Gene Ontology (GO) and Text Mining.  Subheading  2  introduces the reader to basic concepts of text mining applied to biology. For a more general introduction, the reader may refer to a recent review paper by Zheng et al. [ 1 ].  Subheading  3  presents the text mining methods developed to support the assignment of GO descriptors to a gene or a gene prod-uct based on the content of some published articles. The section also introduces the methodological framework needed to assess the performances of these systems called automatic text categorizers. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_6, \u00a9 The Author(s) 2017\f70 Subheading  4  presents the evolution of results obtained today by GOCat, a GO categorizer, which participated in several BioCreative campaigns.  Finally, Subheading  5  discusses an inverted perspective and shows how GO categorization systems are foundational of a new type of text mining applications, so-called Deep Question- Answering (QA). Given a question, Deep QA engines are able to \ufb01 nd answers, which are literally found in no corpus.  Subheading  6  concludes and emphasizes the responsibility of national and international research infrastructures, in establishing virtuous relationships between text mining services and curated databases.  2     State of the Art  This section presents the state of the art in text mining from the point of view of a biocurator, i.e., a person who is maintaining the knowledge stored in gene and protein databases.    In modern molecular biology databases, such as UniProt [ 2 ], the content is authored by biologists called biocurators. The work per-formed by these biologists when they curate a gene or a gene prod-uct encompasses a relatively complex set of individual and collaborative tasks [ 3 ]. We can separate these tasks into two sub-sets: sequence annotation\u2014any information added to the sequence such as the existence of isoforms\u2014and functional annotation\u2014any information about the role of the gene or gene product in a given pathway or phenotype. Such a separation is partially arti\ufb01 cial because a functional annotation can also establish a relationship between the role of a protein and some sequence positions but it is didactically convenient to adopt such a view.  The primary source of knowledge for genomics and proteomics is the research literature. In the context of biocuration, text mining can be de\ufb01 ned as a process aimed at supporting biocurators when they search, read, identify entities, and store the resulting struc-tured knowledge. The developments of benchmarks and metrics to evaluate how automatic text mining systems can help performing these tasks are thus crucial.  BioCreative is a community initiative to periodically evaluates the advances in text mining for biology and biocuration. 1  The forum explored a wide span of tasks with emphasis on  named- entity recognition. Named-entity recognition covers a large set of meth-ods that seek to locate and classify textual elements into prede\ufb01 ned categories such as the names of persons, organizations, locations, genes, diseases, chemical compounds, etc. Thus, querying PubMed 1   http://biocreative.sourceforge.net/ 2.1  Curation TasksPatrick Ruch\f71with the keywords \u201cbiocreative\u201d and \u201cinformation retrieval\u201d returns 8 PMIDs, whereas 32 PMIDs are returned for the keywords \u201cbio-creative\u201d and \u201cnamed entity\u201d [18th of November 2015].  The general work\ufb02 ow of a curation process supported by text mining instruments commonly comprises 6\u20139 steps as displayed in Table  1 , which is a synthesis inspired by both [ 6 ] and [ 4 ].   Search is often the \ufb01 rst step of a text mining pipeline, although information retrieval has received little attention from bioinforma-ticians active in Text Mining. Fortunately, information retrieval has been explored by other scienti\ufb01 c communities and in particular by information scientists via the TREC (Text Retrieval Conferences) evaluation campaigns,  see  ref.  7  for a general introduction. From 2002 to 2015, molecular biology [ 8 ], clinical decision-support [ 9 ] and chemistry-related information retrieval [ 10 ] challenges have been explored by TREC. Interestingly, large-scale information retrieval studies have consistently shown that named-entity recog-nition has no or little impact on search effectiveness [ 11 ,  12 ].     Beyond information retrieval, more elaborated mining instruments can then be derived. Thus, search engines, which return docu-ments or pointers to documents, are often powered with passage retrieval skills [ 7 ], i.e., the ability to highlight a particular sentence, a few phrases, or even a few keywords in a given context. 2.2  From Basic Search to More Advanced Textual Mining     Table 1    Comparative curation steps supported by text mining    [ 4 ]  [ 5 ]  1  Retrieval  Collection  2  Selection  Triage  3  Reading/Passage retrieval  4  Entity extraction  Entity indexing  5  Entity normalization  6  Relationship + evidence annotation  7  Extraction of evidences, e.g., images  8  Feed-back  9  Check of records   Reference [ 4 ] describes the curation task as an iterative process (#8 Feed-back) whereas [ 6 ] describes it as a linear process (ending with #9 Check of records). Both descriptions are however consistent. Thus, it is possible to align steps #1, #2, and #4 in Table  1 . Step #6 is optional in [ 4 ] as the process is regarded as an iterative process. This step is an \u201cintelligent\u201d follow up of the curation task, where already annotated functions/proper-ties should receive less priority in the next Retrieval step. In contrast, steps #3 \u201cReading/passage retrieval\u201d and #6 \u201cFeed-back\u201d is missed by [ 6 ], while the \u201cExtraction of evi-dences\u201d &amp; \u201cCheck of record\u201d is missed by [ 4 ] Step #5, i.e., the assignment of unique identi\ufb01 ers to descriptors, in [ 4 ] is implicit in step #4 of [ 6 ]  Text Mining to Support Gene Ontology Curation and Vice Versa\f72The enriched representation can help the end-user to decide upon the relevance of the document. If for MEDLINE records, such passage retrieval functionalities are not crucial because an abstract is short enough to be rapidly read by a human, passage retrieval tools become necessary when the search is performed on a collec-tion of full-text articles like for instance in PubMed Central. Within a full- text article, the ability to identify the section where a given set of keywords can be very useful as matching the relevant key-words in a \u201cbackground\u201d section has a different value than match-ing them in a \u201cresults\u201d section. The latter is likely to be a new statement while the former is likely to be regarded as a well-estab-lished knowledge.     Unlike in other scienti\ufb01 c or technical \ufb01 elds (\ufb01 nance, high energy physics, etc.), in the biomedical domain, named-entity recognition covers a very large set of entities. Such a richness is well expressed by the content of modern biological databases. Text Mining stud-ies have been published for many of those curation needs, includ-ing sequence curation and identi\ufb01 cation of polymorphisms [ 13 ], posttranslational modi\ufb01 cations [ 14 ], interactions with gene prod-ucts or metabolites [ 15 ], etc. In this context, most studies attempted to develop instruments likely to address a particular set of annotation dimensions, serving the needs of a particular molec-ular biology database. The focus in such studies is often to design a Graphic User Interfaces and to simplify the curation work by highlighting speci\ufb01 c concepts in a dedicated tool [ 16 ]. While most of these systems seem exploratory studies, some seem deeply inte-grated in the curation work\ufb02 ow, as shown by the OntoMate tool designed by the Rat Genome Database [ 17 ], the STRING DB for protein\u2013protein interactions or the BioEditor of neXtProt [ 18 ].  From an evaluation perspective, the idea is to detect the begin-ning and the end of an entity and to assign a semantic type to this string. Thus in named-entity recognition, we assume that entity components are textually contiguous. Inherited from early corpus works on information extraction and computational linguistics [ 19 ], the goal is to assign a unique semantic category\u2014e.g., Time, Location, and Person\u2014to a string in a text [ 20 ].  Semantic categories are virtually in\ufb01 nite but some entities received more attention. Gene, gene products, proteins, species [ 21 ,  22 ], and more recently chemical compounds were signi\ufb01 -cantly more studied than for instance organs, tissues, cell types, cell anatomy, molecular functions, symptoms, or phenotypes [ 23 ].  The initial works dealing with the recognition of GO entities were disappointing (Subheading  3.2 ), which may explain part of the reluctance to address these challenges. We see here one impor-tant limitation of named entities: it is easy to detect a one or two words terms into a document, while the recognition of a protein function does require a \u201cdeeper\u201d understanding or combination of 2.3  Named-Entity RecognitionPatrick Ruch\f73biological concepts. Indeed a complex GO concept is likely to combine subconcepts belonging to various semantic types, includ-ing small molecules, atoms, protein families, as well as biological processes, molecular functions, and cell locations.     In order to compensate for the limitations of named-entity recog-nition frameworks, two more complementary approaches have been proposed: entity normalization and information (or relation-ship) extraction.  Normalization can be de\ufb01 ned as the process by which a unique semantic identi\ufb01 er is assigned to the recognized entities [ 24 ]. The identi\ufb01 ers are available in different resources such as several onto- terminologies or knowledge bases. The assignment of unique iden-ti\ufb01 ers can be relatively dif\ufb01 cult in practice due to a linguistic phenomenon called lexical ambiguity. Many strings are lexically ambiguous and therefore can receive more than one identi\ufb01 er depending on the context (e.g.,  HIV  could be a disease or a virus). The dif\ufb01 culty is ampli\ufb01 ed in cascaded lexical ambiguities. Many entities require the extraction of other entities to receive an unam-biguous identi\ufb01 er. For instance, the assignment of an accession number to a protein may depend on the recognition of an organ-ism or a cell line somewhere else in the text.  Further, the extraction of relationships requires the recognition of the speci\ufb01 c entities, which can be as various as a location, an interaction (binding, coexpression, etc.) [ 25 ], an etiology or a tem-poral marker (cause, trigger, simultaneity, etc.) [ 26 ]. For some information extraction tasks such as protein\u2013protein interactions, the normalization and relationship extraction may require \ufb01 rst the proper identi\ufb01 cation of other entities such as the experimental methods (e.g., yeast 2-hybrid) used to generate the prediction. Furthermore, additional information items may be provided such as the scale of the interaction or the con\ufb01 dence in the interaction [ 27 ].  To identify GO terms, named-entity recognition and informa-tion extraction is insuf\ufb01 cient due to two main dif\ufb01 culties: \ufb01 rst, the dif\ufb01 culty of de\ufb01 ning all (or most) strings describing a given con-cept; second, the dif\ufb01 culty of de\ufb01 ning the string boundaries of a given concept. The parsing of texts to identify GO functions and how they are linked with a given protein demands the develop-ment of speci\ufb01 c methods.     Automatic text categorization (ATC) can be de\ufb01 ned as the assign-ment of any class or category to any text content. The interested reader can refer to [ 28 ], where the author provides a comprehensive introduction to ATC, with a focus on machine learning methods.  In both ATC and in Information Retrieval, documents are regarded as \u201cbag-of-words.\u201d Such a representation is an approxi-mation but it is a powerful and productive simpli\ufb01 cation. From this bag, where all entities and relationships are treated as \ufb02 at and 2.4  Normalization and Relationship Extraction2.5  Automatic Text CategorizationText Mining to Support Gene Ontology Curation and Vice Versa\f74independent data, ATC attempts to assign a set of unambiguous descriptors. The set of descriptors can be binary as in triage tasks, where documents can be either classi\ufb01 ed as relevant for curation or irrelevant, or it can be multiclass. The scale of the problem is one parameter of the model. In some situations, ATC systems do not need to provide a clear split between relevant and irrelevant cate-gories. In particular, when a human is in the loop to control the \ufb01 nal descriptor assignment step, ATC systems can provide a ranked list of descriptors, where each rank expresses the con\ufb01 dence score of the ATC system. ATC systems and search engines share here a second common point: compared to named-entity recognition, which is normally not interactive, ATC and Information Retrieval are well suited for human\u2013computer interactions.   3     Methods  With over 40,000 terms\u2014and many more if we account for syn-onyms\u2014assigning a GO descriptor to a protein based on some published document is formally known as a large multiclass classi-\ufb01 cation problem.    The two basic approaches to solve the GO assignment problem are the following: (1) exploit the lexical similarity between a text and a GO term and its synonyms [ 29 ]; (2) use some existing database to train a classi\ufb01 er likely to infer associations beyond string matching. The second approach uses any scalable machine learning tech-niques to generate a model trained on the Gene Ontology Annotation (GOA) database. Several machine learning strategies have been used but the trade-off between effectiveness, ef\ufb01 ciency, and scalability often converges toward an approach called k- Nearest Neighbors (k-NN);  see  also ref.  30 .      Lexical approaches for ATC exploit the similarities between the content of a text and the content of a GO term and its related syn-onyms [ 31 ]. Additional information can be taken into account to augment the categorization power such as the de\ufb01 nitions of the GO terms. The ranking functions take into account the frequency of words, their speci\ufb01 city (measured by the \u201cinverse document fre-quency,\u201d the inverse of how many documents contain the word), as well as various positional information (e.g., word order);  see  ref.  32  for a detailed description.  The task is extremely challenging if we consider that some GO terms contain a dozen words, which makes those terms virtually unmatchable in any textual repository. The results of the \ufb01 rst BioCreative competition, which was addressing this challenge, were therefore disappointing. The best \u201chigh-precision\u201d system achieved an 80 % precision but this system covered less than 20 % of 3.1  Automatic Text Categorization3.2  Lexical ApproachesPatrick Ruch\f75the test sample. In contrast, with a recall close to 80 %, the best \u201chigh-recall\u201d systems were able to obtain an average precision of 20\u201330 % [ 33 ]. At that time, over 10 years ago, such a complex task was consequently regarded are practically out of reach for machines.     The principle of a k-NN is the following: for an instance X to be classi\ufb01 ed, the system computes a similarity measure between X and some annotated instances. In a GO categorizer, an instance is typi-cally a PMID annotated with some GO descriptors. Instances on the top of the list are assumed \u201csimilar\u201d to X. Experimentally, the value of k must be determined, where k is the number of similar instances (or neighbors), which should be taken into account to assign one or several categories to X.  When considering a full-text article, a particular section in this article, or even a MEDLINE record, it is possible to compute a distance between this section and similar articles in the GOA data-base because in the curated section of GOA, many GO descriptors are associated with a PMID\u2014those marked up with an EXP evi-dence code [ 34 ]. The computation of the distance between two arbitrary texts can be more or less complex\u2014starting with count-ing how many words they share\u2014and the determination of the  k  parameters can also be dependent on different empirical features (number of documents in the collection, average size a document, etc.) but the approach is both effective and computationally simple [ 7 ]. Moreover, the ability to index a priori all the curated instances makes possible to compute distances ef\ufb01 ciently.  The effectiveness of such machine learning algorithms is directly dependent on the volume of curated data. Surprisingly GO categorizers seem not affected by any concept drift, which affects database and data-driven approaches in general. Even old data, i.e., protein annotated with an early version of the GO, seem useful for k-NN approaches [ 35 ]. To give a concrete example, consider pro-teins curated in 2005 with a version of the Gene Ontology and a MEDLINE reports available at that time: it is dif\ufb01 cult to under-stand why a model containing mainly annotations from 2010 to 2014 would outperform a model containing data from 2003 to 2007 using data exactly centered on 2005. While the GO itself has been expanded by at least a factor 4 in the past decade, the consis-tency of the curation model has remained remarkably stable.     In Fig.  1 , we show an example output of GOCat [ 35 ], which is maintained by my group at the SIB Swiss Institute of Bioinformatics. The same abstract is processed by GOCat using two different types of classi\ufb01 cation methods: a lexical approach and a k-NN.   In this example, the title of an article ([ 36 ]; \u201cModulation by copper of p53 conformation and sequence-speci\ufb01 c DNA binding: role for Cu(II)/Cu(I) redox mechanism\u201d) is used as input to con-trast the behavior of the two approaches: This reference is used in 3.3  k-Nearest Neighbors3.4  Properties of Lexical and k-NN CategorizersText Mining to Support Gene Ontology Curation and Vice Versa\f76UniProt to support the assignment of the \u201ccopper ion binding\u201d descriptor to  p53 . We see that the lexical system (left panel) is able to assign the descriptor at rank #12, while the k-NN system (right panel) provides the descriptor in position #1.  Finally, we see how both categorizers are also \ufb02 exible instru-ments as they basically learn to rank a set of a priori categories. Such systems can easily be used as fully automatic systems\u2014thus taking into account only the top N returned descriptors by setting up an empirical threshold score\u2014or as interactive systems able to display dozens of descriptors including many irrelevant ones, which then can be discarded by the curator.  Today, GO k-NN categorizers do outperform lexical catego-rizers; however, the behavior of the two systems is complementary. While the latter is potentially able to assign a GO descriptor, which has rarely or never been used to generate an annotation, the former is directly dependent on the quantity of [GO; PMID] pairs avail-able in GOA.     An important parameter when assessing text mining tools is the development of a ground truth or gold standard. Thus, typically for GO annotation, we assume that the content of curated 3.5  Inter-annotator Agreement11.0011.0020.4230.2240.2150.1960.1670.1380.1390.13100.12110.12120.11130.10140.10150.10160.10170.09180.09GO:0003677GO:0005507GO:0046688GO:0008270GO:0003677GO:0004784GO:0006878GO:0035434GO:0015677GO:0071280GO:0005375GO:0005886GO:0016531GO:0055114GO:0019430GO:0046914GO:0006825GO:0006801GO:0010273DNA bindingsequence-specific DNAbinding (synonym sequencespecific dna binding) +/-RNA cytidine-uridine insertion(synonym rna cu insertion) +/-copper ion binding +/-response to copper ion +/-zinc ion binding +/-DNA binding +/-superoxide dismutase activitycopper ion transmembranecellular response to copper ion +/-Plasma membraneoxidation-reduction processsuperoxide metabolic processremoval of superoxide radicalstransition metal ion binding +/-copper ion import +/-copper ion transmembranetransporter activity +/-copper chaperone activity +/-copper ion transport +/-detoxification of copper ion+/-cellular copper ionhomeostasis +/-transport +/-DNA conformation change(synonym dna conformationmodification) +/-binding +/-copper-nicotianaminetransmembrane transportercopper-exporting ATPaseactivity (synonym cu(2+)-exporting atpase activity) +/-oxidoreductase activity(synonym redox activity) +/-detection of redox state(synonym redox sensing) +/-copper ion binding (synonymcopper binding) +/-spliceosomal conformationalchanges to generate catalyticconformation +/-p53 binding +/-redox taxis +/-activity (synonym cu-nachelate transporter activity)+/-+/-20.77GO:004356530.31GO:007071240.22GO:007110350.22GO:000548860.21GO:005198270.21GO:000400880.19GO:000945590.19GO:0016491100.19GO:0051776110.17GO:0002039120.16GO:0005507130.15GO:0000393#ScoreGO IDName#ScoreGO IDName  Fig. 1    Comparative outputs of lexical vs. k-NN versions of GOCat        Patrick Ruch\f77databases is the absolute reference. This assumption is acceptable from a methodological perspective, as text mining systems need such benchmarks. However, it is worth observing that two cura-tors would not absolutely agree when they assign descriptors, which means that a 100 % precision is purely theoretical. Thus, Camon et al. [ 37 ] reports that two GO annotators would have an agreement score of about 39\u201343 %. The upper score is achieved when we consider that the assignment of a generic concept instead of a more speci\ufb01 c one (children) is counted as an agreement.   4     Today\u2019s Performances  Today, GOCat is able to assign a correct descriptor to a given MEDLINE record two times out of three using the BioCreative I benchmark [ 35 ], which makes it useful to support functional anno-tation. Another type of systems, can be used to support comple-mentary tasks of literature exploration (GoPubMed: [ 38 ]) or named-entity recognition [ 39 ]. While GOCat attempts to assign GO descriptors to any input with the objective to help curating the content of the input, GoPubMed provides a set of facets (Gene Ontology or Medical Subject Headings) to navigate the result of a query submitted to PubMed.  It is worth observing that GO categorizers work best when they assume that the curator is involved in selecting the input papers (performing a triage or selection task as described in Table  1 ). Such a setting, inherited from the BioCreative competi-tions, [ 33 ,  40 ] is questionable for at least two reasons: (1) Curators read full-text articles and not only the abstracts\u2014captions and leg-ends seem especially important; (2) The triage task, i.e., the ability to select an article as relevant for curation, could mostly be per-formed by a machine, provided that fair training data are available. In 2013, the campaign of BioCreative, under the responsibility of the NCBI, revisited the task [ 41 ]. The competitors were provided with full-text articles and they were asked not only to return GO descriptors but also to select a subset of sentences. The evaluation was thus more transparent. A small but high-quality annotated sample of full-text papers was provided [ 42 ].  The main results from these experiments are the following;  see  ref.  41  for a complete report describing the competition metrics as well as the different systems participating in the challenge. First, the precision of categorization systems improved by about +225 % compared to BioCreative 1. Second, the ability to detect all relevant sentences seems less important than being able to select a few high content-bearing sentences. Thus GOCat achieved very competitive results for both recall and precision in GO assignment task, but interestingly the system performed relatively poorly when focusing on the recall of the sentence selection task,  see  Figs.  2  and  3  for Text Mining to Support Gene Ontology Curation and Vice Versa\f78000.050.050.10.150.250.20.10.150.25RecallPrecision0.350.450.30.40.2222221111133333  Fig. 2    Relative performance of the sentence triage module of GOCat4FT (GOCat for full-text,  blue diamond ) at the of\ufb01 cial BioCreative IV competition. Courtesy of Zhiyong Lu, National Institute of Health, National Library of Medicine       2223111111223323300.050.10.150.250.20.30.3500.020.040.060.080.10.120.14RecallPrecision  Fig. 3    Relative performance of GOCat4FT ( blue diamond ) when fed with the sentences selected by the three sentence triage systems evaluated in Fig.  2          Patrick Ruch\f79comparison. We see that two of the sentence ranking systems devel-oped for the BioCreative IV competition (orange dots) outperform other systems in precision but not in recall. References [ 40 ,  43 ] conclude from these experiments that the content in a full-text arti-cle is so (highly) redundant that a weak recall is acceptable provided that the few selected sentences have good precision. The few high relevance sentences selected by GOCat4FT (Gene Ontology Categorizer for Full Text) are suf\ufb01 cient to obtain highly competi-tive results when GO descriptors are assigned by GOCat (orange dots) regarding both recall and precision as the three of\ufb01 cial runs submitted by SIB Text Mining signi\ufb01 cantly outperforms other sys-tems. Such a redundancy phenomenon is probably found not only in full-text contents but more generally in the whole literature.    Together with GO and GOA, which was used by most partici-pants in the competition, some online databases seem particularly valuable to help assigning GO descriptors. Thus, Luu et al. [ 44 ] uses the cross-product databases [ 45 ] with some effectiveness.  5     Discussion  Although a fraction of it is likely to be suf\ufb01 cient to obtain the top- ranked GO descriptors, the results reported in the previous section are obtained by using only 10\u201320 % of the content of an article. This suggests that 80\u201390 % of what is published is unnecessary from an information-theoretic perspective.    New and informative statements are rare in general. They are moreover buried in a mass of relatively redundant and poorly content- bearing claims. It has been shown that the density and precision of information in abstracts is higher [ 5 ,  46 ] than in full- text reports while the level of redundancy across papers and abstracts is probably relatively high as well.  We understand that the separation of valuable scienti\ufb01 c state-ments is labor intensive for curators. This \ufb01 ltering effort is compli-cated within an article but also between articles at retrieval time. We argue that such task could be performed by machines provided that high-quality training data are available. The training data needed by text mining systems are unfortunately lost during the curation process. Indeed, the separation between useful and use-less materials (e.g., PMIDs and sentences) is performed\u2014but not recorded\u2014by the curator during the annotation process but they are unfortunately not stored in databases.  In some cases, the separation is explicit, in other cases, it is implicit but the key point is that a mass of information is de\ufb01 nitely lost with no possible recovery. The capture of the output of the selection process\u2014at least for the positive content but ideally also for a fraction of the negative content\u2014is a minimal requirement to 5.1  Information Redundancy and Curation- Driven Data StewardshipText Mining to Support Gene Ontology Curation and Vice Versa\f80improve text mining methods. The expected impact of the imple-mentation of such simple data stewardship recommendation is likely a game changer for text mining far beyond any hypothetical technological advances.     Some GO concepts describe entities which are so speci\ufb01 c that they can hardly be found anywhere. This has several consequences. Traditional QA systems were recently made popular to answer Jeopardy-like questions with entities as various as politicians, town, plants, countries, songs, etc.,  see  ref.  47 . In the biomedical \ufb01 eld, Bauer and Berleant [ 48 ] compare four systems, looking at their ergonomics. With a precision in the range of 70\u201380 % [ 49 ], these systems perform relatively well. However, none of these systems is able to answer questions about functional proteomics. Indeed, how can a text mining system \ufb01 nd an answer if such an answer is not likely to be found on Earth in any corpus of book, article, or patent? The ability to accurately process questions, such as  what molecular functions are associated with tp53  requires to supply answers, such as \u201cRNA polymerase II transcription regulatory region sequence-speci\ufb01 c DNA binding transcription factor activity involved in positive regulation of transcription\u201d and only GO cat-egorizers are likely to automatically generate such an answer.  We may think that such complex concepts could be made sim-pler by splitting the concept into subconcepts, using clinical termi-nological resources such as SNOMED CT [ 50 ,  51 ] or ICD-10 [ 52 ],  see  also Chap.   20     [ 53 ]. That might be correct in some rare cases but in general, complex systems tend to be more accurately described using complex concepts. The post-coordination meth-ods explored elsewhere remain effective to perform analytical tasks but they make generative tasks very challenging [ 52 ]. Post- coordination is useful to search a database or a digital library because search tasks assume that documents are \u201cbag of words\u201d and they ignore the relationships between these words. However, other tasks such as QA or curation do require to be able to mean-ingfully combine concepts. In this context, the availability of a pre-computed list of concepts or controlled vocabulary is extremely useful to avoid generating ill-formed entities.  Answering functional omics questions is truly original: it requires the elaboration of a new type of QA engines such as the DeepQA4GO engine [ 54 ]. For GO-type of answers, DeepQA4GO is able to answer the expected GO descriptors about two times out of three, compared to one time out of three for traditional systems. We propose to call these new emerging systems: Deep QA engines. Deep QA, like traditional QA engines are able to screen through millions of documents, but since no corpus contain the expected answers, Deep QA is needed to exploit curated biological data-bases in order to generate useful candidate answers for curators.   5.2  Assigning Unmatchable GO Descriptors: Toward Deep QAPatrick Ruch\f816     Conclusion  While the chapter started with introducing the reader to how text mining can support database annotation, the conclusion is that next generation text mining systems will be supported by curated databases. The key challenges have moved from the design of text mining systems to the design of text mining sys-tems able to capitalize on the availability of curated databases. Future advances in text mining to support biocuration and bio-medical knowledge discovery are largely in the hands of database providers. Databases work\ufb02 ows must start recording explicitly all the data they curate and ideally also some of the data they do not curate.  In parallel, the accuracy of text mining system to support GO annotation has improved massively from 20 to 65 % (+225 %) from 2005 to 2015. With almost 10,000 queries a month, a tool like GOCat is useful in order to provide a basic functional annotation of protein with unknown and/or uncurated functions [ 55 ] as exempli\ufb01 ed by the large-scale usage of GOCat by the COMBREX  database [ 56 ,  57 ]. However, the integration of text mining sup-port systems into curation work\ufb02 ows remains challenging. As often stated, curation is accurate but does not scale while text mining is not accurate but scales. National and international Research Infrastructures should play a central role to promote optimal data stewardship practices across the databases they sup-port. Similarly, innovative curation models should emerge by combining the quality and richness of curation work\ufb02 ows, more cost-effective crowd- based triage, and the scalability of text min-ing instruments [ 58 ].  Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     Text Mining to Support Gene Ontology Curation and Vice Versa\f82   References     1.    Zeng Z, Shi H, Wu Y, Hong Z (2015) Survey of natural language processing techniques in bioinformatics. Comput Math Methods Med 2015:674296. doi:  10.1155/2015/674296    , Epub 2015 Oct 7      2.    Dimmer EC, Huntley RP, Alam-Faruque Y, Sawford T, O\u2019Donovan C, Martin MJ, Bely B, Browne P, Mun Chan W, Eberhardt R, Gardner M, Laiho K, Legge D, Magrane M, Pichler K, Poggioli D, Sehra H, Auchincloss A, Axelsen K, Blatter MC, Boutet E, Braconi-Quintaje S, Breuza L, Bridge A, Coudert E, Estreicher A, Famiglietti L, Ferro-Rojas S, Feuermann M, Gos A, Gruaz-Gumowski N, Hinz U, Hulo C, James J, Jimenez S, Jungo F, Keller G, Lemercier P, Lieberherr D, Masson P, Moinat M, Pedruzzi I, Poux S, Rivoire C, Roechert B, Schneider M, Stutz A, Sundaram S, Tognolli M, Bougueleret L, Argoud-Puy G, Cusin I, Duek-Roggli P, Xenarios I, Apweiler R (2012) The UniProt-GO Annotation database in 2011. Nucleic Acids Res 40(Database issue):D565\u2013D570. doi:  10.1093/nar/gkr1048    , Epub 2011 Nov 28      3.   Poux S, Magrane M, Arighi CN, Bridge A, O\u2019Donovan C, Laiho K; UniProt Consortium (2014) Expert curation in UniProtKB: a case study on dealing with con\ufb02 icting and errone-ous data. Database (Oxford):bau016. doi:   10.1093/database/bau016               4.   Vishnyakova D, Emilie Pasche E, Patrick Ruch P (2012) Using binary classi\ufb01 cation to priori-tize and curate articles for the Comparative Toxicogenomics Database. Database 2012       5.    Lin J (2009) Is searching full text more effective than searching abstracts? BMC Bioinformatics 10:46. doi:  10.1186/1471-2105-10-46             6.   Lu Z, Hirschman L. Biocuration work\ufb02 ows and text mining: overview of the BioCreative 2012 Workshop Track II. Database 2012        7.    Singhal A (2001) Modern information retrieval: a brief overview. IEEE Data Eng Bull 24:35\u201343      8.    Hersh W, Bhupatiraju RT, Corley S (2004) Enhancing access to the Bibliome: the TREC Genomics Track. Stud Health Technol Inform 107(Pt 2):773\u2013777      9.   Simpson MS, Voorhees ES, Hersh W (2014) Overview of the TREC 2014. Clinical Decision Support Track. TREC 2014      10.    Lupu M, Huang J, Zhu J, Tait J (2009) TREC- CHEM: large scale chemical informa-tion retrieval evaluation at TREC. SIGIR Forum 43(2):63\u201370      11.    Abdou S, Savoy J (2008) Searching in Medline: query expansion and manual indexing evalua-tion. Inf Process Manag 44(2):781\u2013789      12.    Pasche E, Gobeill J, Kreim O, Oezdemir-Zaech F, Vachon T, Lovis C, Ruch P (2014) Development and tuning of an original search engine for patent libraries in medicinal chemis-try. BMC Bioinformatics 15(Suppl 1):S15      13.    Yip YL, Lachenal N, Pillet V, Veuthey AL (2007) Retrieving mutation-speci\ufb01 c informa-tion for human proteins in UniProt/Swiss- Prot Knowledgebase. J Bioinform Comput Biol 5(6):1215\u20131231      14.    Veuthey AL, Bridge A, Gobeill J, Ruch P, McEntyre JR, Bougueleret L, Xenarios I (2013) Application of text-mining for updat-ing protein post-translational modi\ufb01 cation annotation in UniProtKB. BMC Bioinformatics 14:104. doi:  10.1186/1471-2105-14-104          15.   Xu S, An X, Zhu L, Zhang Y, Zhang H (2015) A CRF-based system for recognizing chemical entity mentions (CEMs) in biomedical litera-ture. J Cheminform 7(Suppl 1 Text mining for chemistry and the CHEMDNER track):S11. doi:  10.1186/1758-2946-7-S1-S11    . eCollec-tion 2015      16.   Dowell KG, McAndrews-Hill MS, Hill DP, Drabkin HJ, Blake JA (2009) Integrating text mining into the MGI biocuration work\ufb02 ow. Database (Oxford):bap019. Epub 2009 Nov 21      17.   Liu W, Laulederkind SJ, Hayman GT, Wang SJ, Nigam R, Smith JR, De Pons J, Dwinell MR, Shimoyama M (2015) OntoMate: a text- mining tool aiding curation at the Rat Genome Database. Database (Oxford):bau129      18.    SIB Swiss Institute of Bioinformatics Members (2015) The SIB Swiss Institute of Bioinformatics\u2019 resources: focus on curated databases. Nucleic Acids Res 44(D1):D27\u2013D37      19.   Black WJ, Gilardoni L, Dressel R, Rinaldi F (1997) Integrated text categorisation and information extraction using pattern matching and linguistic processing. RIAO      20.   Chinchor N (1997) Overview of MUC-7. Message Understanding Conferences (MUC).      21.    Hirschman L, Yeh A, Blaschke C, Valencia A (2005) Overview of BioCreAtIvE: critical assessment of information extraction for biol-ogy. BMC Bioinformatics 6(Suppl 1):S1      22.    Smith L, Tanabe LK, Ando RJ, Kuo CJ, Chung IF, Hsu CN, Lin YS, Klinger R, Friedrich CM, Ganchev K, Torii M, Liu H, Haddow B, Struble CA, Povinelli RJ, Vlachos A, Baumgartner WA Jr, Hunter L, Carpenter B, Tsai RT, Dai HJ, Liu F, Chen Y, Sun C, Katrenko S, Adriaans P, Blaschke C, Torres R, Neves M, Nakov P, Divoli A, Ma\u00f1a-L\u00f3pez M, Mata J, Wilbur WJ (2008) Overview of Patrick Ruch\f83BioCreative II gene mention recognition. Genome Biol 9(Suppl 2):S2      23.   Tran LT, Divita G, Carter ME, Judd J, Samore MH, Gundlapalli AV (2015) Exploiting the UMLS Metathesaurus for extracting and cate-gorizing concepts representing signs and symp-toms to anatomically related organ systems. J Biomed Inform. pii: S1532-0464(15)00192- 6. doi:  10.1016/j.jbi.2015.08.024          24.    Morgan AA, Lu Z, Wang X, Cohen AM, Fluck J, Ruch P, Divoli A, Fundel K, Leaman R, Hakenberg J, Sun C, Liu HH, Torres R, Krauthammer M, Lau WW, Liu H, Hsu CN, Schuemie M, Cohen KB, Hirschman L (2008) Overview of BioCreative II gene normaliza-tion. Genome Biol 9(Suppl 2):S3. doi:  10.1186/gb-2008-9-s2-s3    , Epub 2008 Sep 1      25.    Bell L, Chowdhary R, Liu JS, Niu X, Zhang J (2011) Integrated bio-entity network: a sys-tem for biological knowledge discovery. PLoS One 6(6):e21474      26.    Perfetto L, Briganti L, Calderone A, Perpetuini AC, Iannuccelli M, Langone F, Licata L, Marinkovic M, Mattioni A, Pavlidou T, Peluso D, Petrilli LL, Pirr\u00f2 S, Posca D, Santonico E, Silvestri A, Spada F, Castagnoli L, Cesareni G (2015) SIGNOR: a database of causal relation-ships between biological entities. Nucleic Acids Res 44:D548\u2013D554      27.   Bastian FB, Chibucos MC, Gaudet P, Giglio M, Holliday GL, Huang H, Lewis SE, Niknejad A, Orchard S, Poux S, Skunca N, Robinson- Rechavi M (2015) The Con\ufb01 dence Information Ontology: a step towards a standard for assert-ing con\ufb01 dence in annotations. Database:bav043 doi:  10.1093/database/bav043          28.    Sebastiani F (2002) Machine learning in auto-mated text categorization. ACM Comput Surv 34(1):1\u201347      29.    Ruch P (2006) Automatic assignment of bio-medical categories: toward a generic approach. Bioinformatics 22(6):658\u2013664, Epub 2005 Nov 15      30.    Lena PD, Domeniconi G, Margara L, Moro G (2015) GOTA: GO term annotation of bio-medical literature. BMC Bioinformatics 16:346      31.   Couto F, Silva M, Coutinho P (2005) FiGO: \ufb01 nding GO terms in unstructured text. BioCreative Workshop Proceedings      32.    Ehrler F, Geissb\u00fchler A, Jimeno A, Ruch P (2005) Data-poor categorization and passage retrieval for gene ontology annotation in Swiss- Prot. BMC Bioinformatics 6(Suppl 1):S23, Epub 2005 May 24       33.    Blaschke C, Leon E, Krallinger M, Valencia A (2005) Evaluation of BioCreAtIvE assessment of task 2. BMC Bioinformatics 6(Suppl 1):S16      34.   Gaudet et al. Primer on gene ontology. GO handbook        35.   Gobeill J, Pasche E, Vishnyakova D, Ruch P. Managing the data deluge: data-driven GO cat-egory assignment improves while complexity of functional annotation increases. Database 2013      36.    Hainaut P, Rolley N, Davies M, Milner J (1995) Modulation by copper of p53 confor-mation and sequence-speci\ufb01 c DNA binding: role for Cu(II)/Cu(I) redox mechanism. Oncogene 10(1):27\u201332      37.    Camon EB, Barrell DG, Dimmer EC, Lee V, Magrane M, Maslen J, Binns D, Apweiler R (2005) An evaluation of GO annotation retrieval for BioCreAtIvE and GOA. BMC Bioinformatics 6(Suppl 1):S17, Epub 2005 May 24      38.    Doms A, Schroeder M (2005) GoPubMed: exploring PubMed with the Gene Ontology. Nucleic Acids Res 33(Web Server issue):W783\u2013W786      39.    Rebholz-Schuhmann D, Arregui M, Gaudan S, Kirsch H, Jimeno A (2008) Text processing through Web services: calling Whatizit. Bioinformatics 24(2):296\u2013298       40.    Yeh A, Morgan A, Colosimo M, Hirschman L (2005) BioCreAtIvE task 1A: gene mention \ufb01 nding evaluation. BMC Bioinformatics 6(Suppl 1):S2, Epub 2005 May 24       41.   Mao Y, Van Auken K, Li D, Arighi CN, McQuilton P, G Hayman T, Tweedie S, Schaeffer ML, Laulederkind SJF, Wang S-J, Gobeill J, Ruch P, Luu AT, Kim J-J, Chiang J-H, De Chen Y, Yang C-J, Liu H, Zhu D, Li Y, Yu H, Emadzadeh E, Gonzalez G, Chen J-M, Dai H-J, Lu Z (2014). Overview of the gene ontology task at BioCreative IV. Database (Oxford) 2014      42.   Van Auken K, Schaeffer ML, McQuilton P, Laulederkind SJ, Li D, Wang SJ, Hayman GT, Tweedie S, Arighi CN, Done J, M\u00fcller HM, Sternberg PW, Mao Y, Wei CH, Lu Z (2014) BC4GO: a full-text corpus for the BioCreative IV GO task. Database (Oxford). pii: bau074. doi:  10.1093/database/bau074          43.   Gobeill J, Pasche E, Dina V, Ruch P. (2014) Closing the loop: from paper to protein anno-tation using supervised Gene Ontology classi-\ufb01 cation. Database:bau088      44.   Luu AT, Kim JJ, Ng SK (2013) Gene ontology concept recognition using cross-products and statistical methods. In: The Fourth BioCreative Challenge Evaluation Workshop, vol. 1, Bethesda, MD, USA, pp 174\u2013181      45.    Mungall CJ, Bada M, Berardini TZ et al (2011) Cross-product extensions of the gene ontology. J Biomed Inform 44:80\u201386  Text Mining to Support Gene Ontology Curation and Vice Versa\f84    46.    Jimeno-Yepes AJ, Plaza L, Mork JG, Aronson AR, D\u00edaz A (2013) MeSH indexing based on automatically generated summaries. BMC Bioinformatics 14:208      47.    Ferrucci D (2012) Introduction to \u00ab This is Watson \u00bb. IBM J Res Dev 56(3.4):1\u201315      48.    Bauer MA, Berleant D (2012) Usability survey of biomedical question answering systems. Hum Genomics 6:17      49.   Gobeill J, Patsche E, Teodoro D, Veuthey AL, Lovis C, Ruch P. Question answering for biol-ogy and medicine. Information Technology and Applications in Biomedicine, 2009. ITAB 2009      50.    Campbell WS, Campbell JR, West WW, McClay JC, Hinrichs SH (2014) Semantic analysis of SNOMED CT for a post- coordinated database of histopathology  \ufb01 ndings. J Am Med Inform Assoc 21(5):885\u2013892      51.   Dolin RH, Spackman KA, Markwell D (2002) Selective retrieval of pre- and post-coordi-nated SNOMED concepts. Proc AMIA Symp:210\u2013214       52.   Baud RH, Rassinoux AM, Ruch P, Lovis C, Scherrer JR (1999) The power and limits of a rule-based morpho-semantic parser. Proc AMIA Symp:22\u201326      53.   Denaxas SC (2016) Integrating bio-ontolo-gies and controlled clinical terminologies: from base pairs to bedside phenotypes. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 20      54.   Gobeill J, Gaudinat A, Pasche E, Vishnyakova D, Gaudet P, Bairoch A, Ruch P (2015) Deep question answering for protein annotation. Database (Oxford):bav081      55.    Mills CL, Beuning PJ, Ondrechen MJ (2015) Biochemical functional predictions for protein structures of unknown or uncertain function. Comput Struct Biotechnol J 13:182\u2013191      56.    Anton BP, Chang YC, Brown P, Choi HP, Faller LL, Guleria J, Hu Z, Klitgord N, Levy- Moonshine A, Maksad A, Mazumdar V, McGettrick M, Osmani L, Pokrzywa R, Rachlin J, Swaminathan R, Allen B, Housman G, Monahan C, Rochussen K, Tao K, Bhagwat AS, Brenner SE, Columbus L, de Cr\u00e9cy-Lagard V, Ferguson D, Fomenkov A, Gadda G, Morgan RD, Osterman AL, Rodionov DA, Rodionova IA, Rudd KE, S\u00f6ll D, Spain J, Xu SY, Bateman A, Blumenthal RM, Bollinger JM, Chang WS, Ferrer M, Friedberg I, Galperin MY, Gobeill J, Haft D, Hunt J, Karp P, Klimke W, Krebs C, Macelis D, Madupu R, Martin MJ, Miller JH, O\u2019Donovan C, Palsson B, Ruch P, Setterdahl A, Sutton G, Tate J, Yakunin A, Tchigvintsev D, Plata G, Hu J, Greiner R, Horn D, Sj\u00f6lander K, Salzberg SL, Vitkup D, Letovsky S, Segr\u00e8 D, DeLisi C, Roberts RJ, Steffen M, Kasif S (2013) The COMBREX Project: design, methodology, and initial results. PLoS Biol 11(8):e1001638      57.   \u0160kunca N, Roberts RJ, Steffen M (2016) Evaluating computational gene ontology annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 8      58.    Burger J, Doughty E, Khare R, Wei CH, Mishra R, Aberdeen J, Tresner-Kirsch D, Wellner B, Kann M, Lu Z, Hirschman L (2014) Hybrid curation of gene-mutation relations combining automated extraction and crowdsourcing. Database (Oxford) 22:2014    Patrick Ruch\f85    Chapter 7    How Does the Scienti\ufb01 c Community Contribute to Gene Ontology?                          Ruth     C.     Lovering        Abstract    Collaborations between the scienti\ufb01 c community and members of the Gene Ontology (GO) Consortium have led to an increase in the number and speci\ufb01 city of GO terms, as well as increasing the number of GO annotations. A variety of approaches have been taken to encourage research scientists to contribute to the GO, but the success of these approaches has been variable. This chapter reviews both the successes and failures of engaging the scienti\ufb01 c community in GO development and annotation, as well as, providing motivation and advice to encourage individual researchers to contribute to GO.    Key words     Clinical and basic research  ,   Gene Ontology  ,   Proteomics  ,   Transcriptomics  ,   Community  ,   Community annotation  ,   Community curation  ,   Genomics  ,   Bioinformatics  ,   Curation  ,   Annotation  ,   Biocuration  1      Introduction  The overarching vision of the Gene Ontology Consortium (GOC) is to describe gene products across species\u2014their temporally and spatially characteristic expression and localization, their contribution to multicomponent complexes, and their biochemical, physiologi-cal, or structural functions\u2014and thus enable biologists to easily explore the universe of genomes [ 1 ]. In practical terms, this makes providing an accessible, navigable resource of gene products, rigor-ously described according a structured ontology, the GOC\u2019s key objective. The referenced links, between the identi\ufb01 ers for Gene Ontology (GO) terms and the identi\ufb01 ers for speci\ufb01 c gene products, are the elemental GO annotations.  With Next Generation Sequencing technologies increasing the rate at which genomic and transcriptomic data are accumulating, the need for highly informative annotation data for the human genome is paramount. Community annotation has the potential to improve the information provided by the GO resource. Consequently, the GOC actively encourages contributions from Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_7, \u00a9 The Author(s) 2017\f86the scienti\ufb01 c community, to ensure that the ontology appropriately re\ufb02 ects the current understanding of biology and to supply gene product annotations [ 2 \u2013 4 ]. There are many online resources that encourage community annotation [ 5 \u2013 7 ]; however, annotations created in the majority of these are not submitted to the GO data-base. This chapter, therefore, only discusses the progress of com-munity contributions to the GO database.  2    Ontology Development Workshops  The success of GO is dependent on its ability to represent the research communities\u2019 interpretation of biological processes and individual gene product functions and cellular locations. This is achieved through the use of descriptive GO terms, with detailed de\ufb01 nitions, and appropriate placement of GO terms within the ontology hierarchy. The majority of GO terms are created by GO editors, following a review of the current scienti\ufb01 c literature, often, without the need of discussions with experts in the relevant \ufb01 eld [ 8 \u2013 9 ].  Major revisions or expansions of a speci\ufb01 c GO domain are usu-ally undertaken in consultation with experts working in that bio-logical \ufb01 eld. Notable successful ontology development projects include that of the immune system [ 10 ], heart development [ 2 ], kidney development [ 11 ], muscle processes and cellular compo-nents [ 12 ], cell cycle, and transcription [ 13 ]. The expansion of the heart development domain provides a good example of how experts in the \ufb01 eld can guide the GO editors to create very descrip-tive terms. The GO heart development domain describes heart morphogenesis, the differentiation of speci\ufb01 c cardiac cell types, and the involvement of signaling pathways in heart development. This was achieved following a 1\u00bd day meeting with four heart development experts, as well as considerable email exchanges both before and after the meeting [ 2 ]. The result of this effort was an increase in the number of GO terms describing heart development from 12 to over 280, and the creation of highly expressive terms such as secondary heart \ufb01 eld speci\ufb01 cation (GO:0003139) and canonical Wnt signaling in cardiac neural crest cell differentiation (GO:0061310).  3    Community Contributions to the GO Annotation Database  Lincoln Stein suggested that there are four organizational models to genome annotation: the factory (reliant on a high degree of automa-tion), the museum (requiring expert curators), the cottage industry (scientists working out of their laboratories), and the party (or jamboree\u2014a short intensive annotation workshop) [ 14 ]. To this, list Ruth C. Lovering\f87needs to be added \u201cthe school,\u201d where people are encouraged to annotate as part of a bioinformatics training program.  Currently, there are two major approaches taken to associate GO terms with gene products: manual curation of the literature and auto-mated pipelines based on manually created rules (the \u201cfactory\u201d) [ 15 ]. The majority of manual annotation follows the \u201cmuseum\u201d model, relying on highly trained curators reading the published literature, evaluating the experimental evidence, and applying the appropriate GO terms to the gene record [ 8 ,  16 ]. The majority of these curators are associated with speci\ufb01 c model organism databases, such as FlyBase [ 17 ], PomBase [ 18 ] and ZFIN [ 19 ], or proteomic databases, such as UniProt [ 20 ]. In general, these curators will be annotating gene products across a whole genome. In contrast, there have been a few annotation projects funded to improve the representation of speci\ufb01 c biological domains, such as cardiovascular [ 3 ], kidney [ 21 ] and neu-rological [ 22 ]. Two of these projects are being undertaken by the UCL functional annotation team and provide an example of an expert curation team embedded within a scienti\ufb01 c research group.    In the \u201cschool\u201d model, bioinformatics courses, which include an introduction to GO, provide an opportunity for attendees to contrib-ute GO annotations. However, providing timely feedback to degree students is very labor intensive. Texas A&amp;M University has circum-vented this problem through the use of competitive peer review. A biannual multinational student competition has been established to undertake large-scale manual annotation of gene function using GO. In this competition, known as the Community Assessment of Community Annotation with Ontologies (CACAO), 1  teams of stu-dents get points for making annotations, but can also take points from competitors by correcting their annotations. A professional curator then reviews these and annotations that are judged to be cor-rect are submitted to the GO database. This highly successful crowd-source project uses the online GONUTs wiki [ 23 ] to submit annotations and has supplied 3700 annotations to the GO database. The CACAO attribution identi\ufb01 es the resultant annotations, associ-ated with over 2500 proteins. This competition has given over 700 students the opportunity not only to learn how to use some of the essential online biological knowledgebases, but to reinforce this knowledge over a 3-month period, connecting their curriculum to research applications. An MSc literature review project, at University College London (UCL), also provides an opportunity to supply GO annotations to the GO database. Four projects, to date, have resulted in annotations for proteins involved in autism [ 24 ], heart develop-ment, folic acid metabolism, and hereditary hemochromatosis, creat-ing over 1000 annotations. A limitation of student annotations is that they do not draw on the expertise of the scienti\ufb01 c community. 1   http://gowiki.tamu.edu/wiki/index.php/Category:CACAO 3.1  GO Annotation Within a Bioinformatics CourseHow Does the Scienti\ufb01 c Community Contribute to Gene Ontology?\f88 For the past 5 years, the UCL functional annotation team has run a 2-day introduction to bioinformatics and GO course. This course has been attended by over 200 scientists, who have been given the opportunity to use the UniProt GO annotation tool, Protein2GO [ 20 ], to annotate their own papers or those published in their \ufb01 eld of expertise. However, on average only 50 annotations are submitted during the entire course and very few scientists con-tinue to contribute annotations after the end of the course. A similar problem has been identi\ufb01 ed in many other annotation workshops.     The \ufb01 rst workshop to submit GO annotations to the GO database focused on the annotation of the  Drosophila  genome [ 25 ]. Following on from this, the Pathema group ran several annotation- training workshops, in 2007, with the idea that trained scientists would continue to provide annotation updates thereafter [ 26 ]. Unfortunately, this approach had limited success. Although 150 scientists attended, in general they provided guidance to the cura-tors, rather than creating annotations themselves.     One of the most successful community annotation projects is that run by PomBase [ 18 ]. During pilot projects, PomBase encouraged 80 scientists from the \ufb01 ssion yeast community to submit a variety of annotations, including 226 GO annotations, 2  using their cura-tion tool, CANTO [ 4 ]. Following on from this success the PomBase team now receives regular annotations from the  Schizosaccharomyces pombe  community.  Another successful community annotation project has a tran-scription focus and was initiated by a group at the Norwegian University of Science and Technology. To ensure a consistent anno-tation approach is undertaken, the Norwegian research group, with members of the GOC, has created a set of transcription factor anno-tation guidelines [ 13 ]. These provide details of the ideal GO terms to associate with a transcription factor, with a list of experimental conditions that would support these annotations. By using these standardized conventions, the literature-curated data (currently including annotations for 400 proteins) is imported directly into the GO database, with only minimal quality checking required. Working with the GOC, the SYSCILIA consortium may prove to be just as effective. This group has already contributed to the devel-opment of GO terms to describe ciliary components and processes and started to submit GO annotations [ 27 ].  The outstanding contributions of Ralf Stephan, demonstrates what can be achieved through dedication. 3  Stephan singlehandedly annotated 60 % of the  Mycobacterium tuberculosis  genome, through the review of over 1000 papers. Furthermore, the resultant 7700 2   http://www.pombase.org/community/\ufb01 ssion-yeast-community-curation-pilot-project 3   http://www.ark.in-berlin.de/Site/MTB-GOA.html 3.2  Annotation Workshops3.3  GO Annotation by Speci\ufb01 c Scienti\ufb01 c CommunitiesRuth C. Lovering\f89annotations associated with 2500 proteins were checked by the UniProt-GOA team [ 15 ] and needed very few edits, before incor-poration into the GO database.  The success of PomBase may re\ufb02 ect the small size of the research community and that an early visionary investment has had a signi\ufb01 cant impact on the quality of data available at PomBase, achieved through the contributions of individual scientists and curators. In contrast, the Norwegian transcription factor project, formed to address the de\ufb01 cit of transcription factor annotations and in response to a need for comprehensive annotation of these proteins. The creation of a comprehensive and detailed annotation guide is key to the achievements of this project [ 13 ]. However, the GO database would also bene\ufb01 t from a few more \u201ccottage indus-try\u201d contributions, such as those provided for the  Mycobacterium tuberculosis  genome.   4    Why Contribute to GO?  The motivation behind \u201ccommunity annotation\u201d is varied. Some scientists are contributing GO annotations purely to ensure their research area or gene product(s) of interest are well curated. Others may want to ensure data from their own papers is curated and, therefore, promoted in popular knowledgebases; potentially increasing the citation rate of these papers. Others still are moti-vated by peer competition! Regardless of the motivation, the GOC is always appreciative of input from the scienti\ufb01 c community. Despite the success of some community annotation projects, taken as a whole, very few scientists suggest annotations, or papers for annotation. Consequently, the GOC continues to search for new ways to encourage the research community to contribute to cura-tion activities. For example, the inclusion of data from gene wikis [ 5 \u2013 7 ] could help take community annotation forwards. Considerable funding is being invested in NGS, proteomic and transcriptomic technologies and sequencing of population genomes. However, comprehensive gene annotation is likely to be a limiting factor in the identi\ufb01 cation of genes involved in polygenic diseases and dis-ease-associated disregulated pathways. Many groups are turning to proprietary resources to provide these annotations [ 28 ], which also include freely available annotation data. A more sustainable approach, and one that will also support genomic research in devel-oping countries, is to invest in improving the freely available anno-tation resources. All groups working with high-throughput datasets should consider working with the GOC and including in grant applications a component that would fund the submission of gene annotation data describing their area of interest, by expert curators, rather than requesting funding to enable access to proprietary soft-ware. The majority of members of the GOC do provide facilities to enable researchers to contribute to GO, the question is whether the scienti\ufb01 c community will acknowledge that their input is required.  How Does the Scienti\ufb01 c Community Contribute to Gene Ontology?\f905    Resources Supporting Expert Contributions to GO  It is unrealistic to expect a limited number of GO curators and edi-tors to understand all areas of biological and medical research. Consequently, a range of online facilities have been put in place to encourage scientists to review the ontology, to comment on the annotations, and to suggest papers for curation. In addition, sev-eral GO annotation tools, enable scientists to contribute annota-tion data [ 4 ,  8 ,  20 ]. Furthermore, the Protein2GO curation tool, automatically emails authors when one of their papers has been annotated, giving the authors an opportunity to comment on the curator\u2019s interpretation of their data [ 20 ].  Scientists interested in helping to improve the GO annotation resource can either contact the group providing annotations to their species or area of interest (see GOC contributors webpage   geneon-tology.org/page/go-consortium-contributors-list    ) or submit enquires or information through the GOC webform geneontology.org/form/contact-go, which will be forwarded to the relevant data-base or group. Useful information to provide would be: details of key experimental publications for curation; a review of a particular annotation set (associated with a speci\ufb01 c gene product or GO term), pointing out GO annotations that are missing, wrong, or controver-sial; comments on the ontology structure or de\ufb01 nitions of GO terms, with a reference to support the changes required (Fig.  1 ). This would ensure that any erroneous annotations are removed promptly from the GO database, and that information from seminal papers is included. Scientists who are con\ufb01 dent in using online resources may prefer to submit GO annotations, for any species, using the PomBase curation tool, CANTO   curation.pombase.org/pombe     [ 4 ]. Information provided by any of these means will be forwarded to the appropriate curation or editorial team and con-tributors will be noti\ufb01 ed when their suggestions have been incorpo-rated. Full details about contributing to GO are available on the GOC website    http://geneontology.org/page/contributing-go    . Professional GO curators review all submitted annotations to ensure the annotations follow GO annotation rules and a consistent anno-tation approach is taken.6       Following GO Developments  Scientists interested in \ufb01 nding out more about current GOC annotation and ontology development projects should sign up to the go-friends mailing list. 4  Alternatively, GO-relevant tweets can be followed via #geneontology, or @news4GO.     4   http://mailman.stanford.edu/mailman/listinfo/go-friends Ruth C. Lovering\f91  Acknowledgments  Supported by the British Heart Foundation (RG/13/5/30112), Parkinson\u2019s UK (G-1307), and the National Institute for Health Research University College London Hospitals Biomedical Research Centre. Many thanks to Dr. Rachael Huntley and Professor Suzanna Lewis for their reviews of this manuscript and to Doug Howe and Tanya Berardini for the information they provided. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any Has your paper been annotated by a GO curator?Is your favorite gene/protein well annotated?Contact informationWebforms:GOC: geneontology.org/form/contact-goGOA: www.ebi.ac.uk/GOA/contactusEmail for human gene product annotation: GOA: goa@ebi.ac.ukUCL: goannotation@ucl.ac.ukEmail list of all GOC contacts:geneontology.org/page/go-consortium-contributors-listGo to the QuickGO browser,www.ebi.ac.uk/QuickGOSearch QuickGO for your paper\u2019s PubMed identifier (PMID)Your paper is listed in the search resultsYour paper has been annotated by a GO curatorClick on the PMIDAnnotations accurately represent dataEmail the relevant database: request re-curation of the paperInclude the PMIDSummarize the information that is missing(or suggest GO annotations)List annotations that are wrongAnnotations could be improvedLook at the annotations associated with your paper\u2018Nothing found\u2019 is listed in the search resultsYour paper has not been annotated by a GO curatorContact the GOC: request curation of your paperInclude the PMIDThe experimental species investigated [so that the appropriate curation group deals with your request]Search for your favorite gene/protein recordGo to a gene/protein database, e.g. NCBI Gene, UniProtKB, GeneCards, WikipediaLook at the associated GO annotationsFollow links to see the full list of annotationsGene/protein: well annotatedContact the GOC: request curation of your gene/proteinInclude a list of key publication PMIDsSummarize the information that is missing(or suggest GO annotations)List annotations that are wrongGene/protein: not well annotated; missing or wrong annotations   Fig. 1    How research scientists can help to improve the annotation content of GO        How Does the Scienti\ufb01 c Community Contribute to Gene Ontology?\f92    1.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H et al (2000) Gene ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Consortium. Nat Genet 25:25\u201329        2.    Khodiyar VK, Hill DP, Howe D, Berardini TZ, Tweedie S et al (2011) The representation of heart development in the gene ontology. Dev Biol 354:9\u201317      3.    Lovering RC, Dimmer EC, Talmud PJ (2009) Improvements to cardiovascular gene ontology. Atherosclerosis 205:9\u201314         4.    Rutherford KM, Harris MA, Lock A, Oliver SG, Wood V (2014) Canto: an online tool for community literature curation. Bioinformatics 30:1791\u20131792       5.   Singh M, Bhartiya D, Maini J, Sharma M, Singh AR et al (2014) The Zebra\ufb01 sh GenomeWiki: a crowdsourcing approach to connect the long tail for zebra\ufb01 sh gene annota-tion. Database (Oxford) 2014:bau011     6.    Huss JW 3rd, Orozco C, Goodale J, Wu C, Batalov S et al (2008) A gene wiki for commu-nity annotation of gene function. PLoS Biol 6:e175       7.    Menda N, Buels RM, Tecle I, Mueller LA (2008) A community-based annotation frame-work for linking solanaceae genomes with phe-nomes. Plant Physiol 147:1788\u20131799        8.    Gene Ontology Consortium (2015) Gene Ontology Consortium: going forward. Nucleic Acids Res 43:D1049\u20131056      9.    Leonelli S, Diehl AD, Christie KR, Harris MA, Lomax J (2011) How the gene ontology evolves. BMC Bioinformatics 12:325      10.    Diehl AD, Lee JA, Scheuermann RH, Blake JA (2007) Ontology development for biological systems: immunology. Bioinformatics 23:913\u2013915      11.    Alam-Faruque Y, Hill DP, Dimmer EC, Harris MA, Foulger RE et al (2014) Representing kidney development using the gene ontology. PLoS One 9:e99864      12.    Feltrin E, Campanaro S, Diehl AD, Ehler E, Faulkner G et al (2009) Muscle research and gene ontology: new standards for improved data integration. BMC Med Genomics 2:6        13.   Tripathi S, Christie KR, Balakrishnan R, Huntley R, Hill DP et al (2013) Gene Ontology annotation of sequence-speci\ufb01 c DNA binding transcription factors: setting the stage for a large-scale curation effort. Database (Oxford):bat062      14.    Stein L (2001) Genome annotation: from sequence to biology. Nat Rev Genet 2:493\u2013503       15.    Camon E, Magrane M, Barrell D, Lee V, Dimmer E et al (2004) The Gene Ontology Annotation (GOA) Database: sharing knowl-edge in Uniprot with Gene Ontology. Nucleic Acids Res 32:D262\u2013266      16.   Balakrishnan R, Harris MA, Huntley R, Van Auken K, Cherry JM (2013) A guide to best practices for Gene Ontology (GO) manual annotation. Database (Oxford):bat054      17.    Tweedie S, Ashburner M, Falls K, Leyland P, McQuilton P et al (2009) FlyBase: enhancing Drosophila Gene Ontology annotations. Nucleic Acids Res 37:D555\u2013559       18.    McDowall MD, Harris MA, Lock A, Rutherford K, Staines DM et al (2015) PomBase 2015: updates to the \ufb01 ssion yeast database. Nucleic Acids Res 43:D656\u2013661      19.    Bradford Y, Conlin T, Dunn N, Fashena D, Frazer K et al (2011) ZFIN: enhancements and updates to the Zebra\ufb01 sh Model Organism Database. Nucleic Acids Res 39:D822\u2013829         20.    Huntley RP, Sawford T, Mutowo-Meullenet P, Shypitsyna A, Bonilla C et al (2015) The GOA database: gene Ontology annotation updates for 2015. Nucleic Acids Res 43:D1057\u20131063      21.    Alam-Faruque Y, Dimmer EC, Huntley RP, O\u2019Donovan C, Scambler P et al (2010) The Renal Gene Ontology Annotation Initiative. Organogenesis 6:71\u201375  medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     References Ruth C. Lovering\f93    22.   Foulger RE, Denny P, Hardy J, Martin MJ, Sawford T, Lovering RC (2016) Using the gene ontology to annotate key players in Parkinson\u2019s disease. Neuroinformatics      23.    Renfro DP, McIntosh BK, Venkatraman A, Siegele DA, Hu JC (2012) GONUTS: the Gene Ontology Normal Usage Tracking System. Nucleic Acids Res 40:D1262\u20131269      24.    Patel S, Roncaglia P, Lovering RC (2015) Using Gene Ontology to describe the role of the neurexin-neuroligin-SHANK complex in human, mouse and rat and its relevance to autism. BMC Bioinformatics 16:186      25.    Adams MD, Celniker SE, Holt RA, Evans CA, Gocayne JD et al (2000) The genome sequence of Drosophila melanogaster. Science 287:2185\u20132195      26.   Brinkac L, Madupu R, Caler E, Harkins D, Lorenzi H, Thiagarajan M, Sutton G (2009) Expert assertions through community annota-tion Jamborees. Nature Precedings      27.    van Dam TJ, Wheway G, Slaats GG, Group SS, Huynen MA et al (2013) The SYSCILIA gold standard (SCGSv1) of known ciliary compo-nents and its applications within a systems biol-ogy consortium. Cilia 2:7      28.    Stables MJ, Shah S, Camon EB, Lovering RC, Newson J et al (2011) Transcriptomic analyses of murine resolution-phase macrophages. Blood 118:e192\u2013208    How Does the Scienti\ufb01 c Community Contribute to Gene Ontology?\f   Part III    Evaluating Gene Ontology Annotations        \f97    Chapter 8    Evaluating Computational Gene Ontology Annotations                          Nives     \u0160kunca     ,     Richard     J.     Roberts    , and     Martin     Steffen       Abstract    Two avenues to understanding gene function are complementary and often overlapping: experimental work and computational prediction. While experimental annotation generally produces high-quality annotations, it is low throughput. Conversely, computational annotations have broad coverage, but the quality of annotations may be variable, and therefore evaluating the quality of computational annotations is a critical concern.  In this chapter, we provide an overview of strategies to evaluate the quality of computational annotations. First, we discuss why evaluating quality in this setting is not trivial. We highlight the various issues that threaten to bias the evaluation of computational annotations, most of which stem from the incompleteness of biological databases. Second, we discuss solutions that address these issues, for example, targeted selection of new experimental annotations and leveraging the existing experimental annotations.    Key words     Gene ontology  ,   Evaluation  ,   Tools  ,   Prediction  ,   Annotation  ,   Function  1      Introduction  Sequencing a genome is now routine. However, knowledge of the gene sequence is only the \ufb01 rst step toward understanding it; we ulti-mately want to understand the function(s) of each gene in the cell. Function annotation using computational methods\u2014for example, function propagation via sequence similarity or orthology\u2014can pro-duce high-probability annotations for a majority of gene sequences, the next step toward understanding. But because computational function annotations often generalize the many layers of biological complexity, we are interested in  evaluating  how well these pre-dictions re\ufb02 ect biological reality. In this chapter, we discuss the evaluation of computational predictions.  First, we highlight issues that make the evaluation of computa-tional predictions challenging, with perhaps the primary challenge being the incompleteness of annotation databases: scoring as \u201cwrong\u201d those computational predictions that are not yet proven or disproven could overestimate the count of \u201cincorrect\u201d predictions, and skew perceptions of computational accuracy [ 1 ]. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_8, \u00a9 The Author(s) 2017\f98 Second, we discuss solutions that address various aspects of database incompleteness. For example, some solutions directly address the incompleteness of databases by adding new experimen-tal annotations. Yet another solution leverages existing high- quality annotations in a current release of a database, and retrospectively evaluates previous releases of the annotation databases. Intuitively, those annotations that are unchanged through multiple successive database releases may be expected to be of higher quality. Additional solutions include leveraging negative annotations, though sparse but containing valuable information, or performing extensive experimentation for a subset of functions of interest.    In practice, functional annotation of a gene means the assignment of a single label, or a set of labels; for example, this might involve using BLAST to transfer the labels from another gene. A particu-larly valuable set of labels for denoting gene function are those derived from the controlled vocabulary established by the Gene Ontology (GO) consortium [ 2 ], with terms such as \u201coxygen trans-porter activity,\u201d \u201chemoglobin complex,\u201d and \u201cheme transport,\u201d as descriptors of a gene\u2019s Molecular Function, Cellular Component, and Biological Process.  But just as important as the annotation label itself is the knowl-edge of the source of the annotation. Based on their source, there are two main routes to produce annotations in the GO, and the GO Consortium emphasizes this distinction using evidence codes [ 3 ], as described in Chap.   3     [ 4 ].  The \ufb01 rst route of annotating requires curator\u2019s expertise when assigning: be it examining primary or secondary literature to assign appropriate annotations, manually examining phylogenetic trees to infer events of function loss and gain, or deciding on sequence similarity thresholds for speci\ufb01 c gene families to propagate annota-tions. As curated annotation is time consuming, the curators streamline their efforts, by focusing annotations on the 12 model organisms ([ 5 ] and Fig.  1 , left). Consequently, fewer than 1 % of proteins have this type of annotation in the UniProt-GOA data-base. Elsewhere, a recent examination of the annotation of 3.3 million bacterial genes found that fewer than 0.4 % of annotations can be documented by experiment, although estimates suggest that the actual number might be above 1 % [ 6 ].   The second route of annotating,  computational prediction of function , takes high-quality curated annotations propagates them across proteins in nonmodel organisms. Once the pipeline for the computational prediction has been setup\u2014a task which is by no means trivial\u2014it can be relatively straightforward to obtain computational prediction of function across a large number of  biological sequences. Chapter   5     [ 7 ] contains a detailed introduc-tion to the methods used in computational annotation.  Computational prediction of function propagates annotations to the vast majority of currently annotated genes (Fig.  1 , right). 1.1  Sources of Gene Ontology Annotations: Curated and Computational AnnotationsNives \u0160kunca et al.\f99Over 99 % of all annotations are created in this manner, and they are applied to approximately 76 % of all genes [ 6 ]\u2014the remaining 24 % of genes typically have no annotation or are listed as \u201chypothetical protein.\u201d With the exponential growth of biological databases and the labor-intensive nature of manual curation, it is inevitable that automated computational predictions will provide the vast majority of annotations populating current and future databases.   2    Challenges of Assessing Computational Prediction of Function  Computationally predicted annotations are typically assumed to be less reliable than manually curated ones. Manual curation may be thought of as more cautious, as there is typically a single protein being labeled at a time [ 8 ], whereas the goal of computational prediction is typically more ambitious: labeling a large number of proteins\u2014possibly ignoring subtle aspects of the biological reality.  Arguably the most accurate method to evaluate computational predictions of functions is to perform comprehensive experiments (e.g., [ 9 ]). However, given the number of computational annota-tions available, experimental evaluation is prohibitively expensive even for a small subset of the available computational annotations. 3,856,684,318 annotations without curator intervention18,840,553 annotations with curator interventionModel organismsNon-model organismsModel organismsNon-model organisms78.5%21.5%0.6%99.4%  Fig. 1    The distribution of the number of computational annotations obtained  without  curator intervention (evidence code IEA) to all other annotations (evi-dence codes ISS, IBA, IDA, IMP, ND, IGI, IPI, ISO, TAS, ISA, RCA, IC, NAS, ISM, IEP, IGC, EXP, IRD, IKR). The 12 model organisms are:  Homo sapiens ,  Mus musculus ,  Rattus norvegicus ,  Caenorhabditis elegans ,  Drosophila melanogaster ,  Arabidopsis thaliana ,  Gallus gallus ,  Danio rerio ,  Dictyostelium discoideum ,  Saccharomyces cerevisiae ,  Schizosaccharomyces pombe , and  Escherichia coli  K-12        Evaluating Computational Gene Ontology Annotations\f100As a consequence of this discrepancy in numbers, two practical obstacles interfere with the assessment of computational function prediction: the elusiveness of an unbiased gold standard dataset and the incompleteness of the recorded knowledge.    A major practical obstacle to the evaluation of computational func-tion prediction methods is the lack of a gold standard dataset\u2014a dataset that would contain complete annotations for representative proteins. Such a dataset should not be used to train the prediction algorithms (refer to Chap.   5     [ 7 ]) and can therefore be used to test them. In the current literature, the validation sets mimic the gold standard dataset, but they are biased:proteins that are prioritized for experimental characterization and curation are often selected for their medical or agricultural relevance, and may not be representa-tive of the full function space that the computational methods address. Moreover, with such incomplete validation sets, it is even more dif\ufb01 cult to evaluate algorithms specialized for speci\ufb01 c func-tions\u2014e.g., those identifying membrane-bound proteins. The gold standard dataset needs to cover a large breadth of GO terms and also have comprehensive annotations for these GO terms.  In addition to the dif\ufb01 culties of obtaining a gold standard dataset, the complexity of the GO graph ( see  also Chaps.   14     [ 10 ] and   2     [ 11 ])\u2014a necessary simpli\ufb01 cation of the true biological real-ity\u2014poses obstacles to comparison and evaluation. For example, it is not trivial to compare the prediction scores between the parent (more general) and the child (more speci\ufb01 c) GO terms: consider the case when computational methods correctly predict annota-tions using parent terms, but give erroneous predictions for the child terms, i.e., they overpredict. Alternatively, computational predictions might miss to predict some child GO terms, i.e., they underpredict. One way of handling such situations is to use the structure of the GO to probabilistically model protein function, as described in [ 12 ].     Underlying the elusiveness of the unbiased gold standard dataset is the main issue: the incompleteness of the annotation databases. When evaluating computational function annotation methods, we typically compare the predictions with the currently available knowledge. We  con\ufb01 rm  the computational annotation when it is available in our validation set, and we  reject  when its negation is available, e.g., via the NOT quali\ufb01 er in the GO database. If nega-tive annotations are sparse, as is often the case, it is standard prac-tice to consider wrong a prediction when the predicted annotation is absent from the validation set, e.g., [ 13 ]. This is formally called the  Closed World Assumption (CWA) , the presumption that a statement which is true is also  known  to be true. Conversely, under the CWA, that which is not currently known to be true is considered false. 2.1  The Elusiveness of an Unbiased Gold Standard Dataset2.2  Incomplete KnowledgeNives \u0160kunca et al.\f101 However, the available knowledge\u2014and consequently the vali-dation set\u2014is incomplete; absence of evidence of function does not imply evidence of absence of function [ 14 ]. This is formally referred to as the  Open World Assumption (OWA) , allowing us to  for-malize the concept of incomplete knowledge . As a consequence of the incompleteness of the validation set, we might be rejecting computational predictions that later prove to be correct [ 1 ].  To illustrate the challenges related to the evaluation of function prediction, let us focus on one protein, CLC4E_MOUSE (  http://www.uniprot.org/uniprot/Q9R0Q8    ), in particular to two compu-tational annotations assigned to this protein at the time of writing: the OMA orthology database [ 15 ] predicted annotation with \u201cinte-gral component of membrane\u201d (GO:0016021) and the InterPro pipeline predicted annotation with \u201ccarbohydrate binding\u201d (GO:0030246). There are no available existing high- quality anno-tations that con\ufb01 rm these computational predictions.  However, if we take a closer look at these annotations, the OMA annotation \u201cintegral component of membrane,\u201d compared to the experimental annotation (evidence code IDA) of \u201creceptor activity\u201d is consistent with the experimental annotation: in princi-ple, receptors are integral components of membranes. Additionally, the literature contains evidence that this protein indeed binds car-bohydrates [ 16 ], thereby con\ufb01 rming the InterPro prediction. Therefore, if we revisit the known annotations and make these statements explicitly known to be true, we can con\ufb01 rm them.  Indeed, for the proteins already present in the UniProt-GOA database, we see that curators do revisited them; more than half of the proteins have already been assigned a new GO term annotation after their \ufb01 rst introduction into the database (Fig.  2 ). An extreme example is provided by the Sonic hedgehog entry in mouse More than ten updatesSix to ten updatesTwo to five updatesOne update010000200003000040000500006000070000More updatesNumber of proteins  Fig. 2    Distribution of proteins based on the number of times a curator revisits a protein with an annotation from the literature (updates with evidence codes EXP, IDA, IPI, IMP, IGI, IEP). Among the proteins that have a curated annotation based on literature evidence, 56 % are subsequently updated with a new GO term        Evaluating Computational Gene Ontology Annotations\f102(  http://www.uniprot.org/uniprot/B3GAP8    ), which has already been revised over a hundred times.   To meaningfully compare computational function annotations, one must account for the Closed World Assumption and have the obstacles it implies in mind. But because of the extent of the gap between the closed and the open world\u2014think of the \u201cunknown unknowns\u201d in the protein function space\u2014a quick-\ufb01 x solution does not exist. However, numerous ways of tackling the problem were devised, and we turn our attention to those in the subsequent section.   3    Approaches to Test Computational Predictions with Experimental Data  To test computational predictions, experiments have to be con-ducted. However, the number of proteins that can be experimen-tally tested are dwarfed by the number of genes identi\ufb01 ed by genome sequencing, so a very small number of experimental data points must support an enormous number of predicted gene func-tion annotations.  Among the methods to evaluate computational annotations, some are focused on quantifying the available information (e.g., the number and the speci\ufb01 city of annotations) without providing quality judgment (e.g., [ 17 ,  18 ]), while others, the topic of this section, strive to evaluate the quality of the predictions themselves. Addressing some of the complexities of evaluation addressed in the previous section, the latter methods provide good templates for future evalu-ations of computational methods for function prediction.    The need for experimentally veri\ufb01 ed annotations is of suf\ufb01 cient scope that it is likely that signi\ufb01 cant progress can only be made if tackled by the entire scienti\ufb01 c community. One such attempt at community building is focused on bacterial proteins: COMBREX ( COM putational  BR idge to  Ex periments), along with additional efforts such as the Enzyme Function Initiative [ 19 ]. The database (  http://combrex.bu.edu    ) classi\ufb01 es the gene function status of 3.3 million bacterial genes, including 13,665 proteins that have experi-mentally determined functions [ 6 ]. The database contains traceable statements to experimentally characterized proteins, thereby provid-ing support for a given annotation in a clear and transparent manner. COMBREX also developed a tool, named COMBLAST, to associ-ate query genes with the various types of experimental evidence and data stored in COMBREX. COMBLAST output includes a trace to experimental evidence of function via sequence and domain similar-ity, to available structural information for related proteins, and to association with clinically relevant phenotypes such as antibiotic resistance, and other relevant information. It was used to provide additional annotations for 1474 prokaryotic genomes [ 20 ]. 3.1  The COMBREX InitiativeNives \u0160kunca et al.\f103 Additionally, COMBREX implemented a proof-of-concept prioritization scheme that ranked proteins for experimental test-ing. For each protein family, distances based on multiple align-ments were calculated to help experimentalists easily identify those proteins that might be considered most typical of the family as a whole. The \u201cideal\u201d COMBREX target is a protein close to many other uncharacterized proteins, and relatively far from any protein of known function, but not so far that it would preclude high- quality predictions of the protein\u2019s function for the experi-mentalist to test.  COMBREX helped fund the implementation of new technol-ogy for the experimental characterization of hypothetical proteins from  H. pylori  [ 21 ]. A panel of af\ufb01 nity probes was used in a screen to generate initial hypotheses for hypothetical proteins. These hypotheses were then tested and con\ufb01 rmed using traditional in vitro biochemistry. This approach is complementary to other higher throughput methods, such as the parallel screening of metabolite pools [ 22 ,  23 ], and activity-based proteomic approaches to identify proteins of a particular enzymatic class [ 24 ,  25 ].     CAFA (Critical Assessment of Functional Annotation) is another community-wide effort to evaluate computational annotations, and it promises to uncover some of the most promising algo-rithms applied to computational function annotation [ 13 ]. Such an effort has great utility in establishing success rates of many computational annotation methods based on newly generated curator knowledge. Chapter   10     [ 26 ] covers the details of the CAFA evaluation.  Yet another community effort with a more narrow scope, introduced in Chap.   6     [ 27 ], BioCreAtIvE (Critical Assessment of Information Extraction systems in Biology) [ 28 ] is focused on evaluating annotations obtained through text mining. When eval-uating in this setting, the challenges of evaluation within the open/closed world do not exist: methods are evaluated based on the amount of information they can extract from a scienti\ufb01 c paper, which in itself has de\ufb01 ned bounds. Evaluating the extraction qual-ity of GO annotations for a small set of human proteins showed the extent of the work ahead\u2014text mining algorithms were surpassed by the Precision of expert curators [ 29 ]\u2014but also showed the areas that need to be addressed to improve the quality of computational functional annotation using text mining algorithms.     A strategy to circumvent the problem of the lack of a gold standard is to consider changes in experimental annotations in the UniProt- GOA database [ 30 ].  By keeping track of annotations associated with particular proteins across successive releases of the UniProt-GOA database, 3.2  CAFA and BioCreAtIvE3.3  Evaluating Computational Predictions Over Time Using Successive Database ReleasesEvaluating Computational Gene Ontology Annotations\f104one can assess the extent to which newly added experimental anno-tations agree with previous computational predictions. As a surro-gate for the intuitive notion of speci\ufb01 city, the authors de\ufb01 ned a reliability measure as the ratio of con\ufb01 rmed computational annota-tions to con\ufb01 rmed and rejected/removed ones. One computational annotation is deemed con\ufb01 rmed or rejected, depending on whether a new, corresponding experimental annotation supports or contra-dicts it. Furthermore, if a computational annotation is removed, the annotation is deemed implicitly rejected and thus contributes nega-tively to the reliability measure. As a surrogate for the intuitive notion of sensitivity, coverage was de\ufb01 ned as the proportion of newly added experimental annotations that had been correctly predicted by computational annotations in a previous release.  Overall, this work found that electronic annotations are more reliable than generally believed, to an extent that they are competi-tive with annotations inferred by curators when they use evidence other than experiments from the primary literature. But this work also reported signi\ufb01 cant variations among inference methods, types of annotations, and organisms. For example, the authors noted an overall high reliability of annotations obtained from mapping Swiss-Prot keywords associated with UniProtKB entries to GO terms. Nevertheless, there were exceptions: GO terms related to metal ion binding had low reliability in the analysis due to a large number of removed annotations. Similarly, a few annotations related to ion transport were explicitly rejected with the \u2018NOT\u2019 quali\ufb01 er, e.g., for UniProtID Q6R3K9 (\u2018NOT\u2019 annotation for \u201ciron ion transport\u201d) and UniProtID Q9UN42 (\u2018NOT\u2019 annota-tion for \u201cmonovalent inorganic cation transport\u201d).     Having a comprehensive set of negative annotations would bridge the gap between CWA and OWA; knowing both which functions  are  and are  not  assigned to a protein will not reject predictions that might later prove to be correct.  While experimentally assigning a function to protein is dif\ufb01 cult and time consuming, it may be equally challenging to establish that a protein does  not  perform a particular function. For example, unsuccessfully testing a protein for a particular function may only indicate that it is either more dif\ufb01 cult to demonstrate such an activity or that it is not present under the given conditions. Because the number and the combination of environmental conditions to test\u2014e.g., the right partners or the right environmental stimulus\u2014is numerous, obtaining a set of \u2018NOT\u2019 annotations might be feasible only for a subset of functions. Consequently, the negative annota-tions are few and far in between in annotation databases. For exam-ple, the January 2015 release of the UniProt-GOA database contains only 8961 entries that are marked with a \u2018NOT\u2019 quali\ufb01 er.  There is a small number of reports in the literature stating that a protein does not perform a speci\ufb01 c function (e.g., [ 31 ]), 3.4  Increasing the Number of Negative (\u2018NOT\u2019) AnnotationsNives \u0160kunca et al.\f105and therefore such sporadic reports cannot be the basis for a comprehensive evaluation of computational annotations. Large-scale production of negative annotations do exists; for example, denoting a set of GO terms that are not likely to be assigned to a protein, given its known annotations (e.g., [ 32 ]). However, these are also computational  predictions , they also need to be evaluated.     The BioCreAtIvE challenge performed annotations without the challenges of the open and closed world of function annotations by focusing on de\ufb01 ned \u201cchunks\u201d of information, scienti\ufb01 c papers. In the realm of computational predictions, one of the more straight-forward ways of avoiding the challenges of the closed world is to limit the scope to function where we have close to complete com-prehension. In fact, by narrowing the scope of the function annota-tion problem, Huttenhower et al. did just that [ 9 ].  The authors evaluated the computational predictions, focusing the evaluation on functions related to mitochondrial organization and biogenesis in  Saccharomyces cerevisiae . They trained their func-tion prediction models only on the annotation data available in the databases, but performed comprehensive experiments for all genes in  S. cerevisiae  to check whether they have function related to mitochondrial organization and biogenesis. This way, they had information for every  S. cerevisiae  gene and were able to evaluate the prediction accuracy without the need for the distinction between the open and the closed world.     Simulation studies are abundantly used to evaluate computational methods that simulate various evolutionary events, as is done, for example, with the simulation framework for genome evolution Arti\ufb01 cial Life Framework (ALF) [ 33 ]. In a related application of simulation, simulated erroneous annotations were used to study the quality of computational annotations\u2014curated GO annotations obtained using methods based on sequence similarity, in the GO database denoted with the evidence code ISS [ 34 ]. First, the authors estimated the level of errors among the ISS GO annotations by checking for the effect of randomly adding erroneous annotations. Second, they obtained a linear model that connected the propensity of (arti\ufb01 cially introduced) errors among the annotations with the estimate of Precision. Finally, they used this model to estimate the baseline Precision at the level where there are no introduced errors.   4    Outlook  Experimental annotations are key to evaluate computational methods to predict annotations. Therefore, it is highly desirable that three principles govern experimental testing of gene function: maximal leveraging of existing experimental information, maximal 3.5  Evaluating Computational Predictions for a Speci\ufb01 c Subset of GO Terms3.6  Simulation StudiesEvaluating Computational Gene Ontology Annotations\f106information gain with each new experiment, and the development of higher throughput approaches.  Maximal leveraging of existing experimental information is easiest to obtain through the use of traceable statements, such as the use of the \u201cwith\u201d \ufb01 eld in the UniProt-GOA database: the \u201cwith\u201d \ufb01 eld can record the protein that was used as template to transfer annotation through sequence similarity. However, we could go a step further, toward statements such as: \u201cGene X has 96.8 % sequence identity to the experimentally characterized pro-tein \u2018HP0050\u2019 and therefore this protein is annotated as \u2018adenine speci\ufb01 c DNA methyltransferase\u2019.\u201d Traceable statements greatly increase the transparency of a prediction, and allow the users of gene annotations to estimate their con\ufb01 dence in the annotation, regardless of the source\u2014manual curator or an automated compu-tational prediction [ 35 ].  In order to increase information gain of new experiments, it would be bene\ufb01 cial to develop and incorporate experimental design principles that help guide the identi\ufb01 cation of maximally informative targets for function validation. One way to maximize the information gain from the experimental analysis is to choose proteins that generate or improve predictions for many other pro-teins across many genomes, as opposed to proteins related to few or no other proteins. Alternatively, for function prediction meth-ods that report probabilities, the information gain from an  experiment can be quanti\ufb01 ed as the reduction in the estimated probability of prediction error, summed across all predictions [ 36 ].  Development of higher throughput approaches for the testing of protein function is well underway, and we can hope for the same effects as with DNA sequencing. However, at the time of writing, a small number of experimental studies contribute much of the functional protein annotations collected in the databases, thereby biasing the available experimental annotations [ 8 ]. Indeed, DNA sequencing did not achieve its dramatic cost reductions and increases in throughput fortuitously, but rather was the result of the systematic investment of hundreds of millions of dollars in technology development over two decades.  Traditionally, the increases of success rates associated with computational function annotation are attributed to methodologi-cal re\ufb01 nements. However, we must also quantify the in\ufb02 uence of the data available\u2014e.g., more sequences and more function anno-tations\u2014 independently  of the in\ufb02 uence of the algorithms. This information is critical, if only because of the rate of aggregation of new information in the bioinformatics databases. Indeed, an increase in the number of sequenced genomes and an increase in the number of function annotations has a dramatic positive effect on predictive accuracy of at least one computational method of function annotation, phylogenetic pro\ufb01 ling [ 37 ].  Nives \u0160kunca et al.\f1075    Conclusion  There are a plethora of highly accurate, readily available computa-tional function annotation methods available to scientists, and state-of-the-art computational function annotations, such as in the UniProt-GOA database, are easily accessible to all. However, with-out transparent evaluation and benchmarking, it is still extremely challenging to differentiate among annotations, and annotation methods.  Going forward, the biocuration community will continue to advance along three important lines: increased amounts of biologi-cal sequence to be annotated, increased numbers of high-quality experimental annotations, and increased predictive accuracy of computational methods of annotation. In order to achieve the greatest increase in biological knowledge, we will couple the advances made in each of these three areas to reach other, espe-cially coupling advances in the development of new algorithms with robust evaluations of these algorithms based on experimental data, with the purpose of generating new, useful biological hypoth-eses. Such work will contribute to closing the gap between the Open and the Closed worlds, and greatly increase our  understanding of the large number new sequences that are now generated daily.       Acknowledgments  The authors thank Christophe Dessimoz and Maria Anisimova for helpful comments and suggestions. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.  Evaluating Computational Gene Ontology Annotations\f108   References      1.    Dessimoz C, \u0160kunca N, Thomas PD (2013) CAFA and the open world of protein function predictions. Trends Genet 29:609\u2013610      2.    Ashburner M, Ball CA, Blake JA et al (2000) Gene ontology: tool for the uni\ufb01 cation of biol-ogy. The Gene Ontology Consortium. Nat Genet 25:25\u201329      3.   Guide to GO Evidence Codes | Gene Ontology Consortium.   http://geneontology.org/page/guide-go-evidence-codes    .      4.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3      5.    Reference Genome Group of the Gene Ontology Consortium (2009) The Gene Ontology\u2019s Reference Genome Project: a uni-\ufb01 ed framework for functional annotation across species. PLoS Comput Biol 5:e1000431        6.    Anton BP, Chang Y-C, Brown P et al (2013) The COMBREX project: design, methodology, and initial results. PLoS Biol 11:e1001638       7.   Cozzetto D, Jones DT (2016) Computational methods for annotation transfers from sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu-lar biology, vol 1446. Humana Press. Chapter 5       8.    Schnoes AM, Ream DC, Thorman AW et al (2013) Biases in the experimental annotations of protein function and their effect on our understanding of protein function space. PLoS Comput Biol 9:e1003063       9.    Huttenhower C, Hibbs MA, Myers CL et al (2009) The impact of incomplete knowledge on evaluation: an experimental benchmark for protein function prediction. Bioinformatics 25:2404\u20132410      10.   Gaudet P, Dessimoz C (2016) Gene ontology: pitfalls, biases, and remedies. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 14      11.   Thomas PD (2016) The gene ontology and the meaning of biological function. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 2      12.    Clark WT, Radivojac P (2013) Information- theoretic evaluation of predicted ontological annotations. Bioinformatics 29:i53\u2013i61       13.    Radivojac P, Clark WT, Oron TR et al (2013) A large-scale evaluation of computational protein function prediction. Nat Methods 10:221\u2013227      14.    Thomas PD, Wood V, Mungall CJ et al (2012) On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report. PLoS Comput Biol 8:e1002386      15.    Altenhoff AM, Skunca N, Glover N et al (2014) The OMA orthology database in 2015: function predictions, better plant support, syn-teny view and other improvements. Nucleic Acids Res 43(Database issue):D240\u2013D249      16.    Yamasaki S, Matsumoto M, Takeuchi O et al (2009) C-type lectin Mincle is an activating receptor for pathogenic fungus, Malassezia. Proc Natl Acad Sci U S A 106:1897\u20131902      17.    Buza TJ, McCarthy FM, Wang N et al (2008) Gene ontology annotation quality analysis in model eukaryotes. Nucleic Acids Res 36:e12      18.    del Pozo A, Pazos F, Valencia A (2008) De\ufb01 ning functional distances over gene ontol-ogy. BMC Bioinformatics 9:50      19.    Gerlt JA, Allen KN, Almo SC et al (2011) The enzyme function initiative. Biochemistry 50:9950\u20139962      20.    Wood DE, Lin H, Levy-Moonshine A et al (2012) Thousands of missed genes found in bacterial genomes and their analysis with COMBREX. Biol Direct 7:37      21.    Choi H-P, Juarez S, Ciordia S et al (2013) Biochemical characterization of hypothetical proteins from Helicobacter pylori. PLoS One 8:e66605      22.    Proudfoot M, Kuznetsova E, Sanders SA et al (2008) High throughput screening of puri\ufb01 ed proteins for enzymatic activity. Methods Mol Biol 426:331\u2013341      23.    Kuznetsova E, Proudfoot M, Sanders SA et al (2005) Enzyme genomics: application of gen-eral enzymatic screens to discover new enzymes. FEMS Microbiol Rev 29:263\u2013279      24.    Cravatt BF, Wright AT, Kozarich JW (2008) Activity-based protein pro\ufb01 ling: from enzyme chemistry to proteomic chemistry. Annu Rev Biochem 77:383\u2013414      25.    Simon GM, Cravatt BF (2010) Activity-based proteomics of enzyme superfamilies: serine hydrolases as a case study. J Biol Chem 285:11051\u201311055      26.   Friedberg I, Radivojac P (2016) Community-wide evaluation of computational function pre-diction. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu-lar biology, vol 1446. Humana Press. Chapter 10      27.   Ruch P (2016) Text mining to support gene ontology curation and vice versa. In: Dessimoz C, \u0160kunca N (eds) The gene ontology hand-book. Methods in molecular biology, vol 1446. Humana Press. Chapter 6  Nives \u0160kunca et al.\f109    28.    Krallinger M, Morgan A, Smith L et al (2008) Evaluation of text-mining systems for biology: overview of the Second BioCreative commu-nity challenge. Genome Biol 9(Suppl 2):S1      29.    Camon EB, Barrell DG, Dimmer EC et al (2005) An evaluation of GO annotation retrieval for BioCreAtIvE and GOA. BMC Bioinformatics 6(Suppl 1):S17      30.    Skunca N, Altenhoff A, Dessimoz C (2012) Quality of computationally inferred gene ontol-ogy annotations. PLoS Comput Biol 8:e1002533      31.   Poux S, Magrane M, Arighi CN et al (2014) Expert curation in UniProtKB: a case study on dealing with con\ufb02 icting and erroneous data.   Database:bau016          32.    Youngs N, Penfold-Brown D, Bonneau R et al (2014) Negative example selection for protein function prediction: The NoGO Database. PLoS Comput Biol 10:e1003644      33.    Dalquen DA, Anisimova M, Gonnet GH et al (2012) ALF\u2014a simulation framework for genome evolution. Mol Biol Evol 29:1115\u20131123      34.    Jones CE, Brown AL, Baumann U (2007) Estimating the annotation error rate of curated GO database sequence annotations. BMC Bioinformatics 8:170      35.   Bastian FB, Chibucos MC, Gaudet P et al (2015) The Con\ufb01 dence Information Ontology: a step towards a standard for asserting con\ufb01 -dence in annotations. Database:bav043      36.    Letovsky S, Kasif S (2003) Predicting protein function from protein/protein interaction data: a probabilistic approach. Bioinformatics 19(Suppl 1):i197\u2013i204      37.    \u0160kunca N, Dessimoz C (2015) Phylogenetic pro\ufb01 ling: how much input data is enough? PLoS One 10:e0114701    Evaluating Computational Gene Ontology Annotations\f111    Chapter 9    Evaluating Functional Annotations of Enzymes Using the Gene Ontology                          Gemma     L.     Holliday     ,     Rebecca     Davidson    ,     Eyal     Akiva    , and     Patricia     C.     Babbitt       Abstract    The Gene Ontology (GO) (Ashburner et al., Nat Genet 25(1):25\u201329, 2000) is a powerful tool in the informatics arsenal of methods for evaluating annotations in a protein dataset. From identifying the near-est well annotated homologue of a protein of interest to predicting where misannotation has occurred to knowing how con\ufb01 dent you can be in the annotations assigned to those proteins is critical. In this chapter we explore what makes an enzyme unique and how we can use GO to infer aspects of protein function based on sequence similarity. These can range from identi\ufb01 cation of misannotation or other errors in a predicted function to accurate function prediction for an enzyme of entirely unknown function. Although GO annotation applies to any gene products, we focus here a describing our approach for hierarchical classi\ufb01 cation of enzymes in the Structure-Function Linkage Database (SFLD) (Akiva et al., Nucleic Acids Res 42(Database issue):D521\u2013530, 2014) as a guide for informed utilisation of annotation transfer based on GO terms.    Key words     Catalytic function  ,   Enzyme  ,   Misannotation  ,   Evidence of function  1      Introduction  Enzymes are the biological toolkit that organisms use to perform the chemistry of life, and the Gene Ontology (GO) [ 1 ] represents a detailed vocabulary of annotations that captures many of the functional nuances of these proteins. However, the relative lack of experimentally validated annotations means that the vast majority of functional annotations are electronically transferred, which can lead to erroneous assumptions and missannotations. Thus, it is important to be able to critically examine functional annotations. This chapter describes some of the key concepts that are unique for applying GO-assisted annotation to enzymes. In particular we introduce several techniques to assess their functional annotation within the framework of evolutionarily related proteins (superfamilies). Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_9, \u00a9 The Author(s) 2017\f112   At its very simplest, an enzyme is a protein that can perform at least one overall chemical transformation (the function of the enzyme). The overall chemical transformation is often described by the Enzyme Commission (EC) Number [ 2 \u2013 4 ] (and  see  Chap.   19     [ 5 ]). The EC Number takes the form A.B.C.D, where each position in the code is a number. The \ufb01 rst number (which ranges from 1 to 6) describes the general class of enzyme, the second two numbers (which both range from 1 to 99) describe the chemical changes occurring in more detail (the exact meaning of the numbers depends on the speci\ufb01 c class of enzyme you are looking at) and the \ufb01 nal number (formally ranging from 1 to 999) essentially describes the substrate speci\ufb01 city. The EC number has many limitations, not least the fact that it doesn\u2019t describe the mechanism (the manner in which the enzyme performs its overall reaction) and often contains no information on cofactors, regulators, etc. Nor is it structurally contextual [ 6 ] in that similarity in EC number does not necessarily infer similarity in sequence or structure, making it sometimes risky to use for annotation transfer, especially among remote homolo-gous proteins. However, it does do exactly what it says on the tin: it de\ufb01 nes the overall chemical transformation. This makes it an important and powerful tool for many applications that require a description of enzyme chemistry.  The Molecular Function Ontology (MFO) in GO contains the full de\ufb01 nition of around 70 % of all currently available EC numbers. Theoretically, the MFO would contain all EC numbers available. However, due to many EC numbers not currently being assigned to a speci\ufb01 c protein identi\ufb01 er within UniProtKB, the coverage is lower than might be expected. Another important difference between the EC hierarchy and the GO hierarchy is that the latter is often much more complex than the simple four steps found in the EC hierarchy. For example, the biotin synthase (EC 2.8.1.6) hierarchy is relatively simple and follows the four step nomenclature, while the GO hierar-chy for [cytochrome c]-arginine N-methyltransferase (EC 2.1.1.124) is much more complex ( see  Fig.  1 ).   Formally, MFO terms describe the activities that occur at the molecular level; this includes the \u201ccatalytic activity\u201d of enzymes or \u201cbinding activity\u201d. It is important to remember that EC num-bers and MFO terms represent activities and not the entities (molecules, proteins or complexes) that perform them. Further, they do not specify where, when or in what context the action takes place. This is usually handled by the Cellular Component Ontology. The \ufb01 nal ontology in GO, the Biological Process Ontology (BPO), provides terms to describe a series of events that are accomplished by one or more organised assemblies of molecular functions. Each MFO term describes a unique single function that means the same thing regardless of the evolutionary origin of the entity annotated with that term. Although the BPO describes a collection of activities, some BPO terms can be related 1.1  Enzyme Nomenclature and How It Is Used in GOGemma L. Holliday et al.\f113to their counterparts in the MFO, e.g. GO:0009102 (biotin bio-synthetic process) could be considered to be subsumed with the MFO term GO:0004076 (biotin synthase activity) as GO:0009102 includes the activity GO:0004076, i.e. in such cases, the terms are interchangeable for the purpose of evaluation of a protein\u2019s DBACABCDamolecularfunctioncellularprocessorganicsubstancemetabolicprocesscatalyticactivityprimarymetabolicprocessmacromoleculemetabolicprocesscellularmetabolicprocessmethylationtransferaseactivitytransferaseactivity,transferringone-carboncellularmacromoleculemetabolicprocessmacromoleculemodificationproteinmetabolicprocessproteinmodificationprocesscellular proteinmetabolicprocessmethyltransferase activitycellular proteinmodificationprocessmacromoleculemethylationN-methyltransferase activityS-adenosylmethionine-dependentmethyltransferproteinalkylationproteinmethylationarginineN-methyltransferase activityproteinmethyltransferase activityprotein-arginineN-methyltransferase activity[cytochromec]-arginineN-methyltransferase activitypeptidyl-arginineN-methylationpeptidyl-arginine methylationpeptidyl-arginine modificationpeptidyl-aminoacidmodificationmolecularfunctionbiologicalprocessbiologicalprocessmetabolicprocessmetabolicprocesscatalyticactivitytransferaseactivitytransferaseactivitytransferringsulfur-containiradical SAMenzyme activitysulfurtransferase activitybiotin synthaseactivityb  Fig. 1    Example of the GO hierarchy (taken from the ancestor chart of the QuickGo website (  http://www.ebi.ac.uk/QuickGO/    ) showing the relative complexity of the GO hierarchy for two distinct EC numbers). ( a ) Shows the GO hierarchy for biotin synthase, EC 2.8.1.6; ( b ) shows the GO hierarchy for [cytochrome c]-arginine  N -methyltransferase, EC 2.1.1.24. The  colours  of the  arrows  in the ontology are denoted by the key in the centre of the \ufb01 gure.  Black connections  between terms represent an is_a relationship,  blue connections  repre-sent a part_of relationship. The  A ,  B ,  C  and  D  in  red boxes  denote the four levels of the EC nomenclature        Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f114annotation. Please  see  Chap.   2     [ 7 ] for a more in-depth discussion of the differences between BPO and MFO.  As a protein, an enzyme has many features that can be described and used to de\ufb01 ne the enzyme\u2019s function, from the primary amino acid sequence to the enzyme\u2019s quaternary structure (biological assembly), the chemistry that is catalysed, to the localisation of the enzyme. Features can also denote the presence (or absence) of active site residues to con\ufb01 rm (or deny) a predicted function, such as EC class, using the compositional makeup of a protein amino acid sequences [ 8 ,  9 ]. Nevertheless, for the many proteins of unknown function deposited in genome projects, prediction of the molecular, biological, and cellular functions remains a daunting challenge. Figure  2  provides a view of enzyme-speci\ufb01 c features along with the GO ontologies that can also be used to describe them. Because it captures these features through a systematic and hierarchical classi\ufb01 cation system, GO is heavily used as a standard for evaluation of function prediction methods. For example, a reg-ular competition, the Critical Assessment of Functional Annotation (CAFA) has brought many in the function prediction community together to evaluate automated protein function prediction  algorithms in assigning GO terms to protein sequences [ 11 ]. Please  see  Chap.   10     [ 12 ] for a more detailed discussion of CAFA.EnzymeMolecular FunctionAmino Acid SequenceCellular ComponentBiological ProcessReactionReaction MechanismSiteReaction StepsRegulatory SiteComponentsPolymer ComponentsNon-polymer ComponentsCofactorsSubstratesProductsRegulatorsProteinogenicPost-Translationally ModifiedActive SiteOverall Chemical transformationBiological Assembly  Fig. 2    Hierarchical view of enzyme features. The GO ontologies which describe proteins and their features are highlighted in  light green . Other ontologies available in OBO and BioPortal are shown in the following colours:  light yellow  represents the Amino Acid Ontology,  purple  represents the Enzyme Mechanism Ontology,  blue  represents the ChEBI ontology and  grey  represents the Protein Ontology.  See  also Chap.   5     [ 10 ]. The terms immediately beneath the parent term are those terms that are covered by ontologies, and required for a protein to be considered an enzyme        Gemma L. Holliday et al.\f115      Although there are many different features and methods that can (and are) used to predict the function of a protein, there are several advantages to using GO as a broadly applied standard. Firstly, GO has good coverage of known and predicted functions so that nearly all proteins in GO will have at least one associated annotation. Secondly, annotations associated with a protein are accompanied by an evidence code, along with the information describing that evidence source. Within the SFLD [ 13 ] each annotation has an associated con\ufb01 dence level which is linked to both the evidence code, source of the evidence (including the type of experiment) and the curator\u2019s experience. For example, experimental evidence for an annotation is considered as having high con\ufb01 dence whereas predictions generated by computational methods are considered of lower con\ufb01 dence (Chap.   3     [ 14 ]). In general there are three types of evidence for the assignment of a GO term to a protein:    1.    Fully manually curated: These proteins will usually have an associated experimental evidence that has been identi\ufb01 ed by human curators and who have added relevant evidence codes. For the purposes of the SFLD and this chapter, these are con-sidered high con\ufb01 dence and will have a greater weight than any other annotation con\ufb01 dence level.      2.    Computational with some curator input: These are computa-tionally based annotations that have been propagated through curator derived rules, and are generally considered to be of medium con\ufb01 dence by the SFLD. Due to the huge proportion of sequences in large public databases now available, over 98 % of GO annotations are inferred computationally [ 15 ].      3.    Computational with no curator input: These annotations that have been computationally inferred from information without any curator input into the inference rules and are considered to be of the lowest con\ufb01 dence by the SFLD.      All computationally derived annotations rely upon prior knowl-edge, and so if the rule is not suf\ufb01 ciently detailed, it can still lead to the propagation of annotation errors ( see  Misannotation Section  1.4 ).  Assigning con\ufb01 dence to annotations is highly subjective [ 16 ], however, as one person may consider high-throughput screening, which more frequently is used to predict protein-binding or sub-cellular locations rather than EC number, of low con\ufb01 dence. This is because such experiments often have a relatively high number of false positives that can generate bias in the analysis. However, depending on what your research questions are, you may con-sider such data of high con\ufb01 dence. It all depends on what \ufb01 eld you are in and what your needs are. Generally speaking, the more reproducible the experiment(s), the higher con\ufb01 dence you can have in their results. Thus, even low-to-medium con\ufb01 dent annota-tions (from Table  1 ) may lead to a high-con\ufb01 dence annotation. 1.2  Why Annotate Enzymes with the Gene Ontology?Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f116For example the GO Reference Code GO_REF:0000003 provides automatic GO annotations based on the mapping of EC numbers to MFO terms, so although annotated as IEA, these annotations can be considered of higher con\ufb01 dence [ 18 ]. Some examples of high-, medium- and low-con\ufb01 dence annotations are shown in Table  1 , along with reference to the approach used in SwissProt and the SFLD to describe their reliability.      We de\ufb01 ne here an enzyme (or protein) superfamily as the largest grouping of enzymes for which a common ancestry can be identi-\ufb01 ed. Superfamilies can be de\ufb01 ned in many different ways, and every resource that utilises them in the bioinformatics community has probably used a slightly different interpretation and method to col-late their data. However, they can be broadly classi\ufb01 ed as structure- based, in which the three-dimensional structures of all available proteins in a superfamily have been aligned and con\ufb01 rmed as homol-ogous, or sequence based, where the sequences have been used rather than structures. Many resources use a combination of approaches. Examples of superfamily based resources include CATH [ 19 ], Gene3D [ 20 ], SCOP and SUPERFAMILY [ 21 ], which are primarily structure based, and Pfam [ 22 ], PANTHER [ 23 ] and TIGRFAMs [ 24 ], which are primarily sequence based. A third de\ufb01 -nition of a superfamily includes a mechanistic component, i.e. a set 1.3  Annotation Transfer Under the Superfamily Model      Table 1    Some example proteins (listed by UniProtKB accession) with their associated annotations, source of the annotation (the SFLD is the Structure-Function Linkage Database, Swiss-Prot is the curated portion of UniProtKB) and the con\ufb01 dence of those annotations along with the reason that con\ufb01 dence level has been assigned    Protein ID from UniProtKB [ 17 ]  Annotated protein function ( source )  SFLD con\ufb01 dence level  Types of evidence or reasoning used to annotate the function  Q9X0Z6  [FeFe]-hydrogenase maturase ( From SFLD and Swiss-Prot )  High  Inferred from experimental analysis of protein structures, genomic context and results from spectroscopic assay.  Q11S94  Biotin Synthase (BioB) ( From SFLD and Swiss-Prot )  Medium  Inferred from similarity to other BioB enzymes. Matched by similarity to other BioB sequences and catalytic residues are fully conserved.  Q58692  Biotin Synthase (BioB) ( From Swiss-Prot )  Low  Inferred from similarity to other BioB enzymes. Matched by similarity to other BioB sequences. Whilst all residues required for binding the iron-sulphur clusters are conserved, all the catalytic residues (those required for the BioB reaction to occur) are not. Also has no biotin synthase genomic context. Gemma L. Holliday et al.\f117of sequences must not only be homologous, but there must be some level of conserved chemical capability within the set, e.g. catalytic residues, cofactors, substrate and/or product substructures or mechanistic steps. An example of such a resource is the SFLD and we will focus on this resource with respect to evaluating GO annota-tions for enzymes that are members of a de\ufb01 ned superfamily.  The SFLD (  http://s\ufb02 d.rbvi.ucsf.edu/    ) is a manually curated classi\ufb01 cation resource describing structure-function relationships for functionally diverse enzyme superfamilies [ 25 ]. Members of such superfamilies are diverse in their overall reactions yet share a common ancestor and some conserved active site features associ-ated with conserved functional attributes such as a partial reaction or molecular subgraph that all substrates or products may have in common. Thus, despite their different functions, members of these superfamilies often \u201clook alike\u201d which can make them particularly prone to misannotation. To address this complexity and enable reliable transfer of functional features to unknowns only for those members for which we have suf\ufb01 cient functional information, we subdivide superfamily members into subgroups using sequence information (and where available, structural information), and lastly into families, de\ufb01 ned as sets of enzymes known to catalyse the same reaction using the same mechanistic strategy and catalytic machinery. At each level of the hierarchy, there are conserved chemical capabilities, which include one or more of the conserved key residues that are responsible for the catalysed function; the small molecule subgraph that all the substrates (or products) may include and any conserved partial reactions. A subgroup is essen-tially created by observing  a similarity  threshold at which all mem-bers of the subgroup have more in common with one another than they do with members of another subgroup. (Thresholds derived from similarity calculations can use many different metrics, such as simple database search programs like BLAST [ 26 ] or Hidden Markov Models (HMMs) [ 27 ] generated as part of the curation protocol to describe a subgroup or family.)      Annotation transfer is a hard problem to solve, partly because it is not always easy to know exactly how a function should be trans-ferred. Oftentimes, function and sequence similarity do not track well [ 28 ,  29 ] and so, if sequence similarity is the only criterion that has been used for annotation transfer, the inference of function may have low con\ufb01 dence. However, it is also very dif\ufb01 cult to say whether a protein is truly misannotated, especially if no fairly simi-lar protein has been experimentally characterised that could be used for comparison and evaluation of functional features such as the presence of similar functionally important active site residues. As we have previously shown [ 30 \u2013 32 ] there is a truly staggering amount of protein space that has yet to be explored experimentally and that makes it very dif\ufb01 cult to make de\ufb01 nitive statements as to the validity of an annotation. 1.4  Annotation Transfer and MisannotationEvaluating Functional Annotations of Enzymes Using the Gene Ontology\f118 Misannotation can come from many sources, from a human making an error in curation, which is then propagated from the top down, to an automated annotation transfer rule that is slightly too lax, to the use of transitivity to transfer annotation, e.g. where protein A is annotated with function X, protein B is 70 % identical to A, and so is also assigned function X, protein C is 65 % identical to protein B, and so is also assigned function X. Whilst this may be the correct function, protein C may have a much lower similarity to protein A, and thus the annotation transfer may be \u201crisky\u201d [ 33 ]. As in the example shown in Fig.  3 , sequence similarity networks (SSNs) [ 34 ] offer a powerful way to highlight where potential   Fig. 3    Example of identifying misannotation using an SSN in the biotin synthase- like subgroup in the SFLD. Nodes colours represent different families in the sub-group, where  red  represent those sets of sequences annotated as canonical biotin synthase in the SFLD,  blue  represent the HydE sequences,  green  the PylB sequences and magenta the HmdB sequences. The nodes shown as  large dia-monds  are those annotated as BioB in GO, clearly showing that the annotation transfer for BioB is too broad. The network summarizes the similarity relationships between 5907 sequences. It consists of 2547 representative nodes (nodes repre-sent proteins that share greater than 90 % identity) and 2,133,749 edges, where an edge is the average similarity of pairwise BLAST  E -values between all possible pairs of the sequences within the connected nodes. In this case, edges are included if this average is more signi\ufb01 cant than an  E -value of 1e-25. The organic layout in Cytoscape 3.2.1 is used for graphical depiction. Subheading  2.1  described how such similarity networks are created        Gemma L. Holliday et al.\f119misannotation may occur. In this network, all the nodes are connected via a homologous domain, the Radical SAM domain. Thus, the observed differences in the rest of the protein mean that the functions of the proteins may also be quite different. For details on the creation of SSNs,  see  Subheading  2.1 . Cases where annota-tions may be suspect can often be evaluated based on a protein\u2019s assigned name, and from the GO terms inferred for that protein.   Not all annotations are created equal, even amongst experi-mentally validated annotations, and it is important to consider how well evidence supporting an annotation should be trusted. For example, in the glutathione transferase (GST) superfamily, the cog-nate reaction is often not known as the assays performed use a rela-tively standard set on non-physiological substrates to infer the type of reaction catalysed by each enzyme that is studied. Moreover, GSTs are often highly promiscuous for two or more different reac-tions again complicating function assignment [ 32 ]. That being said, the availability of even a small amount of experimental evidence can help guide future experiments aimed at functional characterisation. A new ontology, the Con\ufb01 dence Information Ontology (CIO) [ 16 ], aims to help annotators assign con\ufb01 dence to evidence. For example, evidence that has been reproduced from many different experi-ments may have an intrinsically higher con\ufb01 dence than evidence that has only been reported once.   2    Using GO Annotations to Visualise Data in Sequence Similarity Networks  Sequence similarity networks (SSNs) are a key tool that we use in the Structure-Function Linkage Database (SFLD) as they give an immediately accessible view of the superfamily and the relation-ships between proteins in this set. This in turn allows a user to identify boundaries at which they might reasonably expect to see proteins performing a similar function in a similar manner. As was shown in Fig.  3 , the GO annotation for BioB covered several dif-ferent SFLD families. These annotation terms have been assigned through a variety of methods, but mostly inferred from electronic annotation (i.e. rule-based annotation transfer as shown in Fig.  4 ).   From the networks shown previously, a user may intuitively see that there are three basic groups of proteins. Further, it could be hypothesised that these groups could have different functions (which is indeed the case in this particular example). Thus, the user may be left with the question: How do I know what boundaries to use for high con\ufb01 dence in the annotation transfer? Figure  5  shows another network, this time coloured by the average bit-score for the sequences in a node against the SFLD HMM for BioB. This net-work exempli\ufb01 es how (1) sequence similarity (network clusters) corresponds with the sequence pattern generated by SFLD curators to represent the BioB family, and (2) HMM true-positive gathering Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f120bit-score cut-off can be \ufb01 ne-tuned. By combining what we know about the protein set from the GO annotation (Fig.  3 ) with the HMM bit-score (Fig.  5 ) it is possible to be much more con\ufb01 dent in the annotations for the proteins in the red/brown group in Fig.  5 .       SSNs provide a visually intuitive method for viewing large sets of similarities between proteins [ 34 ]. Although their generation is subject to size limitations for truly large data sets, they can be easily created and visualised for several thousand sequences. There are many ways to create such networks, the networks created by the SFLD are generated by Pythoscape [ 35 ], a freely available software that can be downloaded, installed and can be run locally. Recently, web servers have been described that will generate networks for users. For example, The Enzyme Similarity Tool (EFI-EST) [ 36 ] created by the Enzyme Function Initiative will take a known set of proteins (e.g. Pfam or InterPro [ 37 ] groups) and generate net-works for users from that set. A similarity network is simply a set of nodes (representing a set of amino acid sequences as described in 2.1  Creating Sequence Similarity Networks  Fig. 4    Biotin synthase-like subgroup coloured by con\ufb01 dence of evidence (as shown in Table  1 ). The  diamond shaped nodes  are all annotated as Biotin Synthase in GO.  Red nodes  are those that only have low con\ufb01 dence annotations, the  orange nodes  are those that have at least one medium-con\ufb01 dence annota-tions and the  green  are those that have at least one high-con\ufb01 dence annotation.  Grey nodes  have no BioB annotations. Node and edge numbers, as well as  e -value threshold are as in Fig.  3         Gemma L. Holliday et al.\f121this chapter, for example) and edges (representing the similarity between those nodes). For the SSNs shown in this chapter, edges represent similarities scored by pairwise BLAST  E -values (used as scores) between the source and target sequences. Using simple metrics such as these, relatively small networks are trivial and fast to produce from a simple all-against-all BLAST calculation. However, the number of edges produced depends on the similarity between all the nodes to each other, so that for comparisons of a large num-ber of closely related sequences, the number of edges will vastly exceed the number of nodes, quickly outpacing computational resources for generating and viewing networks. As a result, some data reduction will eventually be necessary. The SFLD uses repre-sentative networks where each node represents a set of highly   Fig. 5    Example of a sequence similarity network to estimate subgroups for use in initial steps of the curation process and to guide \ufb01 ne-tuning the hidden Markov model (HMM) true-positive detection threshold of an enzyme family (here for the Biotin synthase (BioB) family). Node colours represent the average Bit-score of the BioB family HMM for all sequences represented by the node. The mapping between colours and average Bit scores is given in the legend. Nodes with  thick borders  represent proteins that belong to the BioB family according to SFLD annotation.  Diamonds  represent nodes that include proteins with BioB family annotation according to GO. The \ufb01 nal BioB HMM detection threshold was achieved for the SFLD by further exploration of more strict  E -value thresholds for edge representation, and was set to 241.6. Node and edge numbers, as well as  E -value threshold, are as in Fig.  3         Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f122similar sequences and the edges between them represent the mean  E -value similarity between all the sequences in the source node and all the sequences in the target node. As shown in Fig.  3 , node graphical attributes (e.g. shape and colour) used to represent GO terms for the proteins shown are a powerful way to recognise rela-tionships between sequence and functional similarities. Importantly, statistical analyses must be carried out to verify the signi\ufb01 cance of these trends, as we show below.     A common use of GO enrichment analysis is to evaluate sets of differentially expressed genes that are up- or down-regulated under certain conditions [ 38 ]. The resulting analysis identi\ufb01 es which GO terms are over- or under-represented within the set in question. With respect to enzyme superfamilies, the traditional implementation of enrichment analysis will not work well as there are often very many different species from different kingdoms in the dataset. However, there are several ways that we can still utilise sets of annotated proteins to evaluate the level of enrichment for GO terms.  The simplest method and least rigorous, is to take the set of proteins being evaluated, count up the number of times a single annotation occurs (including duplicate occurrences for a single enzyme, as these have different evidence sources) and up-weight for experimental (or high con\ufb01 dence) annotations. Then, by divid-ing by the number of proteins in the set, any annotation with a ratio greater than one can be considered \u201csigni\ufb01 cant\u201d.  A more rigorous treatment assumes that for a set of closely related proteins (i.e. belonging to a family) a speci\ufb01 c GO term is said to be over-represented when the number of proteins assigned to that term within the family of interest is enriched versus the background model as determined by a probability distribution. Thus, there are two decisions that need to be made, \ufb01 rstly, identi-fying the background model and then which probability function to use. The background model is dependent on the dataset and the question that is being asked. For example in the SFLD model, we might use the subgroup or superfamily and a random back-ground model that gives us an idea of what annotations could occur purely by chance. The lack of high (and sometimes also medium) con\ufb01 dence annotations is another complication in exam-ining enrichment of terms. If one is using IEA annotations to infer function, the assertions can quickly become circular (with inferred annotations being transferred to other proteins which in turn are used to annotate yet more proteins), leading to results which themselves are of low con\ufb01 dence. Similarly, if very few proteins are explicitly annotated with a high/medium con\ufb01 dence annotation, the measure of signi\ufb01 cance can be skewed due to low counts in the dataset. The choice of the probability function is also going to depend somewhat on what question is being asked, but the 2.2  Determining Over- and Under- represented GO Terms in a Set of Species- Diverse ProteinsGemma L. Holliday et al.\f123hypergeometric test (used for a \ufb01 nite universe) is common in GO analyses [ 39 ,  40 ]. For more detail on enrichment analysis,  see  Chap.   13     [ 41 ].     Instead of simply transferring annotations utilising sequence homology and BLAST scores, many tools are now available (e.g. Argot2 [ 42 ] and GraSM [ 43 ]) that utilise semantic similarity [ 42 \u2013 46 ]. Here, the idea is that in controlled vocabularies, the degree of relatedness between two entities can be assessed by comparing the semantic relationship (meanings) between their annotations. The semantic similarity measure is returned as a numerical value that quanti\ufb01 es the relationship between two GO terms, or two sets of terms annotating two proteins.  GO is well suited to such an approach, for example many chil-dren terms in the GO directed acyclic graph (DAG) have a similar vocabulary to their parents. The nature of the GO DAG means that a protein with a function A will also inherit the more generic func-tions that appear higher up in the DAG; this can be one or more functions, depending on the DAG. For example, an ion transmem-brane transporter activity (GO:0015075) is a term similar to volt-age-gated ion channel activity (GO:0005244), the latter of which is a descendent of the former, albeit separated by the ion channel activity (GO:0005216) term. Thus, the ancestry and semantic simi-larity lends greater weight to the con\ufb01 dence in the annotation.  Such similarity measures can be used instead of (or in conjunc-tion with) sequence similarity measures. Indeed, it has been shown [ 47 ] that there is good correlation between the protein sequence similarity and the GO annotation semantic similarity for proteins in Swiss-Prot, the reviewed section of UniProtKB [ 17 ]. Consistent results, however, are often a feature not only of the branch of GO to which the annotations belong, but also the number of high con-\ufb01 dence annotations that are being used. For a more detailed and comprehensive discussion of the various methods,  see  Pesquita et al. [ 44 ] and Chap.   12     [ 48 ].     In the example shown in Fig.  3 , it is clear that many more nodes in the subgroup are annotated as biotin synthase by GO than match the stringent criteria set within the SFLD, which not only require a signi\ufb01 cant  E -value (or Bit Score) to transfer annotation, but the presence of the conserved key residues. As mentioned earlier, one key advantage to using GO annotations over those of some other resources is the evidence code (and associated source of that evi-dence) as shown in Fig.  4 . As indicated by that network, when using GO annotations, it is important to also consider the associated con-\ufb01 dence level for the evidence used in assigning an annotation ( see  Table  1 ). In Fig.  4 , only a few annotations are supported by high-con\ufb01 dence evidence. Alternatively, if a protein has a high con\ufb01 dence experimental evidence code for membership in a family of interest 2.3  Using Semantic Signi\ufb01 cance with GO2.4  Use of Orthogonal Information to Evaluate GO AnnotationEvaluating Functional Annotations of Enzymes Using the Gene Ontology\f124yet is not included by annotators in that family, then the de\ufb01 nition of that family may be too strict, indicating that a more permissive gathering threshold for assignment to the family should be used.  Another way of assessing the veracity of the annotation trans-ferred to a query protein is to examine both the annotations of the proteins that are closest to it in similarity as well as other entirely different types of information.  One example of such orthogonal information is the genomic context of the protein. It can be hypothesised that if a protein occurs in a pathway, then the other proteins involved in that path-way may be co-located within the genome [ 49 ]. This association is frequently found in prokaryotes, and to a lesser extent in plants and fungi. Genomic proximity of pathway components is infre-quent in metazoans, thus genomic context as a means to function prediction is more useful for bacterial enzymes. Additionally, other genes in the same genomic neighbourhood may be relevant to understanding the function of both the protein of interest and of the associated pathway. A common genomic context for a query protein and a homologue provides further support for assignment of that function. (However, the genomic distance between path-way components in different organisms may vary for many reasons, thus the lack of similar genomic context does not suggest that the functions of a query and a similar homologue are different.)  Another type of orthogonal information that can be used can be deduced from protein domains present in a query protein and their associated annotations\u2014what are the predicted domains pres-ent in the protein, do they all match the assigned function or are there anomalies. A good service for identifying such domains is InterProScan [ 50 ]. Further, any protein in UniProtKB will have the predicted InterPro identi\ufb01 ers annotated in the record (along with other predicted annotations from resources such as Pfam and CATH), along with the evidence supporting those predictions. Such sequence context can also be obtained using hidden Markov models (HMMs) [ 51 ], which is the technique used by InterPro, Pfam, Gene3D, SUPERFAMILY and the SFLD to place new sequences into families, subgroups (SFLD-speci\ufb01 c term) and super-families ( see  Fig.  6 ).3        Challenges and Caveats    A signi\ufb01 cant challenge with using SSNs to help evaluate GO annotations is that SSNs are not always trivial to use without a detailed knowledge of the superfamilies that they describe. For example, choosing an appropriate threshold for drawing edges is critical to obtaining network clustering patterns useful for deeper evaluation. In Fig.  3 , HydE (the blue nodes) are not currently annotated as such in GO, but are annotated instead as BioB. Thus, 3.1  The Use of Sequence Similarity NetworkGemma L. Holliday et al.\f125the evaluation of the network becomes signi\ufb01 cantly more complex. It is also not always clear what signal is being picked up in the edge data for large networks. It is usually assumed that all the proteins in the set share a single domain, but this is often only clear when the network is examined in greater detail.     Even using the powerful tools and classi\ufb01 cations provided by GO, interpreting protein function in many cases requires more in-depth analysis. For several reasons, it is not always easy to con\ufb01 dently determine that a protein is not correctly annotated. Firstly, how closely related is the enzyme to the group of interest? Perhaps we can only be relatively certain of its superfamily membership, or maybe we can assign it to a more detailed level of the functional hierarchy. If it \ufb01 ts into a more detailed classi\ufb01 cation level, how well does it \ufb01 t? At what threshold do we begin to see false positives 3.2  Annotation Transfer Is Challenging Because Evolution Is ComplexbioD bioB bioY COG-ArcA COG-bioB MurD COG-GltD Family HMM E-Value Biotin SynthaseHmdB HydE Family HMM E-Value HydE 6.1 x 10\u22121508.6 x 10\u2212366.4 x 10\u221225 HmdB  InterPro Family: [FeFe]-hydrogenase maturation HydE,radical SAM (IPR024021) 2.8 x 10\u2212788.8 x 10\u2212311.1 x 10\u221223InterPro Family: Biotin synthase(IPR024177) Biotin Synthase  Fig. 6    Biotin synthase-like subgroup SSN showing where the biotin synthase GO annotations are shown as  large diamonds . Two proteins, one from the BioB set ( red nodes, top right ) and one from the HydE set ( blue nodes ),  bottom left , are shown with some associate orthogonal information: genomic context highlighted in  light cyan boxes , their HMM match results for the query protein against the three top scoring families in the subgroup are shown in the tables, and family membership (according to InterProScan) shown in coloured text ( blue  for HydE and  red  for BioB). Node and edge numbers, as well as  E -value threshold are as in Fig.  3 . All the proteins are connected via a homologous domain (the Radical SAM domain). Thus, the observed differences in the rest of the protein mean that the functions of the proteins may also be quite different        Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f126creeping into the results list? Using networks, we can also examine the closest neighbours that have differing function and ask whether there are similarities in the function (e.g. Broderick et al. [ 52 ] used sequence similarity networks to help determine the function of HydE). Another complicating issue is whether a protein performs one or more promiscuous functions, albeit with a lesser ef\ufb01 cacy.  Another important piece of evidence that can be used to sup-port an annotation is conservation of the key residues, so it is important to assess if the protein of interest has all the relevant functional residues. Although GO includes an evidence code to handle this concept (Inferred from Key Residues, IKR), it is often not included in the electronic inference of annotations. It is impor-tant to note, however, that there are evolutionary events that may \u201cscramble\u201d the sequence, leaving it unclear to an initial examina-tion whether the residues are conserved or not. A prime example is the case in which a circular permutation has occurred. Thus, it is important to look at whether there are other residues (or patterns of residues) that could perform the function of the \u201cmissing\u201d resi-dues. It is also possible that conservative mutations have occurred, and these may also have the ability to perform the function of the \u201cmissing\u201d residues [ 53 ].  Another consideration with function evaluation is the occurrence of moonlighting proteins. These are proteins that are identical in terms of sequence but perform different functions in different cellu-lar locations or species; for example argininosuccinate lyase (UniProtKB id P24058) is also a delta crystalline which serves as an eye lens protein when it is found in birds and reptiles [ 54 ]. A good source of information on moonlighting proteins is MoonProt (  http://www.moonlightingproteins.org/    ) [ 55 ]. Such cases may arise from physiological use in many different conditions such as dif-ferent subcellular localisations or regulatory pathways. The full extent of proteins that moonlight is currently not known, although to date, almost 300 cases have been reported in MoonProt. Another compli-cating factor for understanding the evolution of enzyme function is the apparent evolution of the same reaction speci\ufb01 city from different intermediate nodes in the phylogenetic tree for the superfamily, for example the N-succinyl amino acid racemase and the muconate lac-tonising enzyme families in the enolase superfamily [ 56 ,  57 ].  Finally, does the protein have a multi-domain architecture and/or is it part of a non-covalent protein-protein interaction in the cell? An example of a functional protein requiring multiple chains that are transiently coordinated in the cell is pyruvate dehydrogenase (acetyl-transferring) (EC 1.2.4.1). This protein has an active site at the interface between pyruvate dehydrogenase E1 component sub-unit alpha (UniProtKB identi\ufb01 er P21873) and beta (UniProtKB identi\ufb01 er P21874), both of which are required for activity. Thus, transfer of annotation relating to this function to an unknown (and hence evaluation of misannotation) needs to include both pro-teins. Similarly, a single chain with multiple domains, e.g. biotin Gemma L. Holliday et al.\f127biosynthesis bifunctional protein BioAB (UniProtKB identi\ufb01 er P53656), which contains a BioA and BioB domain, has two differ-ent functions associated with it. In this example, these two func-tions are distinct from one another so that annotation of this protein only with one function or the other could represent a type of misan-notation (especially as a GO term is assigned to a protein, not a speci\ufb01 c segment of its amino acid sequence).     In some cases, proteins are annotated by some type of \u201cplurality voting\u201d. Plurality voting is simply assuming that the more annota-tions that come from different predictors, the more likely these are to be correct. As we have shown in this chapter (and others before us [ 58 ]), this is not always the case. An especially good example of where plurality voting fails is in the case of the lysozyme  mechanism. For over 50 years, the mechanism was assumed to be dissociative, but a single experiment provided evidence of a covalent intermedi-ate being formed in the crystal structure, calling into question the dissociate mechanism. If plurality voting were applied in ongoing annotations, the old mechanism would still be considered correct. That being said, it is more dif\ufb01 cult to identify problems of this type if experimental evidence challenging an annotation is unavailable. In such cases, we must always look at all the available evidence to transfer function and where there are disagreements between pre-dicted functions, a more detailed examination is needed. Only when we have resolved such issues can we have any true con\ufb01 dence in the plurality vote. Work by Kristensen et al. [ 59 ] provides a good example of the value of this approach. By using three-dimen-sional templates generated using knowledge of the evolutionarily important residues, they showed that they could identify a single most likely function in 61 % of 3D structures from the Structural Genomics Initiative, and in those cases the correct function was identi\ufb01 ed with an 87 % accuracy.   4    Conclusions  Experimentalists simply can\u2019t keep up with the huge volume of data that is being produced in today\u2019s high-throughput labs, from whole genome and population sequencing efforts to large-scale assays and structure generation. Almost all proteins will have at least one asso-ciated GO annotation, and such coverage makes GO an incredibly powerful tool, especially as it has the ability to handle all the known function information at different levels of biological granularity, has explicit tools to capture high-throughput experimental data and utilises an ontology to store the annotation and associated relation-ships. Although over 98 % of all GO annotations are computation-ally inferred, with the ever-increasing state of knowledge, these annotation transfers are becoming more con\ufb01 dent [ 15 ] as rule-based annotations gain in speci\ufb01 city due to more data being 3.3  Plurality Vote May Not Be the Best RouteEvaluating Functional Annotations of Enzymes Using the Gene Ontology\f128available. However, there is still a long way to go before we can simply take an IEA annotation at face value. Con\ufb01 dence in annota-tions transferred electronically has to be taken into account: How many different sources have come to the same conclusion (using different methods)? How many different proteins\u2019 functions have been determined in a single experiment? Similarly, whilst burden of evidence is a useful gauge in determining the signi\ufb01 cance of an annotation, there is also the question of when substantially different annotations were captured in GO and other resources\u2014perhaps there has been a new experiment that calls into question the origi-nal annotation. It is also important to look at whether other, similar proteins were annotated long ago or are based on new experimental evidence. There is a wealth of data available that relates to enzymes and their functions. This ranges from the highest level of associating a protein with a superfamily (and thus giving some information as to the amino acid residues that are evolutionarily conserved), to the most detailed level of molecular function. We can use all of these data to aid us in evaluating the GO annotations for a given protein (or set of proteins), from the electronically inferred annotation for protein domain structure, to the genomic context and protein fea-tures (such as conserved residues). The more data that are available to back up (or refute) a given GO annotation, the more con\ufb01 dent one can be in it (or not, as the case may be).       Acknowledgements  GLH and PCB acknowledge funds from National Institutes of Health and National Science Foundation (grant NIH R01 GM60595 and grant NSF DBI1356193). Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not per-mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.  Gemma L. Holliday et al.\f129   References     1.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-Tarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M, Rubin GM, Sherlock G (2000) Gene ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Consortium. Nat Genet 25(1):25\u201329. doi:  10.1038/75556          2.   Nomenclature committee of the international union of biochemistry and molecular biology (NC-IUBMB), Enzyme Supplement 5 (1999). European J Biochem/FEBS 264(2):610\u2013650     3.    McDonald AG, Boyce S, Tipton KF (2009) ExplorEnz: the primary source of the IUBMB enzyme list. Nucleic Acids Res 37(Database issue):D593\u2013D597. doi:  10.1093/nar/gkn582          4.    Fleischmann A, Darsow M, Degtyarenko K, Fleischmann W, Boyce S, Axelsen KB, Bairoch A, Schomburg D, Tipton KF, Apweiler R (2004) IntEnz, the integrated relational enzyme database. Nucleic Acids Res 32(Database issue):D434\u2013D437. doi:  10.1093/nar/gkh119          5.   Furnham N (2016) Complementary sources of protein functional information: the far side of GO. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 19      6.    Babbitt PC (2003) De\ufb01 nitions of enzyme function for the structural genomics era. Curr Opin Chem Biol 7(2):230\u2013237      7.   Thomas PD (2016) The gene ontology and the meaning of biological function. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 2      8.    Bray T, Doig AJ, Warwicker J (2009) Sequence and structural features of enzymes and their active sites by EC class. J Mol Biol 386(5):1423\u20131436. doi:  10.1016/j.jmb.2008.11.057          9.    Dobson PD, Doig AJ (2005) Predicting enzyme class from protein structure without alignments. J Mol Biol 345(1):187\u2013199. doi:  10.1016/j.jmb.2004.10.024         10.   Cozzetto D, Jones DT (2016) Computational methods for annotation transfers from sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu-lar biology, vol 1446. Humana Press. Chapter 5      11.    Radivojac P, Clark WT, Oron TR, Schnoes AM, Wittkop T, Sokolov A, Graim K, Funk C, Verspoor K, Ben-Hur A, Pandey G, Yunes JM, Talwalkar AS, Repo S, Souza ML, Piovesan D, Casadio R, Wang Z, Cheng J, Fang H, Gough J, Koskinen P, Toronen P, Nokso-Koivisto J, Holm L, Cozzetto D, Buchan DW, Bryson K, Jones DT, Limaye B, Inamdar H, Datta A, Manjari SK, Joshi R, Chitale M, Kihara D, Lisewski AM, Erdin S, Venner E, Lichtarge O, Rentzsch R, Yang H, Romero AE, Bhat P, Paccanaro A, Hamp T, Kassner R, Seemayer S, Vicedo E, Schaefer C, Achten D, Auer F, Boehm A, Braun T, Hecht M, Heron M, Honigschmid P, Hopf TA, Kaufmann S, Kiening M, Krompass D, Landerer C, Mahlich Y, Roos M, Bjorne J, Salakoski T, Wong A, Shatkay H, Gatzmann F, Sommer I, Wass MN, Sternberg MJ, Skunca N, Supek F, Bosnjak M, Panov P, Dzeroski S, Smuc T, Kourmpetis YA, van Dijk AD, ter Braak CJ, Zhou Y, Gong Q, Dong X, Tian W, Falda M, Fontana P, Lavezzo E, Di Camillo B, Toppo S, Lan L, Djuric N, Guo Y, Vucetic S, Bairoch A, Linial M, Babbitt PC, Brenner SE, Orengo C, Rost B, Mooney SD, Friedberg I (2013) A large-scale evaluation of computational pro-tein function prediction. Nat Methods 10(3):221\u2013227. doi:  10.1038/nmeth.2340          12.   Friedberg I, Radivojac P (2016) Community-wide evaluation of computational function pre-diction. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu-lar biology, vol 1446. Humana Press. Chapter 10      13.   Akiva E, Brown S, Almonacid DE, Barber AE 2nd, Custer AF, Hicks MA, Huang CC, Lauck F, Mashiyama ST, Meng EC, Mischel D, Morris JH, Ojha S, Schnoes AM, Stryke D, Yunes JM, Ferrin TE, Holliday GL, Babbitt PC (2014) The Structure-Function Linkage Database. Nucleic Acids Res 42(Database issue):D521\u2013D530. doi:10.1093/nar/gkt1130      14.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3        15.    Skunca N, Altenhoff A, Dessimoz C (2012) Quality of computationally inferred gene ontology annotations. PLoS Comput Biol 8(5):e1002533. doi:  10.1371/journal.pcbi.1002533           16.   Bastian FB, Chibucos MC, Gaudet P, Giglio M, Holliday GL, Huang H, Lewis SE, Niknejad A, Orchard S, Poux S, Skunca N, Robinson- Rechavi M (2015) The Con\ufb01 dence Information Ontology: a step towards a standard for assert-ing con\ufb01 dence in annotations. Database:bav043. doi:  10.1093/database/bav043      Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f130     17.    UniProt C (2015) UniProt: a hub for protein information. Nucleic Acids Res 43(Database issue):D204\u2013D212. doi:  10.1093/nar/gku989          18.    Hill DP, Davis AP, Richardson JE, Corradi JP, Ringwald M, Eppig JT, Blake JA (2001) Program description: strategies for biological annotation of mammalian systems: implement-ing gene ontologies in mouse genome infor-matics. Genomics 74(1):121\u2013128. doi:  10.1006/geno.2001.6513          19.    Sillitoe I, Lewis TE, Cuff A, Das S, Ashford P, Dawson NL, Furnham N, Laskowski RA, Lee D, Lees JG, Lehtinen S, Studer RA, Thornton J, Orengo CA (2015) CATH: comprehensive structural and functional annotations for genome sequences. Nucleic Acids Res 43(Database issue):D376\u2013D381. doi:  10.1093/nar/gku947          20.    Lees J, Yeats C, Perkins J, Sillitoe I, Rentzsch R, Dessailly BH, Orengo C (2012) Gene3D: a domain-based resource for comparative genom-ics, functional annotation and protein network analysis. Nucleic Acids Res 40(Database issue):D465\u2013D471. doi:  10.1093/nar/gkr1181          21.    Fox NK, Brenner SE, Chandonia JM (2014) SCOPe: structural classi\ufb01 cation of proteins--extended, integrating SCOP and ASTRAL data and classi\ufb01 cation of new structures. Nucleic Acids Res 42(Database issue):D304\u2013D309. doi:  10.1093/nar/gkt1240          22.    Finn RD, Bateman A, Clements J, Coggill P, Eberhardt RY, Eddy SR, Heger A, Hetherington K, Holm L, Mistry J, Sonnhammer EL, Tate J, Punta M (2014) Pfam: the protein families database. Nucleic Acids Res 42(Database issue):D222\u2013D230. doi:  10.1093/nar/gkt1223          23.    Mi H, Muruganujan A, Thomas PD (2013) PANTHER in 2013: modeling the evolution of gene function, and other gene attributes, in the context of phylogenetic trees. Nucleic Acids Res 41(Database issue):D377\u2013D386. doi:  10.1093/nar/gks1118          24.    Haft DH, Selengut JD, Richter RA, Harkins D, Basu MK, Beck E (2013) TIGRFAMs and genome properties in 2013. Nucleic Acids Res 41(Database issue):D387\u2013D395. doi:  10.1093/nar/gks1234          25.    Gerlt JA, Babbitt PC (2001) Divergent evolu-tion of enzymatic function: mechanistically diverse superfamilies and functionally distinct suprafamilies. Annu Rev Biochem 70:209\u2013246. doi:  10.1146/annurev.biochem.70.1.209          26.    Camacho C, Coulouris G, Avagyan V, Ma N, Papadopoulos J, Bealer K, Madden TL (2009) BLAST+: architecture and applications. BMC Bioinformatics 10:421. doi:  10.1186/1471-2105-10-421          27.    Finn RD, Clements J, Eddy SR (2011) HMMER web server: interactive sequence similarity searching. Nucleic Acids Res 39(Web Server issue):W29\u2013W37. doi:  10.1093/nar/gkr367          28.    Brown SD, Babbitt PC (2014) New insights about enzyme evolution from large scale studies of sequence and structure relationships. J Biol Chem 289(44):30221\u201330228. doi:  10.1074/jbc.R114.569350          29.    Schnoes AM, Brown SD, Dodevski I, Babbitt PC (2009) Annotation error in public data-bases: misannotation of molecular function in enzyme superfamilies. PLoS Comput Biol 5(12):e1000605. doi:  10.1371/journal.pcbi.1000605          30.    Pieper U, Chiang R, Seffernick JJ, Brown SD, Glasner ME, Kelly L, Eswar N, Sauder JM, Bonanno JB, Swaminathan S, Burley SK, Zheng X, Chance MR, Almo SC, Gerlt JA, Raushel FM, Jacobson MP, Babbitt PC, Sali A (2009) Target selection and annotation for the structural genomics of the amidohydrolase and enolase superfamilies. J Struct Funct Genom 10(2):107\u2013125. doi:  10.1007/s10969-008-9056-5         31.    Gerlt JA, Babbitt PC, Jacobson MP, Almo SC (2012) Divergent evolution in enolase super-family: strategies for assigning functions. J Biol Chem 287(1):29\u201334. doi:  10.1074/jbc.R111.240945           32.    Mashiyama ST, Malabanan MM, Akiva E, Bhosle R, Branch MC, Hillerich B, Jagessar K, Kim J, Patskovsky Y, Seidel RD, Stead M, Toro R, Vetting MW, Almo SC, Armstrong RN, Babbitt PC (2014) Large-scale determination of sequence, structure, and function relation-ships in cytosolic glutathione transferases across the biosphere. PLoS Biol 12(4):e1001843. doi:  10.1371/journal.pbio.1001843          33.    Rentzsch R, Orengo CA (2013) Protein func-tion prediction using domain families. BMC Bioinformatics 14(Suppl 3):S5. doi:  10.1186/1471-2105-14-S3-S5           34.    Atkinson HJ, Morris JH, Ferrin TE, Babbitt PC (2009) Using sequence similarity networks for visualization of relationships across diverse protein superfamilies. PLoS One 4(2):e4345. doi:  10.1371/journal.pone.0004345          35.    Barber AE II, Babbitt PC (2012) Pythoscape: a framework for generation of large protein simi-larity networks. Bioinformatics. doi:  10.1093/bioinformatics/bts532          36.    Gerlt JA, Bouvier JT, Davidson DB, Imker HJ, Sadkhin B, Slater DR, Whalen KL (2015) Enzyme Function Initiative-Enzyme Similarity Tool (EFI-EST): a web tool for generating protein sequence similarity networks. Biochim Gemma L. Holliday et al.\f131Biophys Acta 1854(8):1019\u20131037. doi:  10.1016/j.bbapap.2015.04.015          37.    Mitchell A, Chang HY, Daugherty L, Fraser M, Hunter S, Lopez R, McAnulla C, McMenamin C, Nuka G, Pesseat S, Sangrador- Vegas A, Scheremetjew M, Rato C, Yong SY, Bateman A, Punta M, Attwood TK, Sigrist CJ, Redaschi N, Rivoire C, Xenarios I, Kahn D, Guyot D, Bork P, Letunic I, Gough J, Oates M, Haft D, Huang H, Natale DA, Wu CH, Orengo C, Sillitoe I, Mi H, Thomas PD, Finn RD (2014) The InterPro protein families data-base: the classi\ufb01 cation resource after 15 years. Nucleic Acids Res. doi:  10.1093/nar/gku1243          38.    Webber C (2011) Functional enrichment analy-sis with structural variants: pitfalls and strategies. Cytogenet Genome Res 135(3-4):277\u2013285. doi:  10.1159/000331670          39.    Thomas PD, Wood V, Mungall CJ, Lewis SE, Blake JA, Gene Ontology C (2012) On the use of gene ontology annotations to assess functional similarity among orthologs and par-alogs: a short report. PLoS Comput Biol 8(2):e1002386. doi:  10.1371/journal.pcbi.1002386          40.    Cao J, Zhang S (2014) A Bayesian extension of the hypergeometric test for functional enrich-ment analysis. Biometrics 70(1):84\u201394. doi:  10.1111/biom.12122          41.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13       42.    Falda M, Toppo S, Pescarolo A, Lavezzo E, Di Camillo B, Facchinetti A, Cilia E, Velasco R, Fontana P (2012) Argot2: a large scale func-tion prediction tool relying on semantic simi-larity of weighted Gene Ontology terms. BMC Bioinformatics 13(Suppl 4):S14. doi:  10.1186/1471-2105-13-S4-S14          43.    Couto FM, Silva MJ, Coutinho PM (2007) Measuring semantic similarity between Gene Ontology terms. Data Knowl Eng 61(1):137\u2013152. doi:  10.1016/j.datak.2006.05.003          44.    Pesquita C, Faria D, Falcao AO, Lord P, Couto FM (2009) Semantic similarity in biomedical ontologies. PLoS Comput Biol 5(7):e1000443. doi:  10.1371/journal.pcbi.1000443         45.    Benabderrahmane S, Smail-Tabbone M, Poch O, Napoli A, Devignes MD (2010) IntelliGO: a new vector-based semantic similarity measure including annotation origin. BMC Bioinformatics 11:588. doi:  10.1186/1471-2105-11-588          46.    Wu X, Pang E, Lin K, Pei ZM (2013) Improving the measurement of semantic simi-larity between gene ontology terms and gene products: insights from an edge- and IC-based hybrid method. PLoS One 8(5):e66745. doi:  10.1371/journal.pone.0066745          47.    Apweiler R, Bairoch A, Wu CH, Barker WC, Boeckmann B, Ferro S, Gasteiger E, Huang H, Lopez R, Magrane M, Martin MJ, Natale DA, O'Donovan C, Redaschi N, Yeh LS (2004) UniProt: the Universal Protein knowledge-base. Nucleic Acids Res 32(Database issue):D115\u2013D119. doi:  10.1093/nar/gkh131          48.   Pesquita C (2016) Semantic similarity in the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12      49.    Huynen M, Snel B, Lathe W, Bork P (2000) Exploitation of gene context. Curr Opin Struct Biol 10(3):366\u2013370      50.    Li W, Cowley A, Uludag M, Gur T, McWilliam H, Squizzato S, Park YM, Buso N, Lopez R (2015) The EMBL-EBI bioinformatics web and programmatic tools framework. Nucleic Acids Res. doi:  10.1093/nar/gkv279          51.    Meng X, Ji Y (2013) Modern computational techniques for the HMMER sequence analysis. ISRN Bioinformatics 2013:252183. doi:  10.1155/2013/252183          52.    Betz JN, Boswell NW, Fugate CJ, Holliday GL, Akiva E, Scott AG, Babbitt PC, Peters JW, Shepard EM, Broderick JB (2015) [FeFe]-hydrogenase maturation: insights into the role HydE plays in dithiomethylamine biosynthesis. Biochemistry 54(9):1807\u20131818. doi:  10.1021/bi501205e          53.    Wellner A, Raitses Gurevich M, Taw\ufb01 k DS (2013) Mechanisms of protein sequence diver-gence and incompatibility. PLoS Genet 9(7):e1003665. doi:  10.1371/journal.pgen.1003665          54.    Sampaleanu LM, Yu B, Howell PL (2002) Mutational analysis of duck delta 2 crystallin and the structure of an inactive mutant with bound substrate provide insight into the enzy-matic mechanism of argininosuccinate lyase. J Biol Chem 277(6):4166\u20134175. doi:  10.1074/jbc.M107465200          55.    Mani M, Chen C, Amblee V, Liu H, Mathur T, Zwicke G, Zabad S, Patel B, Thakkar J, Jeffery CJ (2015) MoonProt: a database for proteins that are known to moonlight. Nucleic Acids Res 43(Database issue):D277\u2013D282. doi:  10.1093/nar/gku954          56.    Song L, Kalyanaraman C, Fedorov AA, Fedorov EV, Glasner ME, Brown S, Imker HJ, Babbitt PC, Almo SC, Jacobson MP, Gerlt JA (2007) Prediction and assignment of function Evaluating Functional Annotations of Enzymes Using the Gene Ontology\f132for a divergent N-succinyl amino acid race-mase. Nat Chem Biol 3(8):486\u2013491. doi:  10.1038/nchembio.2007.11          57.    Sakai A, Fedorov AA, Fedorov EV, Schnoes AM, Glasner ME, Brown S, Rutter ME, Bain K, Chang S, Gheyi T, Sauder JM, Burley SK, Babbitt PC, Almo SC, Gerlt JA (2009) Evolution of enzymatic activities in the enolase superfamily: stereochemically distinct mecha-nisms in two families of cis, cis-muconate lac-tonizing enzymes. Biochemistry 48(7):1445\u20131453. doi:  10.1021/bi802277h          58.    Brenner SE (1999) Errors in genome annota-tion. Trends Genet 15(4):132\u2013133      59.    Kristensen DM, Ward RM, Lisewski AM, Erdin S, Chen BY, Fofanov VY, Kimmel M, Kavraki LE, Lichtarge O (2008) Prediction of enzyme function based on 3D templates of evolutionarily important amino acids. BMC Bioinformatics 9:17. doi:  10.1186/1471-2105-9-17        Gemma L. Holliday et al.\fChapter 10</p> <p>Community-Wide Evaluation of Computational Function Prediction</p> <p>Iddo Friedberg and Predrag Radivojac</p> <p>Abstract</p> <p>A biological experiment is the most reliable way of assigning function to a protein. However, in the era of high-throughput sequencing, scientists are unable to carry out experiments to determine the function of every single gene product. Therefore, to gain insights into the activity of these molecules and guide experi- ments, we must rely on computational means to functionally annotate the majority of sequence data. To understand how well these algorithms perform, we have established a challenge involving a broad scientific community in which we evaluate different annotation methods according to their ability to predict the associations between previously unannotated protein sequences and Gene Ontology terms. Here we dis- cuss the rationale, benefits, and issues associated with evaluating computational methods in an ongoing community-wide challenge.</p> <p>Key words Function prediction, Algorithms, Evaluation, Machine learning</p> <p>1</p> <p>Introduction</p> <p>Molecular biology has become a high volume information science. This rapid transformation has taken place over the past two decades and  has  been  chiefly  enabled  by  two  technological  advances:  (1) affordable  and  accessible  high-throughput  sequencing  platforms, sequence  diagnostic  platforms,  and  proteomic  platforms  and  (2) affordable  and  accessible  computing  platforms  for  managing  and analyzing these data. It is estimated that sequence data accumulates at the rate of 100 exabases per day (1 exabase  = 1018 bases) [35]. However,  the  available  sequence  data  are  of  limited  use  without understanding their biological implications. Therefore, the develop- ment of computational methods that provide clues about functional roles of biological macromolecules is of primary importance.</p> <p>Many  function  prediction  methods  have  been  developed  over the past two decades [12, 31]. Some are based on sequence align- ments  to  proteins  for  which  the  function  has  been  experimentally established [4, 11, 24], yet others exploit other types of data such as</p> <p>Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446, DOI 10.1007/978-1-4939-3743-1_10, \u00a9 The Author(s) 2017</p> <p>133</p> <p>134</p> <p>protein structure [26, 27], protein and gene expression data [17], macromolecular interactions [21, 25], scientific literature [3], or a combination of several data types [9, 34, 36]. Typically, each new method is trained and evaluated on different data. Therefore, estab- lishing  best  practices  in  method  development  and  evaluating  the accuracy of these methods in a standardized and unbiased setting is important. To help choose an appropriate method for a particular task,  scientists  often  form  community  challenges  for  evaluating methods [7]. The scope of these challenges extends beyond testing methods: they have been successful in invigorating their respective fields of research by building communities and producing new ideas and collaborations (e.g., [20]).</p> <p>In this chapter we discuss a community-wide effort whose goal is to help understand the state of affairs in computational protein function prediction and drive the field forward. We are holding a series  of  challenges  which  we  named  the  Critical  Assessment  of Functional Annotation, or CAFA. CAFA was first held in 2010\u2013 2011  (CAFA1)  and  included  23  groups  from  14  countries  who entered 54 computational function prediction methods that were assessed for their accuracy. To the best of our knowledge, this was the first large-scale effort to provide insights into the strengths and weaknesses of protein function prediction software in the bioinfor- matics  community.  CAFA2  was  held  in  2013\u20132014,  and  more than doubled the number of groups (56) and participating meth- ods  (126).  Although  several  repetitions  of  the  CAFA  challenge would likely give accurate trajectory of the field, there are valuable lessons already learned from the two CAFA efforts.</p> <p>For  further  reading  on  CAFA1,  the  results  were  reported  in full in [30]. As of this time, the results of CAFA2 are still unpub- lished and will be reported in the near future. The preprint of the paper is available on arXiv [19].</p> <p>2  Organization of the CAFA Challenge</p> <p>We begin our explanation of CAFA by describing the participants. The CAFA challenge generally involves the following groups: the organizers, the assessors, the biocurators, the steering committee, and the predictors (Fig. 1a).</p> <p>The main role of the organizers is to run CAFA smoothly and efficiently. They advertise the challenge to recruit predictors, coordi- nate activities with the assessors, report to the steering committee, establish the set of challenges and types of evaluation, and run the CAFA  web  site  and  social  networks.  The  organizers  also  compile CAFA  data  and  coordinate  the  publication  process.  The   assessors develop  assessment  rules,  write  and  maintain  assessment  software, collect  the  submitted  prediction  data,  assess  the  data,  and  present the evaluations to the community. The assessors work together with the  organizers  and  the  steering  committee  on  standardizing</p> <p>Iddo Friedberg and Predrag Radivojac\fCommunity-Wide Evaluation of Computational Function Prediction</p> <p>135</p> <p>a CAFA organization</p> <p>Biocurators</p> <p>Organizers</p> <p>(cid:127) Provide functional</p> <p>annotations (CAFA2)</p> <p>(cid:127) Direct the experiment</p> <p>(cid:127) Connect all parties</p> <p>Steering Committee</p> <p>Assessors</p> <p>Predictors</p> <p>(cid:127) Oversee the experiment</p> <p>(cid:127) Ensure integrity</p> <p>(cid:127) Collect predictions</p> <p>(cid:127) Evaluate methods</p> <p>(cid:127) Develop methodology</p> <p>(cid:127) Submit predictions</p> <p>b Experiment timeline</p> <p>t0</p> <p>t1</p> <p>t2</p> <p>t3</p> <p>Prediction</p> <p>Annotation growth</p> <p>Assessment</p> <p>Fig. 1 The organizational structure of the CAFA experiment. (a) Five groups of participants in the experiment together  with  their  main  roles.  Organizers,  assessors,  and  biocurators  cannot  participate  as  predictors. (b) Timeline of the experiment</p> <p>submission formats and developing assessment rules. The biocura- tors joined the experiment during CAFA2: they provide additional functional  annotations  that  may  be  particularly  interesting  for  the challenge. The steering committee members are in regular contact with the organizers and assessors. They provide advice and guidance that ensures the quality and integrity of the experiment. Finally, the largest  group,  the  predictors,  consists  of  research  groups  who develop methods for protein function prediction and submit their predictions for evaluation. The organizers, assessors, and biocurators are not allowed to officially evaluate their own methods in CAFA.</p> <p>CAFA is run as a timed challenge (Fig. 1b). At time t0, a large number of experimentally unannotated proteins are made public by the organizers and the predictors are given several months, until time t1,  to  upload  their  predictions  to  the  CAFA  server.  At  time  t1  the experiment enters a waiting period of at least several months, during which  the  experimental  annotations  are  allowed  to  accumulate  in databases  such  as  Swiss-Prot  [2]  and  UniProt-GOA  [16].  These newly  accumulated  annotations  are  collected  at  time  t2  and  are expected to provide experimental annotations for a subset of original proteins. The performance of participating methods is then analyzed between  time  points  t2  and  t3  and  presented  to  the  community  at time t3. It is important to mention that unlike some machine learning challenges,  CAFA  organizers  do  not  provide  training  data  that  is required  to  be  used.  CAFA,  thus,  evaluates  a  combination  of biological knowledge, the ability to collect and curate training data, and the ability to develop advanced computational methodology.</p> <p>136</p> <p>We have previously described some of the principles that guide us in organizing CAFA [13]. It is important to mention that CAFA is  associated  with  the  Automated  Function  Prediction  Special Interest  Group  (Function-SIG)  that  is  regularly  held  at  the Intelligent  Systems  for  Molecular  Biology  (ISMB)  conference [37].  These  meetings  provide  a  forum  for  exchanging  ideas  and communicating  research  among  the  participants.  Function-SIG also  serves  as  the  venue  at  which  CAFA  results  are  initially  pre- sented and where the feedback from the community is sought.</p> <p>3  The Gene Ontology Provides the Functional Repertoire for CAFA</p> <p>Computational  function  prediction  methods  have  been  reviewed extensively [12, 31] and are also discussed in Chapter 5 [8]. Briefly, a function prediction method can be described as a classifier: an algo- rithm that is tasked with correctly assigning biological function to a given  protein.  This  task,  however,  is  arbitrarily  difficult  unless  the function comes from a finite, preferably small, set of functional terms. Thus, given an unannotated protein sequence and a set of available functional  terms,  a  predictor  is  tasked  with  associating  terms  to  a protein, giving a score (ideally, a probability) to each association.</p> <p>The Gene Ontology (GO) [1] is a natural choice when looking for  a  standardized,  controlled  vocabulary  for  functional  annota- tion. GO\u2019s high adoption rate in the protein annotation commu- nity  helped  ensure  CAFA\u2019s  attractiveness,  as  many  groups  were already developing function prediction methods based on GO, or could migrate their methods to GO as the ontology of choice. A second  consideration  is  GO\u2019s  ongoing  maintenance:  GO  is  con- tinuously maintained by the Gene Ontology Consortium, edited and expanded based on ongoing discoveries related to the function of biological macromolecules.</p> <p>One useful characteristic of the basic GO is that its directed acy- clic graph structure can be used to quantify the information provided by the annotation; for details on the GO structure see Chaps. 1 and 3 [14, 15]. Intuitively, this can be explained as follows: the annota- tion term \u201cNucleic acid binding\u201d is less specific than \u201cDNA binding\u201d and, therefore, is less informative (or has a lower  information con- tent). (A more precise definition of information content and its use in GO can be found in [23, 32].) The following question arises: if we know that the protein is annotated with the term \u201cNucleic acid bind- ing,\u201d how can we quantify the additional   information provided by the term \u201cDNA binding\u201d or incorrect information provided by the term  \u201cRNA  binding\u201d?  The  hierarchical  nature  of  GO  is  therefore important  in  determining  proper  metrics  for  annotation  accuracy. The way this is done will be discussed in Sect. 4.2.</p> <p>When  annotating  a  protein  with  one  or  more  GO  terms,  the association of each GO term with the protein should be described using  an  Evidence  Code  (EC),  indicating  how  the  annotation  is</p> <p>Iddo Friedberg and Predrag Radivojac\fCommunity-Wide Evaluation of Computational Function Prediction</p> <p>137</p> <p>supported. For example, the Experimental Evidence code (EXP) is used in an annotation to indicate that an experimental assay has been located in the literature, whose results indicate a gene product\u2019s func- tion.  Other  experimental  evidence  codes  include  Inferred  by Expression Pattern (IEP), Inferred from Genetic Interaction (IGI), and Inferred from Direct Assay (IDA), among others. Computational evidence codes include lines of evidence that were generated by com- putational analysis, such as orthology (ISO), genomic context (IGC), or  identification  of  key  residues  (IKR).  Evidence  codes  are  not intended  to  be  a  measure  of  trust  in  the  annotation,  but  rather  a measure of provenance for the annotation itself. However, annota- tions with experimental evidence are regarded as more reliable than computational  ones,  having  a  provenance  stemming  from  experi- mental  verification.  In  CAFA,  we  treat  proteins  annotated  with experimental evidence codes as a \u201cgold standard\u201d for the purpose of assessing predictions, as explained in the next section. The computa- tional evidence codes are treated as predictions.</p> <p>From the point of view of a computational challenge, it is impor- tant to emphasize that the hierarchical nature of the GO graph leads to the property of consistency or True Path Rule in functional annota- tion. Consistency means that when annotating a protein with a given GO term, it is automatically annotated with all the ancestors of that term. For example, a valid prediction cannot include \u201cDNA binding\u201d but exclude \u201cNucleic acid binding\u201d from the ontology because DNA binding implies nucleic acid binding. We say that a prediction is not consistent if it includes a child term, but excludes its parent. In fact, the UniProt resource and other databases do not even list these parent terms from a protein\u2019s experimental annotation. If a protein is anno- tated with several terms, a valid complete annotation will automati- cally include all parent terms of the given terms, propagated to the root(s) of the ontology. The result is that a protein\u2019s annotation can be  seen  as  a  consistent  sub-graph  of  GO.  Since  any  computational method effectively chooses one of a vast number of possible consistent sub-graphs as its prediction, the sheer size of the functional repertoire suggests that function prediction is non-trivial.</p> <p>4  Comparing the Performance of Prediction Methods</p> <p>In the CAFA challenge, we ask the participants to associate a large number of proteins with GO terms and provide a probability score for each such association. Having associated a set of GO sub-graphs with  a  given  confidence,  the  next  step  is  to  assess  how  accurate these predictions are. This involves: (1) establishing standards of truth and (2) establishing a set of assessment metrics.</p> <p>4.1  Establishing Standards of Truth</p> <p>The main challenge to establishing a standard-of-truth set for test- ing function prediction methods is to find a large set of correctly annotated proteins whose functions were, until recently, unknown.</p> <p>138</p> <p>An obvious choice would be to ask experimental scientists to pro- vide these data from their labs. However, scientists prefer to keep the  time  between  discovery  and  publication  as  brief  as  possible, which means that there is only a small window in which new exper- imental  annotations  are  not  widely  known  and  can  be  used  for assessment.  Furthermore,  each  experimental  group  has  its  own \u201cdata  sequestration  window\u201d  making  it  hard  to  establish  a  com- mon time for all data providers to sequester their data. Finally, to establish a good statistical baseline for assessing prediction method performance,  a  large  number  of  prediction  targets  are  needed, which is problematic since most laboratories research one or only a few  proteins  each.  High-throughput  experiments,  on  the  other hand,  provide  a  large  number  of  annotations,  but  those  tend  to concentrate only on few functions, and generally provide annota- tions that have a lower information content [32].</p> <p>Given these constraints, we decided that CAFA would not ini- tially rely on direct communication between the CAFA organizers and experimental scientists to provide new functional data. Instead, CAFA relies primarily on established biocuration activities around the  world:  we  use  annotation  databases  to  conduct  CAFA  as  a time-based challenge. To do so, we exploit the following dynamics that occurs in annotation databases: protein annotation databases grow over time. Many proteins that at a given time t1 do not have experimentally verified annotation, but later, some of proteins may gain experimental annotations, as biocurators add these data into the databases. This subset of proteins that were not experimentally annotated at t1, but gained experimental annotations at t2, are the ones that we use as a test set during assessment (Fig. 1b). In CAFA1 we reviewed the growth of Swiss-Prot over time and chose 50,000 target  proteins  that  had  no  experimental  annotation  in  the Molecular Function or Biological Process ontologies of GO. At t2, out of those 50,000 targets we identified 866 benchmark proteins; i.e., targets that gained experimental annotation in the Molecular Function  and/or  Biological  Process  ontologies.  While  a  bench- mark set of 866 proteins constitutes only 1.7 % of the number of original targets, it is a large enough set for assessing performance of prediction methods. To conclude, exploiting the history of the Swiss-Prot database enabled its use as the source for standard-of- truth data for CAFA. In CAFA2, we have also considered experi- mental annotations from UniProt-GOA [16] and established 3681 benchmark proteins out of 100,000 targets (3.7 %).</p> <p>One criticism of a time-based challenge is that when assessing predictions,  we  still  may  not  have  a  full  knowledge  of  a  protein\u2019s function.  A  protein  may  have  gained  experimental  validation  for function f1, but it may also have another function, say f2, associated with it, which has not been experimentally validated by the time t2. A method predicting f2 may be judged to have made a false- positive prediction, even though it is correct (only we do not know it yet). This problem, known as the \u201cincomplete knowledge problem\u201d or</p> <p>Iddo Friedberg and Predrag Radivojac\f4.2  Assessment Metrics</p> <p>Community-Wide Evaluation of Computational Function Prediction</p> <p>139</p> <p>the \u201copen world problem\u201d [10] is discussed in detail in Chapter 8 [33]. Although the incomplete knowledge problem may impact the accuracy of time-based evaluations, its actual impact in CAFA has not been substantial. There are several reasons for this and are also discussed in, including the robustness of the evaluation metrics used in CAFA, and that the newly added terms may be unexpected and more difficult to predict. The influence of incomplete data and con- ditions under which it can affect a time-based challenge were inves- tigated and discussed in [18]. Another criticism of CAFA is that the experimental functional annotations are not unbiased because some terms  have  a  much  higher  frequency  than  others  due  to  artificial considerations. There are two chief reasons for this bias: first, high- throughput  assays  typically  assign  shallow  terms  to  proteins,  but being high throughput means they can dominate the experimentally verified annotations in the databases. Second, biomedical research is driven by interest in specific areas of human health, resulting in over- representation  of  health-related  functions  [32].  Unfortunately, CAFA1  and  CAFA2  could  not  guarantee  unbiased  evaluation. However, we will expand the challenge in CAFA3 to collect genome- wide  experimental  evidence  for  several  biological  terms.  Such  an assessment will result in unbiased evaluation on those specific terms.</p> <p>When  assessing  the  prediction  quality  of  different  methods,  two questions  come  to  mind.  First,  what  makes  a  good  prediction? Second, how can one score and rank prediction methods? There is no  simple  answer  to  either  of  these  questions.  As  GO  comprises three ontologies that deal with different aspects of biological func- tion, different methods should be ranked separately with respect to how well they perform in Molecular Function, Biological Process, or the Cellular Component ontologies. Some methods are trained to predict only for a subset of any given GO graph. For example, they may only provide predictions of DNA-binding proteins or of mitochondrial-targeted proteins. Furthermore, some methods are trained only on a single species or a subset of species (say, eukary- otes), or using specific types of data such as protein structure, and it does not make sense to test them on benchmark sets for which they were not trained. To address this issue, CAFA scored methods not  only  in  general  performance,  but  also  on  specific  subsets  of proteins taken from humans and model organisms, including Mus musculus,  Rattus  norvegicus,  Arabidopsis  thaliana,  Drosophila melanogaster,  Caenorhabditis  elegans,  Saccharomyces  cerevisiae, Dictyostelium  discoideum,  and  Escherichia  coli.  In  CAFA2,  we extended this evaluation to also assess the methods only on bench- mark proteins on which they made predictions; i.e., the methods were not penalized for omitting any benchmark protein.</p> <p>One  way  to  view  function  prediction  is  as  an  information retrieval problem, where the most relevant functional terms should be correctly retrieved from GO and properly assigned to the amino acid  sequence  at  hand.  Since  each  term  in  the  ontology  implies</p> <p>140</p> <p>some or all of its ancestors,1 a function prediction program\u2019s task is to  assign  the  best  consistent  sub-graph  of  the  ontology  to  each new protein and output a prediction score for this sub-graph and/ or  each  predicted  term.  An  intuitive  scoring  mechanism  for  this type of problem is to treat each term independently and provide the  precision\u2013recall  curve.  We  chose  this  evaluation  as  our  main evaluation in CAFA1 and CAFA2.</p> <p>Let us provide more detail. Consider a single protein on which evaluation is carried out, but keep in mind that CAFA eventually averages all metrics over the set of benchmark proteins. Let now T be a set of experimentally determined nodes and P a non-empty set of predicted nodes in the ontology for the given protein. Precision (pr) and recall (rc) are defined as</p> <p>pr</p> <p>P T ( ,</p> <p>)</p> <p>=</p> <p>|</p> <p>\u00c7 P T P |</p> <p>|</p> <p>|</p> <p>;</p> <p>rc</p> <p>P T ( ,</p> <p>)</p> <p>=</p> <p>|</p> <p>\u00c7 P T T | |</p> <p>|</p> <p>,</p> <p>where | P | is  the  number  of  predicted  terms, | T | is  the  number  of experimentally determined terms, and | P \u2229 T | is the number of terms appearing in both P and T; see Fig. 2 for an illustrative  example of this measure.  Usually,  however,  methods  will  associate  scores  with  each predicted term and then a set of terms P will be established by defin- ing  a  score  threshold  t;  i.e.,  all  predicted  terms  with  scores  greater than  t  will  constitute  the  set  P.  By  varying  the  decision  threshold t \u2208 [0, 1], the precision and recall of each method can be plotted as a curve (pr(t), rc(t))t, where one axis is the precision and the other the recall; see Fig. 3 for an illustration of pr\u2013rc curves and [30] for pr\u2013rc curves in CAFA1. To compile the precision\u2013recall information into a single number that would allow easy comparison between methods, we used the maximum harmonic mean of precision and recall any- where on the curve, or the maximum F1-measure which we call Fmax</p> <p>= max max F</p> <p>t</p> <p>2</p> <p>\u00b4</p> <p>\u00ec \u00ed \u00ee</p> <p>pr pr</p> <p>( ) t t ( )</p> <p>\u00b4 +</p> <p>( ) rc t rc t ( )</p> <p>,</p> <p>\u00fc \u00fd \u00fe</p> <p>where we modified pr(t) and rc(t) to reflect the dependency on t. It is worth pointing out that the F-measure used in CAFA places equal emphasis on precision and recall as it is unclear which of the two should be weighted more. One alternative to F1 would be the use of a combined measure that weighs precision over recall, which reflects  the  preference  of  many  biologists  for  few  answers  with  a high  fraction  of  correctly  predicted  terms  (high  precision)  over many  answers  with  a  lower  fraction  of  correct  predictions  (high recall);  the  rationale  for  this  tradeoff  is  illustrated  in  Fig. 3.</p> <p>1  Some types of edges in Gene Ontology violate the transitivity property (con- sistency assumption), but they are not frequent.</p> <p>Iddo Friedberg and Predrag Radivojac</p> <p>Community-Wide Evaluation of Computational Function Prediction</p> <p>141</p> <p>a Predicted function</p> <p>b True function</p> <p>Cellular process</p> <p>Biological process</p> <p>Cellular process</p> <p>Apoptosis</p> <p>Biological process</p> <p>Cell differentiation</p> <p>Fig. 2 CAFA assessment metrics. (a) Red nodes are the predicted terms P for a particular decision threshold in a hypothetical ontology and (b) blue nodes are the true, experimentally determined terms T. The circled terms represent the overlap between the predicted sub-graph and the true sub-graph. There are two nodes (circled) in the intersection of P and T, where | P |  = 5 and | T |  = 3. This sets the prediction\u2019s precision at 2/5=0.4 and recall at 2/3 = 0.667, with F1 = 2 x 0.4 x 0.667 / (0.4 + 0.667) = 0.5. The remaining uncertainty (ru) is the information content of the uncircled blue node in panel (b), while the misinformation (mi) is the total informa- tion content of the uncircled red nodes in panel (a). An information content of any node v is calculated from a representative database as \u2212 logPr(v | Pa(v)); i.e., the probability that the node is present in a protein\u2019s annota- tion given that all its parents are also present in its annotation</p> <p>However, preferring precision over recall in a hierarchical setting can steer methods to focus on shallow (less informative) terms in the ontology and thus be of limited use. At the same time, putting more emphasis on recall may lead to overprediction, a situation in which many or most of the predicted terms are incorrect. For this reason,  we  decided  to  equally  weight  precision  and  recall. Additional  metrics  within  the  precision\u2013recall  framework  have been considered, though not implemented yet.</p> <p>Precision and recall are useful because they are easy to interpret: a precision of 1/2 means that one half of all predicted terms are cor- rect, whereas a recall of 1/3 means that one third of the experimen- tal  terms  have  been  recovered  by  the  predictor.  Unfortunately, precision\u2013recall curves and F1, while simple and interpretable mea- sures for evaluating ontology-based predictions, are limited because they ignore the hierarchical nature of the ontology and dependencies among  terms.  They  also  do  not  directly  capture  the  information content of the predicted terms.  Assessment metrics that take into account the information content of the terms were developed in the past  [22,  23,  29],  and  are  also  detailed  in  Chapter  12  [28].  In CAFA2  we  used  an  information-theoretic  measure  in  which  each term is assigned a probability that is dependent on the probabilities of its direct parents. These probabilities are calculated from the fre- quencies of the terms in the database used to generate the CAFA targets.  The  entire  ontology  graph,  thus,  can  be  seen  as  a  simple Bayesian network [5]. Using this representation, two information- theoretic analogs of precision and recall can be constructed. We refer to these quantities as misinformation (mi), the information content attributed to the nodes in the predicted graph that are incorrect, and</p> <p>142</p> <p>a Pr-rc curves</p> <p>b Ru-mi curves</p> <p>1</p> <p>Fmax point for M2</p> <p>i</p> <p>i</p> <p>n o s c e r P</p> <p>Fmax point for M1</p> <p>n o i t a m r o f n s M</p> <p>i</p> <p>i</p> <p>Smin point for M2</p> <p>0</p> <p>Recall</p> <p>1</p> <p>0</p> <p>Remaining uncertainty</p> <p>S</p> <p>min</p> <p>for</p> <p>M 1</p> <p>Fig.  3  Precision-recall  curves  and  remaining  uncertainty-misinformation  curves. This  figure  illustrates  the need for multiple assessment metrics, and understanding the context in which the metrics are used. (a) two pr-rc curves corresponding to two prediction methods M1 and M2. The point on each curve that gives Fmax is marked  as  a  circle. Although  the  two  methods  have  a  similar  performance  according  to  Fmax,  method  M1 achieves its best performance at high recall values, whereas method M2 achieves its best performance at high precision values. (b) two ru-mi curves corresponding to the same two prediction methods with marked points where the minimum semantic distance is achieved. Although the two methods have similar performance in the pr-rc space, method M1 outperforms M2 in ru-mi space. Note, however, that the performance in ru-mi space depends on the frequencies of occurrence of every term in the database. Thus, two methods may score differ- ently in their Smin when the reference database changes over time, or using a different database</p> <p>remaining  uncertainty  (ru),  the  information  content  of  all  nodes that belong to the true annotation but not the predicted annotation. More formally, if T is a set of experimentally determined nodes and P a set of predicted nodes in the ontology, then</p> <p>ru</p> <p>P T ( ,</p> <p>)</p> <p>= -</p> <p>\u00e5</p> <p>\u00ce - v T P</p> <p>log Pr( |</p> <p>v</p> <p>Pa</p> <p>v ( ));</p> <p>mi</p> <p>P T ( ,</p> <p>)</p> <p>= -</p> <p>\u00e5</p> <p>\u00ce - v P T</p> <p>log Pr( |</p> <p>v</p> <p>Pa</p> <p>v ( )</p> <p>)),</p> <p>where Pa(v) is the set of parent terms of the node v in the ontology (Fig. 2). A single performance measure to rank methods, the mini- mum  semantic  distance  Smin,  is  the  minimum  distance  from  the origin to the curve (ru(t), mi(t))t. It is defined as</p> <p>S</p> <p>\u00ec min min ( \u00ed t \u00ee</p> <p>=</p> <p>ru</p> <p>k</p> <p>( ) t</p> <p>+</p> <p>mi</p> <p>k</p> <p>( )) t</p> <p>1 k</p> <p>,</p> <p>\u00fc \u00fd \u00fe</p> <p>where k \u2265 1. We typically choose k = 2, in which case Smin is the mini- mum Euclidean distance between the ru\u2013mi curve and the origin of the coordinate system (Fig. 3b). The ru\u2013mi plots and Smin metrics compare  the  true  and  predicted  annotation  graphs  by  adding  an additional weighting component to high-information nodes. In that manner,  predictions  with  a  higher  information  content  will  be assigned  larger  weights.  The  semantic  distance  has  been  a  useful measure in CAFA2 as it properly accounts for term dependencies in the ontology. However, this approach also has limitations in that it</p> <p>Iddo Friedberg and Predrag Radivojac\f5  Discussion</p> <p>Community-Wide Evaluation of Computational Function Prediction</p> <p>143</p> <p>relies on an assumed Bayesian network as a generative model of pro- tein function as well as on the available databases of protein func- tional annotations where term frequencies change over time. While the latter limitation can be remedied by more robust estimation of term frequencies in a large set of organisms, the performance accura- cies in this setting are generally less comparable over two different CAFA experiments than in the precision\u2013recall setting.</p> <p>Critical assessment challenges have been successfully adopted in a number of fields due to several factors. First, the recognition that improvements to methods are indeed necessary. Second, the ability of the community to mobilize enough of its members to engage in a challenge. Mobilizing a community is not a trivial task, as groups have  their  own  research  priorities  and  only  a  limited  amount  of resources to achieve them, which may deter them from undertak- ing a time-consuming and competitive effort a challenge may pose. At the same time, there are quite a few incentives to join a com- munity  challenge.  Testing  one\u2019s  method  objectively  by  a  third party  can  establish  credibility,  help  point  out  flaws,  and  suggest improvements. Engaging with other groups may lead to collabora- tions and other opportunities. Finally, the promise of doing well in a challenge can be a strong incentive heralding a group\u2019s excellence in their field. Since the assessment metrics are crucial to the perfor- mance of the teams, large efforts are made to create multiple met- rics  and  to  describe  exactly  what  they  measure.  Good  challenge organizers try to be attentive to the requests of the participants, and to have the rules of the challenge evolve based on the needs of the community. An understanding that a challenge\u2019s ultimate goal is  to  improve  methodologies  and  that  it  takes  several  rounds  of repeating the challenge to see results.</p> <p>The first two CAFA challenges helped clarify that protein func- tion prediction is a vibrant field, but also one of the most challeng- ing tasks in computational biology. For example, CAFA provided evidence  that  the  available function  prediction  algorithms  outperform a straightforward use of sequence alignments in func- tion  transfer.  The  performance  of  methods  in  the  Molecular Function category has consistently been reliable and also showed progress  over  time  (unpublished  results  from  CAFA2).  On  the other hand, the performance in the Biological Process or Cellular Component ontologies has not yet met expectations. One of the reasons for this may be that the terms in these ontologies are less predictable using amino acid sequence data and instead would rely more on high-quality systems data; e.g., see [6]. The challenge has also helped clarify the problems of evaluation, both in terms of eval- uating over consistent sub-graphs in the ontology but also in the presence of incomplete and biased molecular data. Finally, although</p> <p>144</p> <p>Acknowledgements</p> <p>it  is  still  early,  some  best  practices  in  the  field  are  beginning  to emerge. Exploiting multiple types of data is typically advantageous, although  we  have  observed  that  both  machine  learning  expertise and good biological insights tend to result in strong performance. Overall,  while  the  methods  in  the  Molecular  Function  ontology seem to be maturing, in part because of the strong signal in sequence data, the methods in the Biological Process and Cellular Component ontologies  still  appear  to  be  in  the  early  stages  of  development. With  the  help  of  better  data  over  time,  we  expect  significant improvements in these categories in the future CAFA experiments. Overall, CAFA generated a strong positive response to the call for both challenge rounds, with the number of participants sub- stantially growing between CAFA1 (102 participants) and CAFA2 (147). This indicates that there exists significant interest in devel- oping  computational  protein  function  prediction  methods,  in understanding how well they perform, and in improving their per- formance. In CAFA2 we preserved the experiment rules, ontolo- gies, and metrics we used in CAFA1, but also added new ones to better capture the capabilities of different methods. The CAFA3 experiment will further improve evaluation by facilitating unbiased evaluation for several select functional terms.</p> <p>More  rounds  of  CAFA  are  needed  to  know  if  computational methods will improve as a direct result of this challenge. But given the community\u2019s growth and growing interest, we believe that CAFA is a welcome addition to the community of protein function annotators.</p> <p>We thank Kymberleigh Pagel and Naihui Zhou for helpful discus- sions.  This  work  was  partially  supported  by  NSF  grants  DBI- 1458359 and DBI-1458477. Open Access charges were funded by the  University  College  London  Library,  the  Swiss  Institute  of Bioinformatics,  the  Agassiz  Foundation,  and  the  Foundation  for the University of Lausanne.</p> <p>Open  Access  This  chapter  is  distributed  under  the  terms  of  the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/),  which  permits  use, duplication,  adaptation,  distribution  and  reproduction  in  any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.</p> <p>The  images  or  other  third  party  material  in  this  chapter  are included  in  the  work\u2019s  Creative  Commons  license,  unless  indicated otherwise  in  the  credit  line;  if  such  material  is  not  included  in  the work\u2019s Creative Commons license and the respective action is not per- mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.</p> <p>Iddo Friedberg and Predrag Radivojac\fCommunity-Wide Evaluation of Computational Function Prediction</p> <p>145</p> <p>References</p> <ol> <li>Ashburner M, Ball CA, Blake JA, Botstein D, Butler  H,  Cherry  JM,  Davis  AP,  Dolinski  K, Dwight  SS,  Eppig  JT,  Harris  MA,  Hill  DP, Issel-Tarver  L,  Kasarskis  A,  Lewis  S,  Matese JC,  Richardson  JE,  Ringwald  M,  Rubin  GM, Sherlock G (2000) Gene ontology: tool for the unification biology.  Nat  Genet 25(1):25\u201329.</li> </ol> <p>of</p> <ol> <li>Bairoch  A,  Apweiler  R,  Wu  CH,  Barker  WC, Boeckmann B, Ferro S, Gasteiger E, Huang H, Lopez R, Magrane M, Martin MJ, Natale DA, O\u2019Donovan C, Redaschi N, Yeh LS (2005) The Universal Protein Resource (UniProt). Nucleic Acids Res 33(Database issue):D154\u2013D159</li> <li> <p>Camon  EB,  Barrell  DG,  Dimmer  EC,  Lee  V, Magrane  M,  Maslen  J,  Binns  D,  Apweiler  R (2005)  An  evaluation  of  GO  annotation retrieval  for  BioCreAtIvE  and  GOA.  BMC Bioinformatics 6(Suppl 1):S17</p> </li> <li> <p>Clark WT, Radivojac P (2011) Analysis of pro- tein  function  and  its  prediction  from  amino acid sequence. Proteins 79(7):2086\u20132096</p> </li> <li>Clark  WT,  Radivojac  P  (2013)  Information- theoretic  evaluation  of  predicted  ontological annotations. Bioinformatics 29(13):i53\u2013i61.</li> <li>Costanzo  M,  Baryshnikova  A,  Bellay  J,  Kim  Y, Spear ED, Sevier CS, Ding H, Koh JL, Toufighi K, Mostafavi S, Prinz J, St Onge RP, VanderSluis, B, Makhnevych T, Vizeacoumar FJ, Alizadeh S, Bahr S, Brost RL, Chen Y, Cokol M, Deshpande R, Li Z, Lin ZY, Liang W, Marback M, Paw J, San Luis BJ, Shuteriqi E, Tong AH, van Dyk N, Wallace IM, Whitney JA, Weirauch MT, Zhong G, Zhu H, Houry WA, Brudno M, Ragibizadeh S, Papp B, Pal C, Roth FP, Giaever G, Nislow C, Troyanskaya OG, Bussey H, Bader GD, Gingras AC, Morris QD, Kim PM, Kaiser CA, Myers CL, Andrews BJ, Boone C (2010) The genetic land- scape of a cell. Science 327(5964):425\u2013431</li> <li>Costello JC, Stolovitzky G (2013) Seeking the wisdom  of  crowds  through  challenge-based competitions  in  biomedical  research.  Clin Pharmacol Ther 93(5):396\u2013398</li> </ol> <p>for</p> <p>transfers</p> <ol> <li>Cozzetto D, Jones DT (2016) Computational methods from annotation sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu- lar biology, vol 1446. Humana Press. Chapter 5</li> <li> <p>Cozzetto  D,  Buchan  DWA,  Bryson  K,  Jones DT  (2013)  Protein  function  prediction  by massive  integration  of  evolutionary  analyses and multiple data sources. BMC Bioinformatics 14(Suppl 3):S1+.</p> </li> <li> <p>Dessimoz  C,  Skunca  N,  Thomas  PD  (2013) CAFA and the open world of protein function predictions. Trends Genet 29(11):609\u2013610</p> </li> <li>Engelhardt  BE,  Jordan  MI,  Muratore  KE, Brenner SE (2005) Protein molecular function</li> </ol> <p>prediction  by  Bayesian  phylogenomics.  PLoS Comput Biol 1(5):e45</p> <ol> <li> <p>Friedberg I (2006) Automated protein func- tion prediction\u2013the genomic challenge. Brief Bioinform 7(3):225\u2013242.</p> </li> <li> <p>Friedberg I, Wass MN, Mooney SD, Radivojac P  (2015)  Ten  simple  rules  for  a  community computational  challenge.  PLoS  Comput  Biol 11(4):e1004150 (2015)</p> </li> <li> <p>Gaudet  P,  \u0160kunca  N,  Hu  JC,  Dessimoz  C (2016)  Primer  on  the  gene  ontology.  In: Dessimoz C, \u0160kunca N (eds) The gene ontol- ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3</p> </li> <li> <p>Hastings  J  (2016)  Primer  on  ontologies.  In: Dessimoz C, \u0160kunca N (eds) The gene ontol- ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1</p> </li> <li> <p>Huntley RP, Sawford T, Mutowo-Meullenet P, Shypitsyna A, Bonilla C, Martin MJ, O\u2019Donovan C  (2015)  The  GOA  database:  gene  ontology annotation updates for 2015. Nucleic Acids Res 43(Database issue):D1057\u2013D1063</p> </li> <li> <p>Huttenhower C, Hibbs M, Myers C, Troyanskaya OG  (2006)  A  scalable  method  for  integration and  functional  analysis  of  multiple  microarray datasets. Bioinformatics 22(23):2890\u20132897</p> </li> <li>Jiang  Y,  Clark  WT,  Friedberg  I,  Radivojac  P (2014)  The  impact  of  incomplete  knowledge on  the  evaluation  of  protein  function  predic- tion: a structured-output learning perspective. England) Bioinformatics 30(17):i609\u2013i616.</li> </ol> <p>(Oxford,</p> <ol> <li>Jiang  Y,  Oron  TR,  Clark  WT,  Bankapur  AR, D\u2019Andrea  D,  Lepore  R,  Funk  CS,  Kahanda  I, Verspoor  KM,  Ben-Hur  A,  Koo  E,  Penfold- Brown D, Shasha D, Youngs N, Bonneau R, Lin A,  Sahraeian  SME,  Martelli  PL,  Profiti  G, Casadio R, Cao R, Zhong Z, Cheng J, Altenhoff A, Skunca N, Dessimoz C, Dogan T, Hakala K, Kaewphan S, Mehryary F, Salakoski T, Ginter F, Fang  H,  Smithers  B,  Oates  M,  Gough  J, Toronen P, Koskinen P, Holm L, Chen CT, Hsu WL, Bryson K, Cozzetto D, Minneci F, Jones DT, Chapman S, Dukka BKC, Khan IK, Kihara D,  Ofer  D,  Rappoport  N,  Stern  A,  Cibrian- Uhalte E, Denny P, Foulger RE, Hieta R, Legge D,  Lovering  RC,  Magrane  M,  Melidoni  AN, Mutowo-Meullenet P, Pichler K, Shypitsyna A, Li B, Zakeri P, ElShal S, Tranchevent LC, Das S, Dawson NL, Lee D, Lees JG, Sillitoe I, Bhat P, Nepusz T, Romero AE, Sasidharan R, Yang H, Paccanaro  A,  Gillis  J,  Sedeno-Cortes  AE, Pavlidis  P,  Feng  S,  Cejuela  JM,  Goldberg  T, Hamp  T,  Richter  L,  Salamov  A,  Gabaldon  T, Marcet-Houben M, Supek F, Gong Q, Ning W, Zhou Y, Tian W, Falda M, Fontana P, Lavezzo E,  Toppo  S,  Ferrari  C,  Giollo  M,  Piovesan  D,</li> </ol> <p>146</p> <p>Tosatto S, del Pozo A, Fern\u00e1ndez JM, Maietta P, Valencia A, Tress ML, Benso A, Di Carlo S, Politano  G,  Savino  A,  Ur  Rehman  H,  Re  M, Mesiti  M,  Valentini  G,  Bargsten  JW,  van  Dijk ADJ, Gemovic B, Glisic S, Perovic V, Veljkovic V,  Veljkovic  N,  Almeida-e  Silva  DC,  Vencio RZN, Sharan M, Vogel J, Kansakar L, Zhang S, Vucetic S, Wang Z, Sternberg MJE, Wass MN, Huntley  RP,  Martin  MJ,  O\u2019Donovan  C, Robinson  PN,  Moreau  Y,  Tramontano  A, Babbitt PC, Brenner SE, Linial M, Orengo CA, Rost  B,  Greene  CS,  Mooney  SD,  Friedberg  I, Radivojac P (2016) An expanded evaluation of protein  function  prediction  methods  shows  an improvement  in  accuracy.  http://arxiv.org/ abs/1601.00891</p> <ol> <li>Kryshtafovych  A,  Fidelis  K,  Moult  J  (2014) CASP10  results  compared those  of  previous  CASP  experiments.  Proteins  82: 164\u2013174.</li> </ol> <p>to</p> <ol> <li> <p>Letovsky S, Kasif S (2003) Predicting protein function interaction from  protein/protein data:  a  probabilistic  approach.  Bioinformatics 19(Suppl 1):i197\u2013204</p> </li> <li> <p>Lord PW, Stevens RD, Brass A, Goble CA (2003) Investigating semantic similarity measures across the  gene  ontology:  the  relationship  between sequence annotation.  Bioinformatics 19(10):1275\u20131283.</p> </li> </ol> <p>and</p> <ol> <li> <p>Lord  PW,  Stevens  RD,  Brass  A,  Goble  CA (2003)  Semantic  similarity  measures  as  tools for  exploring  the  gene  ontology.  In:  Pacific symposium  on  biocomputing.  Pacific  sympo- sium on biocomputing, pp 601\u2013612.</p> </li> <li> <p>Martin  DM,  Berriman  M,  Barton  GJ  (2004) GOtcha: a new method for prediction of pro- tein  function  assessed  by  the  annotation  of seven genomes. BMC Bioinformatics 5:178</p> </li> <li> <p>Nabieva  E,  Jim  K,  Agarwal  A,  Chazelle  B, Singh  M  (2005)  Whole-proteome  prediction of protein function via graph-theoretic analysis of  interaction  maps.  Bioinformatics  21(Suppl 1):i302\u2013i310</p> </li> <li> <p>Pal  D,  Eisenberg  D  (2005)  Inference  of  pro- tein function from protein structure. Structure 13(1):121\u2013130 (2005)</p> </li> <li> <p>Pazos F, Sternberg MJ (2004) Automated pre- diction  of  protein  function  and  detection  of functional sites from structure. Proc Natl Acad Sci USA 101(41):14754\u201314759</p> </li> <li> <p>Pesquita  C  (2016)  Semantic  Similarity  in  the Gene  Ontology.  In:  Dessimoz  C,  \u0160kunca  N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12</p> </li> <li> <p>Pesquita C, Faria D, Falc\u00e3o AO, Lord P, Couto FM  (2009)  Semantic  similarity  in  biomedical ontologies.  PLoS  Comput  Biol  5(7): e1000443+.</p> </li> <li> <p>Radivojac  P,  Clark  WT,  Oron  TRR,  Schnoes AM, Wittkop T, Sokolov A, Graim K, Funk C, Verspoor K, Ben-Hur A, Pandey G, Yunes JM, Talwalkar AS, Repo S, Souza ML, Piovesan D, Casadio R, Wang Z, Cheng J, Fang H, Gough J,  Koskinen  P,  T\u00f6r\u00f6nen  P,  Nokso-Koivisto  J, Holm L, Cozzetto D, Buchan DW, Bryson K, Jones  DT,  Limaye  B,  Inamdar  H,  Datta  A, Manjari  SK,  Joshi  R,  Chitale  M,  Kihara  D, Lisewski AM, Erdin S, Venner E, Lichtarge O, Rentzsch  R,  Yang  H,  Romero  AE,  Bhat  P, Paccanaro A, Hamp T, Ka\u00dfner R, Seemayer S, Vicedo  E,  Schaefer  C,  Achten  D,  Auer  F, Boehm  A,  Braun  T,  Hecht  M,  Heron  M, H\u00f6nigschmid  P,  Hopf  TA,  Kaufmann  S, Kiening M, Krompass D, Landerer C, Mahlich Y,  Roos  M,  Bj\u00f6rne  J,  Salakoski  T,  Wong  A, Shatkay H, Gatzmann F, Sommer I, Wass MN, Sternberg MJ, \u0160kunca N, Supek F, Bo\u0161njak M, Panov P, D\u017eeroski S, \u0160muc T, Kourmpetis YA, van Dijk AD, ter Braak CJ, Zhou Y, Gong Q, Dong X, Tian W, Falda M, Fontana P, Lavezzo E,  Di  Camillo  B,  Toppo  S,  Lan  L,  Djuric  N, Guo Y, Vucetic S, Bairoch A, Linial M, Babbitt PC, Brenner SE, Orengo C, Rost B, Mooney SD,  Friedberg  I  (2013)  A  large-scale  evalua- tion of computational protein function predic- tion. Nat Methods 10(3):221\u2013227.</p> </li> <li> <p>Rentzsch  R,  Orengo  CA  (2009)  Protein  func- tion prediction\u2013the power of multiplicity. Trends Biotechnol 27(4):210\u2013219.</p> </li> <li> <p>Schnoes AM, Ream DC, Thorman AW, Babbitt PC, Friedberg I (2013) Biases in the experimen- tal  annotations  of  protein  function  and  their effect on our understanding of protein function space. PLoS Comput Biol 9(5):e1003,063+.</p> </li> <li>\u0160kunca  N,  Roberts  RJ,  Steffen  M  (2016) Evaluating computational gene ontology anno- tations.  In:  Dessimoz  C,  \u0160kunca  N  (eds)  The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 8.</li> <li> <p>Sokolov  A,  Ben-Hur  A  (2010)  Hierarchical classification of gene ontology terms using the GOstruct  method.  J  Bioinform  Comput  Biol 8(2):357\u2013376</p> </li> <li> <p>Stephens ZD, Lee SY, Faghri F, Campbell RH, Zhai C, Efron MJ, Iyer R, Schatz MC, Sinha S, Robinson GE (2015) Big data: astronomical or genomical? PLoS Biol 13(7):e1002195+.</p> </li> <li> <p>Troyanskaya  OG,  Dolinski  K,  Owen  AB, Altman  RB,  Botstein  D  (2003)  A  Bayesian framework for combining heterogeneous data sources  for  gene  function  prediction  (in Saccharomyces  cerevisiae).  Proc  Natl  Acad  Sci USA 100(14):8348\u20138353</p> </li> <li> <p>Wass MN, Mooney SD, Linial M, Radivojac P, Friedberg  I  (2014)  The  automated  function prediction  SIG  looks  back  at  2013  and  pre- for  2014.  Bioinformatics  (Oxford, pares England) 30(14):2091\u20132092.</p> </li> </ol> <p>Iddo Friedberg and Predrag Radivojac\f   Part IV    Using the Gene Ontology        \f149    Chapter 11    Get GO! Retrieving GO Data Using AmiGO, QuickGO, API, Files, and Tools                          Monica     Munoz-Torres      and     Seth     Carbon       Abstract    The Gene Ontology Consortium (GOC) produces a wealth of resources widely used throughout the scienti\ufb01 c community. In this chapter, we discuss the different ways in which researchers can access the resources of the GOC. We here share details about the mechanics of obtaining GO annotations, both by manually browsing, querying, and downloading data from the GO website, as well as computationally accessing the resources from the command line, including the ability to restrict the data being retrieved to subsets with only certain attributes.    Key words     Gene ontology  ,   Ontology  ,   Annotation resources  ,   Annotation  ,   Genomics  ,   Transcriptomics  ,   Bioinformatics  ,   Biocuration  ,   Curation  ,   Access  ,   AmiGO  ,   QuickGO  1      Introduction  The efforts of the Gene Ontology Consortium (GOC) are focused on three major subjects: (1) the development and maintenance of the ontologies; (2) the annotation of gene products, which includes making associations between the ontologies and the genes and gene products in all collaborating databases; and (3) the develop-ment of tools that facilitate the creation, maintenance, and use of the ontologies. This chapter is focused on the mechanics of obtain-ing GO annotations, both directly and computationally, including the ability to restrict the data being retrieved to subsets with only certain attributes.  GO data is the culmination of various forms of curation, made accessible through a variety of interfaces and downloadable in dif-ferent forms, depending on your intended use. Because the data and software landscape are constantly changing, it is hard to cover with any permanence the best way to access the data; this inherent limitation should be kept in mind as we navigate through this section. This chapter is intended as an overview of the different ways users can access GO data (via web portals, downloadable \ufb01 les, and API) Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_11, \u00a9 The Author(s) 2017\f150a quick description of basic software used by GO, and as a reference for where to \ufb01 nd more detailed and up-to-date information about these subjects.  2    Web Interfaces to Access the GO  This section covers the online interfaces for accessing and interacting with the data using standard web browsers. Most consumers of the GO can make use of data browsers such as AmiGO, QuickGO, and data browsers embedded within more speci\ufb01 c databases.    AmiGO ([ 1 ]   http://amigo.geneontology.org    ; Fig.  1a ) is the of\ufb01 cial web-based open-source tool for querying, browsing, and visualizing the Gene Ontology and annotations collected from the MODs (model organism databases), UniProtKB, and other sources (com-plete list of member institutions currently contributing to the GOC at   http://geneontology.org/page/go-consortium- contributors- list    ). Notable features include: basic searching, browsing, the ability to download custom data sets, and a common question \u201cwizard\u201d interface. Recent changes have brought improvements both in speed and the variety of search modes, as well as the availability of additional data types, such as the display of annotation extensions ( see  Chap.   17     [ 2 ]) and display of protein forms (splice variants and proteins with post translational modi\ufb01 cations). More details about the latest improvements on the AmiGO browser can also be found at GOC\u2014Munoz-Torres (CA), 2015 [ 3 ].      The Gene Ontology Annotation (GOA) project at the European Molecular Biology Laboratory\u2019s European Bioinformatics Institute (EMBL-EBI) also makes available the QuickGO browser ([ 4 ];   http://www.ebi.ac.uk/QuickGO    ; Fig.  1b ), a web-based tool that allows easy browsing of the Gene Ontology (GO) and all associ-ated electronic and manual GO annotations provided by the GO Consortium annotation groups. Included in its many features are extensive search and \ufb01 lter capabilities for GO annotations, a pow-erful integrated subset/slim interface, as well as an integrated his-torical view of the terms. For data consumption, QuickGO provides broad-ranging web services and cart functionality (a way of persist-ing abstract elements, like term IDs, between parts of the QuickGO web application).  AmiGO and QuickGO make use of the same GO data sets, with somewhat different implementations according to the require-ments of funding sources and respective users. AmiGO, in its entirety, is a product of the GO Consortium and is the of\ufb01 cial channel for dissemination of the GO data sets, adhering to funding recommendations from NHGRI-NIH. QuickGO is produced, managed, and funded by EMBL-EBI; the members of QuickGO\u2019s managing team are also members of the GOC.  2.1  AmiGO2.2  QuickGOMonica Munoz-Torres and Seth Carbon\f151  Fig. 1    Landing pages for the AmiGO ( a ) and QuickGO ( b ) browsers. A few features are highlighted for each browser        How to get the GO\f152   The ontology component of the GO is also searchable and browsable from various third party generic ontology browsers such as OntoBee (  http://ontobee.org    ), the EMBL-EBI Ontology Lookup Service (OLS) (  http://www.ebi.ac.uk/ontology-lookup    ), OLSVis (  http://ols.wordvis.com    ), and BioPortal (  http://bioportal.bioontology.org    ). Each of these systems has their own particular strengths\u2014for example OntoBee is aimed at the semantic web community, and pro-vides the ontology as part of a linked data platform [ 5 ], whereas OLSVis is geared towards visualization. However, none of these browsers currently provide access to the annotations.     One of the main uses of the GO is to perform enrichment analysis on gene sets. For example, given a set of genes that are up regulated under certain conditions, an enrichment analysis will \ufb01 nd which GO terms are overrepresented (or underrepresented) using the available annotations for that gene set. The GO website offers a service that directly connects users with the enrichment analysis tool from the PANTHER Classi\ufb01 cation System [ 6 ]. The PANTHER database is up-to-date with GO annotations, and their enrichment tool is driven by GO data. Further details about this enrichment tool, as well as a list of supported gene IDs, are available from the PANTHER website at   http://www.pantherdb.org/     and at   http://www.pant-herdb.org/tips/tips_batchIdSearch_supportedId.jsp    . More infor-mation on enrichment analysis using the GO is available Chap.   13     [ 7 ] on \u201c Gene-Category Analysis .\u201d        To give a concrete example of the type of easy GO data exploration that can be accomplished using a web interface, we here provide an example where a user on the AmiGO annotation search interface (  http://amigo.geneontology.org/amigo/search/annotation    ) is trying to \ufb01 nd associations between genes/gene products and epi-thelial processes, while searching only data outside those available for human, and which have experimental evidence.  The user could: \u2013   Type \u201c epithel \u201d into the text \ufb01 lter box ( Free - text \ufb01 ltering ) to the left of the results area.   \u2013  Open the \u201c Taxon \u201d facet and select the [\u2212] next to \u201c Homo sapiens .\u201d   \u2013  Open the \u201c Evidence type \u201d facet and select the [+] next to \u201c exper-imental evidence .\u201d     The remaining results would \ufb01 t the initial search criteria. However, suppose that the user wants to further re\ufb01 ne their search to strictly look at all GO annotations that are directly or indirectly annotated to the GO term \u201c epithelial cell differentiation \u201d (GO:0009913). Following the steps above, they could:2.3  Other Browsers2.4  Term Enrichment Tool2.5  A Simple Example of Data Exploration Using AmiGO (  See  Fig.  2 )Monica Munoz-Torres and Seth Carbon\f153 \u2013   Open the \u201c Inferred annotation \u201d facet and select the [+] next to \u201c epithelial cell differentiation ,\u201d then   \u2013  Remove the text \ufb01 lter by clicking the [x] next to the text entry.     This would leave the user with all GO annotations directly or indirectly annotated with \u201c epithelial cell differentiation \u201d (GO:0009913), that are not from human data, and have some kind of experimental evidence associated with them.   3    GO Files: Description and Availability  GO data \ufb01 les contain the current and long-term output of ontology and annotation efforts that are used for exchanging data across various systems. There are several use cases where it may be easier to mine the data directly from the \ufb01 les using a variety of tools. The most commonly used raw data \ufb01 les can be broken down into two categories: ontology and association \ufb01 les.   Fig. 2    Data exploration using the AmiGO annotation search interface. All results from this example are listed in  panel  ( a ). ( b ) Shows a detail about the \ufb01 lters applied throughout the search, listed under \u201c User \ufb01 lters .\u201d An example of the details that appear for each gene or gene product is visible in ( c ): note that the information about the GO term ID for \u201c epithelial cell differentiation \u201d (GO:0009913) appears when users hover over the \u201cDirect annotation\u201d details        How to get the GO\f154   In the context of GO, ontologies are graph structures comprised of classes for molecular functions, the biological processes they contrib-ute to, the cellular locations where they occur, and the relationships connecting them all, in a species-independent manner [ 3 ]. Each term in the GO has de\ufb01 ned relationships to one or more other terms in the same domain, and sometimes to other domains. Additional informa-tion about ontologies in general is also available from Chap.   1     [ 8 ].  GO ontology data are available from the GO website at   http://geneontology.org/page/download-ontology    . There are three dif-ferent editions of the GO, in increasing order of complexity: go- basic, go, and go-plus.   go-basic : This basic edition of the GO is \ufb01 ltered such that annota-tions can be propagated up the graph. The relations included are  is _ a ,  part_of ,  regulates ,  negatively_regulates , and  positively_regu-lates . It is important to note that this version excludes relationships that cross the three main GO hierarchies. Many legacy tools that use the GO make these assumptions about the GO, so we make this version available in order to support these tools. This version of the GO ontology is available in OBO format only.   go : This core edition of the GO includes additional relationship types, including some that span the three GO hierarchies, such as  has_part  and  occurs_in , connecting the otherwise disjoint hierar-chies found in  go-basic . This version of the GO ontology is avail-able in two formats, OBO and OWL-RDF/XML.   go-plus : This is the most expressive edition of the GO; it includes more relationships than  go  and connections to external ontologies, including the Chemical Entities of Biological Interest ontology (ChEBI; [ 9 ]), the Uberon anatomy (or stage) ontology [ 10 ], and the Plant Ontology for plant structure/stage (PO; [ 11 ]). It also includes import modules that are minimal subsets of those ontolo-gies. This allows for cross-ontology queries, such as \u201c \ufb01 nd all genes that perform functions related to the brain \u201d (e.g., in AmiGO:   http://amigo.geneontology.org/amigo/term/UBERON:0000955#display-associations-tab    ).  go-plus  [ 12 ] also includes rules encod-ing biological constraints, such as the spatial exclusivity between a nucleus and a cytosol. These constraints are used for validation of the ontology and annotations [ 13 ]. This version of the GO ontol-ogy is available in OWL-RDF/XML.  When working with the ontologies, the of\ufb01 cial language of the Gene Ontology is the Web Ontology Language, or  OWL , which is a standard de\ufb01 ned by the World Wide Web Consortium (W3C). The GO has approximately 41,000 terms covering over 4 million genes in almost 470,000 species [ 3 ]. Its organization goes beyond a simple terminology structured as a directed acyclic graph (DAG), as it con-sists of over 41,000 classes, but it also includes an import chain that brings in an additional 10,000 classes from additional ontologies ([ 10 ] and see \u201c go - plus \u201d above). In order to best represent the 3.1  OntologyMonica Munoz-Torres and Seth Carbon\f155complexity of these classes, along with the approximately 27 million associations that connect them to each molecular entity (genes or gene products), members of the GOC software development team worked on building an axiomatic structure for GO. That is, they assigned logical de\ufb01 nitions (known as OWL axioms or self- evidently true statements) to all the classes; the Gene Ontology has been effec-tively axiomatized, that is, reduced to this system of axioms in OWL, and is highly dependent on the OWL tool stack [ 10 ]. Examples of OWL stanzas for terms that are de\ufb01 ned by a logical de\ufb01 nition in the Gene Ontology are available from GOC\u2014Munoz- Torres (CA), 2015 [ 3 ].  A number of tools, frameworks, and software libraries support OWL, including the ontology editor Prot\u00e9g\u00e9 (  http://protege.stanford.edu/    ; Fig.  3 ), the Java OWL API, and the OWLTools framework produced by the GO (  https://github.com/owlcollab/owltools    ). Figure  3  shows a GO term visualized using Prot\u00e9g\u00e9; its underlying structure is the OWL language. We also make the ontology editions available in OBO Format, which is a simpler for-mat used in many bioinformatics applications (note that \u201c go - plus \u201d is not available in OBO format). The two formats can be intercon-verted using the  Robot  tool produced by the GO Consortium, which can be found at   https://github.com/ontodev/robot/    .  Fig. 3    Visualizing a GO term using Prot\u00e9g\u00e9. Prot\u00e9g\u00e9 displays the details of the term \u201c adenine import across plasma membrane \u201d (GO:0098702). The underlying structure of the term is written in the OWL language, which adds \ufb02 exibility to the expression of associations between genes and gene products and the terms in the ontol-ogy, compared to the possibilities offered in OBO. For example, in this term, inter-ontology logical de\ufb01 nitions (OWL axioms) coming from the ChEBI ontology [ 9 ] are visible; this is not possible to see when visualizing the ontology using OBO        How to get the GO\f156   The GO project is constantly evolving, and it welcomes feed-back from all users ( see  below in Subheading  5.3 ). Research groups may contribute to the GO by either providing suggestions for updat-ing the ontology (e.g., requests for new ontology terms) or by pro-viding annotations. Requests for new synonyms or clari\ufb01 cation of textual de\ufb01 nitions are also welcomed.  Annotators and other data creators can search whether a term currently exists using the AmiGO browser at   http://amigo.geneontology.org/    , or may request new ones using either the GO issue tracker on GitHub or TermGenie. TermGenie ([ 14 ];   http://termgenie.org    ) is a web-based tool for requesting new Gene Ontology classes. It also allows for an ontology developer to review all generated terms before they are committed to the ontology. The system makes extensive use of OWL axioms, but can be easily used without understanding these axioms. Users not yet familiar with TermGenie, or whom do not yet have permission to use directly, may submit ontology updates and requests using the GO curator request tracker on GitHub (  https://github.com/geneon-tology/go-ontology/issues    ), which allows free-text form submis-sions. For more information on how to best contribute to the GO, please  see  Chap.   7     [ 15 ].     Gene Ontology subsets (also sometimes known as \u201c slims \u201d) are cut- down versions of the ontologies, containing a reduced number of terms (e.g., species-speci\ufb01 c subsets or more generic subsets with \u201cuseful\u201d terms in various categories). They give a broad overview of the ontology content without the detail of the speci\ufb01 c \ufb01 ne- grained terms. Subsets are particularly useful for giving a summary of the results of GO annotation of a genome, microarray, or cDNA collection when broad classi\ufb01 cation of gene product function is required. Further information, including Java-based tools and data downloads, is available from the GO website (  http://geneontol-ogy.org/page/go-slim-and-subset-guide    ).     The annotation process captures the activities and localization of a gene product using GO terms, providing a reference, and indicat-ing the kind of available evidence in support of the assignment of each term using evidence codes. Currently, the main format for annotation information in the GO is the Gene Association File (GAF,   http://geneontology.org/page/go-annotation-\ufb01 le- formats    ). This is the standardized \ufb01 le format that members of the Consortium use for submitting data. The annotation data is stored in tab-delimited plain text \ufb01 les, where each line in the \ufb01 le repre-sents a single association between a gene product and a GO term, with an evidence code, the reference to support the link between them, and other information. The GAF \ufb01 le format has several dif-ferent \u201c\ufb02 avors,\u201d with 2.1 being the most current version. Additional details about GAF \ufb01 les is found in Chap.   3     [ 16 ]. 3.2  Ontology Subsets3.3  Association FilesMonica Munoz-Torres and Seth Carbon\f157 Recently, the GPAD/GPI \ufb01 les were developed, which are essentially a normalized version of GAF information. These for-mats are expected to have more prominence in the future, and further details about them can be found on the GO website (  http://geneontology.org/page/go-annotation-\ufb01 le-formats    ).  Because they are tab-delimited text \ufb01 les, both the GAF and GPAD/GPI \ufb01 le formats are very amenable to mining with command line tools. As well, OWLTools can also be used to access this annota-tion information with operations such as: connecting the annotations to ontology information for exploration and reasoning, OWL trans-lation, validation, taxon checks, and link prediction. More advanced details on this topic are further explained on the OWLTools project wiki (  https://github.com/owlcollab/owltools/wiki    ).  Details on how to make and evaluate GO annotations are dis-cussed in Chap.   4     [ 17 ] on \u201c Best Practices in Manual Annotation with the Gene Ontology ,\u201d and in Chap.   8     [ 18 ] on \u201c Evaluating Computational Gene Ontology Annotations .\u201d Information is also available in the GO Annotation Guide (  http://geneontology.org/page/go-annotation-policies    ); more information on the meaning and use of the evidence codes in support of each annotation can be found on the GO Evidence Codes documentation (  http://geneontology.org/page/guide-go-evidence-codes    ). The GOC is currently transitioning from using evidence codes into implement-ing the Evidence Ontology (ECO) to describe the evidence in sup-port of each association between a gene product and a GO term. A detailed description of the Evidence Ontology and its use cases is included in Chap.   18     [ 19 ] on \u201c The Evidence and Conclusion Ontology: Supporting Conclusions &amp; Assertions with Evidence .\u201d   4    Making Your Own Tools  In addition to using off-the-shelf tools provided by the GOC or other users, we also provide libraries and APIs to enable end-users to easily create their own tools for working with and analyzing GO data.  Within the Java/JVM ecosystem, the OWLTools (  https://github.com/owlcollab/owltools    ), and OWL API (  https://github.com/owlcs/owlapi    ) libraries are the primary tools to work with the data. Since OWL is the internal representation format used by the GOC, standard OWL reasoners and tools are all usable with the data. For slightly less general access to the data, the OWLTools(-Core) wrapper library adds numerous helper methods to access OBO-speci\ufb01 c \ufb01 elds (i.e.,  synonyms ,  alt_ids ), walk graphs, create closures, and other common operations.  On the JavaScript side (both client and server), AmiGO develop-ment has produced JavaScript APIs (  http://wiki.geneontology.org/index.php/AmiGO_2_Manual:_JavaScript    ) and widgets (  http://How to get the GO\f158wiki.geneontology.org/index.php/AmiGO_2_Manual:_Widgets    ) for better access and integration with other tools. Users interested in using the JavaScript API or widgets from AmiGO in their own site should become familiar with the manager and response interfaces, which are the core of the JavaScript interface. An introductory over-view of the JavaScript API and widgets, as well as details on imple-mentation engines, the response class, and the con\ufb01 guration class can be also be found on the JavaScript section of the AmiGO Manual, listed above.  As well, AmiGO provides methods for producing incoming searches to allow external sites to link to relevant information. Documentation about these methods can be found at   http://wiki.geneontology.org/index.php/AmiGO_2_Manual:_Linking    .  5    Additional Information    The GO project provides mappings between GO terms and other key related systems (built for other purposes), such as Enzyme Commission numbers or Kyoto Encyclopedia of Genes and Genomes (KEGG). However, one should be aware that these mappings are neither complete nor exact and should be used with caution. A complete listing of mappings available for the resources of the GOC can be found at   http://geneontology.org/page/download- mappings    . Additional information about alternative and complementary resources to the GO is available on Chap.   19     [ 20 ].     Currently, the AmiGO and QuickGO interfaces have moved away from SQL database derivatives of the data sets. However, to sup-port legacy applications and queries, the GO data is regularly con-verted into an SQL database (MySQL). These builds can be downloaded and installed on a local machine, or queried remotely using the GO Online SQL/Solr environment (GOOSE;   http://amigo.geneontology.org/goose    ). More information about SQL access, including various downloads and schema information, can be found in the legacy SQL section of the GO website (  http://geneontology.org/page/lead-database-guide    ).      In additional to other functions, the GO Helpdesk addresses user queries about the Gene Ontology and related resources. The GO Helpdesk will direct any questions or concerns with GO data, software, or analysis to the appropriate people within the consor-tium. You can directly contact the GO Helpdesk using the site form (  http://geneontology.org/form/contact-go    ), which will automatically enter your query into an internal tracker to ensure responsiveness. 5.1  Mappings5.2  Legacy Interface for GO5.3  Help/Troubleshooting Software and DataMonica Munoz-Torres and Seth Carbon\f159  Funding  MMT and SC were supported by the Director, Of\ufb01 ce of Science, Of\ufb01 ce of Basic Energy Sciences, of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231 (http://sci-ence.energy.gov/bes/), and by the U.S. National Institutes of Health, National Human Genome Research Institute grant HG002273. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.   Open Access  This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not per-mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.         References     1.    Carbon S, Ireland A, Mungall CJ, Shu S, Marshall B, Lewis S, AmiGO Hub, Web Presence Working Group (2009) AmiGO: online access to ontology and annotation data. Bioinformatics 25(2):288\u2013289      2.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17         3.    Gene Ontology Consortium, Munoz-Torres MC (Corresponding Author) (2015) Gene Ontology Consortium: going forward. Nucleic Acids Res 43(Database issue):D1049\u2013D1056. doi:  10.1093/nar/gku1179          4.    Binns D, Dimmer E, Huntley R, Barrell D, O\u2019Donovan C, Apweiler R (2009) QuickGO: a web-based tool for Gen Ontology searching. Bioinformatics 25(22):3045\u20133046      5.   Xiang Z, Mungall C, Ruttenberg A, He Y (2011) Ontobee: a linked data server and browser for ontology terms. Proceedings of the 2nd international conference on biomedical ontologies (ICBO), Buffalo, NY, USA, 28\u201330 July 2011, pp 279\u2013281      6.    Mi H, Muruganujan A, Casagrande JT, Thomas PD (2013) Large-scale gene function analysis with the PANTHER classi\ufb01 cation sys-tem. Nat Protoc 8(8):1551\u20131566      7.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13      8.   Hastings J (2016) Primer on ontologies. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1       9.    Hastings J, de Matos P, Dekker A, Ennis M, Harsha B, Kale N, Muthukrishnan V, Owen G, Turner S, Williams M et al (2013) The ChEBI reference database and ontology for biologically relevant chemistry: enhancements for 2013. Nucleic Acids Res 41:D456\u2013D463        10.    Mungall C, Torniai C, Gkoutos G, Lewis S, Haendel M (2012) Uberon, an integrative multi-species anatomy ontology. Genome Biol 13:R5      11.    Cooper L, Walls RL, Elser J, Gandolfo MA, Stevenson DW, Smith B, Preece J, Athreya B, Mungall CJ, Rensing S et al (2013) The Plant Ontology as a tool for comparative plant anat-omy and genomic analyses. Plant Cell Physiol 54:e1      12.    Berardini TZ, Khodiyar VK, Lovering RC, Talmud P (2010) The Gene Ontology in 2010: How to get the GO\f160extensions and re\ufb01 nements. Nucleic Acids Res 38(Database Issue):D331\u2013D335      13.   Mungall CJ, Dietze H, Osumi-Sutherland D (2014) Use of OWL within the gene ontology. In Keet M, Tamma V (eds) Proceedings of the 11th international workshop on owl:  experiences and directions (OWLED 2014), Riva del Garda, Italy, 17\u201318 October 2014, pp 25\u201336. doi:  10.1101/010090          14.    Dietze H, Berardini TZ, Foulger RE, Hill DP, Lomax J, Osumi-Sutherland D, Roncaglia P, Mungall CJ (2014) TermGenie \u2013 a web- application for pattern-based ontology class generation. J Biomed Semantics 5:48. doi:  10.1186/2041-1480-5-48          15.   Lovering RC (2016) How does the scienti\ufb01 c community contribute to gene ontology? In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 7      16.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biol-ogy, vol 1446. Humana Press. Chapter 3      17.   Poux S, Gaudet P (2016) Best practices in manual annotation with the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 4      18.   \u0160kunca N, Roberts RJ, Steffen M (2016) Evaluating computational gene ontology anno-tations. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecu-lar biology, vol 1446. Humana Press. Chapter 8      19.   Chibucos MC, Siegele DA, Hu JC, Giglio M (2016) The evidence and conclusion ontology (ECO): supporting GO annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 18      20.   Furnham N (2016) Complementary sources of protein functional information: the far side of GO. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in  molecular biology, vol 1446. Humana Press. Chapter 19    Monica Munoz-Torres and Seth Carbon\f161    Chapter 12    Semantic Similarity in the Gene Ontology                          Catia     Pesquita        Abstract    Gene Ontology-based semantic similarity (SS) allows the comparison of GO terms or entities annotated with GO terms, by leveraging on the ontology structure and properties and on annotation corpora. In the last decade the number and diversity of SS measures based on GO has grown considerably, and their application ranges from functional coherence evaluation, protein interaction prediction, and disease gene prioritization.  Understanding how SS measures work, what issues can affect their performance and how they compare to each other in different evaluation settings is crucial to gain a comprehensive view of this area and choose the most appropriate approaches for a given application.  In this chapter, we provide a guide to understanding and selecting SS measures for biomedical researchers. We present a straightforward categorization of SS measures and describe the main strategies they employ. We discuss the intrinsic and external issues that affect their performance, and how these can be addressed. We summarize comparative assessment studies, highlighting the top measures in different settings, and compare different implementation strategies and their use. Finally, we discuss some of the extant challenges and opportunities, namely the increased semantic complexity of GO and the need for fast and ef\ufb01 cient computation, pointing the way towards the future generation of SS measures.    Key words     Gene ontology  ,   Semantic similarity  ,   Functional similarity  ,   Protein similarity  1      Introduction  The graph structure of the Gene Ontology (GO) allows the com-parison of GO terms and GO-annotated gene products by semantic similarity. Assessing similarity is crucial to expanding knowledge, because it allows us to categorize objects into kinds. Similar objects tend to behave similarly, which supports inference, a crucial task to support many applications including identifying protein\u2013protein interactions [ 1 ], suggesting candidate genes involved in diseases [ 2 ] and evaluating the functional coherence of gene sets [ 3 ,  4 ].  Semantic similarity (SS) assesses the likeness in meaning of two concepts. It has been a subject of interest to Arti\ufb01 cial Intelligence, Cognitive Science, and Psychology for the last few decades, and an important tool for Natural Language Processing. It has been used Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_12, \u00a9 The Author(s) 2017\f162in this context to perform word sense disambiguation, determining discourse structure, text summarization and annotation, informa-tion extraction and retrieval, automatic indexing, lexical selection, and automatic correction of word errors in text [ 5 ].  Sometimes, research literature uses SS, relatedness, and dis-tance as interchangeable terms, but they are in fact not identical. Semantic relatedness makes use of various relations between two concepts (i.e., hyponymic, hypernymic, meronymic, antonymic, and any kind of functional relations including has-part, is-made-of, and is-an-attribute-of). SS is more limited since it usually only makes use of hierarchical relations, such as hyponymy/hyperon-ymy (i.e., is-a), and synonymy. Most authors support that semantic distance is the opposite of similarity, but it is sometimes also used as the opposite of semantic relatedness.  The basis for much of the earlier research in SS is the WordNet, a large lexical database of the English language, freely available online. However, the last decade has witnessed an explosion in the number of applications of SS to biomedical ontologies, and speci\ufb01 -cally in the GO [ 6 ]. The GO structure provides meaningful links between GO terms, based on the various relationships it estab-lishes. This structure allows us to capture the similarity between GO terms. In general, the closer two terms are in the GO graph, the more similar their meaning is. Moreover, we can also deter-mine the similarity between two GO-annotated gene products by expanding on this notion to compare sets of GO terms. This pro-vides a measure of the functional similarity between two proteins, which has numerous applications in biomedical research.  The remainder of this chapter provides an overview of SS between GO terms and gene products annotated with GO terms, the different kinds of approaches used in this research area, the issues that affect their performance and evaluation and challenges and future directions.  2    SS Measures  A SS measure can be de\ufb01 ned as a function that, given two ontology terms or two sets of terms annotating two entities, returns a numer-ical value re\ufb02 ecting the closeness in meaning between them [ 7 ]. For a theoretical framework for SS measures please refer to [ 8 ], where the core elements shared by most SS measures are identi\ufb01 ed and a foundation for the comparison, selection, and development of novel measures is laid out.  In the context of GO, SS measures can be applied to compute the similarity between two GO terms,  term similarity , or to compute the similarity between two gene products each annotated with a set of GO terms,  gene product similarity . Catia Pesquita\f163 In recent years there have been several categorizations of SS measures [ 7 ,  9 ], and we advise readers to refer to both surveys for a more detailed classi\ufb01 cation and survey of SS measures and their applications.    When considering SS between concepts organized in a taxonomy, as is the case of GO, there are two basic approaches: internal methods based on ontology structure and external methods based on external corpora.  The simplest structural methods calculate distance between two nodes as the number of edges in the path between them [ 10 ]. If there are multiple paths, the shortest path or an average of all pos-sible paths can be used. For instance, in Fig.  1 , the distance between  heme binding  and  anion binding  is 5. This measure depends only on the structure of the graph and it assumes that all semantic links have the same weight. Accordingly, SS is de\ufb01 ned as the inverse score of the semantic distance. This edge-counting approach is intuitive and simple but disregards the depth of the nodes, since it considers 2.1  Term Similarity  Fig. 1    Subgraph of GO covering the annotations of hemoglobin subunit alpha and hemocyanin II proteins. The number of gene products annotated to each term in GOA (January, 2016) are indicated by  n         Semantic Similarity in GO\f164paths of equal length to equate to the same degree of similarity, regardless if they occur near the root or deeper in the ontology. For instance, in Fig.  1 , the classes  transport  and  binding  are at a distance of two edges, the same distance that separates  iron ion binding  and  copper ion binding .   To overcome this limitation of equal distance edges, some approaches give edges different weights to re\ufb02 ect some degree of hierarchical depth. It is intuitive that the deeper the level in the taxonomy, the smaller the conceptual distance, so weights are reduced according to depth. Other factors can be used to deter-mine weights for edges such as node density and type of link.  However these methods have two important limitations, they rely heavily on the assumption that nodes and edges in an ontology are uniformly distributed and that nodes at the same level corre-spond to the same semantic distance, which are untrue in the case of GO. For instance, in Fig.  1 , although  oxygen binding  and  ion bind-ing  are both at a depth of 2, the former is a more speci\ufb01 c concept and is actually a leaf node. More recent approaches attempt at miti-gating some of these issues using for instance the depth of the lowest common ancestor (LCA) [ 11 ], distance to nearest leaf node [ 12 ], and depth of distinct GO subgraphs [ 1 ]. Related approaches, also based on the structure of the ontology, combine distance metrics with node structural properties, such as number of subclasses and distance to the lowest common ancestor between the terms [ 13 ].  External methods typically make use of information-theoretic principles. This type of approach has been demonstrated to be less sensitive or not at all to the issue of link density variability [ 14 ], i.e., that the ontology graph may be unbalanced and edges linking nodes may not be evenly distributed, so that the same depth or distance indicate a different level of speci\ufb01 city or similarity. Information content (IC)-based measures are based on the intu-ition that the similarity between two concepts can be given by the extent to which they share information.  The IC of a concept  c  is a measure of how likely the concept is to occur, which can be quanti\ufb01 ed as the negative log likelihood,  \u2212log p(c)  where  p(c)  is the probability of occurrence of  c  in a spe-ci\ufb01 c corpus, usually estimated by the annotation frequency in the Gene Ontology Annotation database. A normalized version of IC was introduced in [ 15 ], whereby IC values are expressed in a range of uniformly scaled values, making them easier to interpret. Taking Fig.  1  again as an example, the frequency of annotation of  binding  is 750,325/1,948,009, making its IC 1.38 and its nor-malized IC 0.066.  When the concept of IC is applied to the common ancestors two terms have, it can be used to quantify the information they share and thus measure their SS. There are two main approaches for doing this: the most informative common ancestor (MICA technique), in which only the common ancestor with the highest Catia Pesquita\f165IC is considered [ 14 ]; and the disjoint common ancestors (DCA technique), in which all disjoint common ancestors (the common ancestors that do not subsume any other common ancestor) are considered. There are several methods to compute the DCA [ 16 \u2013 18 ], which allow IC-based measures to take into account multiple common ancestors.  Several measures have been used to measure the information shared by two GO terms. The simplest of these measures, Resnik\u2019s, takes the IC of the MICA as the similarity between two terms, and was among the \ufb01 rst to be applied to GO [ 19 ]. The MICA of  chlo-ride ion binding  and  iron ion binding  is  ion binding , making the Resnik similarity between these terms to be 0.066. Other measures combine the IC of terms with the IC of the MICA and weight them according to the MICA\u2019s IC [ 20 ].  More recently, hybrid measures that combine both edge and IC-based strategies have been proposed [ 21 ]. Corpus-independent IC measures have also been proposed, based on number of descen-dants [ 22 ], depth and descendants [ 23 ] and on the notion of entropy [ 24 ].     Since gene products can be annotated with several GO terms within each of the three GO categories, gene product SS measures need to compare sets of terms rather than single terms. Several approaches have been proposed for this, most following one of two strategies: pairwise or groupwise.  Pairwise approaches take the individual similarities between all terms annotating two gene products and combine them into a global measure of functional similarity. Any term similarity mea-sure can be applied with this strategy, where each gene product is represented by its set of direct annotations. Typical combination strategies include the average, maximum, or sum, and these can be applied to every pairwise combination of terms from the two sets or only the best-matching pair for each term.  Groupwise approaches calculate gene product similarity directly by one of three approaches: set, graph, or vector. Set approaches consider only direct annotations and are calculated using set similar-ity techniques. Set-based measures are limited in that they do not take into account the shared ancestry between GO terms. Graph approaches represent gene products as the subgraphs of GO corre-sponding to all their annotations. Functional similarity is then calcu-lated either using graph-matching  techniques or by less computationally intensive approaches such as set similarity. This approach takes into account all annotations (direct and inherited) providing a more comprehensive model of the annotations. Vector approaches represent gene products in vector space, with each term corresponding to a dimension, and functional similarity is calculated using vector similarity measures. Groupwise approaches can also make use of the IC of terms, by using it to weigh set similarity 2.2  Gene Product SimilaritySemantic Similarity in GO\f166computations, such as simGIC [ 15 ], which compares two sets of terms based on a IC-weighted Jaccard similarity; as scalar values in vectors, such as IntelliGO [ 25 ], which combines IC and the evidence content of annotations; or to compute the IC of shared subgraphs, such as the SS measure proposed in [ 14 ].   3    Issues and Challenges in SS  Guzzi et al. [ 9 ] have identi\ufb01 ed several issues affecting SS measures, which they categorize into external issues, which are usually related to annotation corpora, and internal issues, inherent to the design of the measures. They do however recognize that both kinds of issues can be entangled, for instance when measures make errone-ous assumptions about the corpora.  The most relevant external issues are the shallow annotation problem, the annotation length bias, and the use of Evidence Codes. The shallow annotation problem stems from the fact that many proteins are only annotated to very general GO terms, thus for instance two proteins can share 100 % of their terms and still be very dissimilar. SS measures need to account for this issue, which can be especially relevant in the electronic annotations. Nevertheless, the quality and speci\ufb01 city of these annotations has been increasing over the years [ 26 ].  The annotation length bias refers to the positive correlation between SS scores and the number of annotations that some mea-sures produce. This is due to the fact that annotations are not uni-formly distributed among the proteins within an annotation corpus (and also vary among different organisms corpora), with some pro-teins being very well annotated while others have a single annota-tion. Both of these issues stem from incomplete annotations, which have been shown to have a signi\ufb01 cant impact in the performance of information-theoretic measures [ 27 ]. Finally, SS approaches need to be aware of the impact that using electronic annotations (evi-dence code IEA) can have. 1  Although in general the use of IEA annotations has a positive or null effect on the measures perfor-mance, in some cases and particularly when employing the maxi-mum  combination approach over pairwise similarities it can have a detrimental effect and decrease the measure\u2019s ability to capture similarity as conveyed by evaluation metrics [ 9 ,  17 ].  There are three levels at which internal issues can occur: term speci\ufb01 city, term similarity, and gene product similarity. At the term speci\ufb01 city level, both typically used approaches (term depth and IC) have their advantages and drawbacks. IC-based measures can be affected by the corpus bias effect [ 29 ] whereby rarely used but generic terms possess a high IC but are not biologically speci\ufb01 c. 1   Please  see  Chap. 3 [28] for more information on evidence codes. Catia Pesquita\f167This issue is particularly relevant when using speci\ufb01 c corpora that may be incomplete. Term depth measures on the other hand, while being independent of annotation corpora, are unable to handle the fact that terms at the same depth rarely have the same biological speci\ufb01 city, given the fact that GO\u2019s regions have vary-ing node and edge density.  At the term similarity level, distance-based measures suffer from the same issues as term depth term speci\ufb01 city. Moreover, since most measures rely on the concept of common ancestors to measure similarity between two terms, SS measures need to de\ufb01 ne the set of common ancestors over which similarity is computed. While the most informative common ancestor (or lowest common ancestor in the case of edge-based measures) is commonly used and usually provides good performance, it has been argued that measures taking into account all ancestors or a selection of them can more adequately portray the whole gamut of function.  At the gene product similarity level, and in particular for pair-wise measures, special care needs to be taken when choosing a com-bination approach. The maximum approach is unsuitable to assess their global similarity, since it focuses on the single most similar aspect. The average approach, on the other hand, by making an all-against-all comparison of the terms of two gene products, produces counterintuitive results for gene products with multiple distinct functional aspects. For instance, two gene products both annotated with the same two unrelated terms,  t1  and  t2 , will be 50 % similar under the average approach, because similarity will be calculated between both the matching ( t1\u2013t1 , t2\u2013t2 ) and the oppo-site ( t1\u2013t2 , t2\u2013t1 ) terms of the two gene products. The best-match approach would rely on comparing just ( t1\u2013t1,t2\u2013t2 ), since these are the best- matching term pairs in the annotations set. The best-match average approach generally provides a better performance by considering all terms but only the most signi\ufb01 cant matches.  4    Evaluating and Comparing SS Measures  Evaluating the reliability of SS measures or determining the best measure for each application scenario is still an open question since there is no gold standard. Furthermore, each of the existing mea-sures formalizes the notion of function similarity in slightly differ-ent ways and for that reason it is not possible to de\ufb01 ne what the best SS measure would be, since it becomes a subjective decision. Ultimately, SS measures attempt to capture functional similarity based on GO annotations, so one possible solution is to compare SS measures to other measures or proxies of functional similarity. These include sequence similarity, family similarity, protein\u2013pro-tein interactions, functional modules and complexes, and expres-sion pro\ufb01 le similarity. Table  1  details the best performing measures Semantic Similarity in GO\f168for each aspect according to a recent survey of literature. Although more classic measures of SS such as Resnik still provide top results in some settings, it is the newer generation of measures that pro-vides the best results. And if until recently [ 9 ] GOA-based IC mea-sures were regarded as the best performing measures for most settings, the new wave of more complex structural-based measures, such as SSDD [ 13 ], SORA [ 23 ] and TCSS [ 1 ] are now on the lead, though closely followed by SimGIC. SSDD is based on the concept of semantic \u201ctotipotency\u201d whereby terms are assigned val-ues according to their distance to the root and the number of descendants for each of the levels in that path, and then similarity corresponds to the smallest sum of \u201ctotipotencies\u201d along a path between two terms. SORA uses an IC based on structural informa-tion that considers depth and number of descendants, and then applies set similarity to gene products. TCSS divides the GO graph into subgraphs and considers gene products more similar if they belong to the same subgraph. We postulate that the recent success of structural and hybrid measures, is not only due to their ability to more accurately capture the complexity of the GO graph, but also due to the evolution of GO itself, which has grown considerably since the \u201cclassic\u201d measures were proposed. Linear correlation to sequence similarity is one of the most used measures, and in gen-eral a positive correlation between sequence and SS has been found, particularly on binned data. Nonlinear regression analysis found that the normal cumulative distribution \ufb01 ts data for many different SS measures, con\ufb01 rming the positive yet, nonlinear agree-ment between sequence and SS [ 15 ]. Linear correlation has also been used to compare SS to Pfam-based and Enzyme Commission Class similarity.   One of the most relevant efforts in this area is the Collaborative Evaluation of Semantic Similarity Measures (CESSM) tool [ 30 ], which was created in 2009 to answer this need. It enables the    Table 1    Best performing SS measures according to different protein similarity measures or proxies. Sequence, Pfam, and ECC similarity correspond to correlation evaluated using CESSM    Similarity proxy or measure  Best performing SS measures  Sequence similarity  SSDD [ 13 ], SimGIC [ 15 ], HRSS [ 21 ]  Pfam similarity  SORA [ 23 ], SSDD, SimGIC  ECC similarity  SSDD, HRSS, SORA  Expression similarity  TCSS [ 1 ], SimGIC, SimIC, Best-Match-Avg (Resnik [ 15 ])  Protein\u2013protein interaction  TCSS, SimIC, Max(Resnik)   Results compiled from refs.  9 ,  13 ,  21 ,  23 ,  30   Catia Pesquita\f169comparison of new GO-based SS measures against previously pub-lished ones considering their relation to sequence, Pfam, and Enzyme Commission Class (ECC) similarity. Since its inception, CESSM has been adopted by the community and used to evaluate several novel SS measures.  The predictive power of SS measures in identifying protein\u2013protein interactions is also commonly employed in SS evaluation [ 9 ]. In general SS measures are good predictors of PPI, but the most effective are groupwise or maximum combination approach measures. This is unsurprising given that proteins can interact when sharing a single functional aspect.  5    Tools  There are two main kinds of available tools to compute SS mea-sures in GO: webservers, which typically provide easy to use solu-tions with fewer parametrizations possible; and software packages, which are more customizable, though more complex to use.  Many of the recently proposed SS measures provide speci\ufb01 c webservers, but some online tools provide a wider array of mea-sures, such as ProteInOn [ 31 ], FunSimMat [ 32 ], or GOssToWeb [ 33 ]. These tools rely on their own GO and GOA versions, and though they can output similarity scores with an input of just GO terms or Uniprot accession numbers, these scores are based on the tool\u2019s ontology and annotation versions.  If a user needs more control over the parametrization of the input data, then the best option is to employ a software package. Options include R packages (e.g., GoSemSim [ 34 ]) or standalone programs (GOssTo [ 33 ]), which give the user more freedom in terms of ontology and annotation versions as well as in programmatic access or the computation of SS for larger datasets. A Java library has been recently developed for ontology-based SS calculations [ 35 ], which includes over 50 different SS measures and accepts input ontologies in a number of formats, including OWL, OBO, and RDF. This library is well suited for large input datasets, being able to run over 100 million comparisons in under 1 h. In the case of webt-ools, we advise readers to check their update frequency to ensure that recent versions of GO and the annotations are in use.  6    Challenges and Future Directions  The last decade has witnessed a growing interest in GO-based SS, with dozens of new measures being proposed and applied in different settings. Although measures have become increasingly sophisti-cated, there remain several challenges and opportunities. Semantic Similarity in GO\f170 GO-based SS measures are inherently dependent on GO\u2019s development and its use in annotations. Measures should evolve with GO, striving to provide ever more accurate metrics for gene product functional similarity. In recent years there have been several developments of GO which SS measures are still not explor-ing. For instance, the different kinds of regulatory and occurrence relationships, the categorization of evidence codes, logical de\ufb01 ni-tions and internal and external cross-products, can all in principle be explored by SS approaches.  The need to provide more semantically sound measures of SS for biomedical ontologies has been argued [ 36 ], and though GO is commonly viewed as a DAG for a controlled vocabulary it is actu-ally well axiomatized in OWL [ 37 ]. The presence of these axioms should be considered by SS measures, and the exploration of dis-jointness in SS has been recently proposed in ChEBI [ 38 ].  In general, the computational complexity of SS measures has not been addressed. Current GO-based SS applications happen in an of\ufb02 ine context where computational speed is not a relevant factor. However, for applications such as similarity-based search, which so far are based on precomputed similarities [ 32 ], perfor-mance should be taken into consideration. In addition, the growth in size of biomedical datasets spurred by genomic scale studies in the last few years, also places further computational constraints on SS measures. The challenge of handling very large datasets is increasingly recognized, and recent implementations of SS mea-sures allow for parallel computation [ 35 ], but the development of SS measures is not taking this issue into consideration  a priori.   The next generation of SS measures should take into account these two aspects, on one hand, the possibility for increased com-plexity in SS measures to provide more accurate similarity scores, and on the other the need for ef\ufb01 cient SS computation, and strive to achieve a balance between increased accuracy and ef\ufb01 ciency.  7    Exercises  Consider the subgraph of GO represented in Fig.  1  and the num-ber of annotations for each GO term it shows.    1.    Calculate the IC of the term \u201cheme binding\u201d considering that the total universe of annotations corresponds to the number of annotations to the root term.      2.    Transform the IC value calculated in 1 to a uniform scale [0,1]. Consider that the maximum IC is given to a term with a single annotated gene product, and an IC of zero corresponds to the IC of the root term, \u201cmolecular function.\u201d      3.    Calculate the SS between the terms \u201cchloride ion binding\u201d and \u201ciron ion binding,\u201d and \u201coxygen transporter activity,\u201d and Catia Pesquita\f171\u201ctetrapyrrole binding,\u201d following the minimum edge distance measure.      4.    Calculate Resnik\u2019s SS between the same terms as in c.      5.    Calculate the similarity between the protein  hemoglobin subunit alpha  annotated with [ion iron binding, copper ion binding, pro-tein binding, heme binding, oxygen binding, oxygen transporter activity], and the protein  hemocyanin II  annotated with [chloride ion binding, copper ion binding, oxygen transporter activity]:   (a)    Using the average of all pairwise Resnik\u2019s similarities     (b)    Using the maximum of all pairwise Resnik\u2019s similarities     (c)    Using the simGIC measure, which corresponds to the ratio between sum of the IC of the shared terms between the two proteins and the sum of the IC of the union of all terms between the two proteins.     (d)    Compare the obtained results with your perception of the actual functional similarity between the two proteins.               Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not per-mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.     References        1.    Jain S, Bader GD (2010) An improved method for scoring protein-protein interactions using semantic similarity within the gene ontology. BMC Bioinformatics 11(1):562      2.    Li X, Wang Q, Zheng Y, Lv S, Ning S, Sun J, Li Y (2011) Prioritizing human cancer microR-NAs based on genes\u2019 functional consistency between microRNA and cancer. Nucleic Acids Res 39(22):e153      3.    Richards AJ, Muller B, Shotwell M, Cowart LA, Rohrer B, Lu X (2010) Assessing the functional coherence of gene sets with metrics based on the Gene Ontology graph. Bioinformatics 26(12):i79\u2013i87      4.    Bastos HP, Clarke LA, Couto FM (2013) Annotation extension through protein family annotation coherence metrics. Front Genet 4:201      5.   Budanitsky A, Hirst G (2001) Semantic dis-tance in WordNet: an experimental, application- oriented evaluation of \ufb01 ve measures. In Workshop on WordNet and other lexical resources, vol 2, pp 2\u20132  Semantic Similarity in GO\f172    6.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Sherlock G et al (2000) Gene ontology: tool for the uni\ufb01 cation of biol-ogy. Nat Genet 25(1):25\u201329       7.    Pesquita C, Faria D, Falcao AO, Lord P, Couto FM (2009) Semantic similarity in bio-medical ontologies. PLoS Comput Biol 5(7):e1000443      8.    Harispe S, S\u00e1nchez D, Ranwez S, Janaqi S, Montmain J (2014) A framework for unifying ontology-based semantic similarity measures: a study in the biomedical domain. J Biomed Inform 48:38\u201353           9.    Guzzi PH, Mina M, Guerra C, Cannataro M (2012) Semantic similarity analysis of protein data: assessment with biological features and issues. Brief Bioinform 13(5):569\u2013585      10.    Rada R, Mili H, Bicknell E, Blettner M (1989) Development and application of a metric on semantic nets. IEEE Trans Syst Man Cybernet 19(1):17\u201330      11.    Yu H, Gao L, Tu K, Guo Z (2005) Broadly predicting speci\ufb01 c gene functions with expres-sion similarity and taxonomy similarity. Gene 352:75\u201381      12.    Cheng J, Cline M, Martin J, Finkelstein D, Awad T, Kulp D, Siani-Rose MA (2004) A knowledge-based clustering algorithm driven by gene ontology. J Biopharm Stat 14(3):687\u2013700         13.    Xu Y, Guo M, Shi W, Liu X, Wang C (2013) A novel insight into Gene Ontology semantic similarity. Genomics 101(6):368\u2013375        14.    Resnik P (1999) Semantic similarity in a tax-onomy: an information-based measure and its application to problems of ambiguity in natural language. J Artif Intell Res (JAIR) 11:95\u2013130          15.    Pesquita C, Faria D, Bastos H, Ferreira AE, Falc\u00e3o AO, Couto FM (2008) Metrics for GO based protein semantic similarity: a systematic evaluation. BMC Bioinformatics 9(Suppl 5):S4      16.   Couto FM, Silva MJ, Coutinho PM (2005) Semantic similarity over the gene ontology: Family correlation and selecting disjunctive ancestors. Proceedings of the ACM conference in information and knowledge management      17.    Couto FM, Silva MJ (2011) Disjunctive shared information between ontology concepts: applica-tion to Gene Ontology. J Biomed Semantics 2:5      18.    Zhang SB, Lai JH (2015) Semantic similarity measurement between gene ontology terms based on exclusively inherited shared informa-tion. Gene 558(1):108\u2013117      19.    Lord P, Stevens R, Brass A, Goble C (2003) Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation. Bioinformatics 19:1275\u20131283      20.    Schlicker A, Domingues FS, Rahnenf\u00fchrer J, Lengauer T (2006) A new measure for func-tional similarity of gene products based on gene ontology. BMC Bioinformatics 7:302        21.    Wu X, Pang E, Lin K, Pei ZM (2013) Improving the measurement of semantic simi-larity between gene ontology terms and gene products: insights from an edge-and IC-based hybrid method. PLoS One 8(5):e66745      22.   Seco N, Veale T, Hayes J (2004) An intrinsic information content metric for semantic simi-larity in wordnet. ECAI, pp 1089\u20131090         23.   Teng Z, Guo M, Liu X, Dai Q, Wang C, Xuan P (2013) Measuring gene functional similarity based on group-wise comparison of GO terms. Bioinformatics:btt160      24.   Warren A, Setubal J (2012) Using entropy esti-mates for DAG-based ontologies. In Proceedings of the 15th bio-ontologies special interest group meeting of ISMB 2012      25.    Benabderrahmane S, Smail-Tabbone M, Poch O, Napoli A, Devignes MD (2010) IntelliGO: a new vector-based semantic similarity mea-sure including annotation origin. BMC Bioinformatics 11(1):588      26.    \u0160kunca N, Altenhoff A, Dessimoz C (2012) Quality of computationally inferred gene ontology annotations. PLoS Comput Biol 8(5):e1002533      27.    Jiang Y, Clark WT, Friedberg I, Radivojac P (2014) The impact of incomplete knowledge on the evaluation of protein function predic-tion: a structured-output learning perspective. Bioinformatics 30(17):i609\u2013i616     28.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3      29.    Mistry M, Pavlidis P (2008) Gene ontology term overlap as a measure of gene functional similarity. BMC Bioinformatics 9:327       30.   Pesquita C, Pessoa D, Faria D, Couto F (2009) CESSM: collaborative evaluation of semantic similarity measures. In: JB2009: challenges in bioinformatics, vol 157, p 190      31.   Faria D, Pesquita C, Couto FM, Falc\u00e3o A (2007) Proteinon: a web tool for protein semantic similarity. Department of Informatics, University of Lisbon       32.    Schlicker A, Albrecht M (2008) FunSimMat: a comprehensive functional similarity data-base. Nucleic Acids Res 36(Suppl 1):D434\u2013D439  Catia Pesquita\f173     33.    Caniza H, Romero AE, Heron S, Yang H, Devoto A, Frasca M et al (2014) GOssTo: a stand-alone application and a web tool for cal-culating semantic similarities on the Gene Ontology. Bioinformatics 30(15):2235\u20132236      34.    Yu G, Li F, Qin Y, Bo X, Wu Y, Wang S (2010) GOSemSim: an R package for measuring semantic similarity among GO terms and gene products. Bioinformatics 26(7):976\u2013978       35.    Harispe S, Ranwez S, Janaqi S, Montmain J (2014) The semantic measures library and toolkit: fast computation of semantic similarity and relatedness using biomedical ontologies. Bioinformatics 30(5):740\u2013742      36.    Couto FM, Pinto HS (2013) The next  generation of similarity measures that fully explore the semantics in biomedical ontolo-gies. J Bioinforma Comput Biol 11(05):1371001      37.   Mungall CJ, Dietze H, Osumi-Sutherland D (2014) Use of OWL within the Gene Ontology. Proceedings of the 11th international work-shop on OWL: experiences and directions. Riva del Garda, Italy, 2014      38.    Ferreira JD, Hastings J, Couto FM (2013) Exploiting disjointness axioms to improve semantic similarity measures. Bioinformatics 29(21):2781\u20132787    Semantic Similarity in GO\fChapter 13</p> <p>Gene-Category Analysis</p> <p>Sebastian Bauer</p> <p>Abstract</p> <p>Gene-category analysis is one important knowledge integration approach in biomedical sciences that com- bines knowledge bases such as Gene Ontology with lists of genes or their products, which are often the result of high-throughput experiments, gained from either wet-lab or synthetic experiments. In this chapter, we will motivate this class of analyses and describe an often used variant that is based on Fisher\u2019s exact test. We show that this approach has some problems in the context of Gene Ontology of which users should be aware. We then describe some more recent algorithms that try to address some of the shortcomings of the standard approach.</p> <p>Key words Enrichment, Overrepresentation, Knowledge integration, Fisher\u2019s exact text, Gene prop- agation problem</p> <p>1</p> <p>Introduction</p> <p>The  result  of  biological  high-throughput  methods  is  often  a  list consisting of several hundreds of biological entities, which are in case of gene expression profiling experiments identifiers of genes or their products. As a biological entity may have different context- specific  functions,  it  is  difficult  for  humans  to  interpret  the  out- come of an experiment on the basis of such a list. Computational approaches  to  access  the  biological  knowledge  about  features  of biological entities therefore play an important part in the successful realization of research based on high-throughput experiments. A practical way to address the question of what is going on? is to per- form a gene-category analysis, i.e., to ask whether these responder genes share some biological features that distinguish them among the set of all genes tested in the experiment.</p> <p>First of all, gene-category analysis involves a list of gene catego- ries, in which genes with similar features are grouped together. The exact definition of the attribute similar depends on the provider of  the  categories.  For  instance,  if  Gene  Ontology  is  the  choice, then genes usually are grouped according to the terms, to which they  are  annotated.  Another  scheme  is  the  KEGG   database  [1],</p> <p>Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446, DOI 10.1007/978-1-4939-3743-1_13, \u00a9 The Author(s) 2017</p> <p>175</p> <p>176</p> <p>Sebastian Bauer</p> <p>2</p> <p>Fisher\u2019s Exact Test</p> <p>in  which  genes  are  grouped  according  to  the  pathways  in  which they are involved. The second ingredient is a statistical method for identifying the really interesting categories.</p> <p>In this chapter, we introduce some commonly used approaches for gene-category analysis. Throughout the remainder of this chap- ter, we refer to the set of items, which a study could possibly select, as the population set. We denote this set by the uppercase letter M while the size of the set, or its cardinality, is identified by its lower- case  variant  m.  If,  for  example,  a  microarray  experiment  is  con- ducted, the population set will comprise all genes whose expression can be measured with the microarray chip. The actual outcome of the study is referred to as the study set. It is denoted by N and has the cardinality n. In the microarray scenario the study set could consist of all genes that were detected to be differentially expressed.</p> <p>One approach for gene-category analysis is to cast the problem as a statistical test. For this purpose, the study set is assumed to be a random sample that is obtained by drawing n items without replacement from the population. The population is dichotomic as the items can be characterized according to whether they are annotated to term t or not. In particular, the set Mt with cardi- nality  mt  constitutes  all  items  that  are  annotated  to t.  Denote the random variable that describes the number of items of the study  set  that  are  annotated  to t  in  this  random  sample  as Xt. The  hypergeometric distribution applies to Xt, and the proba- bly of observing exactly k items annotated to t, i.e., P(Xt = k) is specified by</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/#of-ways-of-choosing-the-remaining","title":"of ways of choosing the remaining","text":"<p>k items that are not annotated to t</p> <p>\u2212</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/#of-ways-of-choosing-k-items-among-all","title":"of ways of choosing k items among all","text":"<p>items annotated to t</p> <p>n</p> <p>Xt</p> <p>\u223c</p> <p>h(k</p> <p>|</p> <p>m; mt; n) := P (Xt = k) =</p> <p>(cid:31)</p> <p>mt k</p> <p>\u2212 \u2212</p> <p>(cid:30)</p> <p>.</p> <p>mt k (cid:30)(cid:31)</p> <p>m n m n (cid:30)</p> <p>(cid:31)</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/#of-ways-of-choosing-n-items-among-m","title":"of ways of choosing n items among m","text":"<p>Furthermore, the set of items that are annotated to t and mem- bers  of  the  study  set  are  denoted  by  Nt  with  cardinality  nt.  The objective is to assess whether the study set is enriched for term t, i.e., whether the observed nt is higher than one would expect. This forms the alternative hypothesis H1 of the statistical test. The null hypothesis  H0  in  this  case  is  that  there  is  no  positive  association between the observed occurrence of the items in the study set and the annotations of the items to the term t. Thus, the proportion of</p> <p>Gene-Category Analysis</p> <p>177</p> <p>items annotated to term t is approximatively identical for the study set and the population set. In order to be able to reject H0 in sup- port of H1 we conduct a one-tailed test, in which we ask for the probability  of  the  event  that  we  see  nt  or  more  annotated  items given that H0 is true:</p> <p>tft = p t</p> <p>\u00b3 P X n H</p> <p>(</p> <p>|</p> <p>t</p> <p>t</p> <p>)</p> <p>=</p> <p>0</p> <p>min(</p> <p>m t</p> <p>m ,,</p> <p>)</p> <p>\u00e5</p> <p>= k n t</p> <p>m t k</p> <p>\u00e6 \u00e7 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>.</p> <p>- m m \u00e6 t \u00e7 - n k \u00e8 m \u00e6 \u00e7 n \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>(1)</p> <p>If the probability obtained by this equation1 is below a certain significance level \u03b1, e.g., \u03b1 &lt; 0. 05, we reject H0 in favor of H1. In that case, the tested term t is regarded as an interesting term that contributes to the characterization of the study set.</p> <p>Example  2.1.  Suppose  that  we  are  given  a  population  of  m  =  18 genes, of which mt = 4 genes are annotated to a term t. The outcome of an experiment yields a study set of 5 differentially expressed genes. A total of nt = 3 genes from the genes of the study set are annotated to t. Figure 1 illustrates the participating sets and how they are related to one another in that particular situation.</p> <p>In order to check whether term t can be used to characterize the experiment, we ask whether term t is overrepresented in the study set. The application of Eq. 1 yields a p-value for t</p> <p>tft = p t</p> <p>P X (</p> <p>t</p> <p>\u00b3</p> <p>3</p> <p>|</p> <p>H</p> <p>)</p> <p>=</p> <p>0</p> <p>\u00e6 \u00e7 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>4 \u00f6 \u00e6 \u00f7 \u00e7 3 \u00f8 \u00e8 18 \u00e6 \u00e7 5 \u00e8</p> <p>14 2 \u00f6 \u00f7 \u00f8</p> <p>+</p> <p>\u00e6 \u00e7 \u00e8</p> <p>\u00f6\u00f6 \u00f7 \u00f8</p> <p>4 \u00f6 \u00e6 \u00f7 \u00e7 4 \u00f8 \u00e8 18 \u00e6 \u00e7 5 \u00e8</p> <p>14 1 \u00f6 \u00f7 \u00f8</p> <p>=</p> <p>0 044</p> <p>.</p> <p>.</p> <p>Thus, the null hypothesis is rejected and the term is said to be overrep- resented among the differentially expressed genes and is thus likely to reflect an association between the term and the experiment.</p> <p>3</p> <p>Multiple Testing Problem</p> <p>In hypothesis-generating studies it is a priori not clear, which terms should be tested. Therefore, the procedure is not only conducted using a single term but also applied to many, often all terms that Gene Ontology provides and to which at least one gene is anno- tated. The result of the entire analysis is then a list of terms that were found to be significant. This, however, implies that the num- ber of false-positive terms is high.</p> <p>1  The superscript tft in pt this p-value with other measures that are described later.</p> <p>tft stands for term-for-term. It allows to distinguish</p> <p>178</p> <p>Sebastian Bauer</p> <p>16</p> <p>5 5</p> <p>3</p> <p>15</p> <p>1</p> <p>14</p> <p>4</p> <p>17</p> <p>7</p> <p>mt</p> <p>6</p> <p>8</p> <p>9 nt</p> <p>10 10</p> <p>11</p> <p>18</p> <p>13</p> <p>12</p> <p>study: n</p> <p>population: m</p> <p>2</p> <p>Fig.  1  Sets  and  their  relations  in  the  standard  approach.  In  this  example  the population consists of m = 18 genes and n = 5 of them are part of the study set. Exactly mt = 4 genes of the population are annotated to term t. This term has nt = 3 genes in common with the study set. The null hypothesis of the standard approach (term-for-term) is that there is no association between the number of genes that are in the study set and the number of genes that are annotated to the term t, i.e., the study set is a random sample of the population set. We therefore would  expect  that  it  contains  the  same  proportion  of  annotated  terms  as  the population set does. The probability under the null hypothesis of the event to see at least nt genes can be assessed via Eq. 1.</p> <p>To see this, suppose that there are T tests to be performed. We assume that the null hypothesis is true for all of those tests. Before its actual determination, any p-value can be considered as a random variable as well, for which P(p \u2264 \u03b1 | H0) \u2264 \u03b1 holds [2]. This implies that it can be expected that \u03b1\u2009\u00d7\u2009T tests lead to the rejection of a null hypothesis although it is true.</p> <p>Example 3.1.  If there are 10,000 null hypotheses that are true and all of them are tested, then we expect that we reject the null hypotheses for about 500 tests. Obviously, describing the result of experiment with 500 random terms is not useful.</p> <p>Therefore,  the  result  of  a  term  enrichment  analysis  shall  be further subjected to a multiple test correction. The most simple is the Bonferroni correction [3]. Here, each p-value is simply multi- plied by the number of tests saturated at a value of 1.0. Bonferroni controls  the  so-called  family-wise  error  rate,  which  is  the  probability  of  making  one  or  more  false  discoveries.  It  is  a  very conservative approach because it handles all p-values as independent. But as we see later, this is not a typical case of gene-category analysis, so this approach often goes along with a reduced statistical power.</p> <p>Gene-Category Analysis</p> <p>179</p> <p>In contrast, the Westfall\u2013Young [4] procedure also takes depen- dencies into account. This correction, however, is computation- ally more costly as it is based on resampling schemes. In particular in the gene category setting, this scheme involves randomly sam- pling study sets of the same size as the original study set from the population. Each set is subjected to the test procedure yielding a set of p-values for each term, also referred to as the null distribu- tion of that term. By relating the original p-value to the null dis- tribution, an adjusted p-value is derived. There are other types of multiple  test  corrections  that  do  not  aim  to  control  the  family- wise  error  rate.  For  instance,  the  Benjamini\u2013Hochberg  [5] approach controls the expected false discovery rate (FDR), which is  the  proportion  of  false  discoveries  among  all  rejected  null hypotheses.  This  has  a  positive  effect  on  the  statistical  power  at the  expense  of  having  less  strict  control  over  false  discoveries. Controlling the FDR is considered by the American Physiological Society as \u201cthe best practical solution to the problem of multiple comparisons\u201d [6].</p> <p>Note  that  less  conservative  corrections  usually  yield  a  higher amount of significant terms, which may be not desirable after all. In the following section, we further explore the structural origin of the correlations of the p-values in the setting of enrichment tests for ontology terms.</p> <p>While the application of multiple testing correction aims to reduce the number of false-positives in a rather universal manner, one can also try to tackle the problem at a more basic level. The root of the problem is that if a term shares genes with a second term, and one of the terms is overrepresented, then it is not too surprising that the other term is also detected as overrepresented.</p> <p>That the gene sharing of terms of an ontology is more a rule than  an  exception  can  be  deduced  from  the  principles  of  how ontologies are designed. Within an ontology, terms describe con- cepts  of  a  domain  that  can  be  related  to  other  terms  by  various types of relationships. The most prominent relationship thereby is the is a relationship, which effectively propagates the membership of the subject (source) of the relationship to the object (destina- tion). That means, if a term T1 is related to a term T2 by the is a relationship,  and  a  gene  is  annotated  to  T1,  then  it  is  implicitly annotated also to term T2 (see Chap. 1 [7]). In the context of GO overrepresentation analysis, we refer to this as the gene propagation problem.2</p> <p>2  Note that in addition to this gene sharing that is due to the graph structure of the ontology, also unrelated terms can be annotated to similar sets of genes, for instance, if the same gene plays a role in distinct biological processes.</p> <p>4</p> <p>Gene Propagation</p> <p>180</p> <p>Sebastian Bauer</p> <p>is a</p> <p>is a</p> <p>t</p> <p>is a parent of</p> <p>s</p> <p>is a parent of</p> <p>r</p> <p>mt = 4 nt = 3 pt = 0.044</p> <p>ms = 6 ns = 4 ps = 0.022</p> <p>m = 18 n = 5</p> <p>Fig.  2  Extended  example  with  three  terms.  This  depicts  the  situation  of Example 2.1 with two more terms. Term t is a s and therefore s is a parent of t. Term r is the root of the ontology. It is the only parent of s. As indicated in the last row, the procedure based on Fisher\u2019s exact test determines a p-value below 0.05 for both terms. Thus, both terms will be considered as a meaningful summary of the underlying experiment.</p> <p>Example  4.1  (Continuation  of  Example  2.1).  There  is  another term s, which is the only parent of t. For s we know that ms = 6 and ns = 4. Figure 2 shows this structure graphically. There, it is also indi- cated that the p-values of terms t and s are 0.044 and 0.022, respec- tively, which means that both terms are considered as significant for \u03b1 &lt;  0.05  if  no  multiple  test  correction  is  performed.  Obviously,  both terms share the majority of items that are also part of the study set. One  can  argue  that  the  fact  that  term  t  is  identified  as  overrepre- sented is a consequence of the fact that s is overrepresented.</p> <p>A simple synthetic experiment, in which a term will be artifi- cially  overrepresented,  demonstrates  the  extent  of  the  problem. Let\u2019s select the term localization for this purpose. We create a study set that consists of all genes that are annotated to that term with probability  0.8.  This  corresponds  to  false-negative  rate  \u03b2 = 0. 2. Furthermore, to introduce some background noise, each gene that is not annotated to the term is added to that study set with a false- positive rate of \u03b1 = 0. 1. In this example, the procedure yields a set of 1542 genes. For each considered term, this set is subjected to Fisher\u2019s exact test resulting in a list of 4549 p-values3. Finally, the p-values are adjusted using the Bonferroni correction.</p> <p>The analysis correctly identifies the term localization as signifi- cantly enriched. In addition to that, it identifies 275 other terms as significantly enriched. In particular, 6 of the 6 children, to which at least one gene is annotated, are significant. Among the 681 possi- ble descendants of localization, we find 172 significant ones. These figures suggest that descendants come up only because their anno- tations converge in the term localization. Although, in the statistical sense, this is a correct result, it is not desirable to use that huge amount of terms to characterize the study set, especially as it is suf- ficient  to  use  the  term  localization  for  this  purpose,  and  what  is</p> <p>3</p> <p>This corresponds to the number of terms from the biological process subon- tology that are annotated by at least one gene.</p> <p>Gene-Category Analysis</p> <p>181</p> <p>more, the result suggests a specificity that we did not put in there. It makes sense to consider each of the additional 275 significant terms  as  a  false-positive  and  in  the  next  sections  we  will  briefly describe methods that attempt to reduce that number.</p> <p>5</p> <p>Parent\u2013Child Approach</p> <p>The parent\u2013child approach [8] is still based on Fisher\u2019s exact test, but the probability of t being overrepresented is conditioned on properties of the parental terms. In the following, let pa(t) be the set  of  parents  of  term  t,  which  are,  for  instance,  those  terms,  to which t is connected by a is a relation. In order to introduce the principal ideas of the parent\u2013child approaches, we initially assume that there is only a single parent of t, i.e., pa(t) = {s}.</p> <p>Instead of drawing the items from the population M, items will be drawn just from the set of items that are annotated to the parent of t, which is written as Mpa(t) and whose size is mpa(t). This consid- eration yields the following equation:</p> <p>m t k</p> <p>\u00e6 \u00e7 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>|</p> <p>pa</p> <p>( )) t</p> <p>=</p> <p>P X k t</p> <p>=</p> <p>(</p> <p>\u00f6 \u00f7 \u00f8</p> <p>.</p> <p>(2)</p> <p>- m t - k</p> <p>( ) t</p> <p>m pa n</p> <p>pa</p> <p>\u00e6 \u00e7 \u00e8 m \u00e6\u00e6 \u00e7 n \u00e8</p> <p>pa t ( )</p> <p>pa</p> <p>t ( )</p> <p>t ( ) \u00f6 \u00f7 \u00f8</p> <p>The right part of Fig. 3 shows the setting of the parent\u2013child approaches. Effectively, in the parent\u2013child approaches, we change the population that underlies Fisher\u2019s exact test to the items anno- tated to the parents. Obviously, this also alters the involved sets for the study set. As previously, we ask for the probability of seeing the observed number of items or a more extreme event:</p> <p>pc p t</p> <p>=</p> <p>\u00b3 P X n H</p> <p>(</p> <p>|</p> <p>t</p> <p>t</p> <p>m t k</p> <p>\u00e6 \u00e7 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>)( )</p> <p>pa t</p> <p>)</p> <p>=</p> <p>0</p> <p>min(</p> <p>, m m t</p> <p>\u00e5</p> <p>= k n t</p> <p>\u00f6 \u00f7 \u00f8</p> <p>.</p> <p>(3)</p> <p>- m t - k</p> <p>( ) t</p> <p>m pa n</p> <p>pa</p> <p>\u00e6 \u00e7 \u00e8 m \u00e6 \u00e7 n \u00e8</p> <p>pa</p> <p>t ( )</p> <p>pa</p> <p>t (( )</p> <p>t ( ) \u00f6 \u00f7 \u00f8</p> <p>Example 5.1 (Continuation of Example 4.1).  As shown in Fig. 2, the parent of term s is the root r of the ontology, which is always anno- tated to all genes of the population. Therefore, the p-value for s is the same  for  previous  approach  and  for  parent\u2013child  approach,  i.e., p</p> <p>However, for term t, Eq. 3 yields</p> <p>= 0 22.</p> <p>p</p> <p>pc = s</p> <p>s</p> <p>pc = p t</p> <p>\u00b3 P X n H</p> <p>(</p> <p>|</p> <p>t</p> <p>t</p> <p>\u00e6 \u00e7 \u00e8</p> <p>)0</p> <p>=</p> <p>2 1</p> <p>4 3</p> <p>\u00f6 \u00e6 \u00f7 \u00e7 \u00f8 \u00e8 6 \u00e6 \u00f6 \u00e7 \u00f7 4 \u00e8 \u00f8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>= .</p> <p>0 6</p> <p>.</p> <p>\u00f6 \u00f7 \u00f8</p> <p>\u00e6 \u00e7 \u00e8</p> <p>+</p> <p>2 0</p> <p>4 4</p> <p>\u00f6 \u00e6 \u00f7 \u00e7 \u00f8 \u00e8 66 \u00e6 \u00f6 \u00e7 \u00f7 4 \u00e8 \u00f8</p> <p>182</p> <p>Sebastian Bauer</p> <p>a</p> <p>standard</p> <p>b</p> <p>parent-child</p> <p>16 16</p> <p>5 5</p> <p>3 3</p> <p>15 15</p> <p>1 1</p> <p>14 14</p> <p>4 4</p> <p>17 17</p> <p>7 7</p> <p>mt</p> <p>6 6</p> <p>8 8</p> <p>9 9 nt</p> <p>10 10</p> <p>16 16 16</p> <p>3 3 3</p> <p>15 15 15</p> <p>1 1 1</p> <p>14 14 14</p> <p>2 2</p> <p>4 4 4</p> <p>17 17 17</p> <p>mpa(t)</p> <p>5 5 5</p> <p>7 7 7</p> <p>mt</p> <p>6 6 6</p> <p>8 8 8</p> <p>9 9 9 nt</p> <p>10 10 10</p> <p>2 2 2</p> <p>11 11</p> <p>18 18</p> <p>13 13</p> <p>12 12</p> <p>study: n</p> <p>11 11 11</p> <p>18 18 18</p> <p>13 13 13</p> <p>12 12 12</p> <p>study: n</p> <p>population: m</p> <p>population: m</p> <p>Fig. 3 Sets and their relations in the parent\u2013child approaches. Part (a) depicts the model of the term-for-term approach as it was shown in Fig. 1. This is contrasted in part (b) with the model of the parent\u2013child approaches. In this approach, we shift the focus to a smaller set of genes, for instance to the genes that are annotated to at least one of the parents of term t. In this particular situation it is the set whose size is mpa(t) = 6 with pa(t) = {s} following Example 4.1. Genes that are not part of this set do not contribute to the calculation. This has an effect on the involved proportions, and thus on the outcome of the test. Effectively, for each term, we alter the popula- tion of the association test. Eq. 2 quantifies the probability.</p> <p>Thus, the null hypothesis for term t is not rejected, which is in contrast to the result of the previous approach. Given the initial observations that the study set is already skewed to the parent s of t makes the enrich- ment  of  term  t  less  surprising,  which  the  parent\u2013child  approaches reflect by returning a higher p-value.</p> <p>If term t has more than one parent term, then it is not imme- diately apparent how to calculate mpa(t) and the observation npa(t) in Eqs. 2 and 3. In Grossmann et al. [8] we examined two variants in detail, the union and the intersection of genes that are annotated to each of the parents.</p> <p>6</p> <p>Topology-Based Algorithms</p> <p>Alexa et al. devised another method to address the gene propaga- tion problem. The authors propose calculating a score for the term that depends on the relevance of the children of the term [9]. They argue that capturing the meaning in that way is biologically more interesting as the definitions of children are more specific. Following this  argumentation,  the  authors  formulated  two  concrete  algo- rithms that try to provide a more suitable, i.e., less correlated, dis- tribution  of  terms  that  get  flagged  as  important.  While  the  first approach which they called the elim-algorithm strictly favors sig- nificance of the most specific levels of the GO graph, their second</p> <p>Gene-Category Analysis</p> <p>183</p> <p>algorithm called weight relaxes this restriction such that terms that are most significant are favored.</p> <p>As before, we understand the top of the graph as the root of the ontology, while the bottom of the graph consists of the most specific  terms.  The  idea  of  the  elim  algorithm  is  to  traverse  the graph representation of the ontology in bottom-up fashion, which, for instance, can be accomplished by utilizing the backtrack phase of a depth-first search (DFS) [10].</p> <p>The elim procedure awaits a term t as a variable parameter and returns a set of flagged genes. On its initial invocation, it begins with  the  root  of  the  ontology.  For  the  current  term  t,  we  apply Fisher\u2019s exact test in order to relate the genes of the study set to the genes of the population with respect to the genes that are anno- tated to term t. As in the parent\u2013child approaches, not all genes of the study set contribute to the calculation. For elim, a set of previ- ously determined genes is subtracted from the set of the study set before the calculation for pt is carried out. This set is constructed by recursively applying the elim procedure for all children of t and taking the union of the result. If pt is significant, we add all genes of t to the set of flagged genes. Finally, we return the set of flagged genes to the caller. Note that when the DFS reaches a leaf node of the ontology, Fisher\u2019s exact test is performed exactly as in the stan- dard approach.</p> <p>Obviously, the complexity of the algorithm is the same as the complexity of a depth-search algorithm if we assume that the num- ber of genes that are annotated to a term is constant. Note in the original  publication  of  the  elim,  the  algorithm  was  based  on  an iteration  over  the  levels  of  the  GO  DAG,  which  partitions  the nodes according to their longest distance to  the root.  The  algo- rithm as outlined here yields an equivalent result without the need to explicitly keep track of the DAG levels.</p> <p>=</p> <p>tft p t</p> <p>= 0 044 .</p> <p>Example  6.1  (Continuation  of  Example  5.1).  The  p-value  of term t matches the p-value of term t of the standard approach, i.e., elim p . As this is a significant result, at least, if correc- t tion for multiple testing is omitted, all four genes that are annotated to t are removed in the consideration of upper terms, i.e., we assume that those four genes are not annotated to them. This leaves two genes for the computation of term s, of which only one is member of the study set (Fig. 3b). With ms = 2, ns = 1, and the rest as before, Eq. 1 yields</p> <p>p</p> <p>elim = s</p> <p>P X (</p> <p>s</p> <p>\u00b3</p> <p>1</p> <p>|</p> <p>H</p> <p>)</p> <p>=</p> <p>0</p> <p>\u00e6 \u00e7 \u00e8</p> <p>16 4</p> <p>\u00f6 \u00f7 \u00f8</p> <p>\u00e6 \u00e7 \u00e8</p> <p>+</p> <p>2 1</p> <p>\u00f6 \u00e6 \u00f7 \u00e7 \u00f8 \u00e8 18 \u00e6 \u00e7 5 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>16 3</p> <p>\u00f6 \u00f7 \u00f8</p> <p>=</p> <p>0 49.</p> <p>.</p> <p>2 2</p> <p>\u00f6 \u00e6 \u00e7\u00e7 \u00f7 \u00f8 \u00e8 18 \u00e6 \u00e7 5 \u00e8</p> <p>\u00f6 \u00f7 \u00f8</p> <p>Hence, the elim method doesn\u2019t report term s as important.</p> <p>184</p> <p>Sebastian Bauer</p> <p>An equivalent characterization of the elim method is the fol- lowing:  If  a  term  t  is  identified  as  significant,  all  genes  that  are annotated to t are no longer considered in the computation of the relevance of the ancestors of t. As it was discussed in Example 2.1 at  page  2.1  and  as  can  also  be  seen  in  Fig. 2,  the  term-for-term approach assigns term s a lower p-value than it does for term t. One may conclude that it is more appropriate to take term s than to take term t in order to provide a compact description of the study set. However,  in  Example  13.6.1  we  saw  that  the  application  of  the elim method results in usage of term t to describe the outcome, which is contrary to that conclusion.</p> <p>This concern is addressed by weight method. It compares sig- nificance scores of a family terms (a parent and its child) to identify the locally most significant terms and down-weight genes in less significant neighbors. This effectively decorrelates the p-values of the related terms such that their differences are enforced while the existence of the most significant terms is still maintained.</p> <p>7</p> <p>Model-Based Approaches</p> <p>The previously described procedures that address gene propagation problem have in common that they successively test overrepresen- tation for each of the terms. They all use some form of the Fisher\u2019s exact  test.  In  contrast  to  this,  model-based  gene  set  analysis (MGSA) models the gene response in a genome-wide experiment as the result of an activation of a number of terms [11].4</p> <p>The approach is based on a model that can nicely be expressed using  a  Bayesian  network  with  three  layers  of  Boolean  random variables. The term layer consists of m Boolean nodes correspond- ing to m terms of the ontology. A term can be active or inactive. A  parameter  p,  usually  much  less  than  0.5,  represents  the  prior probability  of  a  term  being  active.  The  hidden  layer  contains  n Boolean nodes representing the n hidden state of the genes. The hidden state of a gene is a consequence of the states the terms to which the gene is annotated: The gene is on if and only if at least one term to which the gene is annotated is active, otherwise it is off.  The  third  layer,  the  observed  layer,  contains  Boolean  nodes reflecting  the  experimentally  observed  state  of  all  genes.  For instance,  in  the  setting  of  a  microarray  experiment,  the  on  state would  correspond  to  differential  expression,  and  the  off  state would correspond to a lack of differential expression of a gene. The observed  gene  state  depends  on  the  corresponding  hidden  gene state  in  a  one-to-one  fashion  with  a  false-positive  (\u03b1)  and  false- negative rates (\u03b2) that is identical and independent for all genes. A simple instance of the model is depicted in Fig. 4.</p> <p>4  We  use  the  word  term  here  because  we  primarily  work  with  GO,  but  the method can be applied to any other structured or unstructured vocabulary.</p> <p>Gene-Category Analysis</p> <p>185</p> <p>T1</p> <p>T2</p> <p>T3</p> <p>T4</p> <p>H1</p> <p>H2</p> <p>H3</p> <p>O1</p> <p>O2</p> <p>O3</p> <p>Fig. 4 The graphical representation of an MGSA network. An example structure for four terms and three genes with a possible realizations is displayed. Terms (Ti ) that constitute the first layer can be either active (light ) or inactive (dark ). Terms that are active enable the hidden state (Hj ) of all genes annotated to them, the other genes remaining off. The observed states (Oj ) of the genes are noisy obser- vations of their true hidden state. In this example, the observed states for gene 1 and 3 match the hidden state while for some unknown reasons the measurement of gene 2 doesn\u2019t correspond to the hidden state. It\u2019s a false-negative.</p> <p>The  model  describes  how  the  activity  of  terms  leads  to  the observed stats of genes. This, however, is not the direction we are interested in. We are interested in the set of terms that explain the experimentally  obtained  data  best,  and  the  mathematical  tool that can be applied to and such sets is probabilistic inference. The optimization problem that finds the term state configuration that explains  the  observed  gene  pattern  best  is  NP-hard  [12]. However, it is easily possible to find nearby solutions by sampling from the state space. This procedure additionally allows to deter- mine the so-called marginal probability for each term, which is a measure how good the particular term will explain the observed genes  with  respect  to  all  the  other  terms.  The  value  ranges between 0 and 1 with 0 being the lowest possible support and 1 being the best possible support for a term. As all terms compete with one another, the inference takes dependencies both due to gene  propagation  and  due  to  similarity  of  annotations  into account.  For  example,  if  two  unrelated  terms  are  annotated  to the same set of genes that matches the observation, the marginal probability for both terms will be 0.5. Consequently, it is advis- able  to  run  MGSA  for  each  of  the  subontologies  separately  as they are designed to express orthogonal features.</p> <p>186</p> <p>Sebastian Bauer</p> <p>8</p> <p>Gene Set Enrichment Analysis</p> <p>In addition to approaches that take a fixed subset of the population as input, procedures that take the measurements of the genes into account are also widely in use. This is attractive as it frees the inves- tigator from the need to define a sometimes arbitrary cutoff that is used to construct the study set.</p> <p>A first version of the so-called Gene Set Enrichment Analysis (GSEA) that received much attention of the scientific community was published by Mootha et al. [13]. In this approach, genes are ranked according to an interesting feature (e.g., the difference of the  mean  of  their  expression  values  for  two  experimental  condi- tions). The null hypothesis is that the genes of the interesting set (e.g., genes annotated to a term) have no association with that list, in  which  case  they  would  be  randomly  ordered.  The  alternative hypothesis is that the genes of the interesting set have an associa- tion. For instance, if the genes of the set are grouped together on the top of the list, we would tend to believe that there is such an association.</p> <p>To  capture  the  association  via  statistical  means,  the  authors proposed  a  normalized  Kolmogorov\u2013Smirnov  (KS)  test  statistic. Let ri \u2208 M be the gene of the population M that has rank i in the gene list that is sorted according to the interesting gene feature. Using the previously established notation, i.e., that m is the total number of genes and Nt is the set of cardinality nt that contains only genes that are annotated to t, the score is defined as:</p> <p>( ES N</p> <p>t</p> <p>) max</p> <p>=</p> <p>i</p> <p>i</p> <p>\u00e51</p> <p>\u00ce \u00bc { , , m</p> <p>}</p> <p>j</p> <p>=</p> <p>1</p> <p>X</p> <p>j</p> <p>with</p> <p>X</p> <p>j</p> <p>\u00ec \u00ef = - \u00ed \u00ee\u00ef</p> <p>n t - m n t</p> <p>,</p> <p>if</p> <p>\u00cf r N i</p> <p>t</p> <p>- m n t n t</p> <p>,</p> <p>ootherwise</p> <p>Thus, the score is the maximum of a running sum that is increased if the gene is annotated to t and decreased if the gene is not anno- tated to t. In order to check if the obtained score is significant, the 1, \u2026, Ntk, calculation  is  repeated  for  k  randomly  chosen  sets  Nt which all are subsets of M with size nt. The p-value for a term t is calculated as</p> <p>p t</p> <p>=</p> <p>{ | i ES N</p> <p>(</p> <p>i t</p> <p>)</p> <p>\u00b3</p> <p>( ES N</p> <p>)}</p> <p>t</p> <p>k</p> <p>.</p> <p>The  GSEA  method  went  a  slight  revision  Subramanian  et  al. [14],  where  ad-hoc  modifications  are  implemented  that  are  sup- posed  to  countervail  the  well-known  lack  of  sensitivity  of  the  KS test [15, 16].</p> <p>9</p> <p>Software</p> <p>10</p> <p>Exercises</p> <p>Gene-Category Analysis</p> <p>187</p> <p>Gene-category  analysis  is  a  very  prominent  use  case  of  Gene Ontology.  It  shouldn\u2019t  come  as  a  surprise  that  users  can  choose among a variety of software implementations that will perform this sort  of  analysis.  For  instance,  current  version  of  the  web  site  of Gene  Ontology  Consortium  (geneontology.org)  provides  access to the method of the basic Fisher\u2019s exact test directly on the front page.  There  are  also  graphical  tools  that  integrate  into  existing frameworks such as BiNGO [17], standalone graphical clients such as  Ontologizer5  [18]  or  packages  for  Bioconductor  such  as  topGo [19], mgsa [20], or gCMAP [21], just to name a few of them.</p> <ol> <li> <p>Repeat  the  random  experiment  outlined  in  the  text  that  was used  to  show  the  influence  of  the  gene  propagation.  When doing this in R/Bioconductor, it is advisable to use the GO.db and org.Sc.sgd.db packages that provide the structure and the annotations. The calculation involving the hypergeometric dis- tribution can be expressed directly in R using dhyper and phy- per. Now repeat this experiment with other approaches based on study sets that were outlined in this chapter and compare the results. For the topology-based algorithms the topGo pack- age can be used and for the model-based approach the mgsa package is well suited.</p> </li> <li> <p>Apply  the  approach  now  to  an  arbitrary  example  or  on  real</p> </li> </ol> <p>world data. Compare the results.</p> <p>Funding  Open  Access  charges  were  funded  by  the  University College London Library, the Swiss Institute of Bioinformatics, the Agassiz  Foundation,  and  the  Foundation  for  the  University  of Lausanne.</p> <p>Open  Access  This  chapter  is  distributed  under  the  terms  of  the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/),  which  permits  use, duplication,  adaptation,  distribution  and  reproduction  in  any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.</p> <p>The  images  or  other  third  party  material  in  this  chapter  are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the</p> <p>5</p> <p>http://ontologizer.de</p> <p>188</p> <p>Sebastian Bauer</p> <p>work\u2019s Creative Commons license and the respective action is not permitted  by  statutory  regulation,  users  will  need  to  obtain  per- mission from the license holder to duplicate, adapt or reproduce the material.</p> <p>References</p> <ol> <li> <p>Kanehisa  M,  Goto  S  (2000)  KEGG:  Kyoto encyclopedia  of  genes  and  genomes.  Nucleic Acids Res 28(1):27\u201330</p> </li> <li> <p>Ewens WJ, Grant GR (2005) Statistical meth- ods  in  bioinformatics:  an  introduction,  2nd edn. Springer, Berlin. ISBN 978-0387400822</p> </li> <li> <p>Abdi  H  (2007)  Bonferroni  and  Sidak  correc- tions for multiple comparisons. Sage, Thousand Oaks, CA</p> </li> <li> <p>Westfall  PH,  Young  SS  (1993)  Resampling- based multiple testing: examples and methods for P-value adjustment. Wiley, London. ISBN 978-0471557616</p> </li> <li> <p>Benjamini Y, Hochberg Y (1995) Controlling the false discovery rate: a practical and power- ful approach to multiple testing. J R Stat Soc Ser B 57:289\u2013300</p> </li> <li> <p>Curran-Everett D, Benos DJ (2004) Guidelines for reporting statistics in journals published by the  American  Physiological  Society.  Adv Physiol Educ 28:85\u201387</p> </li> <li> <p>Hastings  J  (2016)  Primer  on  ontologies.  In: Dessimoz C, \u0160kunca N (eds) The gene ontol- ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1</p> </li> <li> <p>Grossmann S, Bauer S, Robinson PN, Vingron M (2007) Improved detection of overrepresenta- tion of Gene-Ontology annotations with parent child analysis. Bioinformatics 23:3024\u20133031</p> </li> <li>Alexa  A,  Rahnenf\u00fchrer  J,  Lengauer  T  (2006) Improved  scoring  of  functional  groups  from gene  expression  data  by  decorrelating  GO graph structure. Bioinformatics 22(13):1600\u2013</li> <li>doi:10.1093/bioinformatics/btl140</li> <li> <p>Cormen  TH,  Leiserson  CE,  Rivest  RL,  Stein  C (2001) Introduction to algorithms, 2nd edn. MIT Press, Cambridge, MA. ISBN 978-0262531962</p> </li> <li> <p>Bauer  S,  Gagneur  J,  Robinson  PN  (2010) GOing Bayesian: model-based gene set analysis of  genome-scale  data.  Nucleic  Acids  Res 38(11):3523\u20133532</p> </li> <li> <p>Bauer  S  (2012)  Algorithms  for  knowledge</p> </li> </ol> <p>integration in biomedical sciences. PhD thesis</p> <ol> <li> <p>Mootha  VK,  Lindgren  CM,  Eriksson  K-F, Subramanian A, Sihag S, Lehar J, Puigserver P,  Carlsson  E,  Ridderstr\u00e5le  M,  Laurila  E, Houstis N, Daly MJ, Patterson N, Mesirov JP, Golub TR, Tamayo P, Spiegelman B, Lander ES,  Hirschhorn  JN,  Altshuler  D,  Groop  LC (2003) PGC-1\u03b1-responsive genes involved in oxidative  phosphorylation  are  coordinately downregulated in human diabetes. Nat Genet 34(3):267\u2013273. doi:10.1038/ng1180</p> </li> <li> <p>Subramanian  A,  Tamayo  P,  Mootha  VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A,  Pomeroy  SL,  Golub  TR,  Lander  ES, Mesirov JP (2005) Gene set enrichment analy- sis: a knowledge-based approach for interpret- ing  genome-wide  expression  profiles.  Proc Natl  Acad  Sci  USA  102(43):15545\u201315550. doi:10.1073/pnas.0506580102</p> </li> <li> <p>Mason DM, Schuenemeyer JH (1983) A mod- ified Kolmogorov-Smirnov test sensitive to tail alternatives. Ann Stat 11(3):933\u2013946</p> </li> <li> <p>Irizarry  RA,  Wang  C,  Zhou  Y,  Speed  TP (2009)  Gene  set  enrichment  analysis  made simple. Stat Methods Med Res 18(6):565\u2013575. ISSN 1477-0334</p> </li> <li> <p>Maere S, Heymans K, Kuiper M (2005) Bingo: a cytoscape plugin to assess overrepresentation of gene ontology categories in  biological net- works. Bioinformatics 21:3448\u20133449</p> </li> <li> <p>Bauer S, Grossmann S, Vingron M, Robinson PN (2008) Ontologizer 2.0\u2013a multifunctional tool for go term enrichment analysis and data exploration.  Bioinformatics  24(14):1650\u2013</p> </li> <li>doi:10.1093/bioinformatics/btn250</li> <li> <p>Alexa  A,  Rahnenf\u00fchrer  J  (2010)  topGO: enrichment  analysis  for  Gene  Ontology.  R package version 2.22.0</p> </li> <li> <p>Bauer  S,  Robinson  NP,  Gagneur  J  (2011) for</p> </li> </ol> <p>Set  Analysis</p> <p>Model-based  Gene Bioconductor. Bioinformatics 27</p> <ol> <li>Sandmann  T,  Kummerfeld  SK,  Gentleman  R, Bourgon  R  (2014)  gcmap:  user-friendly  con- nectivity  mapping  with  r.  Bioinformatics 30(1):127\u2013128</li> </ol> <p>189    Chapter 14    Gene Ontology: Pitfalls, Biases, and Remedies                          Pascale     Gaudet      and     Christophe     Dessimoz        Abstract    The Gene Ontology (GO) is a formidable resource, but there are several considerations about it that are essential to understand the data and interpret it correctly. The GO is suf\ufb01 ciently simple that it can be used without deep understanding of its structure or how it is developed, which is both a strength and a weakness. In this chapter, we discuss some common misinterpretations of the ontology and the annotations. A better understanding of the pitfalls and the biases in the GO should help users make the most of this very rich resource. We also review some of the misconceptions and misleading assumptions commonly made about GO, including the effect of data incompleteness, the importance of annotation quali\ufb01 ers, and the transitivity or lack thereof associated with different ontology relations. We also discuss several biases that can confound aggregate analyses such as gene enrichment analyses. For each of these pitfalls and biases, we suggest remedies and best practices.    Key words     Gene ontology  ,   Gene/protein annotation  ,   Data mining  ,   Bias  ,   Confounding  ,   Simpson\u2019s paradox  1      Introduction  As we have seen in previous chapters (for example refer to Chap.   1     [ 1 ], Chap.   12     [ 2 ], Chap.   13     [ 3 ]), by providing a large amount of structured information, the Gene Ontology (GO) greatly facili-tates large-scale analyses and data mining. A very common type of analysis entails comparing sets of genes in terms of their functional annotations, for instance to identify functions that are enriched or depleted in particular subsets of genes (Chap.   13     [ 3 ]) or to assess whether particular aspects of gene function might be associated with other aspects of genes, such as sequence divergence or regula-tory networks.  Despite conscious efforts to keep GO data as normalized as possible, it is heterogeneous in many respects\u2014to a large extent simply because the body of knowledge underlying the GO is itself very heterogeneous. This can introduce considerable biases when the data is used in other analysis, an effect that is magni\ufb01 ed in large-scale comparisons. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_14, \u00a9 The Author(s) 2017\f190 Statisticians and epidemiologists make a clear distinction between  experimental data \u2014data from a controlled experiment, designed such that the case and control groups are as identical as possible in all respects other than a factor of interest\u2014and  observa-tional data \u2014data readily available, but with the potential presence of unknown or unmeasured factors that may confound the analy-sis. GO annotations clearly falls into the second category. Therefore, testing and controlling for potential confounders is of paramount importance.  Before we go through some of the key biases and known potential confounders, let us consider Simpson\u2019s Paradox, which provides a stark illustration of the perils of data aggregation.    Simpson\u2019s paradox is the counterintuitive observation that a statis-tical analysis of aggregated data (combining multiple individual datasets) can lead to dramatically different conclusions from analy-ses of each dataset taken individually, i.e., that the whole appears to disagree with the parts. Simpson's paradox is easiest to grasp through an example. In the classic \u201cBerkeley gender bias case\u201d [ 4 ], the University of California at Berkeley was sued for gender bias against women applicants based on the aggregate 1973 admission \ufb01 gures (44 % men admitted vs. 35 % women)\u2014an observational dataset. The much higher male \ufb01 gure appeared to be damning. However, when individually looking at the men  vs.  women, admis-sion rate for each department, the rate was in fact similar for both sexes (and even in favor of women in most departments). The lower overall acceptance rate for women was not due to gender bias, but to the tendency of women to apply to more competitive departments, which have a lower admission rate in general. Thus, the association between gender and admission rate in the aggre-gate data could almost entirely be explained through strong asso-ciation of these two variables with a third, confounding variable, the department. When controlling for the confounder, the associa-tion between the two \ufb01 rst variables dramatically changes. This type of phenomenon is referred to as Simpson\u2019s paradox.  Because of the inherent heterogeneity of GO data, Simpson\u2019s paradox can manifest itself in GO analyses. This illustrates the importance of recognizing and controlling for potential biases and confounders.     The Gene Ontology is a representation of the current state of knowledge; thus, it is very dynamic. The ontology itself is con-stantly being improved to more accurately represent biology across all organisms. The ontology is augmented as new discoveries are made. At the same time, the creation of new annotations occurs at a rapid pace, aiming to keep up with published work. Despite these efforts, the information contained in the GO database, that is, the ontology and the association of ontology terms with genes and 1.1  Simpson\u2019s Paradox: The Perils of Data Aggregation1.2  The Inherent Incompleteness of the Gene Ontology (Open World Assumption)Pascale Gaudet and Christophe Dessimoz\f191gene products, is necessarily incomplete. Thus, absence of evidence of function does not imply absence of function. 1  This is referred to as the Open World Assumption [ 5 ,  6 ].  Associations between genes/gene products and GO terms (\u201cannotations\u201d) are made via various methods: some manual, some automated based on the presence of protein domains or because they belong to certain protein families [ 7 ]. Annotations can also be transferred to orthologs by manual processes [ 8 ], or automatically (e.g., [ 9 ,  10 ], reviewed in ref.  11 ). There are cur-rently over 210 million annotations in the GO database. Despite these massive efforts to provide the widest possible coverage of gene products annotated, users should not expect each gene prod-uct to be annotated.  A further challenge is that the incompleteness in the GO is very uneven. Interestingly, the more comprehensively annotated parts of the GO can also pose challenges, presenting users with seemingly contradictory information ( see  Subheading  3.2 ).  The inherent incompleteness of GO creates problems in the evaluation of computational methods. For instance, overlooking the Open World Assumption can lead to in\ufb02 ated false positive rates in the assessment of gene function prediction tools [ 6 ]. However, there are ways of coping with this uncertainty. For instance, it is possible to gauge the effect of incomplete annotations on conclu-sions by thinning annotations [ 12 ], or analyzing successive, increasingly complete database releases [ 13 ,  14 ].   2    Gene Ontology Structure  One potential source of bias is that not all parts of the GO have the same level of details. This has a strong implication on measuring the similarity of GO annotations (Chap.   12     [ 2 ]). For instance, sister terms (terms directly attached to a common parent term) can be semantically very similar or very different in different parts of the GO structure, which has been called the \u201cshallow annotation problem\u201d (e.g., [ 15 ,  16 ]). This problem can partly be mitigated by the use of information-theoretic measures of similarity, instead of merely counting the number of edges separating terms, at the expense of requiring a considerable number of relevant annotations from which the frequency of co-occurrence of terms can be esti-mated (more details in Chap.   13     [ 3 ]). 1   Proteins whose function is uncharacterized are annotated to the root of the ontology, which formally means \u201cthis protein is associated with  some  molecu-lar function, biological process, or cellular component, but a more speci\ufb01 c assertion cannot be made\u201d. This annotation is associated with the evidence code \u201cNo biological Data available\u201d (ND). The absence of annotation indi-cates that no curator has reviewed the literature for this gene product. Gene Ontology: Pitfalls, Biases, and Remedies\f192   The GO is structured as a graph, and one pitfall of using the GO is to ignore this structure. Recall that each term is linked to other terms via different relationships ( see  Chaps.   1     [ 1 ] and   3     [ 17 ] for introductions to ontologies and GO annotations). These relation-ships need to be taken into account when using GO for data analysis.  Some relationships, such as \u201cis a\u201d and \u201cpart of\u201d, are  transitive , which means that any protein annotated to a speci\ufb01 c term is also implicitly annotated to all of its parents. 2  An illustration of this is a \u201cserine/threonine protein kinase activity\u201d: it is a child of \u201cprotein kinase activity\u201d with the relationship \u201cis a\u201d. The transitivity of the relation means that the association between the protein and the term \u201cserine/threonine protein kinase activity\u201d and all its parents has the same meaning: the protein associated with \u201cserine/threo-nine protein kinase activity\u201d has this function, and it also has the more general function \u201cprotein kinase.\u201d  On the other hand, relations such as \u201cregulates\u201d are  non- transitive . This implies that the semantics of the association of a gene to a GO term is not the same for its parent: if A is part of B, and B regulates C, we cannot make any inferences about the relationship between C and A. The same is true for positive and negative regula-tion. To illustrate, if we follow the term \u201cpeptidase inhibitor activ-ity\u201d (GO:0030414) to its parents, one of the terms encountered is \u201cproteolysis\u201d via a combination of \u201cis a\u201d, \u201cpart of\u201d, and \u201cregulates\u201d relations. However, a \u201cpeptidase inhibitor activity\u201d does not  mediate  proteolysis, but quite the contrary (Fig.  1 ). Thus, any logical reason-ing on the ontology should take transitivity into account.2   With the exception of \u201cNOT\u201d annotations, for which the transitivity applies to  children  terms, not  parents  ( see  also Subheading  3.2 ). 2.1  Understanding Relationships Between Ontological Conceptspeptidase inhibitor activitymolecular regulator activityis anegative regulation of peptidase activitypeptidase activityis anegatively regulatespart ofproteolysis  Fig. 1    Example of transitive ( black arrows ) and non-transitive ( red arrow ) rela-tionships between classes. A protein annotated to \u201cpeptidase inhibitor activity\u201d term does not imply it has a role in \u201cproteolysis,\u201d since the link is broken by the non- transitive relation  negatively regulates         Pascale Gaudet and Christophe Dessimoz\f193   The relation \u201c has part \u201d is the inverse of \u201c part of \u201d, and connects terms in the opposite direction. Because of this, it generates cycles in the ontology. The relation \u201c occurs in\u201d  connects molecular func-tion terms to the cellular components in which they occur. Thus, taking these relationships into account, it is possible to deduce additional cellular component annotations from molecular function annotations, without requiring additional experimental or compu-tational evidence.  It important to know that there are three version of the GO ontology available: GO-basic, GO, and GO-plus. 3  Only the GO-basic \ufb01 le is completely acyclic. Therefore, applications requiring the traversal of the ontology graph usually assume that the graph is acy-clic; hence, the GO-basic \ufb01 le should be used. The different GO ontology \ufb01 les are discussed in more detail in Chap.   11     [ 18 ].     The \u201cpart of\u201d relation, when linking terms across the different  aspects  of the Gene Ontology (molecular function to biological pro-cess, or biological process to cellular component, for instance), trig-gers an annotation to the second term, using the same evidence code and the same reference, but \u201cGOC\u201d as the source of the anno-tation (\u201c\ufb01 eld 15 of the annotation \ufb01 le,  see  (Chap.   3     [ 17 ] for a description of the contents of the annotation \ufb01 le). For example, a DNA ligase activity annotation will automatically trigger an anno-tation to the biological process DNA ligation. The advantage of having these annotations inferred directly from the ontology is that it increases the annotation coverage by making annotations that may have been overlooked by the annotator when making the pri-mary annotation. However, these inter-ontology links trigger a large number of annotations: there are currently 12 million annota-tions to 7 million proteins in the GO database. Changes in the structure of these links (as any change in the ontology), can poten-tially have a large impact on the annotation set. Indeed, Huntley et al. [ 19 ] reported that in November 2011, there was a decrease of ~2500 manually and automatically assigned annotations to the term \u201ctranscription, DNA-dependent\u201d (GO:0006351) due to the removal of an inter-ontology link between this term and the Molecular Function term \u201csequence- speci\ufb01 c DNA binding tran-scription factor activity\u201d (GO:0003700). Figure  2  shows the strong and sudden variation in the number of annotations with term \u201cATPase activity\u201d (GO:0016887).   Such large changes in GO annotations can affect GO enrich-ment analyses, which are sensitive to the choice of background distribution (Chap.   13     [ 3 ]; [ 20 ]). For instance, Clarke et al. [ 21 ] have shown that changes in annotations contribute signi\ufb01 cantly to changes in overrepresented terms in GO analysis. To mitigate this problem, researchers should analyze their datasets using the most 3   http://geneontology.org/page/download-ontology 2.2  Inter-ontology Links and Their Impact on GO Enrichment AnalysesGene Ontology: Pitfalls, Biases, and Remedies\f194up-to-date version of the ontology and annotations, and ensure that the conclusions they draw hold across multiple recent releases. At the time of the writing of this chapter, DAVID, a popular GO analysis tool, had not been updated since 2009 (  http://david.abcc.ncifcrf.gov/forum/viewtopic.php?f=10&amp;t=807    ). Enrichment analyses performed with it may thus identify terms whose distribu-tion has substantially changed irrespective of the analysis of inter-est. The Gene Ontology Consortium now links to the PantherDB GO analysis service (  http://amigo.geneontology.org/rte    ) [ 22 ]. This tool uses the most current version of the ontology and the annotations. Regardless of the tool used, researchers should dis-close the ontology and annotation database releases used in their analyses.   DateAuthorAutomaticComputationalCuratorialExperimental200420062008201020122014020040060080010001200Annotation count of GO:0016887 over time Annotation Count  Fig. 2    Strong and sudden variation in the number of annotations with the GO term \u201cATPase activity\u201d (GO:0016887) over time. Such changes can heavily affect the estimation of the background distribution in enrichment analyses. To mini-mize this problem, use an up-to-date version of the ontology/annotations and ensure that conclusions drawn hold across recent releases. Data and plot obtained from GOTrack (  http://www.chibi.ubc.ca/gotrack    )        Pascale Gaudet and Christophe Dessimoz\f1953    Gene Ontology Annotations  Having discussed common pitfalls associated with the ontology structure, we now turn our attention to annotations. Understanding how annotations are done is essential to correctly interpreting the data. In particular, the information provided for each GO annota-tion extends beyond the mere association of a term with a protein (reference to Chap.   3     [ 17 ]). The full extent of this rich informa-tion, aimed to more precisely re\ufb02 ect the biology within the GO framework, is often overlooked.    The Gene Ontology uses three quali\ufb01 ers that modify the meaning of association between a gene-product and a Gene Ontology term: These are \u201cNOT\u201d, \u201ccontributes to\u201d, and \u201cco-localizes with\u201d (see documentation at   http://geneontology.org/page/go-quali\ufb01 ers    ).  The \u201ccontributes to\u201d quali\ufb01 er is used to capture the molecular function of complexes when the activity is distributed over several subunits. However, in some cases the usage of the quali\ufb01 er is more permissive, and all subunits of a complex are annotated to the same molecular function even if they do not make a direct contribution to that activity. For example, the rat G2/mitotic-speci\ufb01 c cyclin-B1 CCNB1 is annotated as contributing to histone kinase activity, based on data in [ 23 ], although it has only been shown to  regulate  the kinase activity of CDK1. Finding a cyclin annotated as having protein kinase activity may be unintuitive to users who fail to con-sider the \u201ccontributes to\u201d quali\ufb01 er.  The \u201cco-localizes with\u201d quali\ufb01 er is used with two very different meanings: it \ufb01 rst means that a protein is transiently or peripherally associated with an organelle or complex, while the second use is for cases where the resolution of an assay is not accurate enough to say that the gene product is a bona \ufb01 de component member. Unfortunately, it is currently not possible to know which of the two meanings is meant in any given annotation.       The \u201cNOT\u201d quali\ufb01 er is the one with the most impact, since it means that there is evidence that a gene product does  not  have a certain function. The \u201cNOT\u201d quali\ufb01 er is mostly used when a spe-ci\ufb01 c function may be expected, but has shown to be missing, either based on closer review of the protein\u2019s primary sequence (e.g., loss of an active site residue) or because it cannot be experimentally detected using standard assays.  The existence of negative annotations can also lead to apparent contradictions. For instance, protein ARR2 in  Arabidopsis thaliana  is associated with \u201cresponse to ethylene\u201d (GO:0009723) both positively on the basis of a paper by Hass et al. [ 24 ] and negatively based on a paper by Mason et al. [ 25 ]. The latter discusses this contradiction as follows:3.1  Modi\ufb01 cation of Annotation Meaning by Quali\ufb01 ers3.2  Negative and Contradictory ResultsGene Ontology: Pitfalls, Biases, and Remedies\f196  Hass et al. [ 24 ] reported a reduction in the ethylene sensitivity of seedlings containing an arr2 loss-of-function mutation. By contrast, we observed no signi\ufb01 cant difference from the wild type in the seed-ling ethylene response when we tested three independent arr2 inser-tion mutants, including the same mutant examined by Hass et al. [ 24 ]. This difference in results could arise from differences in growth conditions, for, unlike Hass et al. [ 24 ], we used a medium containing Murashige and Skoog (MS) salts and inhibitors of ethylene biosynthesis.    Thus, in this case, the contradiction in the GO is a re\ufb02 ection of the primary literature. As Mason et al. note, this is not necessarily re\ufb02 ective of a mistake, as there can be differences in activity across space (tissue, subcellular localisation) and time (due to regulation), with some of these details not fully captured in the experiment or in its representation in the GO.  A NOT annotation may also be assigned to a protein that does not have an activity typical of its homologs, for instance the STRADA pseudokinase (UniProtKB:Q7RTN6); STRADA adopts a closed conformation typical of active protein kinases and binds substrates, promoting a conformational change in the substrate, which is then phosphorylated by a \u201ctrue\u201d protein kinase, STK11 [ 26 ]. In this case, the \u201cNOT\u201d annotation is created to alert the user to the fact that although the sequence suggests that the pro-tein has a certain activity, experimental evidence shows otherwise.  In contrast to positive annotations, \u201cNOT\u201d annotations propagate to children in the ontology graph and not to parents. To illustrate, a protein associated with a negative annotation to \u201cprotein kinase activity\u201d is not a tyrosine protein kinase either, a more speci\ufb01 c term.     As also described in Chap.   17     [ 27 ], the Gene Ontology has recently introduced a mechanism, the \u201cannotation extensions\u201d, by which contextual information can be provided to increase the expressivity of the annotations [ 28 ]. Until recently, annotations had consisted of an association between a gene product and a term from one of the three ontologies comprising the GO. With this new knowledge representation model, additional information about the context of a GO term such as the target gene or the location of a molecular function may be provided.  Common uses are to provide data regarding the location of the activity/process in which a protein or gene product participates. For example, the role of Mouse opsin-4 (MGI:1353425) in rhodopsin mediated signaling pathway is biologically relevant in retinal gan-glion cells. Annotation extensions also allow capture of dynamic subcellular localization, such as the  S. pombe  bir1 protein (SPCC962.02c), which localizes to the spindle speci\ufb01 cally during the mitotic anaphase. The annotation extensions can also be used to capture substrates of enzymes, which used to be outside the scope of GO. 3.3  Annotation ExtensionsPascale Gaudet and Christophe Dessimoz\f197 The annotation extension data is available in the AmiGO [ 29 ] and QuickGO [ 30 ] browsers, as well as in the annotation \ufb01 les compliant with the GAF2.0 format (  http://geneontology.org/page/go-annotation-\ufb01 le-gaf-format-20    ). However, because annotation extensions are relatively new, guidelines are still being developed, and some uses are inconsistent across different data-bases. Furthermore, most tools have yet to take this information into account.  In effect, extensions of an annotation create a \u201cvirtual\u201d GO class that can be composed of more than one \u201cactual\u201d GO class, and can be traced up through multiple parent lineages. Thus, just as with inter-ontology links, accounting for annotation extensions can result in a substantial in\ufb02 ation in the number of annotations, which needs to be appropriately accounted for in enrichment anal-yses and other statistical analyses that require precise speci\ufb01 cation of GO term background distribution.     Annotations are backed by different types of experiments or analyses categorized according to evidence codes (Chap.   3     [ 17 ]). Different types of experiments provide varying degrees of precision and con\ufb01 -dence with respect to the conclusions that can be derived from them. For most experiment types, it is not possible to provide a quantita-tive measure of con\ufb01 dence. Evidence codes are informative but can-not directly be used to exclude low-con\ufb01 dence data. 4  Nonetheless, the different evidence codes are prone to speci\ufb01 c biases.   Direct evidence.  Taking these caveats into account, the evidence code inferred from direct assay (abbreviated as IDA in the annota-tion \ufb01 les) provides the most reliable evidence with respect to the how directly a protein has been implicated in a given function, as it names implies.   Mutant phenotype evidence.  Mutants are extremely useful to impli-cate genes products in pathways and processes; however exactly how the gene product is implicated in the process/function annotated is dif\ufb01 cult to assess using phenotypic data because such data are inher-ently derivative. Therefore, associations between gene products and GO terms based on mutant phenotypes (abbreviated as IMP in the annotation \ufb01 les) may be weak. The same caveat applies to annota-tions derived from mutations in  multiple  genes, indicated by evi-dence code \u201cinferred from genetic interaction\u201d (IGI).   Physical interactions.  Evidence based on physical interactions (IPI; mostly protein\u2013protein interactions) is comparable in con\ufb01 dence to a direct assay for protein binding annotations or for cellular components; however for molecular functions and biological 4   An evidence con\ufb01 dence ontology has been proposed by Bastien et al. [ 31 ] but has yet to be adopted by the GO project. 3.4  Biases Associated with Particular Evidence CodesGene Ontology: Pitfalls, Biases, and Remedies\f198processes, the evidence is of the type \u201cguilt by association\u201d and is of low con\ufb01 dence. Inferences based on expression patterns (IEP) are typically of low con\ufb01 dence. The presence of a protein in a spe-ci\ufb01 c subcellular localization, at a speci\ufb01 c developmental stage, or associated with a protein or a protein complex can provide a hint to uncover a protein\u2019s role in the absence of other evidence, but without more direct evidence that information is very weak.   High-throughput experiments.  Schnoes et al. [ 32 ] reported that annotations deriving from high-throughput experiments tend to consist of high-level GO terms, and tend to represent a limited number of functions. This arti\ufb01 cially decreases the information content of these terms, since they are frequently annotated, and arti\ufb01 cially decreased information content affects similarity analyses. This potentially has a large impact, since a signi\ufb01 cant fraction of the annotations in the GO database are derived from these types of analyses (as much as 25 %, according to Schnoes et al., who used the operational de\ufb01 nition of a high throughput paper as one in which over 100 proteins were annotated). The GO does not currently record whether particular experimental annotations may be derived from high-throughput methods, but this may change in the future.   Biases from automatic annotation methods.  The GO association \ufb01 le, containing the annotations, has information regarding the method used to assign electronic annotations. The annotations can be assigned by a large number of different methods. Examples include domain functions, as assigned for example by InterPro, by Enzyme Commission numbers being associated with an entry, by BLAST, by orthology assignment, etc. Note that this information is not provided as an evidence code, but as a \u201creference code\u201d. The list of methods and their associated reference code is available at   http://www.geneontology.org/cgi-bin/references.cgi    . The large number of electronic annotations can also make them have a dispropor-tionate impact on the results. Most analysis tools allow for the inclusion or exclusion of electronic annotations, but not at the more \ufb01 ne-grained level of the particular method. It is nevertheless possible to use the combination of evidence code plus reference (available at:   http://www.geneontology.org/cgi-bin/references.cgi    ) to automatically deepen the evidence type, see   https://raw.githubusercontent.com/evidenceontology/evidenceontology/master/gaf-eco-mapping.txt    ).  Note that a gene or gene product can have multiple annota-tions to the same term but with different evidence. This can pro-vide corroborating information on particular genes, but may also require appropriate normalization in statistical analyses of term frequency, as the frequency of terms that can be determined through multiple types of experiments may be arti\ufb01 cially in\ufb02 ated. Furthermore, because different experiments can vary in their speci\ufb01 city\u2014thus resulting in annotations at different levels of Pascale Gaudet and Christophe Dessimoz\f199granularity for basically the same function\u2014this redundancy only becomes conspicuous when the transitivity of the ontology structure is appropriately taken into account.  For more discussion on evidence codes, and their use in quality control pipelines, refer to Chap.   18     [ 33 ].     There can be substantial differences in the nature and extent of GO annotations across different species. For instance, zebra\ufb01 sh is heavily studied in terms of developmental biology and embryo-genesis while the rat is the standard model for toxicology. These differences are re\ufb02 ected in the frequency of GO terms across spe-cies, which can vary considerably across species [ 34 ]. This has important implications on enrichment analyses and other statisti-cal analyses requiring a background distribution of GO annota-tions. For instance, consider an experiment trying to establish the biological processes associated with a particular zebra\ufb01 sh protein by identifying its interaction partners and performing an enrich-ment analysis on them. If we naively use the entire database as background, the interaction partners might appear to be enriched in developmental genes simply because this class is over-repre-sented in general in zebra\ufb01 sh. Instead, one should use zebra\ufb01 sh gene-related annotations only as background [ 20 ].     Other biases are less obvious but can nevertheless be strong and thus have a high potential to mislead. Recently, sets of annotations derived from the same scienti\ufb01 c article were shown to be on aver-age much more similar than annotations derived from different papers (Fig.  3 ; [ 34 ]). For instance, Nehrt et al. compared the 3.5  Differences Among Species3.6  Authorship BiasAuthorship biasab0.00.20.40.6Same paperDifferent paper, common authorDifferent AuthorsPropagated annotation bias0.00.20.40.6ExperimentalCuratedUncuratedaverage GO Similarityaverage GO Similarity  Fig. 3    ( a ) Average GO annotation similarity (using the measure of Schlicker et al. [ 35 ] between homologous genes, considering experimental annotations partitioned according to the provenance; ( b ) Average GO annota-tion similarity between homologous genes, partitioned according to their GO annotation evidence tags (Experimental: evidence code EXP and subcategories; Uncurated: evidence code IEA; Curated: all other evidence codes). Figure adapted from ref.  34         Gene Ontology: Pitfalls, Biases, and Remedies\f200functional similarity of orthologs (genes related through speciation) across different species and paralogs (genes related through dupli-cation) within the same species, and observed a much higher level of functional conservation among the latter [ 36 ]. However, this difference was almost entirely due to the fact that the GO func-tional annotations of same-species paralogs are ~50 times more likely to be derived from the same paper than orthologs; when controlling for authorship and other biases, the difference in func-tional similarity between same-species paralogs and orthologs van-ished and even became in favor of orthologs [ 34 ].   Note that the difference is smaller but remains signi\ufb01 cant if we compare annotations established from different papers, but with at least one author in common, with annotations from different arti-cles with no author in common.     Just as systematic differences among investigators can lead to the authorship bias, systematic differences in the way GO curators capture this information can lead to annotator bias. These annotator biases can in part be attributed to different annotation focus, but also to dif-ferent interpretation or application of the GO annotation guidelines (  http://geneontology.org/page/go-annotation-policies    ).  UniProt provides annotations for all species, which allows us to assess the effect of annotator (or database) bias. If we compare UniProt annotations for mouse proteins with those done by the Mouse Genome Informatics group (MGI), we see that comparable fractions of proteins are annotated using the different experimental evidence codes, with mutant phenotypes being the most widely used (78 % of experimental annotations in MGI, versus 63 % in UniProt), followed by direct assays (20 % of annotations in MGI and 32 % in UniProt).  However when we look at which GO terms are annotated based on phenotypes (IMP and IGI) by the two groups, we notice a large difference in the terms annotated. The top term annotated by MGI supported by the IMP evidence code is \u201cin utero embryonic devel-opment\u201d, with 1170 annotations to 1020 proteins. UniProt has only 4 annotations for this term. On the other hand, UniProt has as one of its top-annotated classes \u201cregulation of circadian rhythm\u201d, for 49 annotations to 38 proteins; 96 annotations for 69 proteins if we also include annotations to more speci\ufb01 c, descendant terms. MGI on the other hand, only has 18 annotations for 19 proteins. This indicates that the annotations provided by different groups are biased towards speci\ufb01 c aspects, and are not a uniform representation of the biology of all gene products in a species.     Another strong and perhaps surprising bias lies in the very different average GO similarity between electronic annotations compared with between experimental annotations. Indeed, if we consider 3.7  Annotator Bias3.8  Propagation BiasPascale Gaudet and Christophe Dessimoz\f201homologous genes, their similarity in terms of electronic annotations tend to be much higher than in terms of experimental annotations, with curated annotations lying in-between ([ 34 ]; Fig.  3 ). A likely explanation for this phenomenon is that electronic annotations are typically obtained by inferring annotations among homologous sequences, a process that can only increase the average functional similarity of homologs.  Because of this homology inference bias, one must exercise caution when drawing conclusions from sets of genes whose anno-tations might have different proportions of experimental vs. elec-tronic annotations. For instance, this would be the case when comparing annotations from model organisms with those from non-model organisms (the latter being likely to consist mostly of electronic annotations obtained through propagation).  More subtly, because function conservation is generally believed to correlate with sequence similarity, many computational methods preferentially infer function among phylogenetically close homologs. This bias can thus confound analyses attempting to gauge the conservation of gene function across different levels of species divergence.     As discussed above, both our knowledge of gene function and its representation in the GO remain very incomplete. We have already discussed the pitfalls of ignoring this fact altogether (closed vs. open world assumption), or assuming similar term frequencies across species. But the extent of missing data varies along other dimensions as well: for example it can depend on how easy it is to experimentally establish a particular function and how interesting the potential function might be. The problem is particularly acute in the case of negative annotations, because they can be even more dif\ufb01 cult to establish than their positive counterparts (e.g., a nega-tive result can also be due to inadequate experimental conditions, differences in spatiotemporal regulation, etc.)  and  they are often perceived as being less useful, and certainly less publishable. As a result, currently less than 1 % of all experimental annotations are negative ones in UniProt-GOA [ 37 ]. This imbalance causes prob-lems with training of machine learning algorithms [ 38 ]. Rider et al. [ 39 ] investigated the reliability of typical machine learning evaluation metrics (area under the \u201creceiver operating characteris-tic\u201d (ROC) curve, area under the precision-recall curve) under different levels of missing negative annotations and concluded that this bias could strongly affect the ranking obtained from the different metrics. Though this particular study adopted a closed world assumption, the effect of a varying proportion of negative annotations is likely to be even greater under the open world assumption.   3.9  Imbalance Between Positive and Negative AnnotationsGene Ontology: Pitfalls, Biases, and Remedies\f2024    Getting Help  This chapter provides a broad overview of some of the pitfalls associ-ated with GO-based analysis. Table  1  summarizes the most impor-tant pitfalls users encounter using GO.   Users are advised to make use of a number of excellent resources provided by the GO consortium:     Table 1    Main pitfalls or biases discussed in the chapter and their remedies    Pitfall or bias  Remedy  Wrongly assume that absence of annotation implies absence of function.  Account for the fact that both ontology and annotations are necessary incomplete, for instance by assessing the impact of incompleteness on one\u2019s analyses and \ufb01 ndings.  Not all directed edges in the ontology structure have the same meaning: depending on their type, the relationship they represent may or may not be transitive.  The transitivity of each type of relations must be taken into account when reasoning over the GO. \u201cIs a\u201d and \u201cpart of\u201d are transitive, but \u201cregulates\u201d is not.  To yield meaningful results, GO enrichment analyses require accurate speci\ufb01 cation of the background distribution, which can vary substantially across releases, species, etc.  Specify the actual background distribution used in the analysis of interest. Short of this, ensure that the enrichment analysis is performed on consistent database release and subsets of species, terms, etc. To test the robustness of results, consider repeating the analysis using several releases of GO ontology/annotation databases. Avoid tools that are not regularly updated.  Inter-ontology links and annotation extensions can result in large variations in the number of annotations. Furthermore, annotation extensions may not be consistently implemented, if at all, across analyses tools or work\ufb02 ows.  Keep track of database releases in analyses. If they are relevant, make sure that annotation extensions are implemented consistently.  Quali\ufb01 ers such as \u201cNOT\u201d or \u201cco-localizes with\u201d are important parts of a gene annotation in that they fundamentally change the meaning of annotations. Because only a small minority of all annotations have quali\ufb01 ers, such errors can easily go unnoticed.  Remember to take into account quali\ufb01 ers. When using tools or software libraries, make sure that these take quali\ufb01 ers into account as well.  Annotations are supported by different types of evidence (categorized by evidence codes). The annotations associated with each code vary in their scope, speci\ufb01 city, and number. These differences can confound some analyses.  Take evidence code into account. In statistical analyses, consider the distribution of annotations in terms of evidence codes, and, if needed, control for this potential confounder. (continued)Pascale Gaudet and Christophe Dessimoz\f203Table 1(continued) Pitfall or bias  Remedy  Different species tend to have very different types of annotations. For instance, model species have many more experiment-based annotations.  When performing statistical analyses or using information- theoretic similarity measures, use species-speci\ufb01 c frequencies of GO term.  Experiment-based annotations derived from the same research article tend to be more similar than annotations derived from different articles. Similar trends hold for annotations derived from same versus different authors, and same versus different annotators.  Control for authorship bias in analyses that may have varying proportion of annotations stemming from the same article, lab, or annotation team.  Because annotations are preferentially propagated among closely related sequences, electronic annotations can confound analyses seeking to characterize relationships between evolution and function.  Restrict such analyses to experiment-based annotations. Avoid circularity.  There are many more positive annotations than negative annotations. As a result, standard accuracy measures used by machine learning methods may be misleading (\u201cclass imbalance problem\u201d).  Consider false-positive and false-negative rates separately. Focus on subset of data for which the class imbalance problem is less pronounced.  \u25cf   The GO website   http://geneontology.org       \u25cf  The GO FAQ   http://geneontology.org/faq-page       \u25cf  The GO team are eager to help with your problems: e-mail go- help@geneontology.org   \u25cf  The wider bioinformatics community can be consulted via sites like Biostars\u2014see the GO tag   https://www.biostars.org/t/go/       \u25cf  The GO community can be contacted on Twitter at   @news4go         5    Conclusion  This chapter surveys some of the main pitfalls and biases of the Gene Ontology. The number of potential issues, summarized in Table  1 , may seem daunting. Indeed, as discussed at the start of this chapter, there are some inherent risks in working with observational data. However, simple remedies are available for many of these (Table  1 ). By understanding the subtleties of the GO, controlling for known confounders, trying to identify unknown ones, and cautiously proceeding forward, users can make the most of the formidable resource that is the GO.     Gene Ontology: Pitfalls, Biases, and Remedies\f204     1.   Hastings J (2016) Primer on ontologies. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1       2.   Pesquita C (2016) Semantic similarity in the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12         3.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13      4.    Bickel PJ, Hammel EA, O\u2019connell JW (1975) Sex bias in graduate admissions: data from Berkeley. Science 187:398\u2013404      5.    Thomas PD, Wood V, Mungall CJ et al (2012) On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report. PLoS Comput Biol 8:e1002386      6.    Dessimoz C, Skunca N, Thomas PD (2013) CAFA and the Open World of protein function predictions. Trends Genet 29:609\u2013610      7.     Burge S, Kelly E, Lonsdale D et al (2012) Manual GO annotation of predictive protein signatures: the InterPro approach to GO cura-tion. Database:bar068          8.    Gaudet P, Livstone MS, Lewis SE et al (2011) Phylogenetic-based propagation of functional annotations within the Gene Ontology consor-tium. Brief Bioinform 12:449\u2013462          9.    Vilella AJ, Severin J, Ureta-Vidal A et al (2008) EnsemblCompara GeneTrees: complete, dupli-cation-aware phylogenetic trees in vertebrates. Genome Res 19:327\u2013335      10.    Altenhoff AM, \u0160kunca N, Glover N et al (2015) The OMA orthology database in 2015: function predictions, better plant support, syn-teny view and other improvements. Nucleic Acids Res 43:D240\u2013D249      11.   Rentzsch R, Orengo CA (2009) Protein func-tion prediction--the power of multiplicity. Trends Biotechnol 27:210\u2013219      12.    \u0160kunca N, Dessimoz C (2015) Phylogenetic pro\ufb01 ling: how much input data is enough? PLoS One 10:e0114701    Acknowledgements  We thank Natasha Glover, Rachel Huntley, Suzanna Lewis, Chris Mungall, and Paul Thomas for detailed and helpful feedback on the manuscript. PG acknowledges National Institutes of Health/National Human Genome Research Institute grant HG002273. CD acknowledges Swiss National Science Foundation grant 150654 and UK BBSRC grant BB/M015009/1. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     References Pascale Gaudet and Christophe Dessimoz\f205    13.    \u0160kunca N, Altenhoff A, Dessimoz C (2012) Quality of computationally inferred gene ontology annotations. PLoS Comput Biol 8:e1002533            14.    Jiang Y, Clark WT, Friedberg I et al (2014) The impact of incomplete knowledge on the evaluation of protein function prediction: a structured-output learning perspective. Bioinformatics 30:i609\u2013i616       15.    Sevilla JL, Segura V, Podhorski A et al (2005) Correlation between gene expression and GO semantic similarity. IEEE/ACM Trans Comput Biol Bioinform 2:330\u2013338      16.    Mistry M, Pavlidis P (2008) Gene Ontology term overlap as a measure of gene functional similarity. BMC Bioinformatics 9:327      17.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3      18.   Munoz-Torres M, Carbon S (2016) Get GO! retrieving GO data using AmiGO, QuickGO, API, \ufb01 les, and tools. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 11         19.    Huntley RP, Sawford T, Martin MJ et al (2014) Understanding how and why the Gene Ontology and its annotations evolve: the GO within UniProt. GigaScience 3:4      20.    Rhee SY, Wood V, Dolinski K et al (2008) Use and misuse of the gene ontology annotations. Nat Rev Genet 9:509\u2013515      21.    Clarke EL, Loguercio S, Good BM et al (2013) A task-based approach for Gene Ontology evaluation. J Biomed Semantics 4(Suppl 1):S4      22.    Mi H, Muruganujan A, Casagrande JT et al (2013) Large-scale gene function analysis with the PANTHER classi\ufb01 cation system. Nat Protoc 8:1551\u20131566      23.    Granada JF, Ensenat D, Keswani AN et al (2005) Single perivascular delivery of mitomy-cin C stimulates p21 expression and inhibits neointima formation in rat arteries. Arterioscler Thromb Vasc Biol 25:2343\u20132348      24.    Hass C, Lohrmann J, Albrecht V et al (2004) The response regulator 2 mediates ethylene signalling and hormone signal integration in Arabidopsis. EMBO J 23:3290\u20133302      25.    Mason MG, Mathews DE, Argyros DA et al (2005) Multiple type-B response regulators mediate cytokinin signal transduction in Arabidopsis. Plant Cell 17:3007\u20133018       26.    Baas AF, Boudeau J, Sapkota GP et al (2003) Activation of the tumour suppressor kinase LKB1 by the STE20-like pseudokinase STRAD. EMBO J 22:3062\u20133072          27.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17      28.    Huntley RP, Harris MA, Alam-Faruque Y et al (2014) A method for increasing expressivity of Gene Ontology annotations using a composi-tional approach. BMC Bioinformatics 15:155      29.    T. Gene and Ontology Consortium (2010) The Gene Ontology in 2010: extensions and re\ufb01 ne-ments. Nucleic Acids Res 38:D331\u2013D335      30.    Binns D, Dimmer E, Huntley R et al (2009) QuickGO: a web-based tool for Gene Ontology searching. Bioinformatics 25:3045\u20133046      31.     Bastian FB, Chibucos MC, Gaudet P et al (2015) The Con\ufb01 dence Information Ontology: a step towards a standard for asserting con\ufb01 -dence in annotations. Database:bav043          32.    Schnoes AM, Ream DC, Thorman AW et al (2013) Biases in the experimental annotations of protein function and their effect on our understanding of protein function space. PLoS Comput Biol 9:e1003063     33.   Chibucos MC, Siegele DA, Hu JC, Giglio M (2016) The evidence and conclusion ontology (ECO): supporting GO annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 18     34.    Altenhoff AM, Studer RA, Robinson-Rechavi M et al (2012) Resolving the ortholog conjec-ture: orthologs tend to be weakly, but signi\ufb01 -cantly, more similar in function than paralogs. PLoS Comput Biol 8:e1002514     35.    Schlicker A, Domingues FS, Rahnenf\u00fchrer J et al (2006) A new measure for functional similar-ity of gene products based on Gene Ontology. BMC Bioinformatics 7:302     36.    Nehrt NL, Clark WT, Radivojac P et al (2011) Testing the ortholog conjecture with compara-tive functional genomic data from mammals. PLoS Comput Biol 7:e1002073     37.    Huntley RP, Sawford T, Mutowo-Meullenet P et al (2015) The GOA database: gene ontology annotation updates for 2015. Nucleic Acids Res 43:D1057\u2013D1063     38.     Kotsiantis S, Kanellopoulos D (2006) Handling imbalanced datasets: a review, Annual Symposium on Foundations of Computer Science         39.    Rider AK, Johnson RA, Davis DA et al (2013) Classi\ufb01 er evaluation with missing negative class labels. In: Advances in Intelligent Data Analysis XII. Springer, Berlin, pp 380\u2013391    Gene Ontology: Pitfalls, Biases, and Remedies\f207    Chapter 15    Visualizing GO Annotations                          Fran     Supek      and     Nives     \u0160kunca       Abstract    Contemporary techniques in biology produce readouts for large numbers of genes simultaneously, the typical example being differential gene expression measurements. Moreover, those genes are often richly annotated using GO terms that describe gene function and that can be used to summarize the results of the genome-scale experiments. However, making sense of such GO enrichment analyses may be challeng-ing. For instance, overrepresented GO functions in a set of differentially expressed genes are typically output as a \ufb02 at list, a format not adequate to capture the complexities of the hierarchical structure of the GO annotation labels.  In this chapter, we survey various methods to visualize large, dif\ufb01 cult-to-interpret lists of GO terms. We catalog their availability\u2014Web-based or standalone, the main principles they employ in summarizing large lists of GO terms, and the visualization styles they support. These brief commentaries on each soft-ware are intended as a helpful inventory, rather than comprehensive descriptions of the underlying algo-rithms. Instead, we show examples of their use and suggest that the choice of an appropriate visualization tool may be crucial to the utility of GO in biological discovery.    Key words     Gene Ontology  ,   Visualization  ,   Interpretation  ,   Redundancy  ,   Enrichment  ,   Tools  1      Introduction  We have entered the era of massive data sets in biology. A variety of experimental and computational techniques can produce read-outs for many genes\u2014or whole genomes\u2014simultaneously. Moreover, we can also assign rich functional annotations to most of the genes of interest. Such a wealth of data is accompanied with challenges in interpretation.  In this chapter, we focus on methods that visualize long lists of Gene Ontology (GO) terms [ 1 ]. The methods we survey take as input a \ufb02 at list of GO terms, often accompanied by some user- supplied measure of statistical signi\ufb01 cance or importance. Visualization methods summarize such lists to distil the most rele-vant information. Finally, these methods produce various styles of visualization that can aid interpretation. Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_15, \u00a9 The Author(s) 2017\f208 First, we examine the challenges related to understanding large lists of GO terms; second, we provide a systematic overview of the published methods that address these challenges; third, we discuss different visualization styles these methods use; and fourth, we give usage examples for a selection of these tools.  2    Understanding Large Lists of Genes and Their Gene Ontology Labels  A classical example of a large biological dataset are gene expression measurements by RNA-Seq, which monitor the genome-wide changes in transcriptional regulation between experimental condi-tions. Typically, tens or hundreds of genes will be upregulated or downregulated in response to a particular treatment. This indicates that a systems-level change in the experimental model has occurred, which may be described by examining the common properties of the genes whose expression was altered. Do these genes participate in the same metabolic or signaling pathways? Do they perform similar biochemical functions? Do their protein products co- localize in the cell? Formally, such sets of genes are subjected to statistical tests for enrichment for various functional categories [ 2 ]. The gene functions tested are typically described by Gene Ontology (GO) terms [ 3 ], although alternatives such as KEGG Pathways or CORUM protein complexes can be used.  Of note, such GO enrichment analyses are by no means restricted to experiments measuring changes in gene expression, nor to experi-mental data in general. Any list of genes for which interpretation is sought can be described using enriched GO terms and it could, for instance, derive from comparative genomics. In particular, one could perform an evolutionary analysis to look at biological roles of gene families that have expanded in a certain eukaryotic lineage, e.g., [ 4 ]. Similarly, a researcher may wish to describe the overall functional repertoire in a newly sequenced genome, while comparing to exist-ing genomes of related organisms.    As Chap.   3     [ 5 ] describes, the GO is a hierarchical structure, wherein the individual terms can have not only multiple descendants, but also multiple parents; more formally, GO is a directed graph; the basic version of the GO is also a directed  acyclic  graph (Chap.   3     1  [ 5 ]; Fig.  1 ). This complex structure, along with its large size\u2014the GO has thousands of nodes\u2014make it challenging to display the part(s) of the GO of interest. For instance, a list of GO terms found to be enriched in a gene expression experiment could be concen-trated in one part of the GO graph.   A further complication is that such lists of interesting GO terms tend to be large, meaning that many different biological processes or molecular functions may appear to be affected in the experiment. 1   http://geneontology.org/page/download-ontology 2.1  Challenges in Interpreting Lists of Enriched GO TermsFran Supek and Nives \u0160kunca\f209One reason for this is that the GO itself is designed and developed to describe nuances in gene function as exhaustively as possible; conse-quently, many of the GO terms will be partially redundant. For instance, many of the genes participating in \u201ctranslation\u201d (GO:0006412) are also structurally a part of \u201cribosome\u201d (GO:0005840).  In addition to the inherent redundancy of the GO, responses of biological systems to experimental perturbation often genuinely involve coordinated activity of many related and/or overlapping subsystems. For example, replicating cells facing DNA damage may upregulate \u201cnucleotide-excision repair\u201d (GO:0006289) to help \ufb01 x the lesions, but at the same time resorting to \u201cerror-prone transle-sion synthesis\u201d (GO:0042276) to ensure DNA replication \ufb01 nishes.     GO term enrichment analyses often result in lists of signi\ufb01 cant GO terms that are both long and redundant, hampering interpre-tation. Various methods to visualize such lists may help investiga-tors spot dominant trends in the data, leading to novel biological insight. Such visualizations mostly operate by different ways of grouping and displaying similar GO terms together, wherein the structure of the GO de\ufb01 nes what is similar and what is not (see  semantic similarity analysis  below). In its simplest form, this involves displaying a part of the GO hierarchy with the GO terms of interest highlighted and their parent\u2013child relationships shown. Displaying also the user-supplied experimental data may help prioritize which GO terms, among many similar ones, are of higher interest.  We suggest that having an unbiased way to algorithmically organize GO terms derived from experimental data helps prevent unintentional biases in interpretation. If unaware of the overall semantic structure in the set of signi\ufb01 cant GO terms, the investigator may pick one or two GO terms in the list that \u201cmake sense,\u201d in terms of \ufb01 tting with their expectations. By visualizing the interre-2.2  Visualizing the GO to Facilitate Insight and Avoid Biases  Fig. 1    A subset of the Gene Ontology Directed Acyclic Graph (DAG) for the GO term \u201cvesicle fusion\u201d (GO:0006906). The GO is a DAG: terms are nodes, while the relations are edges. Two main relation types between terms are \u201cis_a\u201d and \u201cpart_of.\u201d More speci\ufb01 c terms are found deeper in the graph. Thus, if a gene product is annotated with a GO term, it is by de\ufb01 nition also annotated with all the parent terms of that GO term        Visualizing GO Annotations\f210lationships between the GO terms alongside the statistical support for each in the experimental data could help avoid focusing on outlying\u2014and perhaps spurious\u2014results. In addition, one could be made aware of the common pitfall where one GO term is cho-sen, while other similarly statistically supported terms are ignored. Finally, and very importantly, a good visualization is also an effec-tive means of presenting summaries of scienti\ufb01 c results, whether in papers, presentations or posters.   3    Overview of the GO Visualization-Related Tools  Here we systematize and describe the currently available tools for visualizing sets of GO annotations. Additionally, we highlight three of these tools in more detail. The tools and the underlying meth-ods they implement can be classi\ufb01 ed thusly:    1.     Interactive GO browsers.  Tools for interactively browsing the entire GO and also the genes known to be annotated with chosen GO terms. Importantly, these do not take into account a user-supplied set of annotations of interest, e.g., derived from an enrichment analysis of experimental data. Visualization is typically not emphasized and not con\ufb01 gurable. See AmiGO [ 6 ] and QuickGO [ 7 ]. Of note, OLSVis [ 8 ] can display other biomedical ontologies in addition to the GO.      2.     Network visualization tools.  These are not particular to the GO, but can display any kind of graph, including the GO or a part thereof. The visualization options are highly con\ufb01 gurable; however, since these tools were not designed speci\ufb01 cally for GO, they tend to be more complicated to use. See Cytoscape [ 9 ], Gephi [ 10 ], and Pajek [ 11 ].   (a)    Of note, there are Cytoscape plugins specialized for han-dling groups of GO terms: EnrichmentMap [ 12 ] and BINGO [ 13 ].          3.     GO visual overlays.  Tools that can visualize an interesting sub-set of the GO, and display some additional data about each shown GO term. Typically, this involves coloring the GO terms by the enrichments or p-values determined from user-supplied gene lists (these tools tend to also perform the GO enrichment analysis). They display the terms arranged by parent\u2013child rela-tionships, in a tree-like visual layout. Examples include GOrilla [ 14 ], GRYFUN [ 15 ], GOFFA [ 16 ], and SimCT [ 17 ].   (a)    In addition to the GO, similar tools are available which can highlight the individual members in displayed KEGG pathways [ 18 ]; the pathways can also be shown in a KEGG BRITE functional hierarchy with FuncTree [ 19 ].          4.     Semantic similarity analysis.  Tools that examine the semantic similarity (redundancy) between various GO terms, including Fran Supek and Nives \u0160kunca\f211those that are not linked by direct parent\u2013child relationships. The similarities are used to organize a set of interesting GO terms into clusters and/or graphs, while simultaneously allow-ing highly redundant terms to be \ufb01 ltered out. The user can supply enrichments or p-values to prioritize results. Implemented in REVIGO [ 20 ] and RedundancyMiner [ 21 ].   (a)    Some provisions for this are made in g:Pro\ufb01 ler [ 22 ], which collapses similar GO terms.     (b)    The Ontologizer [ 23 ] can perform a statistical test for enrichment that accounts for the parent\u2013child redundancy [ 24 ] prior to visualizing results.          5.     Emerging methods.  These may involve display of the trends underlying a group of GO terms in a so-called \u201ctag cloud\u201d (with text in various colors and sizes), or in a tree map (a hier-archical organization of colored tiles), as in REVIGO [ 20 ] or GOSummaries [ 25 ]. Additionally, several tools now support the display of multiple GO enrichment analyses side-by-side; see BACA [ 26 ] or GOSummaries. SimCT [ 17 ] can display subtrees of other biomedical ontologies in addition to the GO.      4    Case Studies with Selected Tools   GOrilla  [ 14 ] is a Web-based tool that can take two types of input: either a ranked list of genes or two lists, one with the target genes and the other with the background genes. As output, GOrilla produces a visualization that indicates which terms are signi\ufb01 cantly enriched.  We focus here on the enrichment analysis that takes a ranked list of genes. Brie\ufb02 y, the null hypothesis is that the occurrences of a GO term at various points in the ranked list are equiprobable. Lower  p -values indicate a higher con\ufb01 dence for a GO term to be enriched towards the top of the list.  As an example analysis, we downloaded a dataset of transcrip-tion pro\ufb01 ling by microarray of human peripheral blood  mononuclear cells after a treatment with  Staphylococcus aureus  and incubation for different lengths of time [ 27 ], obtained from the Gene Expression Atlas [ 28 ] at   http://www.ebi.ac.uk/gxa/experiments/E-GEOD-16837    . In the GOrilla Web interface (  http://cbl- gorilla.cs.technion.ac.il/    ), we set the p-value threshold to 10 \u22123 , and the remaining settings were the defaults in the tool.  The display is shown in Fig.  2 . Based on the color of the boxes, the user can visualize which GO terms are enriched, and the con-necting lines describe their relationship to other terms in the GO graph.    REVIGO  [ 20 ] analyzes large lists of signi\ufb01 cant GO terms and removes the redundant terms, in order to further narrow the search to a set of nonredundant and highly signi\ufb01 cant GO terms. Brie\ufb02 y, REVIGO creates clusters of GO terms that are semantically similar, and selects one representative for each cluster. Visualizing GO Annotations\f212 One possible input for REVIGO is a list of GO terms with the associated p-values, such as the output list from GOrilla. Alternatively, REVIGO can take as input any other list of GO terms, with or without associated numerical values, and provide various styles of visualization. First, a scatterplot that distributes the GO terms, represented as bubbles, in a 2D space that will put two GO terms closer together if they are more semantically similar. Second, an interactive graph that connects the user-supplied set of GO terms based on the structure of the GO hierarchy. Third, a TreeMap where terms are clustered and clusters displayed as colored tiles. Fourth, REVIGO provides a word cloud that highlights the most frequent keywords in the names and descriptions of the GO terms.  To perform the analysis, we used the setting in GOrilla to automatically forward its GO term enrichment results as a query to the REVIGO tool. In REVIGO, we used the default settings.   Fig. 2    A visualization of the Biological Process Gene Ontology annotations using GOrilla. The dataset used is a microarray transcription pro\ufb01 ling of human peripheral blood mononuclear cells after treatment with  Staphylococcus aureus  (Expression Atlas dataset ID E-GEOD-16837). The GOrilla settings were left at default values:  p -value threshold of  p  &lt; 10 \u22123 , organism  Homo sapiens  and running mode \u201csingle ranked list\u201d       Fig. 3 (continued) while its size re\ufb02 ects the generality of the GO term in the UniProt-GOA database. ( b ) The table view shows the list of all the input GO terms: those shown in the scatterplot are written in regular font, while those labeled as redundant by REVIGO are shown in  gray italics         Fran Supek and Nives \u0160kunca\f  Fig. 3    Visualizations of Biological Process GO annotations using REVIGO: scatterplot and table views. The data-set used was imported from GOrilla (see legend of Fig.  2 ). We used the default settings of the REVIGO tool. ( a ) The scatterplot view visualizes the GO terms in a \u201csemantic space\u201d where the more similar terms are positioned closer together [ 20 ]. The color of the bubble re\ufb02 ects the p-value obtained in the GOrilla analysis,  \f  Fig. 4    Visualizations of Biological Process GO annotations using REVIGO: TreeMap ( a ), interactive graph ( b ) and word cloud views ( c ). The dataset used was imported from GOrilla (see legend of Fig.  2 ). We used the default settings of the tool        \f215The results are shown in Figs.  3  and  4 . The various visualization styles highlight the GO terms that are enriched in the input dataset.     RedundancyMiner  [ 21 ] is another tool that focuses on non-redundant terms in a large list of enriched GO terms, producing a Clustered Image Map (CIM) as a result. It is a part of a larger pipeline: RedundancyMiner relies on GOminer input and on CIM miner for visualization. In particular, RedundancyMiner performs Fisher\u2019s exact tests for each pair of GO terms in the datasets, calcu-lating whether the two sets of genes annotated with these GO terms are overlapping. A symmetrical matrix of these p-values is subsequently analyzed to arrive to a set of GO terms that are most independent, and therefore least redundant.  To perform the analysis, we started with the same \ufb01 le as for the two tools described above. First, we generated two \ufb01 les using a custom Python script: (1) a \ufb01 le containing all the genes in the array and (2) a \ufb01 le containing the genes that are over or underexpressed, labeled with \u201c1\u201d or \u201c\u22121,\u201d respectively. Of note, Python is not necessary for RedundancyMiner and these \ufb01 les could be generated otherwise. Second, we put these \ufb01 les as input for the GOminer tool (  http://discover.nci.nih.gov/gominer/GoCommandWebInterface.jsp    ). We selected the databases that contain  Homo sapiens  data and as the organism we set  H. sapi-ens . The remaining parameters were the defaults in the tool. Third, we used the resulting folder as the working folder for RedundancyMiner and we ran the analysis in default mode. Finally, we visualized the resulting CIM \ufb01 le using cimMiner [ 29 ], avail-able at   http://discover.nci.nih.gov/cimminer/home.do    , in single matrix mode.  Results of our example analysis are shown in Fig.  5 . Even with the stringent threshold of requiring the log 2  fold change greater than 5, similar trends in signi\ufb01 cant GO terms are visible as shown with the remaining two tools.5       Choice of Visualization  Above, we have outlined some of the currently available software tools that can visualize a set of GO terms. We have also argued that a good visualization is an effective means of discovering underlying trends in the data in an unbiased fashion; an appropriate visual dis-play is also imperative when communicating the results to others. The question of which software tool to apply should be addressed keeping these goals in mind. A related yet distinct question is which speci\ufb01 c visualization method to choose. Here, we give a summary of the available options. Of note, the authors of this text are also the developers of REVIGO [ 20 ], a versatile visualization tool, which implements several of the approaches listed below.Visualizing GO Annotations\f216    1.     Graphs/networks.  The GO graph consists of  nodes  (here, Gene Ontology terms) and  edges  (here, parent\u2013child relation-ships), which connect the nodes and which have directional-ity. Nodes and edges can have multiple attributes that can be visualized. For instance, the enrichment of a GO term in a user\u2019s experiment may be shown as a color of a node (Fig.  2 ). Importantly, the spatial arrangement of the nodes on the \ufb01 nal plot is called a  layout , and is often created to suggest related clusters of nodes by placing similar nodes closer together. Such approaches are reviewed and demonstrated by Merico et al. [ 30 ]; tools like Cytoscape [ 9 ] support a vari-ety of visual layouts.   (a)    A special case of a layout is a tree-like display that high-lights the \u2018levels\u2019 in the Gene Ontology and the parent\u2013child relationships between terms (e.g., Fig.  2 ). These levels (determining the  depth  of a node in the graph) are often used as a measure for how general the GO term is. However, this may be misleading in some instances\u2014for example, the Molecular Function ontology is more shal-low than the Biological Process ontology\u2014and we there-fore recommend the use of the  information content  (IC) measure [ 31 ] for this purpose. This is de\ufb01 ned as the negative   Fig. 5    A visualization of a set of Biological Process GO annotations using RedundancyMiner. The dataset used is a microarray transcription pro\ufb01 ling of human peripheral blood mononuclear cells after treatment with  Staphylococcus aureus . For this visualization, we focus on genes that had log2 fold change greater than 5        Fran Supek and Nives \u0160kunca\f217logarithm of the relative frequency of the respective term annotations in some underlying database, such as the UniProt-GOA [ 32 ].          2.     Semantic similarity space.  Various mathematical methods mea-sure the semantic similarity between pairs of GO terms, such as SimRel [ 33 ]; see ref.  34  for a review. If the \ufb01 rst term in a pair is a direct parent, child or sibling of the second term, their semantic similarity will be very high. However, also the more distantly related terms will show some degree of similarity, as long as they reside in a common branch of the GO tree struc-ture. Many such pairwise similarities within a group of GO terms can be processed by a projection technique, such as  prin-cipal components analysis  (PCA) or  multidimensional scaling . The resulting plots preserve as much of the original pairwise distances as possible, while showing all supplied GO terms in a two- dimensional plane. The main visualization in REVIGO is based on this approach (Fig.  3a ).      3.     Treemaps.  Hierarchical diagrams consisting of tiles subdivided into smaller tiles. Treemaps are good for interactive explora-tion, as they can be \u2018zoomed in\u2019 by clicking a tile and revealing \ufb01 ner levels of subdivisions. Here, tiles can be GO terms and the subdivisions their child terms. The tile sizes may corre-spond to some measure of importance of GO terms to the user, such as enrichment or p-values. REVIGO has an imple-mentation of this visualization approach (Fig.  4b ).      4.     Word clouds.  A display with text shown in various sizes and pos-sibly colors. Here, the individual words or short phrases may be the names of the GO terms or some keywords associated to the GO terms. The text size/color may convey the importance to the user (enrichment), or in some instances generality of a GO term (see  information content  above). This visualization method is implemented in GOSummaries and REVIGO (Fig.  4c ).      5.     Clustered Heatmaps.  Two-dimensional grids of values, wherein the rows and/or columns are clustered to reveal the \u2018block structure\u2019 in the data. Clustered heatmaps are often used for showing high-dimensional data in biology, but rarely so for GO terms. In fact, this could be done to show the GO terms\u2019 similarity based on what genes are annotated to them, or on the terms\u2019 semantic similarity (which is de\ufb01 ned by the struc-ture of the GO graph). An example implementation can be found in RedundancyMiner (Fig.  5 ).      In addition to the above, many of the tools specializing in GO enrichment testing (or in other analyses of large-scale biological data) often come bundled with visualizations that include GO as an important context. Examples include the Bioconductor pack-ages GOexpress, GOfunction and GOSim. In addition, it is often Visualizing GO Annotations\f218possible to customize such displays in more detail by manually passing the GO data to a dedicated visualization software, such as the  ggplot2  package [ 35 ] in R, or to  gnuplot  software. For example, a specialized software to draw treemaps can be made to display GO enrichments from a biological experiment via a script that prepares the data in a correct format [ 36 ]. REVIGO will draw bubble charts where the GO terms are displayed in a semantic similarity space [ 20 ], and it can export a  ggplot2  script which is further customiz-able for e.g., font sizes, colors, and line styles; it can similarly export a graph to be further customized in Cytoscape.  6    Concluding Remarks and Outlook  In summary, we outline several tools that biologists can use to visual-ize sets of Gene Ontology terms and uncover novel and interesting trends in their experimental data. We anticipate that the future will bring even more massive biological data sets, which will have several consequences. First, the lists of interesting GO terms will grow in length, as larger sample sizes afford more statistical power to detect associations. Therefore, re\ufb01 nements of the existing approaches that address redundant GO terms [ 20 ,  21 ] will come in useful. Second, the visualization software will need to deal with more than a single list of enriched GO terms. While some current tools can display such results from multiple experiments side-by- side, e.g. BACA [ 26 ], tools will be needed that can integrate such lists and extract patterns across them. Finally, while GO is a prominent example of an ontol-ogy used by biologists, it is far from the only one [ 37 ]\u2014over 100 biomedical ontologies exist that describe environments, phenotypes, and chemical entities ( see  Chap. 19) [ 38 ]. We foresee substantial developments in the tools that can summarize and visualize results of various biological experiments in the context of such emerging ontologies.       Acknowledgements  We acknowledge the support of the European Commission via grants MAESTRA (ICT-2013-612944) and InnoMol (FP7-REGPOT-2012-2013-1-316289), and of the Croatian Science Foundation grant MultiCaST (# 5660). Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, Fran Supek and Nives \u0160kunca\f219    1.    Ashburner M, Ball CA, Blake JA et al (2000) Gene ontology: tool for the uni\ufb01 cation of biol-ogy. The Gene Ontology Consortium. Nat Genet 25:25\u201329      2.    Rivals I, Personnaz L, Taing L et al (2007) Enrichment or depletion of a GO category within a class of genes: which test? Bioinformatics 23:401\u2013407      3.   du Plessis L, Skunca N, Dessimoz C (2011) The what, where, how and why of gene ontol-ogy--a primer for bioinformaticians. Brief Bioinform 12:723\u2013735        4.    Lespinet O, Wolf YI, Koonin EV et al (2002) The role of lineage-speci\ufb01 c gene family expan-sion in the evolution of eukaryotes. Genome Res 12:1048\u20131059      5.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3      6.    Carbon S, Ireland A, Mungall CJ et al (2009) AmiGO: online access to ontology and anno-tation data. Bioinformatics 25:288\u2013289      7.    Binns D, Dimmer E, Huntley R et al (2009) QuickGO: a web-based tool for Gene Ontology searching. Bioinformatics 25:3045\u20133046       8.    Vercruysse S, Venkatesan A, Kuiper M (2012) OLSVis: an animated, interactive visual browser for bio-ontologies. BMC Bioinformatics 13:116      9.    Smoot ME, Ono K, Ruscheinski J et al (2011) Cytoscape 2.8: new features for data integra-tion and network visualization. Bioinformatics 27:431\u2013432      10.   Bastian M, Heymann S, Jacomy M (2009) Gephi: an open source software for exploring and manipulating networks. In: Third interna-tional AAAI conference on weblogs and social media      11.    Batagelj V (2011) Exploratory social network analysis with Pajek (Structural analysis in the social sciences). Cambridge University Press, Cambridge      12.    Merico D, Isserlin R, Bader GD (2011) Visualizing gene-set enrichment results using the Cytoscape plug-in enrichment map. Methods Mol Biol 781:257\u2013277       13.    Maere S, Heymans K, Kuiper M (2005) BiNGO: a Cytoscape plugin to assess overrepresentation of gene ontology categories in biological net-works. Bioinformatics 21:3448\u20133449      14.    Eden E, Navon R, Steinfeld I et al (2009) GOrilla: a tool for discovery and visualization of enriched GO terms in ranked gene lists. BMC Bioinformatics 10:48      15.    Bastos HP, Sousa L, Clarke LA et al (2015) GRYFUN: a web application for GO term annotation visualization and analysis in protein sets. PLoS One 10:e0119631       16.   Sun H, Fang H, Chen T et al (2006) GOFFA: gene ontology for functional analysis--a FDA gene ontology tool for analysis of genomic and proteomic data. BMC Bioinformatics 7(Suppl 2):S23      17.    Herrmann C, B\u00e9rard S, Tichit L (2009) SimCT: a generic tool to visualize ontology-based relationships for biological objects. Bioinformatics 25:3197\u20133198      18.     KEGG Mapper    .   http://www.genome.jp/kegg/tool/map_pathway2.html                19.    Uchiyama T, Irie M, Mori H et al (2015) FuncTree: functional analysis and visualization for large-scale omics data. PLoS One 10:e0126967        20.    Supek F, Bo\u0161njak M, \u0160kunca N et al (2011) REVIGO summarizes and visualizes long lists of gene ontology terms. PLoS One 6:e21800      21.    Zeeberg BR, Liu H, Kahn AB et al (2011) RedundancyMiner: de-replication of redun-duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.     References Visualizing GO Annotations\f220dant GO categories in microarray and pro-teomics analysis. BMC Bioinformatics 12:52      22.    Reimand J, Arak T, Vilo J (2011) g:Pro\ufb01 ler\u2014a web server for functional interpretation of gene lists (2011 update). Nucleic Acids Res 39:W307\u2013W315      23.   Bauer S, Grossmann S, Vingron M et al (2008) Ontologizer 2.0--a multifunctional tool for GO term enrichment analysis and data explo-ration. Bioinformatics 24:1650\u20131651      24.    Bauer S, Gagneur J, Robinson PN (2010) GOing Bayesian: model-based gene set analy-sis of genome-scale data. Nucleic Acids Res 38:3523\u20133532       25.    Kolde R, Vilo J (2015) GOsummaries: an R Package for visual functional annotation of experimental data. F1000Research 4:574      26.    Fortino V, Alenius H, Greco D (2015) BACA: bubble chArt to compare annotations. BMC Bioinformatics 16:37      27.    Kobayashi SD, Braughton KR, Palazzolo-Ballance AM et al (2010) Rapid neutrophil destruction following phagocytosis of Staphylococcus aureus. J Innate Immun 2:560\u2013575      28.    Petryszak R, Burdett T, Fiorelli B et al (2014) Expression Atlas update\u2014a database of gene and transcript expression from microarray- and sequencing-based functional genomics experi-ments. Nucleic Acids Res 42:D926\u2013D932      29.    Weinstein JN, Myers TG, O\u2019Connor PM et al (1997) An information-intensive approach to the molecular pharmacology of cancer. Science 275:343\u2013349      30.    Merico D, Gfeller D, Bader GD (2009) How to visually interpret biological data using net-works. Nat Biotechnol 27:921\u2013924      31.    Lord PW, Stevens RD, Brass A et al (2003) Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation. Bioinformatics 19:1275\u20131283      32.    Dimmer EC, Huntley RP, Alam-Faruque Y et al (2012) The UniProt-GO Annotation database in 2011. Nucleic Acids Res 40:D565\u2013D570      33.    Schlicker A, Domingues FS, Rahnenf\u00fchrer J et al (2006) A new measure for functional simi-larity of gene products based on Gene Ontology. BMC Bioinformatics 7:302      34.     Mazandu GK, Mulder NJ (2013) Information content-based gene ontology semantic similar-ity approaches: toward a uni\ufb01 ed framework theory. BioMed Res Int 2013:292063          35.     Wickham H (2009) ggplot2: elegant graphics for data analysis           36.    Baehrecke EH, Dang N, Babaria K et al (2004) Visualization and analysis of microarray and gene ontology data with treemaps. BMC Bioinformatics 5:84     37.    Smith B, Ashburner M, Rosse C et al (2007) The OBO Foundry: coordinated evolution of ontologies to support biomedical data integra-tion. Nat Biotechnol 25:1251\u20131255     38.   Furnham N (2016) Complementary sources of protein functional information: the far side of GO. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 19    Fran Supek and Nives \u0160kunca\fChapter 16</p> <p>A Gene Ontology Tutorial in Python</p> <p>Alex Warwick Vesztrocy and Christophe Dessimoz</p> <p>Abstract</p> <p>This  chapter  is  a  tutorial  on  using  Gene  Ontology  resources  in  the  Python  programming  language. This entails querying the Gene Ontology graph, retrieving Gene Ontology annotations, performing gene enrichment analyses, and computing basic semantic similarity between GO terms. An interactive version of the tutorial, including solutions, is available at http://gohandbook.org.</p> <p>Key words Gene Ontology, Tutorial, Python</p> <p>1</p> <p>Introduction</p> <p>One of the main goals of developing a formal ontology is to facili- tate computational analysis. The purpose of this chapter is to pro- vide  a  hands-on  introduction  to  handling  GO  terms  and  GO annotations in Python. This tutorial also shows how Python can be used to perform GO term enrichment analyses, as well as how to compute the similarity between GO terms.</p> <p>This tutorial uses Python, but other popular languages com- monly  used  to  perform  GO  analyses  include  Java,  R,  Perl,  and Matlab. The Gene Ontology consortium website maintains a list of software libraries, accessible from</p> <p>ftp://ftp.geneontology.org/pub/go/www/GO.tools_by_type. software.shtml</p> <p>An interactive version of this tutorial, with model solutions to all the questions, is available from the book homepage at http:// gohandbook.org.</p> <p>2</p> <p>Querying the Gene Ontology</p> <p>A fundamental first step is to retrieve the Gene Ontology and anal- yse that structure (Chap. 3 [1]).</p> <p>Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446, DOI 10.1007/978-1-4939-3743-1_16, \u00a9 The Author(s) 2017</p> <p>221</p> <p>222</p> <p>One convenient Python package available to query the GO is GOATOOLS [2]. This package can read the GO structure stored in  OBO  format,  which  is  available  from  the  GO  website  (see Chap. 11 [3]). After loading this file, it is possible to traverse the GO structure, search for particular GO terms, and find out which other terms they are related to and how.</p> <p>This package is available on the Python Package Index (PyPI), a standard repository of python libraries. As such, it is possible to install it locally using the command1:</p> <p>pip install goatools</p> <p>The GOATOOLS package contains the functions necessary to parse  the  GO  in  OBO  format,  to  query  it,  and  to  visualise  the ontology.  Using  the  function  obo_parser.GODag()  from GOATOOLS,  the  GO  file  can  be  loaded.  Each  GO  term  in  the resulting object is an instance of the GOTerm class, which contains many useful attributes, such as:</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>GOTerm.name: textual definition;</p> <p>GOTerm.namespace: the ontology the term belongs to (i.e., Molecular Function [MF], Biological Process [BP], or Cellular Component [CC]);</p> <p>GOTerm.parents: list of parent terms;</p> <p>GOTerm.children: list of children terms;</p> <p>GOTerm.level: shortest distance to the root node;</p> <p>Exercise 2.1 Download  the  GO  basic  file  in  OBO  format  (go-basic.obo),  and load  the  GO  using  the  function  obo_parser.GODag()  from GOATOOLS. Using this library, answer the following questions:</p> <p>(a)  What is the name of the GO term GO:0048527?</p> <p>(b)  What are the immediate parent(s) of the term GO:0048527?</p> <p>(c)  What are the immediate children of the term GO:0048527?</p> <p>(d)  Recursively  find  all  the  parent  and  child  terms  of  the  term GO:0048527. Hint: use your solutions to the previous two ques- tions, with a recursive loop.</p> <p>(e)  How many GO terms have the word \u201cgrowth\u201d in their name?</p> <p>(f)  What is the deepest common ancestor term of GO:0048527 and</p> <p>GO:0097178?</p> <p>(g)  Which GO terms regulate GO:0007124 (pseudohyphal growth)? Hint: load the relationship tags and look for terms which define regulation.</p> <p>1</p> <p>GOATOOLS version 0.6.4 was used to write this tutorial and the exercises. To install this exact version, use pip install goatools==0.6.4</p> <p>Alex Warwick Vesztrocy and Christophe Dessimoz\f223</p> <p>GO:0008150 biological_process</p> <p>is_a</p> <p>is_a</p> <p>is_a</p> <p>GO:0009987 cellular process</p> <p>GO:0044699 single-organism process</p> <p>GO:0032502 developmental process</p> <p>is_a</p> <p>is_a</p> <p>is_a</p> <p>is_a</p> <p>is_a</p> <p>GO:0044763 single-organism cellular process</p> <p>GO:0044767 single-organism developmental process</p> <p>is_a</p> <p>is_a</p> <p>GO:0048856 anatomical structure development</p> <p>GO:0048869 cellular developmental process</p> <p>is_a</p> <p>is_a</p> <p>GO:0048468 cell development</p> <p>is_a</p> <p>GO:0048627 myoblast development</p> <p>Fig. 1 Selected parts of the Gene Ontology can be visualised using the GOATOOLS library [2]</p> <p>Exercise 2.2 Using the visualisation function in the GOATOOLS library, answer the following questions:</p> <p>(a)  Produce  a  figure  similar  to  that  in  Fig.  1,  for  the  GO  term GO:0097190. From the visualisation, what is the name of this term?</p> <p>(b)  Using this figure, what is the most specific term that is in the parent terms of both GO:0097191 (extrinsic apoptotic signalling pathway) and GO:0038034 (signal transduction in absence of ligand)? This is also referred to as the lowest common ancestor (see Chap. 12 [4]).</p> <p>Furthermore,  other  tag-value  lines  such  as  the  \u201crelation- ships\u201d  can  be  loaded  with  an  optional  argument  of,  e.g., optional_attrs=['relationship'].</p> <p>The GOATOOLS library also includes functions to visualise the GO graph. For instance, it is possible to depict the location of a par- ticular GO term in the ontology using the method GOTerm.draw_ lineage(). For example, the plot in Fig. 1 showing the  lineage of the GO term GO:0048527 was created using this function.</p> <p>As an alternative to GOATOOLS and OBO files, it is possible to retrieve information relating to a specific term from a web ser- vice. One such service is the EMBL-EBI QuickGO resource (see</p> <p>A Gene Ontology Tutorial in Python\f224</p> <p>Chap. 11; [3, 5]), which can provide descriptive information about GO  terms  in  OBO-XML  format.  It  is  possible  to  request  this OBO-XML file over HTTP, using a URL of the form</p> <p>http://www.ebi.ac.uk/QuickGO/GTerm?id=&amp; format=oboxml <p>where  is replaced with the GO identifier for the term of interest. In Source Code 2.1, an example function to automate this in Python is listed, which uses the urllib library to request the OBO- XML and the xmltodict library to parse the XML into an easy to use dictionary structure. Both libraries are available to install using pip, if required. Note that the future library was used to ensure that the function is both Python 2 and 3 compatible. <p>The dictionary structure that is returned can vary based on what information is available in the database. One example of an informa- tion-rich  term  is  GO:0043065.  A  visualisation  of  the  dictionary</p> <p>obo</p> <p>header</p> <p>term</p> <p>format-version</p> <p>auto-generated-by</p> <p>synonymtypedef</p> <p>default-namespace</p> <p>remark</p> <p>id</p> <p>name</p> <p>namespace</p> <p>def</p> <p>comment</p> <p>synonym</p> <p>xref</p> <p>is_a</p> <p>relationship</p> <p>id</p> <p>name</p> <p>scope</p> <p>defstr</p> <p>type</p> <p>to</p> <p>Fig.  2  Visualisation  of get_oboxml('GO:0043065')</p> <p>the  keys</p> <p>in</p> <p>the  hierarchical  dictionary</p> <p>structure</p> <p>returned  by</p> <p>Source Code 2.1. get_oboxml() function for Python 2 and 3. from future.standard_library import install_aliases install_aliases() from urllib.request import urlopen import xmltodict</p> <p>def get_oboxml(go_id):     \"\"\"</p> <p>This function  retrieves  the  OBO-XML  for  a given Gene Ontology term, using EMBL-EBI's QuickGO browser.  Input:  go_id\u00a0 -  a  valid  Gene  Ontology  ID, e.g. GO:0048527.</p> <pre><code>\"\"\"\n</code></pre> <p>quickgo_url= \"http://ebi.ac.uk/QuickGO/GTerm?id=\"+ go_id+\"&amp;format=oboxml\" oboxml = urlopen(quickgo_url)</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/#check-the-response","title":"Check the response","text":"<p>if(oboxml.getcode() == 200):</p> <p>obodict = xmltodict.parse(oboxml.read()) return obodict</p> <p>else:</p> <p>raise  ValueError(\"Couldn't  receive  OBOXML from QuickGO.\u00a0Check URL and try again.\")</p> <p>Alex Warwick Vesztrocy and Christophe Dessimoz</p> <p>225</p> <p>structure for this term, created with the visualisedictionary package available from PyPI (using pip), has been included in Fig. 2. The main advantage of using a web service, such as QuickGO, is  that  there  is  no  requirement  to  download  and  parse  the  entire Gene Ontology structure; only the information required is retrieved. This  is  therefore  more  efficient  if  only  a  few  particular  terms  are involved  in  an  analysis.  By  contrast,  for  analyses  involving  many terms, the file-based approach described above is more suitable.</p> <p>Exercise 2.3 Using the function get_oboxml(), listed in Source Code 2.1, answer the following questions:</p> <p>(a)  Find the name and description of the GO term GO:0048527 (lat- eral root development). Hint: print out the dictionary returned by the function and study its structure, or use the visualisation in Fig. 2.</p> <p>(b)  Look at the difference in the OBO-XML output for the GO terms GO:00048527  (lateral  root  development)  and  GO:0097178 (ruffle  assembly),  then  generate  a  table  of  the  synonymous  rela- tionships of the term GO:0097178.</p> <p>3</p> <p>Retrieving GO Annotations</p> <p>This  section  looks  at  manipulating  the  Gene  Association  File (GAF) standard, using a parser from the BioPython package [6].</p> <p>Firstly,  a  GAF  file,  which  contains  GO  annotations,  shall  be downloaded  from  the  UniProt-GOA  database  [7].  Their  website (https://www.ebi.ac.uk/GOA/downloads) lists a number of vari- ants. For this tutorial the reduced GAF file containing only the gene association data for Arabidopsis thaliana is going to be used.</p> <p>Annotations from GAF files can be loaded into a Python diction- ary using an iterator from the BioPython package (Bio.UniProt. GOA.gafiterator). Source Code 3.1 shows a simple example of this being used, in order to print out the protein ID for each annotation.</p> <p>Source Code 3.1 from Bio.UniProt.GOA import gafiterator import gzip</p>"},{"location":"paper/literature/Gene_Ontology_Handbook_Full/#filename","title":"filename =  <p>filename = 'gene_association.goa_arabidopsis.gz'</p> <p>with gzip.open(filename, 'rt') as fp:     for annotation in gafiterator(fp):         # Output annotated protein ID         print(annotation['DB_Object_ID'])</p> <p>A Gene Ontology Tutorial in Python\f226</p> <p>Recall that the latest GAF standard, version 2.1, has 17 tab- delimited fields, which are described in detail in Chap. 3 [1]. Some of them include:</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>\u25cf\u25cf</p> <p>'DB': the protein database;</p> <p>'DB_Object_ID': protein ID;</p> <p>'Qualifier': annotation qualifier (such as NOT);</p> <p>'GO_ID': GO term;</p> <p>'Evidence': evidence code.</p> <p>Exercise 3.1</p> <p>(a)  Find the total number of annotations for Arabidopsis thaliana with NOT qualifiers. What is this as a percentage of the total number of annotations for this species?</p> <p>(b)  How  many  genes  (of  Arabidopsis  thaliana)  have  the  annotation</p> <p>GO:0048527 (lateral root development)?</p> <p>(c)  Generate a list of annotated proteins which have the word \u201cgrowth\u201d</p> <p>in their name.</p> <p>(d)  There are 21 evidence codes used in the Gene Ontology project. As discussed in Chap. 3 [1], many of these are inferred, either by curators or automatically. Find the counts of each evidence code in the Arabidopsis thaliana annotation file.</p> <p>4</p> <p>GO Enrichment or Depletion Analysis</p> <p>As discussed in detail in Chap. 13 [8] one of the most common analyses  performed  on  GO  data  is  an  enrichment  (or  depletion) analysis.  In  this  tutorial,  the  GOEnrichmentStudy()  function available in the GOATOOLS library (which has been seen in sec- tion 2) will be used.</p> <p>The GOEnrichmentStudy()  function  requires  the  follow-</p> <p>ing arguments:</p> <ol> <li>the background set of terms (also known as the \u201cpopulation</li> </ol> <p>set\u201d), passed as a list of GO term IDs;</p> <ol> <li> <p>associations between proteins IDs and GO term IDs, passed as a dictionary with protein IDs as the keys and sets of associated GO terms as the values;</p> </li> <li> <p>the  Gene  Ontology  structure,  i.e.,  the  output  by  the  obo_</p> </li> </ol> <p>parser() function from GOATOOLS;</p> <ol> <li>whether annotations should be propagated to all parent terms, (defined in terms of is_a tags, only), indicated by setting the optional  boolean  parameter  propagate_counts  to  True (default) or False;</li> </ol> <p>Alex Warwick Vesztrocy and Christophe Dessimoz\f227</p> <ol> <li>the significance level, indicated by setting the optional parameter</li> </ol> <p>alpha to the desired cut-off (default: 0.05);</p> <ol> <li> <p>the foreground set of terms (also known as \u201cstudy set\u201d), indi- cated by setting the parameter study to a list of GO term IDs;</p> </li> <li> <p>the list of method(s) to be used to assess significance, indicated by setting the parameter methods to a list containing one or several of these elements:</p> </li> </ol> <p>(a)  \"bonferroni\": Fisher\u2019s exact test with Bonferroni cor-</p> <p>rection for multiple testing;</p> <p>(b)  \"sidak\": Fisher\u2019s exact test with \u0160id\u00e1k correction for mul-</p> <p>tiple testing;</p> <p>(c)  \"holm\": Fisher\u2019s exact test with Holm\u2013Bonferroni correc-</p> <p>tion for multiple testing;</p> <p>(d)  \"fdr\": Fisher\u2019s exact test, controlling the false discovery</p> <p>rate (see Chap. 13 [8]).</p> <p>The function returns the list of over-represented and under- represented  GO  terms  in  the  population  set,  compared  to  the background set.</p> <p>Exercise 4.1 Perform an enrichment analysis using the list of genes with the \u201cgrowth\u201d keyword from exercise 3.1.c. Use the Arabidopsis thaliana annotation set as background, also from exercise 3.1, and the GO structure from exercise 2.1.</p> <p>(a)  Which GO term is most significantly enriched or depleted? Does</p> <p>this make sense?</p> <p>(b)  How  many  terms  are  enriched,  when  using  the  Bonferroni  cor-</p> <p>rected p-value \u2264 0.01?</p> <p>(c)  How many terms are enriched, when using the false discovery rate</p> <p>(a.k.a. q-value) \u2264 0.01?</p> <p>5</p> <p>Computing Basic Semantic Similarities Between GO Terms</p> <p>In  this  section,  the  focus  is  on  computing  semantic  similarity between GO terms, based on ideas presented in detail in Chap. 12 [4]. Semantic similarity measures enable us to quantify the func- tional similarity of genes annotated with GO terms.</p> <p>Recall that semantic similarity measures are broadly separated in two categories: graph-based and information-theoretic  measures. The  former  relies  only  on  the  structure  of  the  Gene  Ontology graph, whilst the latter also accounts for the information content of the terms.</p> <p>One graph-based measure of semantic similarity, presented in Chap. 12 [4], is the inverse of the number of edges separating two</p> <p>A Gene Ontology Tutorial in Python\f228</p> <p>Acknowledgements</p> <p>terms.  It  is  possible  to  compute  the  minimum  number  of  edges separating two terms (t1, t2) by first finding the deepest common ancestor (tDCA). Then the difference in depth between each term and  the  deepest  common  ancestor  can  be  used  to  calculate  the minimum distance between the terms. i.e.,</p> <p>min_</p> <p>distance</p> <p>(</p> <p>t 1</p> <p>,</p> <p>t</p> <p>2</p> <p>) =</p> <p>depth</p> <p>( ) + t 1</p> <p>depth</p> <p>(</p> <p>t</p> <p>2</p> <p>) \u2212 \u00d7 2</p> <p>( depth DCA</p> <p>t</p> <p>)</p> <p>Further,  one  example  of  an  information-theoretic  measure  (see Chap. 12 [4]) is Resnik\u2019s similarity measure\u2014the information con- tent of the most informative common ancestor of the two terms in question. The information content of a term is defined as the nega- tive  logarithm  of  its  probability,  which  can  be  estimated  from  the frequency of the term in the annotation database of choice.</p> <p>Exercise 5.1</p> <p>(a)  GO:0048364  (root  development)  and  GO:0044707  (single- multicellular organism process) are two GO terms taken from Fig. 1. Calculate the semantic similarity between them based on the inverse of the semantic distance (number of branches separating them).</p> <p>(b)  Calculate  the</p> <p>information  content  (IC)  of  the  GO  term GO:0048364  (root  development),  based  on  the  frequency  of observation in Arabidopsis thaliana.</p> <p>(c)  Calculate  the  Resnik  similarity  measure  between  the  same  two</p> <p>terms as in part a.</p> <p>We thank Adrian Altenhoff, Debra Klopfenstein, and Haibao Tang for  helpful  feedback  on  the  tutorial.  CD  acknowledges  Swiss National Science Foundation grant 150654 and UK BBSRC grant BB/M015009/1.  Open  Access  charges  were  funded  by  the University  College  London  Library,  the  Swiss  Institute  of Bioinformatics,  the  Agassiz  Foundation,  and  the  Foundation  for the University of Lausanne.</p> <p>Open  Access  This  chapter  is  distributed  under  the  terms  of  the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits use, dupli- cation, adaptation, distribution and reproduction in any medium or  format,  as  long  as  you  give  appropriate  credit  to  the  original author(s)  and  the  source,  a  link  is  provided  to  the  Creative Commons license and any changes made are indicated.</p> <p>Alex Warwick Vesztrocy and Christophe Dessimoz \f229</p> <p>The  images  or  other  third  party  material  in  this  chapter  are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted  by  statutory  regulation,  users  will  need  to  obtain  per- mission from the license holder to duplicate, adapt or reproduce the material.</p> <p>References</p> <ol> <li> <p>Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer  on  the  gene  ontology.  In:  Dessimoz  C, \u0160kunca  N  (eds)  The  gene  ontology  handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3</p> </li> <li> <p>Tang  H,  Klopfenstein  D,  Pedersen  B  et  al (2015)  GOATOOLS:  tools  for  gene  ontology, Zenodo</p> </li> <li> <p>Munoz-Torres  M,  Carbon  S  (2016)  Get  GO! retrieving  GO  data  using  AmiGO,  QuickGO, API, files, and tools. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular  biology,  vol  1446.  Humana  Press. Chapter 11</p> </li> <li> <p>Pesquita  C  (2016)  Semantic  similarity  in  the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The  gene  ontology  handbook.  Methods  in</p> </li> </ol> <p>molecular  biology,  vol  1446.  Humana  Press. Chapter 12</p> <ol> <li> <p>Binns  D,  Dimmer  E,  Huntley  R  et  al  (2009) QuickGO: a web-based tool for Gene Ontology searching. Bioinformatics 25:3045\u20133046</p> </li> <li> <p>Cock  PJA,  Antao  T,  Chang  JT  et  al  (2009) Biopython:  freely  available  Python  tools  for computational  molecular  biology  and  bioinfor- matics. Bioinformatics 25:1422\u20131423</p> </li> <li> <p>Huntley  RP,  Sawford  T,  Mutowo-Meullenet  P et al (2015) The GOA database: gene Ontology annotation updates for 2015. Nucleic Acids Res 43:D1057\u201363</p> </li> <li> <p>Bauer  S  (2016)  Gene-category  analysis.  In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook.  Methods  in  molecular  biology,  vol</p> </li> <li>Humana Press. Chapter 13</li> </ol> <p>A Gene Ontology Tutorial in Python\f   Part V    Advanced Gene Ontology Topics        \f233    Chapter 17    Annotation Extensions                          Rachael     P.     Huntley      and     Ruth     C.     Lovering       Abstract    The speci\ufb01 city of knowledge that Gene Ontology (GO) annotations currently can represent is still restricted by the legacy format of the GO annotation \ufb01 le, a format intentionally designed for simplicity to keep the barriers to entry low and thus encourage initial adoption. Historically, the information that could be captured in a GO annotation was simply the role or location of a gene product, although genetically interacting or binding partners could be speci\ufb01 ed. While there was no mechanism within the original GO annotation format for capturing additional information about the context of a GO term, such as the target gene of an activity or the location of a molecular function, the long-term vision for the GO Consortium was to provide greater expressivity in its annotations to capture physiologically relevant information.  Thus, as a step forwards, the GO Consortium has introduced a new \ufb01 eld into the annotation for-mat,  annotation extensions , which can be used to capture valuable contextual detail. This provides exper-imentally veri\ufb01 ed links between gene products and other physiological information that is crucial for accurate analysis of pathway and network data. This chapter will provide a simple overview of annotation extensions, illustrated with examples of their usage, and explain why they are useful for scientists and bioinformaticians alike.    Key words     Gene Ontology  ,   Annotation  ,   Biocuration  ,   Context  ,   Pathway  ,   Network  ,   Analysis  ,   Annotation extension  1      Introduction  Functional annotation of gene products using the GO has gone far in simplifying the task of \ufb01 nding functional roles of both individual and groups of gene products. It has enabled a multitude of analyses that were previously not possible. For example, GO annotations are invaluable for analyzing a list of genes that are identi\ufb01 ed as differentially expressed in a microarray experiment using one of the many freely available functional enrichment programs [ 1 ,  2 ] ( see  also Chap.   13     [ 3 ]).  The original simplistic GO annotation pairs a gene product with a GO term (one of  biological process ,  molecular function  or  cellular component ). Because these pair-wise associations are treated independently, vast amounts of correlated functional data are Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_17, \u00a9 The Author(s) 2017\f234omitted from the basic GO annotation and therefore inaccessible to network and pathway analyses. This contextual information is essential for understanding the physiological roles of gene prod-ucts. Without contextual information bioinformatics analyses can-not identify gene products that perform a role only under certain conditions or in the presence of speci\ufb01 c factors and therefore will present an incomplete view of the available data [ 4 ]. Speci\ufb01 c gene products will often have different biological roles in different cells or tissues as these roles will be dependent on the available interact-ing partners; already tissue-speci\ufb01 c network analyses are able to demonstrate the importance of the cellular environment. For example, Greene et al. [ 5 ] analyzed the GO and pathway annota-tions of the available interaction partners of the transcription factor, LEF1, in different tissue types. They demonstrated that LEF1 was signi\ufb01 cantly associated with biological processes that were relevant to each tissue type. For instance, in blood vessels the LEF1 interact-ing partners were associated with angiogenesis, whereas in hypo-thalamus they are associated with hypothalamus development.  Here we describe an incremental extension of the GO annota-tion format to allow more detailed statements about gene product function, which will bene\ufb01 t all types of functional analyses [ 5 ].  2    Extending the Core GO Annotation Model  In practical terms, the newly introduced  annotation extensions  \ufb01 eld enables curators to provide appropriate experimentally evidenced contextual information for manually curated annotations (extant software pipelines for electronically inferred annotations (IEA) do not yet support population of this \ufb01 eld).  Generating a comprehensive annotation, one that includes its context, involves re\ufb01 ning the core pair-wise association with addi-tional relationships to other ontology classes [ 5 ]. This dynamic approach is logically equivalent to creating a new term for the sub-type in the ontology, but offers advantages in terms of both \ufb02 exi-bility and ef\ufb01 ciency.  In essence this approach allows curators to dynamically create \u201cvirtual\u201d terms. It enables curators to combine all of the speci\ufb01 c terms needed to fully describe a gene product in a way that can be reproducibly, computationally interpreted. For example, \u201ccore RNA polymerase binding transcription factor in hypothalamus\u201d, associates a gene product with that activity occurring in that spe-ci\ufb01 c location. From the computer logic perspective this effectively has created a subclass of \u201ccore RNA polymerase binding transcrip-tion factor activity\u201d (GO:0000990). The \ufb02 exibility of expression thus supports the virtual creation of complex, compound child terms on an as-needed basis. Additionally, this approach to virtual Rachael P. Huntley and Ruth C. Lovering\f235term creation is immediate. Because the parent can be automati-cally inferred from the primary term of the association, and because the additional relationships to other terms provide the re\ufb01 nements needed to create a more speci\ufb01 c term, the result is that the previ-ously independent processes of annotating gene products and cre-ating ontology terms are now fully integrated. The use of annotation extensions means that curators can immediately make the biologi-cal statement required without having to return to the annotation to update it only after the term is available in the ontology, thus making the overall process more ef\ufb01 cient. As these virtual terms are not consequently added to the ontology\u2014although they could be if required\u2014the extended annotations can be \u201cfolded\u201d to create the logical equivalent of a GO term [ 5 ]. The GO Consortium (GOC) is in the process of incorporating these inferred annota-tions into the \ufb01 les it provides and so this contextual information will be included by default for use by anyone, or any analysis tool, that utilizes the annotation \ufb01 les.  3    Annotation Extension Format  Annotation extensions re\ufb01 ne the GO term used in the basic anno-tation by adding one or more relational expressions (extensions). Each extension is written as  Relation(Entity) , where  Relation  is a label describing the relationship between the GO term and the entity, and  Entity  is an identi\ufb01 er for a database object or ontology term, for example  part_of(GO:0005634),  where GO:0005634 is the Gene Ontology identi\ufb01 er for \u201cnucleus\u201d.  Relations can be one of two types: \u201cmolecular relations\u201d that are used with entities such as a gene, gene product, complex, or chemical and \u201ccontextual relations\u201d that are used with entities such as a cell type, anatomy term, developmental stage, or a GO term.  In order to clearly de\ufb01 ne the semantics of the extensions, rules have been implemented de\ufb01 ning what types of entity identi\ufb01 ers may be used with each relation. Generally, curators may only use contextual relations (e.g., where and when) with terms from the Cell Type Ontology (CL) [ 6 ], Uber Anatomy Ontology (Uberon) [ 7 ], Plant Ontology (PO) [ 8 ], nematode life stages (WBls) [ 9 ] and certain GO terms, and molecular target relations may only apply to a physical entity such as a gene product (e.g., UniProtKB [ 10 ] or PomBase [ 11 ]), a macromolecular complex (e.g., Intact Complex Portal [ 12 ]), or a chemical using a ChEBI [ 13 ] identi\ufb01 er. Curation tools can incorporate these rules to prevent invalid annotations from being created. Table  1  shows the most commonly used relations with examples of their usage.Annotation Extensions\f2364       Improved Expressiveness of GO Annotations: Examples    One means of adding value to a GO annotation, using annotation extensions, is by specifying the molecular target of an enzyme activity. The inability to add effector\u2013target relationships has been a major limitation of the core GO annotation model, with this addition we can now begin to provide directional information that can be used for network and pathway analyses. Take as an example the annotation of human mitogen-activated protein kinase- activated protein kinase 2 (MAPKAP-K2), which was shown to phosphorylate the CapZ-interacting protein (CapZIP) [ 14 ]. A basic GO annotation would describe MAPKAP-K2 as a protein serine/threonine kinase:  Gene product :  UniProtKB:P49137 ( human MAPKAP-K2 )   GO term:   GO:0004674 ( protein serine/threonine kinase activity )    Using an annotation extension, a curator can add more detail as follows:  Gene product :  UniProtKB:P49137 ( human MAPKAP-K2 )   GO term:   GO:0004674 ( protein serine/threonine kinase activity )   Extension:   has_direct_input(UniProtKB:Q6JBY9) ( human CapZIP ) 4.1  Targets of an Enzyme   Table 1    Most commonly used relationships for annotation extension statements and examples of their usage    Contextual relationships  Example (gene product; primary GO term; annotation extension)  part_of   C. elegans  psf-1; nucleus; part_of(WBbt:0006804  body wall muscle cell )  occurs_in  Mouse opsin-4; G-protein coupled photoreceptor activity; occurs_in(CL:0000740  retinal ganglion cell )  happens_during   S. pombe  wis4; stress-activated MAPK cascade; happens_during(GO:0071470  cellular response to osmotic stress )  Molecular relationships  Example (gene product; primary GO term; annotation extension)  has_regulation_target  Human suppressor of fused homolog SUFU; negative regulation of transcription factor import into nucleus; has_regulation_target(UniProtKB:P08151  zinc \ufb01 nger protein GLI1 )  has_input   S. pombe  rlf2: protein localization to nucleus; has_input(PomBase:SPAC26H5.0  pcf2 )  has_direct_input  Human WNK4; chloride channel inhibitor activity; has_direct_input(UniProtKB:Q7LBE3  Solute carrier family 26 member 9 )  Molecular relations take an entity such as a gene, gene product, complex, or chemical as an argument; contextual relations take an entity such as a cell type, anatomy term, development stage, or a GO term as an argument. Entity names in italics are shown for clarity and are not part of the annotation extension format.   Reproduced from Huntley et al. [ 5 ]. Open access licence   http://creativecommons.org/licenses/by/4.0/      Rachael P. Huntley and Ruth C. Lovering\f237   N.B. phrases in italics are not part of the syntax but are added for better interpretation by the reader.  The extended GO annotation describes MAPKAP-K2 as a pro-tein serine/threonine kinase that can phosphorylate CapZIP. This is vital information that can be utilized for linking together pro-cesses and pathways that MAPKAP-K2 and CapZIP, and any fur-ther targets of these proteins, are involved in. The rules of usage for has_direct_input are that the primary GO term used should be a Biological Process or Molecular Function and in this example the term used is a Molecular Function, additionally the entity used in the extension should be a gene product, macromolecular complex, or chemical and in this example it is a gene product, i.e., a pro-tein. Note that has_direct_input was used here instead of has_input because there was evidence in the paper that MAPKAP-K2 acted directly on the substrate CapZIP, if there was a possibility of an intermediate molecule in this reaction, has_input would have been used.     An annotation can be extended to specify the locational context in which a gene product performs its roles. It is important to note that we intend only to capture those locations that are physiologi-cally relevant to the organism and not the experimental detail in which the observation was made.  The rat protein dihydrofolate reductase (Dhfr) was shown to reduce dihydrofolic acid to tetrahydrofolic acid in rat neurons [ 15 ]. From this evidence a basic GO annotation could be made as follows:  Gene product :  UniProtKB:Q920D2 ( rat Dhfr )   GO term:   GO:0004146 ( dihydrofolate reductase activity )    By extending the annotation the curator can also specify in which cell type this activity occurs:  Gene product :  UniProtKB:Q920D2 ( rat Dhfr )   GO term:   GO:0004146 ( dihydrofolate reductase activity )   Extension:   occurs_in(CL:0000540) ( neuron )    This annotation now provides the physiologically relevant information that Dhfr is active in neurons. The rules for occurs_in are that the primary GO term used must be a Biological Process or Molecular Function (in this example it is a Molecular Function); additionally the entity in the extension must be a cell type, ana-tomical feature, or GO Cellular Component (in this example it is an identi\ufb01 er from the Cell Type Ontology).     A gene product\u2019s annotation may be made more speci\ufb01 c by including the appropriate developmental stage. An example is the location of the  C. elegans  PAXT-1 protein, which is located in the nucleus during the embryo stage [ 16 ]. Using the basic GO annotation format, a curator might indicate that PAXT-1 is located in the nucleus:4.2  Anatomical Location of a Gene Product\u2019s Function4.3  Timing-Speci\ufb01 c Location of a Gene ProductAnnotation Extensions\f238  Gene product :  UniProtKB:Q21738 ( C. elegans PAXT-1 )   GO term:   GO:0005634 ( nucleus )    By extending the annotation the curator can also specify when this localization occurs:  Gene product :  UniProtKB:Q21738 ( C. elegans PAXT-1 )   GO term:   GO:0005634 ( nucleus )   Extension:   exists_during(WBls:0000003) ( embryo )    This annotation means that PAXT-1 is located in the nucleus during the  C. elegans  embryo stage. The rules for exists_during are that the primary GO term used should be a Cellular Component and the entity in the extension should be a developmental stage or a GO Biological Process, in this case the entity is from the  C.  elegans  life stage ontology.     If several contextual statements can be made for the gene product, it is possible to combine relational expressions to make even more complex statements. Relational expressions can be separated by commas \u201c,\u201d (meaning AND) or by pipes, \u201c|\u201d (meaning OR), depending on whether the conditions in the statement are co- occurring (AND) or independent (OR).  The human microRNA miR-145 provides an example of the application of multiple annotation extensions. MiR-145 was shown to directly bind and silence the POU5F1 transcription factor, among others, causing inhibition of embryonic stem cell division [ 17 ]. This evidence could therefore be represented by two basic GO annotations as follows:  Gene product :  RNACentral:URS0000527F89_9606 ( human miR-145 )   GO term:   GO:1903231 ( mRNA binding involved in posttranscriptional gene silencing )   Gene product :  RNACentral:URS0000527F89_9606 ( human miR-145 )   GO term:   GO:1904676 ( negative regulation of somatic stem cell division )    Using relational expressions, separated by commas, we can make one extended annotation as follows:  Gene product :  RNACentral:URS0000527F89_9606 ( human miR-145 )   GO term:   GO:1903231 ( mRNA binding involved in posttranscriptional gene silencing )   Extension:   has_direct_input(Ensembl:ENSG00000204531), occurs_in(CL:0002322), part_of(GO:1904676) ( human POU5F1, embryonic stem cell ,  negative regulation of somatic stem cell division ) 4.4  Multiple Relational ExpressionsRachael P. Huntley and Ruth C. Lovering\f239   The extended annotation signi\ufb01 es that miR-145 directly binds and silences POU5F1 mRNA expression as part of the inhibition of somatic stem cell division of embryonic stem cells. Again, this contextual information will be essential information when analyz-ing the physiological relevance of the role of a gene product in a pathway.  Although the use of a pipe (|) to indicate independent contex-tual statements does not provide any additional expressivity to the statements already made, it allows a curator to capture several statements from the same evidence within a paper. An example is when specifying the multiple substrates of an enzyme\u2014the enzyme may act on each of the substrates independently, but not all at the same time; therefore, the substrates can be listed in the extension separated by pipe symbols:  Gene product :  UniProtKB:O14522 ( human PTPRT )   GO term:   GO:0004725 ( protein tyrosine phosphatase activity )   Extension:   has_direct_input(UniProtKB:P12830) |  has_direct_input(UniProtKB:O60716) ( E-cadherin|CTNND1     )    This annotation indicates that the receptor protein tyrosine phosphatase rho (PTPRT) dephosphorylates E-cadherin and CTNND1, but not necessarily both simultaneously. It would be equally correct to create two separate annotations each with a single substrate in the extension.   5    Practical Use of Extended Annotations  There are likely to be many use cases for extended annotations\u2014even some we have not yet envisioned. Users will be able to per-form more advanced queries with the available functional data; such as \ufb01 ltering on the subcellular, cellular or anatomical locations in which a gene product performs its roles, or which genes a transcrip-tion factor regulates in a speci\ufb01 ed cell type. Annotation extensions can also help create functional networks through the use of direc-tional relationships such as has_input and has_direct_input, which allow speci\ufb01 cation of the target of an effector, for example in a sig-naling pathway or the substrates of a metabolic enzyme activity.  Without contextual detail, bioinformatics analyses of gene prod-ucts involved in a speci\ufb01 ed process cannot distinguish, for example, between those gene products that are active only in a particular cell type and those that are inactive or absent from that cell type, there-fore creating a bias in the interpretation of the data. With extended annotations any differences in the active components of a process or pathway between various cell or tissue types can be determined. Annotation Extensions\f240   Extended annotations are available for download in the current GO annotation \ufb01 les, both in the GAF2.0 format (column 16;   http://www.geneontology.org/GO.format.gaf-2_0.shtml    ) and in the Gene Product Association Data format (GPAD column 11;   http://www.geneontology.org/GO.format.gpad.shtml    ). These \ufb01 les can be accessed from the GOC website (  http://geneontol-ogy.org/GO.downloads.annotations.shtml    ) and the GOA website (  http://www.ebi.ac.uk/GOA/downloads    ).  Extended annotations can be accessed on the web via the GO browsers QuickGO ([ 18 ];   www.ebi.ac.uk/QuickGO-Beta    ) and AmiGO 2 ([ 19 ];   http://amigo.geneontology.org/amigo/    ). Both browsers allow users to \ufb01 lter annotation sets based on the contents of the annotation extension. The display of extended annotations may be different depending on the resource (Fig.  1 ), but the GO annota-tion \ufb01 les display the plain text extension since this is more compatible for computational analysis ( see  also Chap.   11     [ 20 ]). Any questions on how to access or use extended annotations should be directed to the GOC helpdesk (  http://geneontology.org/form/contact-go    ).      The addition of extended annotations to Gene Ontology datasets enables users to perform sophisticated queries. This exercise will demonstrate how to build such a query in the GOC browser 5.1  Access5.2  Exercise  Fig. 1    Display of extended annotations in ( a ) the beta version of the EBI GO browser QuickGO, ( b ) AmiGO 2, and ( c ) PomBase (  http://www.pombase.org/    )        Rachael P. Huntley and Ruth C. Lovering\f241AmiGO 2, namely, to provide all of the gene products from  S. pombe  that are located in the spindle midzone during mitotic anaphase.    1.    Open the AmiGO 2 browser (  http://amigo.geneontology.org/amigo/    ).      2.    Click on the Advanced Search button and select \u201cAnnotations\u201d from the drop-down list.      3.    In the free-text \ufb01 ltering box on the left (Fig.  2a ) type in GO:0051233, the GO identi\ufb01 er for the Cellular Component term \u201cspindle midzone\u201d.       4.    Now open the Taxon menu on the left and click on the \u201cmore\u201d button at the bottom. A pop-up menu will open, in the top \ufb01 lter box start typing \u201cpombe\u201d--\u201cSchizosaccharomyces pombe\u201d should be the only option that appears. Click on the + next to the species name to add this to the \ufb01 lter.      5.    Now open the Annotation Extension menu on the left and click on the + button next to the term \u201cmitotic anaphase\u201d to add this to the \ufb01 lter.      6.    AmiGO 2 will display all of the annotations that use the \u201cmitotic anaphase\u201d term (or one of its child terms) in the annotation extension of a primary annotation to \u201cspindle mid-zone\u201d (or one of its child terms) (Fig.  2b ).      Fig. 2    Finding annotations in AmiGO 2 based on annotation extension data. ( a ) Filters applied in the AmiGO 2 browser: GO:ID (GO:0051233 \u201cspindle midzone\u201d), annotation extension (mitotic anaphase), taxon ( Schizosaccharomyces pombe ). ( b ) Results of the search using the \ufb01 lters applied in ( a ). Six unique gene prod-ucts are located to the spindle midzone during mitotic anaphase        Annotation Extensions\f2426       Summary  The Gene Ontology has proven a vital resource for researchers, enabling them to easily \ufb01 nd and use functional data. GO is con-tinually evolving to re\ufb02 ect both accumulating biological knowl-edge and the computational techniques that researchers need for analysis of a list of gene products. One of the major limitations of using the original simple GO functional annotation has been the lack of contextual information linking together gene products and the roles and pathways they are involved in [ 4 ]. Inclusion of this type of data within GO annotations can advance pathway and net-work analyses substantially, allowing more sophisticated queries and analyses to be performed.  As with all other aspects of GO, annotation extensions con-tinue to evolve\u2014through discussion involving all GOC members and the community\u2014to allow representation and ultimately simple access to a wide variety of contextual data.  Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.        References     1.    Khatri P, Dr\u0103ghici S (2005) Ontological analy-sis of gene expression data: current tools, limi-tations, and open problems. Bioinformatics 21:3587\u20133595. doi:  10.1093/bioinformatics/bti565          2.    Schmidt A, Forne I, Imhof A (2014) Bioinformatic analysis of proteomics data. BMC Syst Biol 8(Suppl 2):S3. doi:  10.1186/1752-0509-8-S2-S3          3.   Bauer S (2016) Gene-category analysis. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 13       4.    Khatri P, Sirota M, Butte AJ (2012) Ten years of pathway analysis: current approaches and outstanding challenges. PLoS Comput Biol 8:e1002375. doi:  10.1371/journal.pcbi.1002375      Rachael P. Huntley and Ruth C. Lovering\f243        5.    Huntley RP, Harris MA, Alam-Faruque Y et al (2014) A method for increasing  expressivity of Gene Ontology annotations using a  compositional approach. BMC Bioinformatics 15:155. doi:  10.1186/1471-2105-15-155          6.    Meehan TF, Masci AM, Abdulla A et al (2011) Logical development of the cell ontology. BMC Bioinformatics 12:6. doi:  10.1186/1471-2105-12-6          7.    Mungall CJ, Torniai C, Gkoutos GV et al (2012) Uberon, an integrative multi-species anatomy ontology. Genome Biol 13:R5. doi:  10.1186/gb-2012-13-1-r5          8.    Avraham S, Tung C-W, Ilic K et al (2008) The Plant Ontology Database: a community resource for plant structure and developmental stages controlled vocabulary and annotations. Nucleic Acids Res 36:D449\u2013D454. doi:  10.1093/nar/gkm908          9.    Lee RYN, Sternberg PW (2003) Building a cell and anatomy ontology of Caenorhabditis ele-gans. Comp Funct Genomics 4:121\u2013126. doi:  10.1002/cfg.248          10.    The UniProt Consortium (2014) UniProt: a hub for protein information. Nucleic Acids Res 43:D204\u2013D212. doi:  10.1093/nar/gku989          11.    McDowall MD, Harris MA, Lock A et al (2015) PomBase 2015: updates to the \ufb01 ssion yeast database. Nucleic Acids Res 43:D656\u2013D661. doi:  10.1093/nar/gku1040          12.    Meldal BHM, Forner-Martinez O, Costanzo MC et al (2014) The complex portal\u2014an ency-clopaedia of macromolecular complexes. Nucleic Acids Res. doi:  10.1093/nar/gku975          13.    Hastings J, de Matos P, Dekker A et al (2013) The ChEBI reference database and ontology for biologically relevant chemistry: enhance-ments for 2013. Nucleic Acids Res 41:D456\u2013D463. doi:  10.1093/nar/gks1146          14.    Eyers CE, McNeill H, Knebel A et al (2005) The phosphorylation of CapZ-interacting pro-tein (CapZIP) by stress-activated protein kinases triggers its dissociation from CapZ. Biochem J 389:127\u2013135. doi:  10.1042/BJ20050387          15.    Iskandar BJ, Rizk E, Meier B et al (2010) Folate regulation of axonal regeneration in the rodent central nervous system through DNA methylation. J Clin Invest 120:1603\u20131616. doi:  10.1172/JCI40000          16.    Gloerich M, ten Klooster JP, Vliem MJ et al (2012) Rap2A links intestinal cell polarity to brush border formation. Nat Cell Biol 14:793\u2013801. doi:  10.1038/ncb2537          17.    Xu N, Papagiannakopoulos T, Pan G et al (2009) MicroRNA-145 regulates OCT4, SOX2, and KLF4 and represses pluripotency in human embryonic stem cells. Cell 137:647\u2013658. doi:  10.1016/j.cell.2009.02.038          18.    Binns D, Dimmer E, Huntley R et al (2009) QuickGO: a web-based tool for Gene Ontology searching. Bioinformatics 25:3045\u20133046. doi:  10.1093/bioinformatics/btp536          19.    The Gene Ontology Consortium (2010) The Gene Ontology in 2010: extensions and re\ufb01 ne-ments. Nucleic Acids Res 38:D331\u2013D335. doi:  10.1093/nar/gkp1018          20.   Munoz-Torres M, Carbon S (2016) Get GO! retrieving GO data using AmiGO, QuickGO, API, \ufb01 les, and tools. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 11    Annotation Extensions\f245    Chapter 18    The Evidence and Conclusion Ontology (ECO): Supporting GO Annotations                          Marcus     C.     Chibucos     ,     Deborah     A.     Siegele    ,     James     C.     Hu    , and     Michelle     Giglio       Abstract    The Evidence and Conclusion Ontology (ECO) is a community resource for describing the various types of evidence that are generated during the course of a scienti\ufb01 c study and which are typically used to support assertions made by researchers. ECO describes multiple evidence types, including evidence resulting from experimental (i.e., wet lab) techniques, evidence arising from computational methods, statements made by authors (whether or not supported by evidence), and inferences drawn by researchers curating the literature. In addition to summarizing the evidence that supports a particular assertion, ECO also offers a means to document whether a computer or a human performed the process of making the annotation. Incorporating ECO into an annotation system makes it possible to leverage the structure of the ontology such that associ-ated data can be grouped hierarchically, users can select data associated with particular evidence types, and quality control pipelines can be optimized. Today, over 30 resources, including the Gene Ontology, use the Evidence and Conclusion Ontology to represent both evidence and how annotations are made.    Key words     Annotation  ,   Biocuration  ,   Conclusion  ,   Con\ufb01 dence  ,   Evidence  ,   ECO  ,   Experiment  ,   Inference  ,   Literature curation  ,   Quality control  1      Describing Evidence in Scienti\ufb01 c Investigations    Investigations in the life sciences routinely produce data from diverse methodologies using a wide range of tools and techniques. Such data generated during the course of a research project con-tribute to the pool of evidence that ultimately leads a scienti\ufb01 c researcher to make a particular inference or draw a given conclu-sion. Ultimately, one goal of a scientist is to publish the conclu-sions that are drawn from a given research project in the scienti\ufb01 c literature. Such conclusions typically take the form of assertions, i.e., statements that are believed to be true, about some aspect of biology. The process of biocuration seeks to extract from the litera-ture the  assertion  that summarizes the research \ufb01 nding  in  addition to  any relevant  evidence  in support of the \ufb01 nding. Ideally, both of 1.1  Importance of Documenting EvidenceChristophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_18, \u00a9 The Author(s) 2017\f246these pieces of information will become integrated into a database in a structured way, so that they are readily accessible to the scien-ti\ufb01 c community [ 1 ,  2 ] (Fig.  1 ).   Recording evidence is essential because: (1) knowing what methodologies were used is central to the scienti\ufb01 c method and can impact one\u2019s evaluation of the data or results; (2) associating evidence with data maintained electronically allows for selective data queries and retrieval from even the largest of databases; and (3) a structured representation of evidence makes automated qual-ity control possible, which is absolutely essential to managing the ever-increasing number and size of biological databases.     Evidence can be associated with assertions in many ways. Manual curation is a common approach [ 3 ,  4 ], outlined in Fig.  1 . However, text mining or other computational methods can also be used to extract biological assertions from the scienti\ufb01 c literature [ 5 ,  6 ], and assertions can also be made directly via bioinformatic tech-niques [ 7 ], e.g. assigning of functional annotations as resulting from a functional genome annotation pipeline.  Numerous types of evidence form the bases for assertions that are made by researchers. Laboratory and \ufb01 eld experiments are com-mon sources of evidence, but computational (or  in silico ) analysis, whether executed by a person or an unsupervised machine, can also generate the evidence that is used to support assertions about bio-logical function (Fig.  2 ). In addition, conclusions can be synthesized from investigator speculation or implied by known biology during the literature curation process. We can also consider  provenance , a concept related to and sometimes con\ufb02 ated with evidence. A central goal of biological data repositories is to record in a structured fash-ion as much information as is known about the origins of a given accession. Yet sometimes an accession is imported from another database where the source for the annotation at that database is 1.2  Multiple Types of Evidence and Ways of Associating Evidence with Assertions  Fig. 1    Representing experimental methods and conclusions in a biological database. ( a ) An experiment is performed that generates data. ( b ) A researcher interprets methods and data, and draws conclusions that are published in a scienti\ufb01 c journal and indexed in PubMed, for example. ( c ) A biocurator reads that paper, inter-prets the results presented therein, and makes an assertion. ( d ) The assertion is represented by associating an ontology term with the item being studied and stored along with other data, for example a protein sequence, at a biological database. (General summaries and related ECO classes are depicted along the bottom.)        Marcus C. Chibucos et al.\f247unclear. Even in this case it might be useful for the importing data-base to note the source of the statement/annotation along with a description of \u201cimported information,\u201d indicating that nothing else is known about the evidence or provenance of that particular anno-tation. Thus there are numerous advantages to capturing scienti\ufb01 c evidence and provenance, from describing speci\ufb01 c methodologies to representing chains of custody.2        The Evidence and Conclusion Ontology (ECO)    Due to the diversity of ways that exist to describe the multitude of scienti\ufb01 c research methodologies, a means of representing evidence in a descriptive but structured way is required in order to maximize utility. The most ef\ufb01 cient way to achieve this is to use an ontology, a controlled vocabulary where each term is well-de\ufb01 ned and linked to other terms via de\ufb01 ned relationships [ 8 ,  9 ]. In an ontological framework, evidence descriptions are represented not as free text, but rather as networked ontology classes where each child term is more speci\ufb01 c (granular) than its parent [ 10 ]. High- level descrip-tions of types of evidence (such as \u201cexperimental evidence\u201d) are contained in more basal classes closest to the root class  evidence . Increasingly speci\ufb01 c terms that are grouped under the more general classes describe particular sub-types of evidence (such as \u201cchroma-tography evidence\u201d). The most speci\ufb01 c terms, the  so- called \u201cleaf nodes\u201d that contain no child terms, represent the most granular types of evidence generated during the course of a scienti\ufb01 c investi-gation (for example \u201cthin layer chromatography evidence\u201d).  The Evidence and Conclusion Ontology (ECO)  (  http://eviden-ceontology.org    ) was created to enable the structured description of 2.1  The Argument for an Ontology of Evidence  Fig. 2    Computational evidence and assertion. ( a ) A human or computer performs an analysis, for example comparing the sequence of a protein of unknown function to sequences at a database. A protein of known function is returned as a hit with corresponding alignment. ( b ) The alignment is analyzed and the protein sequences are deemed to share enough similarity to be considered homologs (related through common evo-lutionary descent). The query protein is assigned the same function as the database protein. ( c ) This informa-tion is stored at a sequence repository along with other data and metadata. ( Text in white boxes  depicts evidence and assertion methods used in this process.)        Supporting GO Annotations with Evidence\f248experimental, computational, and other evidence types to support the assertions captured by scienti\ufb01 c databases [ 11 ].     As described throughout this book, the Gene Ontology (GO) uses terms organized into controlled vocabularies, and the relationships among these terms, to capture functional information about gene products. The need to systematically document evidence while curating annotations was recognized from the inception of the GO [ 12 ] and a set of \u201cevidence codes\u201d was created for this purpose [ 13 ]. In time it was realized that a better-structured and more compre-hensive way to represent evidence was required. Thus, the set of initially created GO codes, along with terms created by two model organism databases, FlyBase [ 14 ] and The  Arabidopsis  Information Resource [ 15 ], evolved into the \ufb01 rst version of ECO, the \u201cEvidence Code Ontology\u201d. Since then, the use of ECO by other resources has continued to grow and the ontology has shifted its focus beyond GO in order to become a generalized ontology for the capture of evidence information. The of\ufb01 cial name of ECO is now the \u201cEvidence and Conclusion Ontology\u201d. ECO is presently being developed to de\ufb01 ne and broaden its scope, normalize its content, and enhance interoperability with related resources. The GO remains an active user and participant in developing ECO. It is anticipated that soon the three letter GO evidence codes to which so many are accustomed will be replaced by ECO term identi\ufb01 ers.  2.2  A Brief History of ECOevidenceIIIIIIIIIIexperimental evidenceassertion methodautomatic assertionmanual assertionmatch to InterPro membersignature evidence used inautomatic assertionmatch to InterPro membersignature evidence used inmanual assertionauthor statementsimilarity evidencesequence similarity evidencematch to sequence modelevidencematch to InterPro membersignature evidence  Fig. 3    Simpli\ufb01 ed representation of ECO, depicting general structure. ECO comprises two root classes along with their respective hierarchies,  evidence  (terms in  black ) and  assertion method  (terms in  pink ). A given type of evidence can be applied to ( used_in ;  dotted lines ) automatic assertion or manual assertion, which neces-sitated the creation of ECO leaf nodes that are  evidence  x  assertion method  cross products. For simplicity, most ECO classes are not displayed in the \ufb01 gure, including, for example, \ufb01 ve of eight direct subclasses of  evidence  or three of four types of  similarity evidence  and so on        Marcus C. Chibucos et al.\f249   Evidence terms descend from the root class \u201cevidence\u201d, which is de\ufb01 ned as \u201ca type of information that is used to support an assertion\u201d (Fig.  3 ). Most evidence terms are either experimental or computational in nature, e.g., \u201cchromatography evidence\u201d or \u201csequence similarity evidence\u201d, respectively (Fig.  3 ). However, ECO also comprises other types of evi-dence, such as \u201ccurator inference\u201d and \u201cauthor statement\u201d.   In addition to describing evidence, ECO can also describe the means by which assertions are made, i.e., by a human or a machine. ECO calls this the \u201cassertion method\u201d and de\ufb01 nes it as \u201ca means by which a statement is made about an entity\u201d (Figs.  1c  and  2b ). For example, whether a curator makes an annotation after reading about an experimental result in a scienti\ufb01 c paper or after manually evaluating pairwise sequence alignment results, ECO can express that a manual curation method was used (3,8). Conversely, if an algorithm was used to assign a predicted function to a protein, ECO can express that an automated computational method was used. Thus \u201cassertion method\u201d forms a second root class with two branches: \u201cmanual assertion\u201d and \u201cautomatic assertion\u201d (Fig.  3 ).  The current version of ECO comprises 630 terms that describe \u201cevidence\u201d, \u201cassertion method\u201d, or \u201cevidence x assertion method\u201d cross products. Ontology architecture of ECO was recently described in Chibucos et al. [ 11 ].    Recent development efforts of ECO have emphasized meeting the needs of a larger research community;  see  for example [ 11 ,  16 ], while still capturing the needed information for GO annotation, such as by adding comments and synonyms to a term. Many high- level ECO term de\ufb01 nitions were written with explicit GO usage notes contained therein because ECO originated during early efforts of the GO. However, in order to increase overall usability of ECO by resources other than the GO, such verbiage has been removed, while retaining the essence of the term\u2019s meaning and applicability to GO. As ECO has been developed, more and more granular terms have been created to represent increasingly com-plex laboratory, computational, and even inferential techniques.  A discussion of ECO and GO would not be complete without mention of the GO evidence code IEA or \u201cinferred from  electronic annotation\u201d. IEA is used to connote that an annotation was assigned through automated computational means, e.g., transfer-ring annotations from one protein to another. Because IEA describes how an annotation was  assigned , rather than the speci\ufb01 c type of supporting evidence, this term belongs as a subclass of \u201cassertion method\u201d. As described above, \u201cassertion method\u201d has two child terms, \u201cmanual assertion\u201d and \u201cautomatic assertion\u201d, with the latter being equivalent to IEA. Now it is possible to more accurately model evidence and the annotation process using ECO.  Aside from rewording de\ufb01 nitions and creating a second root class, the biggest conceptual modi\ufb01 cation of ECO is re\ufb02 ected by removal of the pre\ufb01 x \u201cinferred from\u201d from every term name (see the GO codes 2.3  ECO Structure and Content2.3.1  Extending ECO Beyond GOSupporting GO Annotations with Evidence\f250for a sense of how ECO terms were previously labeled). This was done because ECO considers not just inferences made during the curation process, per se, but other aspects of evidence documentation, such as what research methodologies were performed.    3    Fundamentals of Evidence-Based GO Annotation  Creating an association between a GO term and a gene product is the fundamental essence of the GO annotation process. Documenting the evidence for any given GO annotation is a critical component of this annotation process, and an annotation would be incomplete without the requisite evidence. In fact, evidence capture by the GO requires both a \u201cGO evidence code\u201d that describes in detail the type of work or analysis that was performed in support of the annotation, as well as a citation for the reference from which the evidence was derived. Curators go to great lengths to understand and properly apply the correct \u201cevidence code\u201d to a given annota-tion, and an online guide exists to explain the often- subtle distinc-tions between multiple related evidence types (  http://geneontology.org/page/guide-go-evidence-codes    ) [ 4 ,  13 ].  The GO gene association \ufb01 le (GAF) format contains required columns for both evidence code and reference. Each GO evidence code maps directly to an ECO term. ECO maintains database cross references to the GO codes for easy mapping between systems. GO codes therefore represent a subset of the Evidence and Conclusion Ontology. Since independent development of ECO was undertaken, a number of new GO evidence codes have been created, e.g., IBA, IBD, IKR, IRD. Equivalent terms have been instantiated in ECO (Fig.  4a ), which will continue to develop such terms for the GO.     Although GO evidence codes are useful in themselves because they represent detailed descriptions of evidence types, they are main-tained as a controlled vocabulary with a shallow hierarchical struc-ture that lacks the advantages of a formal ontology like ECO. Further, the full set of terms within ECO provides the ability to capture more breadth and depth of evidence information than the GO evi-dence codes do. Additionally, as the \ufb01 eld of biocuration evolves and the kinds of evidence being curated from the literature continue to grow both more detailed and nuanced, the number of two- and three-letter acronyms (e.g., IEA, IMP, EXP, and ISS) available for new terms will hit an upper limit (there are only 676 possibilities using all 26 two-letter combinations, as the \ufb01 rst letter of the three-letter GO codes often stands for \u201cinferred\u201d). In fact, ECO develop-ers have already received requests from different users to develop new, but unrelated, terms that had the same suggested three-letter acronyms. For all of these reasons, there are discussions underway about transitioning GO evidence storage to use ECO terms rather than GO evidence codes. Such a shift would combine the 3.1  ECO Terms Versus GO CodesMarcus C. Chibucos et al.\f251advantages of both systems and would still provide a mechanism for \ufb01 ltering evidence annotations by the previous codes if desired. If ECO terms were to be fully adopted by GO, the GAF format would change to require \u201cECO term\u201d instead of \u201cevidence code.\u201d Since most GO evidence codes have a one-to-one mapping to ECO terms (while the remainder, i.e., IEA, IGC, ISS, map, in conjunction with various GO standard references [  http://purl.obolibrary.org/obo/eco/gaf-eco-mapping.txt    ], to speci\ufb01 c ECO terms), GO data depos-itors could use a straightforward replacement based on the map-pings. Other resources outside of GO have modeled their annotation capture systems on the GAF format. For example, the Ontology of Microbial Phenotypes [ 17 ] uses a modi\ufb01 ed version of the GO GAF, but employs ECO terms instead of GO evidence codes. The full use of ECO terms by the GO would enhance the integration of data derived from such diverse sources.     Fig. 4    Applications of ECO to GO. ( a ) ECO evidence classes are hierarchical such that broader classes parent more granular ones; depicted here are evidence types that support a phylogenetic tree-based approach for generating manually reviewed, homology-based annotations. ( b ) When a protein is annotated based on sequence similarity to another annotated protein, the identity of that protein must be recorded in the annota-tion \ufb01 le along with the evidence. ( c ) Quality control assessment: Expression pattern evidence is only allowable for annotations to the GO Biological Process ontology. ( d ) Evidence is used to prevent circular annotations based solely on computational predictions. Chains of evidence are computationally evaluated to ensure that inferential annotations are linked to experimental evidence        Supporting GO Annotations with Evidence\f2524    Bene\ufb01 ts of ECO and Applications for the GO  There are currently over 365 million annotations in the GO reposi-tory linked to an evidence term, and these can be queried and main-tained better with the help of an ontology by leveraging its hierarchical structure. One of the most direct applications for using an ontology of evidence is  selective data query , i.e., to query a database for records associated with a particular evidence type. For example, searching for \u201cthin layer chromatography evidence\u201d (at present a leaf term with no subclasses) would return only the records associated with that evi-dence type and no others. But  grouping annotations  is also possible with this approach. A query for \u201cchromatography evidence\u201d will return data associated not only with \u201cchromatography evidence\u201d but also its more speci\ufb01 c subtypes including \u201cthin layer chromatography evidence\u201d and \u201chigh performance liquid chromatography evidence\u201d.  But there are further bene\ufb01 ts to be derived from an ontology of evidence beyond simple structured queries (Fig.  4 ). For example:    1.    To amplify the bene\ufb01 ts of experimental knowledge that cura-tors capture, the GO Consortium is using a phylogenetic tree-based approach to generate manually reviewed, homology-based annotations for a range of species [ 18 ]. This phylogenetic annotation methodology necessitated a new set of evidence terms to capture the inference process (Fig.  4a ). Currently over 150,000 annotations are associated with these new terms and the number continues to grow.      2.    The GO curatorial process uses evidence to support comput-able rules about the kinds of information that must be associ-ated with different evidence types. For example, one rule states that annotation of a protein based on alignment with another protein requires that the identity of the matching protein be captured, along with the evidence type \u201cprotein alignment evi-dence\u201d (Fig.  4b ). If such an evidence type were missing, this would \ufb02 ag the annotation for review.      3.    The GO uses evidence as a quality control mechanism for annotation consistency. For example, expression pattern evi-dence is restricted to annotations for terms from the \u201cbiologi-cal process\u201d ontology. Annotations to terms from either of the other two GO ontologies (\u201cmolecular function\u201d or \u201ccellular component\u201d) would be \ufb02 agged as suspect (Fig.  4c ).      4.    Evidence is used to prevent circular annotations based solely on computational predictions (Fig.  4d ). Chains of evidence are computationally evaluated to ensure that inferential annota-tions are linked to experimental evidence. For example, anno-tations supported by \u201csequence alignment evidence\u201d require the inclusion of a database identi\ufb01 er for the matching gene Marcus C. Chibucos et al.\f253product that is itself linked to an annotation supported by experimental evidence.      Yet another application of ECO for the GO has been realized in the UniProt-Gene Ontology Annotation (UniProt-GOA) project. Arguably, UniProt is the most comprehensive and best-curated pro-tein database available to the research community. ECO terms have replaced the original UniProtKB [ 19 ] evidence types and are available in UniProtKB XML [ 11 ]. Novel ways of mapping and extending ontologies have been discussed with ECO and the GO Consortium to ensure appropriate development for UniProtKB annotation. The   Fig. 5    AmiGO 2 query and results. ( a ) User has typed \u201cproteolysis\u201d into the search box. ( b ) Number of hits ( right gray box ) shown for each document category ( blue boxed text ). Clicking on \u201cAnnotations\u201d will open a new page with more detailed results        Supporting GO Annotations with Evidence\f254UniProt-GOA project provides &gt;169 million manual and electronic evidence-based associations between GO terms and 26.5 million UniProtKB proteins covering &gt;411,000 taxa [ 20 ]. Of these, manual annotation provides 1.4 million annotations to ~260,000 proteins. Since 2010, UniProt-GOA has supplied GO annotations in a Gene Product Association Data (GPAD) \ufb01 le format, which allows inclusion of ECO terms. Because ECO terms are cross referenced to corre-sponding GO codes, even if evidence for annotations was supplied to UniProt as GO codes, the GPAD \ufb01 le will display the appropriate equivalent ECO term. Thus, UniProt annotations can be grouped by leveraging the structure of ECO.    Once the reader has gained a basic understanding of ECO and its connection to GO, we can perform the following simple exercise 4.1  Exercise  Fig. 6    Annotation hits to a query search. ( a ) To the left of the search results, the user has an opportunity to click on \ufb01 lters. ( b ) To the right, each annotation row is shown for a given protein        Marcus C. Chibucos et al.\f255that displays a faceted query using ECO in AmiGO 2  (  http://amigo2.geneontology.org/amigo    ).  User types \u201cproteolysis\u201d into the query box (Fig.  5a ) and sees a number of hits returned (Fig.  5b ). Next, after clicking on \u201cAnnotations\u201d in the blue rectangle, the user sees all the annotation- related terms that had hits to \u201cproteolysis\u201d (Fig.  6a, b ), split into two parts here for easier viewing. Clicking on \u201cEvidence\u201d in the \ufb01 lter box (Fig.  6a ) will expand it to display all constituent evidence types (Fig.  7 ). Clicking on   Fig. 7    Selected ECO terms in use by the GO Consortium that are related to the present query. The number of annotations supported by a given evidence type is shown in  parentheses         Supporting GO Annotations with Evidence\f256\u201ctraceable author statement used in manual assertion\u201d will open a subset of the results that match that more restrictive \ufb01 lter (Fig.  8 ). The evidence \ufb01 lter box now says \u201cNothing to \ufb01 lter\u201d (Fig.  9 ).5            The Future of ECO  What else can an ontology of evidence do? One aspect of active exploration for ECO is the evaluation of con\ufb01 dence or quality of evidence. Work has begun [ 21 ] to develop a mechanism to incor-porate quality information into ECO or, as needed, to create a standalone system. It might one day be possible to use ECO to describe the  quality  of the evidence supporting an annotation in addition to the  type  of evidence that supports the annotation.  In summary, the Evidence and Conclusion Ontology can be used to support faceted queries of data, to establish computable rules about required types of evidence, as a quality control check for annotation consistency, and as a mechanism to prevent circular annotations rooted only in computational predictions. GO is already bene\ufb01 tting from these applications of ECO, and the future promises both additional new applications of ECO as well as advancements to current ones.       Acknowledgements   This material is based upon work supported by the National Science Foundation under Award Number 1458400 and National   Fig. 8    Filtering on evidence. After \ufb01 ltering on \u201ctraceable author statement used in manual assertion\u201d, only annotations supported by that evidence type are displayed, shown as \u201cTAS\u201d in the \u201cEvidence\u201d column. Number of annotations associated with that evidence type is shown at the top left        Marcus C. Chibucos et al.\f257  Fig. 9    Filter box fully selected. Increasingly granular evidence \ufb01 lters have been applied until there is nothing left to \ufb01 lter       Institutes of Health/National Institute of General Medical Sciences under Grant Number 2R01 GM089636. Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.   Supporting GO Annotations with Evidence\f258   References     1.   Gaudet P, Arighi C, Bastian F, Bateman A, Blake JA, Cherry MJ, D\u2019Eustachio P, Finn R, Giglio M, Hirschman L, Kania R, Klimke W, Martin MJ, Karsch-Mizrachi I, Munoz-Torres M, Natale D, O\u2019Donovan C, Ouellette F, Pruitt KD, Robinson-Rechavi M, Sansone SA, Scho\ufb01 eld P, Sutton G, Van Auken K, Vasudevan S, Wu C, Young J, Mazumder R (2012) Recent advances in biocuration: meet-ing report from the Fifth International Biocuration Conference. Database:bas036.  doi:  10.1093/database/bas036          2.   Burge S, Attwood TK, Bateman A, Berardini TZ, Cherry M, O\u2019Donovan C, Xenarios L, Gaudet P (2012) Biocurators and biocuration: surveying the 21st century challenges. Database:bar059. doi:  10.1093/database/bar059          3.   Balakrishnan R, Harris MA, Huntley R, Van Auken K, Cherry JM (2013) A guide to best practices for Gene Ontology (GO) manual annotation. Database:bat054. doi:  10.1093/database/bat054           4.   Poux S, Gaudet P (2016) Best practices in manual annotation with the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 4      5.   Arighi CN, Carterette B, Cohen KB, Krallinger M, Wilbur WJ, Fey P, Dodson R, Cooper L, Van Slyke CE, Dahdul W, Mabee P, Li D, Harris B, Gillespie M, Jimenez S, Roberts P, Matthews L, Becker K, Drabkin H, Bello S, Licata L, Chatr-aryamontri A, Schaeffer ML, Park J, Haendel M, Van Auken K, Li Y, Chan J, Muller HM, Cui H, Balhoff JP, Chi-Yang Wu J, Lu Z, Wei CH, Tudor CO, Raja K, Subramani S, Natarajan J, Cejuela JM, Dubey P, Wu C (2013) An overview of the BioCreative 2012 Workshop Track III: interactive text mining task. Database:bas056. doi:  10.1093/database/bas056          6.    Altman RB, Bergman CM, Blake J, Blaschke C, Cohen A, Gannon F, Grivell L, Hahn U, Hersh W, Hirschman L, Jensen LJ, Krallinger M, Mons B, O\u2019Donoghue SI, Peitsch MC, Rebholz-Schuhmann D, Shatkay H, Valencia A (2008) Text mining for biology--the way forward: opinions from leading scientists. Genome Biol 9(Suppl 2):S7. doi:  10.1186/gb-2008-9-s2-s7          7.   Cozzetto D, Jones DT (2016) Computational methods for annotation transfers from sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 5      8.    Smith B (2003) Ontology. In: Floridi L (ed) Blackwell guide to the philosophy of comput-ing and information. Blackwell, Oxford, pp 155\u2013166      9.    Smith B (2008) Ontology (Science). In: Eschenbach C, Gr\u00fcninger M (eds) Formal ontology in information systems. Ios Press, Amsterdam, pp 21\u201335      10.   Hastings J (2016) Primer on ontologies. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 1         11.   Chibucos MC, Mungall CJ, Balakrishnan R, Christie KR, Huntley RP, White O, Blake JA, Lewis SE, Giglio M (2014) Standardized description of scienti\ufb01 c evidence using the Evidence Ontology (ECO). Database:bau075. doi:  10.1093/database/bau075          12.    Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-Tarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M, Rubin GM, Sherlock G (2000) Gene ontology: tool for the uni\ufb01 cation of biology. The Gene Ontology Consortium. Nat Genet 25(1):25\u201329. doi:  10.1038/75556           13.   Gaudet P, \u0160kunca N, Hu JC, Dessimoz C (2016) Primer on the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 3      14.    The FlyBase Consortium (2002) The FlyBase database of the  Drosophila  genome projects and community literature. Nucleic Acids Res 30(1):106\u2013108      15.    Huala E, Dickerman AW, Garcia-Hernandez M, Weems D, Reiser L, LaFond F, Hanley D, Kiphart D, Zhuang M, Huang W, Mueller LA, Bhattacharyya D, Bhaya D, Sobral BW, Beavis W, Meinke DW, Town CD, Somerville C, Rhee SY (2001) The  Arabidopsis  Information Resource (TAIR): a comprehensive database and web-based information retrieval, analysis, and visualization system for a model plant. Nucleic Acids Res 29(1):102\u2013105      16.    Kilic S, White ER, Sagitova DM, Cornish JP, Erill I (2014) CollecTF: a database of exper-imentally validated transcription factor-binding sites in Bacteria. Nucleic Acids Res 42(Database issue):D156\u2013D160. doi:  10.1093/nar/gkt1123          17.    Chibucos MC, Zweifel AE, Herrera JC, Meza W, Eslamfam S, Uetz P, Siegele DA, Hu JC, Giglio MG (2014) An ontology for microbial Marcus C. Chibucos et al.\f259phenotypes. BMC Microbiol 14(1):294. doi:  10.1186/s12866-014-0294-3          18.    Reference Genome Group of the Gene Ontology Consortium (2009) The Gene Ontology\u2019s Reference Genome Project: a uni-\ufb01 ed framework for functional annotation across species. PLoS Comput Biol 5(7):e1000431. doi:  10.1371/journal.pcbi.1000431          19.    UniProt Consortium (2014) Activities at the Universal Protein Resource (UniProt). Nucleic Acids Res 42(Database issue):D191\u2013D198. doi:  10.1093/nar/gkt1140          20.    Dimmer EC, Huntley RP, Alam-Faruque Y, Sawford T, O'Donovan C, Martin MJ, Bely B, Browne P, Mun Chan W, Eberhardt R, Gardner M, Laiho K, Legge D, Magrane M, Pichler K, Poggioli D, Sehra H, Auchincloss A, Axelsen K, Blatter MC, Boutet E, Braconi-Quintaje S, Breuza L, Bridge A, Coudert E, Estreicher A, Famiglietti L, Ferro-Rojas S, Feuermann M, Gos A, Gruaz-Gumowski N, Hinz U, Hulo C, James J, Jimenez S, Jungo F, Keller G, Lemercier P, Lieberherr D, Masson P, Moinat M, Pedruzzi I, Poux S, Rivoire C, Roechert B, Schneider M, Stutz A, Sundaram S, Tognolli M, Bougueleret L, Argoud-Puy G, Cusin I, Duek-Roggli P, Xenarios I, Apweiler R (2012) The UniProt-GO Annotation database in 2011. Nucleic Acids Res 40(Database issue):D565\u2013D570. doi:  10.1093/nar/gkr1048          21.   Bastian FB, Chibucos MC, Gaudet P, Giglio M, Holliday GL, Huang H, Lewis SE, Niknejad A, Orchard S, Poux S, Skunca N, Robinson- Rechavi M (2015) The Con\ufb01 dence Information Ontology: a step towards a standard for assert-ing con\ufb01 dence in annotations. Database:bav043.  doi:  10.1093/database/bav043        Supporting GO Annotations with Evidence\f   Part VI    Beyond the Gene Ontology        \f263    Chapter 19    Complementary Sources of Protein Functional Information: The Far Side of GO                          Nicholas     Furnham        Abstract    The GO captures many aspects of functional annotations, but there are other alternative complementary sources of protein function information. For example, enzyme functional annotations are described in a range of resources from the Enzyme Commission (E.C.) hierarchical classi\ufb01 cation to the Kyoto Encyclopedia of Genes and Genomes (KEGG) to the Catalytic Site Atlas amongst many others. This chapter describes some of the main resources available and how they can be used in conjunction with GO.    Key words     Function similarity  ,   Protein domain functions  ,   Enzyme Commission (EC)  ,   Pathway annotation  1       Introduction  The Gene Ontology (GO) offers experimental and computational biology researchers an accessible range of controlled vocabulary annotations to describe protein function. This allows detailed as well as large-scale analyses to be conducted. There is, however, a range of other sources of functional annotations, which in combi-nation with GO provide enhance function descriptions. Examples of such complementary resources include the Enzyme Commission\u2019s classi\ufb01 cation of enzyme reactions [ 1 ], the Kyoto Encyclopedia of Genes and Genomes (KEGG) [ 2 ], BRENDA [ 3 ], CSA [ 4 ], MACiE [ 5 ], MetaCyc database of enzyme and pathways [ 6 ], amongst many others. Most of these resources include GO terms within their own annotations or their de\ufb01 nitions are included within the Gene Ontology. Mapping terms between resources offers enhanced descriptions and relationships between them not readily captured solely within GO. The Gene Ontology provides many of these mappings through its website (  http://geneontol-ogy.org/page/download-mappings    ), which are automatically updated with various periodicities depending on how often the Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_19, \u00a9 The Author(s) 2017\f264corresponding resource is updated. This chapter describes some of these complementary resources focusing mainly on enzymes.  2     Annotating Enzymes  Due to the over 100 years of experimental biochemical data, one of the richest areas for complementary functional annotations are for enzymes. Historically, naming conventions for enzymes have been confused and haphazard, with several names being given to one enzyme and one name being given to several enzymes. Often the names bear little information as to the reaction the enzyme is under-taking. This led to the development of the Enzyme Classi\ufb01 cation (E.C.) system by the International Commission on Enzymes founded in 1956 by the International Union of Biochemistry [ 1 ]. The E.C. number is a hierarchal system consisting of four levels. The \ufb01 rst level has six divisions giving a broad description of the overall chemical transformation (enzyme class): Oxidoreductases, Transferases, Hydrolases, Lyases, Isomerases and Ligases. The next two levels (sub class and sub-subclass) generally describe the reac-tive species and the type of bond being acted upon. The meaning of these numbers is class dependent. The \ufb01 nal level is a serial number for the overall reaction of that sub-subclass. The overall reactions described are mass-balanced, as much as possible, though they are not necessarily charge-balanced, nor are they meant to represent the equilibrium position or reaction direction with a convention for writing the reaction in the same direction for all reactions within a given sub-subclass even if their physiological direction is different. General reactions, where the enzyme has broad speci\ufb01 c-ity, are given as single generic reactions and alternative reactions with speci\ufb01 c metabolites are also given. Some reactions are incom-plete, while others are combinations of successive reactions [ 7 ]. Thus it is possible that one enzyme E.C. number might have a multiple number of reactions associated with it and for many reac-tions to be assigned to the same E.C. number ( see  Fig.  1a ).   Currently there are 6510 E.C. numbers approved, with 5560 of them in active use. Of these active annotations only 3924 (70 %) have an equivalent GO term. A full list of E.C. to GO cross- references can be found on the GO website (  http://geneontology.org/external2go/ec2go    ). There are a number of reasons why a mapping between E.C. and GO cannot be made. Most likely is that GO does not yet have a term that covers the EC term, e.g. E.C. 1.1.1.287 ( d -arabinitol dehydrogenase). An automatic pipe-line updates the cross-reference \ufb01 le after each GO release with any new terms that are created. Other reasons why E.C. and GO terms cannot be mapped are because of E.C. entries being transferred from one term to another or the E.C. number has yet to be associ-ated with a gene product (termed orphaned E.C. terms). Nicholas Furnham\f265Additionally, there are \u201cpseudo\u201d E.C. terms created by UniProt that describe an overall reaction derived from the literature but have yet to be included in the E.C. These are easily identi\ufb01 able as they have a letter n in the fourth level of the hierarchy, e.g. 1.1.1.n5 (3- methylmalate dehydrogenase).  Databases such as KEGG and BRENDA hold details of alter-native reactions and data relating to physiological function. Other resources hold more speci\ufb01 c functional annotations such as the catalytic residues and how they function in the overall reactions, as cataloged by the Catalytic Site Atlas (CSA), or MACiE that anno-tates the steps in an enzyme\u2019s reaction, the order in which bonds are broken and formed, the role of cofactors and the function of protein residues at each step. To bridge the gap between these more chemical descriptors and the biological descriptors associated with a protein a new ontology, the Enzyme Mechanism Ontology (EMO), has been developed [ 4 ]. Though not directly linked to GO, EMO terms can be determined though links with GOA terms of the UniProtKB record for a particular enzyme.  E.C. Hierarchy GO Term ChartEC 3 - HydrolasesEC 3.1 - Acting on ester bondsEC 3.1.4 - Phosphoric diester hydrolasesEC 3.1.4.11 - Phosphoinositide phospholipase CBiological ProcessMetabolic ProcessMolecular FunctionCatalytic ActivityHydrolase ActivityHydrolase Activity ActingOn Ester BondsLipase ActivityPhosphoric diesterhydrolase activity Phospholipase ActivityReactionPhospholipase C ActivityPhosphatidylinositol phospholipase C activityabE.C. 3.1.4.4R01310R07385R02051R04962E.C. 2.3.1.85E.C. 2.3.1.86E.C. 1.3.1.10E.C. 1.3.1.39E.C. 1.3.1.104  Fig. 1    ( a ) Examples of ambiguity in the E.C. classi\ufb01 cation, where one E.C. number can represent many reac-tions and where many E.C. numbers are describing one reaction. ( b ) The two representations of the same enzyme (phosphoinositide phospholipase C) in E.C. and GO, with the overall chemical reaction also shown. The reaction diagram is highlighted to show sub-structures across the reaction used in the determination of bond changes and reaction centers in EC-Blast        Complementary Sources of Protein Functional Information: The Far Side of GO\f2663     Comparing Enzyme Annotations  Unlike GO, the E.C. number cannot be used to make automated quantitative comparisons between annotations. There are a number of measures of annotation similarity that can be made based on the GO ontological graph. The most basic similarity measure is based on the length of the common path between two terms to the ontol-ogy root and has been enhanced to overcome the fact that the depth of a term within the ontology is not necessarily indicative of its speci\ufb01 city, termed information content (IC). Further enhance-ments normalize the IC measure (Lin score) and use semantic simi-larity (Wang score) [ 8 ,  9 ]. To overcome the de\ufb01 ciencies of E.C. as a means to measure functional similarity and to capture detailed reaction information not encapsulated in GO, new methods have been developed. Efforts to compare reactions based on their overall reaction chemistry have met with only moderate success, limited by their reliance upon the consistency and reliability of the underlying reaction data and the ability of the algorithm used to process a diverse range of reactions. The latest method called EC-Blast [ 10 ] has proven more successful. It uses an atom-atom mapping approach to automatically assign bond changes and reaction centers (the atom and bond type in the immediate region of the metabolite where the bonds are broken/formed). This allows for the reaction to be described in a set of \ufb01 ngerprints that in composite can be used to compare reactions. Taking all available E.C. numbers and equiv-alent GO terms that can be compared to each other, the difference between the two ways of measuring functional similarity is shown in Fig.  2 . Though many comparisons result in similar scores, a sub-stantial number diverge signi\ufb01 cantly. For example, E.C. 2.1.2.9 when compared to E.C. 2.1.2.11, based on bond order changes, the similarity score as calculated by EC-Blast is 0.22, where as the semantic similarity between the equivalent GO terms is 0.73. The low similarity from EC-Blast encapsulates the differences in bonds cleaved (two C-N bonds and 2 H-N bonds for E.C. 2.1.2.9; com-pared to one C-C, one H-O and one C-H for E.C. 2.1.2.11 as well as differences in stereochemistry changes and bond order rearrange-ments.) Thus, care needs to be taken in choosing the best measure of functional similarity, a widely used technique in functional infer-ence ( see  Chap.   12     [ 26 ]).4        Annotating Domains  One of the challenges of functional annotation is the granularity to which an annotation can be attached. Most genomic annotations are assigned to whole protein translations, i.e. the gene, but for many functions it is a protein domain that can be considered the Nicholas Furnham\f267functional unit. Of course functions are not solely con\ufb01 ned to a single domain and many functions are a product of multiple domains in combination. Many domains are combined with others in increasingly complex combinations and arrangements ( see  Fig.  3 ). This biological complexity adds considerable complexity to functional annotations, where a function can be assigned to com-plete gene products and other functional annotation to just one component domain or multi-domain combinations. There are a number of domain and motif databases that provide functional annotations, many of which are mapped to GO via the InterPro [ 11 ] proteins family database, that integrates predictive models from a range of different protein family databases. One of the main sequence based domain protein family databases is PFam [ 12 ], with the goal of creating a collection of functionally annotated families that is representative as much as possible of  protein- sequence space. PFam curators provide functional annotations, but in recent releases these annotations have been outsourced to the community via the use of Wikipedia allowing anyone to freely edit and improve the content, with the original curator annotations maintained. By their very nature these annotations do not conform to a controlled vocabulary, but it is possible for PFam annotations to be mapped back to GO terms; this is provided by the InterPro group and is available via the GO website.01\u221210.5\u22120.50100000200000300000400000Difference Between GO /  ECBlast Bond Similarity ScoreFrequency  Fig. 2    Differences between GO and EC measures of functional similarity. A fre-quency histogram showing the difference between the similarity scores of all- by- all pairs of E.C. numbers calculated using EC-Blast bond similarity measure and the equivalent GO term. GO similarity scores are calculated using the Wang semantic similarity method. Not all E.C. numbers are used as: EC-Blast requires fully balanced reactions, and not all E.C. numbers have a GO term equivalents        Complementary Sources of Protein Functional Information: The Far Side of GO\f268   The CATH [ 13 ] resource, which uses protein structures to de\ufb01 ne domains both within known protein structures and sequences where there is no structural information, uses the GO terms associ-ated with a sequence to de\ufb01 ne functionally coherent clusters (termed FunFams) within the superfamily division of the classi\ufb01 ca-tion. The functional annotation provided is derived from the pre-dominant GO term found within the FunFam. These terms though are assigned to the whole sequence and not the domain and there-fore may not directly relate to the speci\ufb01 c function the domain is participating in. In the SFLD [ 14 ] domains that are critical for function are determined (often being used to de\ufb01 ne the superfamily), thereby linking the functional annotation to a domain or   Fig. 3    Biological complexity generated by multi-domain architectures. A force-directed graph of the multi- domain architectures associated with a domain superfamily (\u201cwinged helix\u201d repressor DNA binding domain). The graph is centered on architecture containing just the single domain with nodes ( red boxes ) radiating from this representing ever-increasing multi-domain architecture (shown to the right of the node). A key to the domains in these multi-domain architectures is shown on the left identi\ufb01 ed by PFam codes (starting PF or PB) or CATH codes. Functions are associated with the whole gene product as well as for single domains within the multi-domain architecture. An interactive version of this graph can be found at   http://www.funtree.info/tem-plates/showArch.php?cathcode=00001.00010.00010.00010&amp;cathmethod=&amp;cathcluster=&amp;type=AS            Nicholas Furnham\f269combination of domains within a multi-domain architecture ( see  Chap.   9     [ 27 ]). SUPERFAMILY [ 15 ], a domain centric resource that uses an alternative structure based domain classi\ufb01 cation called SCOP, attempts to assign functional annotations speci\ufb01 cally to a domain. Using the GO semantic structure and the proteins multi domain architecture, domain-centric functional annotations are sta-tistically inferred based on the assumption that if a GO term is annotated to proteins that contain a shared domain then that term should also confer functional indicators for that domain. The SUPERFAMILY developers have generated a reduced version of GO for annotating domains and forms part of a structural domain functional ontology (SDFO) [ 16 ]. The approach of linking onto-logical terms to a domain can be generalized to other ontologies, most notably for phenotypic annotations. For example SUPERFAMILY integrates mammalian phenotype ontology (MPO) [ 17 ] from the mouse genome informatics (MGI) and the Human Phenotype Ontology (HPO) from the (OMIM) [ 18 ] resource.  5     Pathways and Interactions  Individual components of a pathway or groups of interacting pro-teins are described by the molecular function set of GO terms, while the pathways and interactions these components participate in are captured in the biological process GO terms. These provide overall descriptions of a biological process, such as signal transduc-tion, or more speci\ufb01 c terms such as thiamine metabolism. GO does not try to represent the dynamics or dependencies that are equiva-lent to a signal or metabolic pathway, though the GO consortium has recognized the importance of contextualizing gene product annotations and had begun to add some directional information ( see  Chap.   17     [ 28 ]). To be able to put the components into the context of a metabolic pathway for example, the use of specialist databases such as KEGG, BioCarta, MetaCyc, Pathway Interaction Database [ 19 ] and Reactome [ 20 ] is required ( see  Table  1 ). These provide curated and computationally derived descriptions of over-all topologies and interactions, often displayed as pathway dia-grams and maps. Many of these data resources are able to map terms back to GO. IntAct [ 21 ], which is a molecular interaction database curated from the literature or by data depositors, scores and \ufb01 lters interaction evidences to generate a high con\ufb01 dence sub-set of molecular interactions that are exported to GO.   Combinations of GO terms and pathway/interactions data-bases can be used in the analysis of proteomics data for functional annotation. This can be achieved either using methods for GO enrichment analysis and subsequently linking the results to exter-nal pathway resources [ 22 ] or by dynamically constructing the Complementary Sources of Protein Functional Information: The Far Side of GO\f270   Table 1    A summary of the data resources mentioned    Resource  Data curated  Relationship to GO  URL  ENZYMES  E.C.  A four level hierarchical classi\ufb01 cation of enzyme functions curated by the IUBMB Enzyme Commission  Levels have equivalent GO terms in the molecular function ontology. Not all E.C. numbers have equivalent GO terms.    http://www.ebi.ac.uk/intenz      EC-Blast  A database of reaction \ufb01 ngerprints that are used to compare enzyme reactions de\ufb01 ned by the E.C.  Provides function similarity scores as an alternative to GO semantic similarity measures.    https://www.ebi.ac.uk/thornton- srv/software/rbl      KEGG  A curated database of genes, enzyme reactions, metabolites, drugs and metabolic pathways.  Reactions, via E.C. numbers, are mapped to GO as well as pathways.    http://www.kegg.jp      BRENDA  A curated database of enzyme functions.  Catalogs GO terms amongst a number of other ontologies and can be used to provide a wide range of enzyme related data such metabolic rates, molecular interactions, etc.    http://www.brenda-enzymes.org      CSA  A curated and computationally inferred database of residues in protein structures that make up an enzymes catalytic site.  Can be used to extend GO functional annotations to include residue speci\ufb01 c functions involved in catalysis for known structures. Can be linked to GO via EMO ontology.    https://www.ebi.ac.uk/thornton- srv/databases/CSA      MACiE  A curated database of enzyme mechanisms.  Can be used to extend GO functional annotations to include enzyme mechanistic steps. Can be linked to GO via EMO ontology.    https://www.ebi.ac.uk/thornton- srv/databases/MACiE      DOMAINS  InterPro  Integrates predictive models from a range of different protein family databases.  Provides mappings between GO terms and many domain- centered data resources.    https://www.ebi.ac.uk/interpro     Nicholas Furnham\f271 Resource  Data curated  Relationship to GO  URL  Pfam  A sequence based classi\ufb01 cation of domains.  Provides curated and community sourced functional annotations of domain families that can be mapped to GO.    http://pfam.xfam.org      CATH  A structure based classi\ufb01 cation of domains.  Provides functionally coherent clusters (FunFams) annotated by GO terms.    http://www.cathdb.info      SUPERFAMILY  A structure based classi\ufb01 cation of domains based on SCOP.  Provides domain centered functional annotations in a structural domain functional ontology that contains a slimed down version of GO.    http://supfam.org      PATHWAYS &amp; INTERACTIONS  Reactome  A database of molecular pathways.  Provides descriptions of overall topologies and interactions and can be used in conjunction with GO molecular process terms.    http://www.reactome.org      IntAct  A database of molecular interactions.  Provides curated and depositor annotations of molecular interactions a high con\ufb01 dence subset of which is exported to GO.    https://www.ebi.ac.uk/intact       This is not an exhaustive list, but a representation of some of the alternative resources available and how they relate to GO. Many of the mappings between these data resources are available on the GO website and are updated on a daily, weekly, or monthly basis depending on the resource release cycle (  http://geneontology.org/page/download-mappings    )  Complementary Sources of Protein Functional Information: The Far Side of GO\f272pathway/interaction network based on the gene list of interest to create a functionally organized GO/pathway term network [ 23 ]. Additionally proteins participating in common biological processes or sharing molecular functions are predictive of interactions [ 24 ]. Many methods that combine semantic similarity and machine learning techniques have been developed to use GO to predict PPIs ( see  ref.  25  and references therein).  6     Conclusions  The Gene Ontology provides a rich set of ontological terms to describe many aspects of a protein\u2019s function. Many of these terms have equivalences in more specialist resources that like the Gene Ontology collate primary data derived from the literature. Often these resources include functional annotations that are not directly captured in GO or allow for annotations to be collated around a different functional unit, as in the case of protein domain centered functional annotations. Other types of functional descriptors such as the dependencies in metabolic pathways and protein\u2013protein interactions are not explicitly captured in GO (though this is cur-rently being addressed through GO annotation extensions), but in combination with other resources can be used to provide and enhance functional annotation of proteins.       Acknowledgements   NF is supported by a MRC Research Methodology Fellowship (MR/K020420/1). Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.  Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.  Nicholas Furnham\f273   References      1.   International Union of Biochemistry and Molecular Biology. Nomenclature C, Webb EC (1992) Enzyme nomenclature 1992: recommen-dations of the Nomenclature Committee of the International Union of Biochemistry and Molecular Biology on the nomenclature and classi\ufb01 cation of enzymes/prepared for NC-IUBMB by Edwin C. Webb. Published for the International Union of Biochemistry and Molecular Biology by Academic Press, San Diego      2.    Kanehisa M, Goto S, Sato Y, Furumichi M, Tanabe M (2012) KEGG for integration and interpretation of large-scale molecular data sets. Nucleic Acids Res 40(Database issue):D109\u2013D114. doi:  10.1093/nar/gkr988          3.    Chang A, Schomburg I, Placzek S, Jeske L, Ulbrich M, Xiao M, Sensen CW, Schomburg D (2015) BRENDA in 2015: exciting devel-opments in its 25th year of existence. Nucleic Acids Res 43(Database issue):D439\u2013D446. doi:  10.1093/nar/gku1068           4.    Furnham N, Holliday GL, de Beer TA, Jacobsen JO, Pearson WR, Thornton JM (2014) The Catalytic Site Atlas 2.0: cataloging catalytic sites and residues identi\ufb01 ed in enzymes. Nucleic Acids Res 42(Database issue):D485\u2013D489. doi:  10.1093/nar/gkt1243          5.    Holliday GL, Andreini C, Fischer JD, Rahman SA, Almonacid DE, Williams ST, Pearson WR (2012) MACiE: exploring the diversity of bio-chemical reactions. Nucleic Acids Res 40(Database issue):D783\u2013D789      6.    Caspi R, Altman T, Billington R, Dreher K, Foerster H, Fulcher CA, Holland TA, Keseler IM, Kothari A, Kubo A, Krummenacker M, Latendresse M, Mueller LA, Ong Q, Paley S, Subhraveti P, Weaver DS, Weerasinghe D, Zhang P, Karp PD (2014) The MetaCyc data-base of metabolic pathways and enzymes and the BioCyc collection of Pathway/Genome Databases. Nucleic Acids Res 42(Database issue):D459\u2013D471. doi:  10.1093/nar/gkt1103          7.    McDonald AG, Tipton KF (2014) Fifty-\ufb01 ve years of enzyme classi\ufb01 cation: advances and dif-\ufb01 culties. FEBS J 281(2):583\u2013592. doi:  10.1111/febs.12530          8.    du Plessis L, Skunca N, Dessimoz C (2011) The what, where, how and why of gene ontol-ogy--a primer for bioinformaticians. Brief Bioinform 12(6):723\u2013735. doi:  10.1093/bib/bbr002          9.    Yu G, Li F, Qin Y, Bo X, Wu Y, Wang S (2010) GOSemSim: an R package for measuring semantic similarity among GO terms and gene products. Bioinformatics 26(7):976\u2013978. doi:  10.1093/bioinformatics/btq064          10.    Rahman SA, Cuesta SM, Furnham N, Holliday GL, Thornton JM (2014) EC-BLAST: a tool to automatically search and compare enzyme reactions. Nat Methods 11(2):171\u2013174      11.    Mitchell A, Chang HY, Daugherty L, Fraser M, Hunter S, Lopez R, McAnulla C, McMenamin C, Nuka G, Pesseat S, Sangrador- Vegas A, Scheremetjew M, Rato C, Yong SY, Bateman A, Punta M, Attwood TK, Sigrist CJ, Redaschi N, Rivoire C, Xenarios I, Kahn D, Guyot D, Bork P, Letunic I, Gough J, Oates M, Haft D, Huang H, Natale DA, Wu CH, Orengo C, Sillitoe I, Mi H, Thomas PD, Finn RD (2015) The InterPro protein families data-base: the classi\ufb01 cation resource after 15 years. Nucleic Acids Res 43(Database issue):D213\u2013D221. doi:  10.1093/nar/gku1243          12.    Finn RD, Bateman A, Clements J, Coggill P, Eberhardt RY, Eddy SR, Heger A, Hetherington K, Holm L, Mistry J, Sonnhammer EL, Tate J, Punta M (2014) Pfam: the protein families database. Nucleic Acids Res 42(Database issue):D222\u2013D230. doi:  10.1093/nar/gkt1223          13.    Sillitoe I, Lewis TE, Cuff A, Das S, Ashford P, Dawson NL, Furnham N, Laskowski RA, Lee D, Lees JG, Lehtinen S, Studer RA, Thornton J, Orengo CA (2015) CATH: comprehensive structural and functional annotations for genome sequences. Nucleic Acids Res 43(Database issue):D376\u2013D381. doi:  10.1093/nar/gku947          14.    Akiva E, Brown S, Almonacid DE, Barber AE, Custer AF, Hicks MA, Huang CC, Lauck F, Mashiyama ST, Meng EC, Mischel D, Morris JH, Ojha S, Schnoes AM, Stryke D, Yunes JM, Ferrin TE, Holliday GL, Babbitt PC (2014) The structure-function linkage database. Nucleic Acids Res 42(D1):D521\u2013D530. doi:  10.1093/nar/gkt1130          15.    Oates ME, Stahlhacke J, Vavoulis DV, Smithers B, Rackham OJ, Sardar AJ, Zaucha J, Thurlby N, Fang H, Gough J (2015) The SUPERFAMILY 1.75 database in 2014: a doubling of data. Nucleic Acids Res 43(Database issue):D227\u2013D233. doi:  10.1093/nar/gku1041          16.    de Lima Morais DA, Fang H, Rackham OJ, Wilson D, Pethica R, Chothia C, Gough J (2011) SUPERFAMILY 1.75 including a domain-centric gene ontology method. Nucleic Acids Res 39(Database issue):D427\u2013D434. doi:  10.1093/nar/gkq1130          17.    Smith CL, Eppig JT (2009) The mammalian phe-notype ontology: enabling robust annotation and comparative analysis. Wiley Interdiscip Rev Syst Biol Med 1(3):390\u2013399. doi:  10.1002/wsbm.44          18.    Amberger JS, Bocchini CA, Schiettecatte F, Scott AF, Hamosh A (2015) OMIM.org: Complementary Sources of Protein Functional Information: The Far Side of GO\f274Online Mendelian Inheritance in Man (OMIM(R)), an online catalog of human genes and genetic disorders. Nucleic Acids Res 43(Database issue):D789\u2013D798. doi:  10.1093/nar/gku1205          19.    Schaefer CF, Anthony K, Krupa S, Buchoff J, Day M, Hannay T, Buetow KH (2009) PID: the Pathway Interaction Database. Nucleic Acids Res 37(Database issue):D674\u2013D679. doi:  10.1093/nar/gkn653          20.    Croft D, Mundo AF, Haw R, Milacic M, Weiser J, Wu G, Caudy M, Garapati P, Gillespie M, Kamdar MR, Jassal B, Jupe S, Matthews L, May B, Palatnik S, Rothfels K, Shamovsky V, Song H, Williams M, Birney E, Hermjakob H, Stein L, D\u2019Eustachio P (2014) The Reactome path-way knowledgebase. Nucleic Acids Res 42(Database issue):D472\u2013D477. doi:  10.1093/nar/gkt1102          21.    Kerrien S, Aranda B, Breuza L, Bridge A, Broackes-Carter F, Chen C, Duesbury M, Dumousseau M, Feuermann M, Hinz U, Jandrasits C, Jimenez RC, Khadake J, Mahadevan U, Masson P, Pedruzzi I, Pfeiffenberger E, Porras P, Raghunath A, Roechert B, Orchard S, Hermjakob H (2012) The IntAct molecular interaction database in 2012. Nucleic Acids Res 40(Database issue):D841\u2013D846. doi:  10.1093/nar/gkr1088          22.    Ramos H, Shannon P, Aebersold R (2008) The protein information and property explorer: an easy-to-use, rich-client web application for the management and functional analysis of pro-teomic data. Bioinformatics 24(18):2110\u20132111. doi:  10.1093/bioinformatics/btn363          23.    Bindea G, Mlecnik B, Hackl H, Charoentong P, Tosolini M, Kirilovsky A, Fridman WH, Pages F, Trajanoski Z, Galon J (2009) ClueGO: a Cytoscape plug-in to decipher functionally grouped gene ontology and path-way annotation networks. Bioinformatics 25(8):1091\u20131093. doi:  10.1093/bioinformat-ics/btp101          24.    Qi Y, Bar-Joseph Z, Klein-Seetharaman J (2006) Evaluation of different biological data and computational classi\ufb01 cation methods for use in protein interaction prediction. Proteins 63(3):490\u2013500. doi:  10.1002/prot.20865          25.    Maetschke SR, Simonsen M, Davis MJ, Ragan MA (2012) Gene Ontology-driven inference of protein-protein interactions using inducers. Bioinformatics 28(1):69\u201375.  doi:  10.1093/bio-informatics/btr610          26.   Pesquita C (2016) Semantic similarity in the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 12      27.   Holliday GL, Davidson R, Akiva E, Babbitt PC (2016) Evaluating functional annotations of enzymes using the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 9      28.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17    Nicholas Furnham\f275    Chapter 20    Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs to Bedside Phenotypes                          Spiros     C.     Denaxas        Abstract    Electronic Health Records (EHR) are inherently complex and diverse and cannot be readily integrated and analyzed. Analogous to the Gene Ontology, controlled clinical terminologies were created to facilitate the standardization and integration of medical concepts and knowledge and enable their subsequent use for translational research, of\ufb01 cial statistics and medical billing. This chapter will introduce several of the main controlled clinical terminologies used to record diagnoses, surgical procedures, laboratory results and medi-cations. The discovery of novel therapeutic agents and treatments for rare or common diseases increasingly requires the integration of genotypic and phenotypic knowledge across different biomedical data sources. Mechanisms that facilitate this linkage, such as the Human Phenotype Ontology, are also discussed.    Key words     Electronic health records  ,   Clinical terminologies  ,   Phenotypes  1      Introduction  We are arguably entering the era of data-driven, personalized med-icine, where electronic health records are considered the transfor-mational force for measuring and improving the quality of clinical care and accelerating the pace of biomedical research [ 1 ,  2 ]. Electronic Health Record (EHR) data, alternatively referred to as Electronic Medical Record (EMR) data, are broadly de\ufb01 ned as electronic data that are generated, captured and collected as part of routine clinical care across primary, secondary, and tertiary health care settings. EHR data can be structured (i.e., recorded using clinical terminologies), semi-structured (e.g., laboratory test results), or unstructured (e.g., free text). EHR data present mul-tiple opportunities that have the potential to transform medical practice and research across all stages of translation [ 3 \u2013 6 ].  Health care is an intrinsically multidisciplinary process and the care of patients, even within a single clinical specialty, intimately involves clinicians from a diverse set of other specialties (e.g., physi-cians, surgeons, radiologists, pharmacologists). Patient  interactions Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_20, \u00a9 The Author(s) 2017\f276often occur within distinct health care settings: some diseases are almost exclusively managed in primary care while acute manifesta-tions are usually treated in secondary care. For chronic conditions, such as cardiovascular diseases, patients may have multiple interac-tions within primary and secondary care, and undergo assessments and diagnostic tests across both settings over long periods of time. The amount of EHR data being digitally generated and collected are thus vast and rapidly expanding but lack a common structure to facilitate their use, both for care across clinical settings but also for research, auditing, and other administrative purposes.  The purpose of this chapter is to provide a brief introduction to clinical terminologies for capturing and representing different aspects of clinical care in electronic health records. Firstly, contem-porary terminologies for recording diagnoses, surgical procedures, lab measurements, and medication are described. Secondly, the main applications and challenges of using clinical terminologies are set out. Lastly, a potential pathway for integrating clinical termi-nologies with biological ontologies is illustrated through a case study in breast cancer.  2    Controlled Clinical Terminologies  Similar to bio-ontologies, such as the Gene Ontology [ 7 ,  8 ], con-trolled clinical terminologies (Table  1 ) were created to facilitate the systematic capture, curation, and description of health care- related concepts encountered during clinical care [ 9 ]. These can include but are not limited to diagnoses, symptoms, anatomical terms of location, prescribed medications, medical tests, surgical procedures, and laboratory measurements. Clinical terminologies are considered the conceptual core of clinical information systems and an essential tool for facilitating clinical data integration and reuse amongst disparate data sources. Initiatives such as the Open Biomedical Ontologies Consortium (OBO) [ 10 ] were founded to coordinate their evolution and alignment and provide a set of guidelines for creating and maintaining them with the aim of estab-lishing an ecosystem of interoperable entities.   Several systematic literature reviews provide in-depth detail on their different aspects and characteristics [ 11 \u2013 16 ]. A brief descrip-tion of some key terminologies is provided below.    SNOMED-Clinical Terms (SNOMED-CT) [ 17 ,  18 ] contains repre-sentations for over 300,000 health care-related concepts and is designed to capture and represent patient data for clinical care. It consists of four primary components that de\ufb01 ne the structure of the recorded information: concepts, descriptions, relationships and refer-ence sets.  Concepts  are the basic unit of describing health care- related information and are uniquely identi\ufb01 ed, e.g., the  Myocardial Infarction  concept (id 22298006). All concepts have a unique 2.1  DiagnosesSpiros C. Denaxas\f277Fully Speci\ufb01 ed Name, a list of Preferred Terms (e.g., Myocardial Infarction), and Synonyms (e.g., Heart attack, Cardiac infarction) de\ufb01 ned. Concepts are organized into an acyclic hierarchy of is-a rela-tionships that enables multiple inheritance i.e. concepts can have    Table 1    Common clinical terminologies, classi\ufb01 cation systems, and ontologies used in electronic health records    Terminology  Information  CPT   Name : Current Procedural Terminology   Context : surgical procedures   Website :   http://www.ama-assn.org/go/cpt      DSM-5   Name : Diagnostic and Statistical Manual of Mental Disorders\u2014version 5   Context : mental health diagnoses   Website :   http://www.dsm5.org/      ICD-10   Name : International Statistical Classi\ufb01 cation of Diseases and Related Health Problems\u201410th revision   Context : diagnoses   Website :   http://www.who.int/classi\ufb01 cations/icd/en/      LOINC   Name : Logical Object Identi\ufb01 ers and Codes   Context : laboratory measurements   Website :   https://loinc.org/      MedDRA   Name : Medical Dictionary for Regulatory Activities   Context : biopharmaceutical regulation   Website :   http://www.meddra.org/      MeSH   Name : Medical Subject Headings   Context : life sciences literature indexing   Website :   https://www.nlm.nih.gov/mesh/      NCIT   Name : National Cancer Institute Thesaurus   Context : biomedical concepts related to cancer   Website :   http://ncit.nci.nih.gov/      OPCS   Name : OPCS Classi\ufb01 cation of Interventions and Procedures   Context : surgical procedures   Website :   http://systems.hscic.gov.uk/data/clinicalcoding/codingstandards/opcs4      Read   Name : Read Codes, Clinical Terms   Context : all health care related concepts   Website :   http://systems.hscic.gov.uk/data/uktc/readcodes      RxNorm   Name : RxNorm   Context : US clinical drugs   Website :   http://www.nlm.nih.gov/research/umls/rxnorm/      SNOMED-CT   Name : Systematized Nomenclature of Medicine-Clinical Terms   Context : all health care related concepts   Website :   http://www.ihtsdo.org/snomed-ct      UMLS   Name : Uni\ufb01 ed Medical Language System   Context : clinical terminology mappings   Website :   http://www.nlm.nih.gov/research/umls/     Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f278multiple parent concepts. For example  Myocardial Infarction  (id 22298006) is a subclass of the concepts  Necrosis of anatomical site  (id 609410002),  Ischaemic heart disease  (414545008), and  Myocardial disease  (id 57809008). SNOMED-CT contains terms for describing clinical \ufb01 ndings, symptoms, diagnoses, procedures, medication, devices and anatomical body structures. It provides a compositional syntax which allows multiple ontology terms to be combined in order to build composite terms to represent complex medical concepts, a process known as post-coordination. Signi\ufb01 cant variation exists internationally with regards to SNOMED-CT adop-tion and implementation [ 19 ] and its use for research or routine clini-cal care. In the UK National Health Service (NHS), SNOMED-CT has been designated to become the standard clinical terminology to be used across the entire health care system by 2020.  The International Statistical Classi\ufb01 cation of Diseases and Related Health Problems (ICD) is a statistical classi\ufb01 cation system maintained by the World Health Organization [ 20 ]. ICD encapsu-lates concepts for classifying diseases, signs and symptoms, abnormal investigation \ufb01 ndings, complaints, interactions with the health care system, social circumstances, and external causes of injury or disease. It maps health conditions to corresponding generic categories together with speci\ufb01 c variations, assigning for these a designated alphanumeric code, up to six characters long. Major categories are designed to include a set of similar diseases (e.g., ICD chapter \u201cI\u201d encapsulates all diseases of the circulatory system). It is currently the most widely used statistical classi\ufb01 cation system in the world with many countries developing their own extensions and modi\ufb01 cations tailored to their local health care system (e.g., ICD- 9- CM used in the USA [ 21 ]). The primary use case of ICD is to abstract EHR data by assigning unique codes to diagnoses and procedures. This pro-cess is known as  clinical coding , and performed manually or algorith-mically by specialist staff according to a prespeci\ufb01 ed protocol. Coded data are then utilized for research [ 22 ], of\ufb01 cial statistics [ 23 ], medi-cal billing, and health care resource planning.     Clinical terminologies are used for describing surgical procedures, interventions, and investigations that patients undergo in hospi-tals, during in patient and outpatient interactions. In the USA, the American Medical Association maintains the Current Procedural Terminology [ 24 ] (CPT) and in the UK, the OPCS Classi\ufb01 cation of Interventions and Procedures version 4 (OPCS-4) [ 25 ] is used by the National Health Service. Both terminologies are used to convey information with regards to procedures to physicians and clinical coders and are combined with diagnosis codes during the medical billing process.      Logical Observation Identi\ufb01 ers Names and Codes (LOINC)  [ 26 \u2013 28 ] is maintained by the Regenstrief Institute and used for describing medical laboratory observations. LOINC facilitates the exchange of 2.2  Procedures2.3  Laboratory MeasurementsSpiros C. Denaxas\f279information with regards to laboratory tests and results between health care providers, laboratories and public health agencies. LOINC terms correspond to a single test, panel, observation, or measurement and are uniquely identi\ufb01 ed by a numeric code. Terms are formed of six parts: component (what is being measured), prop-erty (characteristics of what is being measured), time (measurement temporal information), system (observation context or specimen type), scale (scale of measure), and method (procedure used to obtain the measure).     RxNorm [ 29 ] is a US-speci\ufb01 c terminology developed by the Library of Medicine for describing information about clinical drugs (de\ufb01 ned as pharmaceutical products taken by patients with a therapeutic or diagnostic intent). It provides normalized names for all clinical drugs and links information about their active ingredient(s), strengths, form, and branded versions. RxNorm is widely used for recording drug information in patient health records, exchanging information between health care providers [ 30 ], personal medication records [ 31 ], and medication-related clinical decision support [ 32 ] and con-tains cross-references to other commonly used drug vocabularies.   3    Uses of Clinical Terminologies  While clinical terminologies are primarily used for the purposes of clinical data standardization and integration, the provision of a sys-tematic and common language for describing health care concepts enables the subsequent use of EHR data for a diverse set of pur-poses, such as clinical research, auditing and billing. Adoption of clinical terminologies worldwide varies across health care settings and by purpose but diagnostic and procedural classi\ufb01 cation sys-tems are primarily used for medical billing purposes. This section will brie\ufb02 y describe the opportunities and challenges of using EHR data and clinical terminologies.    EHR data are increasingly being linked and used for translational research [ 33 ] as they offer larger sample sizes at a higher clinical resolution [ 34 ]. A primary use-case of linked EHR data is to accu-rately extract phenotypic information (i.e., disease status), a process known as  phenotyping  [ 35 ]. Identifying cohorts of patients that share a common characteristic (e.g., have been diagnosed with hypertension or have abnormally high blood glucose measure-ments) enables researchers to use EHR data to perform large-scale clinical research studies at a lower cost compared to traditional bespoke investigator-led studies. EHR data have been used to examine disease aetiology in relation to clinical risk factors [ 36 ,  37 ] or genotypic information [ 38 ,  39 ], develop disease prognosis mod-els [ 40 ], perform health outcome comparisons between countries 2.4  Medication3.1  OpportunitiesIntegrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f280[ 41 ], and facilitate pragmatic clinical trials [ 24 ]. Clinical terminolo-gies are heavily used by deterministic rule-based algorithms curated by experts for identifying and constructing patient cohorts from raw EHR data but data-driven methodologies are increasingly being utilized [ 42 ]. Comprehensive reviews provide additional information on the use of clinical terminologies for other purposes such as annotating and accessing medical knowledge sources, data integration, semantic interoperability, data aggregation, and clinical decision support systems [ 43 \u2013 46 ].     Merging EHR data across sources becomes challenging due to the differences in the manner in which data are recorded. Each health care setting generates and records data for a particular purpose using the clinical terminology that is optimal in that speci\ufb01 c con-text. For example, information in primary care can be recorded using SNOMED-CT whereas hospital morbidities would be recorded using ICD-10. This mismatch between the clinical termi-nologies used to record information leads to signi\ufb01 cant challenges as information is recorded at varying levels of granularity across sources. Semantic mapping systems, such as the Uni\ufb01 ed Medical Language System [ 47 ] (UMLS), can provide further details on the relationship between terms in each clinical terminology and facili-tate the translation or integration of information across sources. However, direct one-to-one mappings might not always exist between terminologies leading to information loss due to insuf\ufb01 -cient resolution or con\ufb02 icts between two sources where multiple potential mappings exist. These issues and their severity vary by clinical speciality and context but often require a set of rules to be created by users and manually applied in order to resolve them before the data can be used for research purposes. In cases of incomplete mappings, synonyms or adjacent terms in the clinical terminology might be used as a replacement term but that is assessed on a case-by-case basis.   4    Integrating Biological and Clinical Data  A key challenge in genomics is to understand and elucidate the phe-notypic consequences of variation observed in the genotypic level. Even among Mendelian diseases, the association between genotype and phenotype is often complex. With the advent of next-genera-tion sequencing methods, the focus is now shifting from generating genomic sequence data to ef\ufb01 ciently interpreting them.  From a clinical care perspective, diseases presented by patients can be phenotypically distinct and associated with a speci\ufb01 c set of treatments, symptoms, investigative procedures and management strategies. From a molecular scientist\u2019s perspective however, it might be appropriate to group and analyze diseases that share a common biological pathway as a single entity in order to discover similarities 3.2  ChallengesSpiros C. Denaxas\f281in the way they manifest in different patient groups. Both of these viewpoints are valid, but as a direct consequence, data describing phenotypic and molecular properties are recorded in a different, and often incompatible, manner [ 48 ]. The problem is exacerbated in rare diseases where researchers are required to create larger cohorts of patients by pooling data across research consortia in order to increase the sample sizes and obtain accurate estimates of risk.  Increasing amounts of molecular function knowledge are being recorded in a hierarchical manner, using bio-ontologies such as the GO, which offer a rigid way to represent knowledge in a machine-readable manner, interoperable between different data sources and annotated [ 11 ]. Scientists aim to link and integrate this with pheno-typic information in order to elucidate the genotype- phenotype relationship and facilitate the discovery of novel therapeutic agents and treatments for common or rare disorders. Ontologies such as the Human Phenotype Ontology (HPO) [ 49 ,  50 ] and the Disease Ontology [ 51 ,  52 ] were created to provide streamlined disease de\ufb01 -nitions by systematically combining the diverse and heterogeneous knowledge contained within clinical terminologies and other anno-tation sources under a single framework. These tools aim to provide researchers with a rich resource that semantically links diverse dis-ease de\ufb01 nitions from clinical terminologies and enables the linking of phenotypic, genotypic and genetic information of a disease.    The HPO is a structured, curated ontology describing phenotypic abnormalities and the relationships between them. The HPO aims to act as scaffolding for enabling the interoperability between molecular biology and human disease by providing a centralized resource for integrating genotypic and phenotypic data across biomedical sources. The HPO enables the computational analysis of human (and model organism) phenotypes against the background biological and molecu-lar knowledge incorporated in biological ontologies such as the GO.  The HPO is organized as three independent sub-ontologies that cover different domains with the largest one being the one describ-ing phenotypic abnormalities. The other two sub- ontologies describe the mode of inheritance and the onset and clinical course of the abnormalities. The primary focus of the HPO is not to capture dis-eases but rather the phenotypic abnormalities that are associated with them. Each HPO term describes a phenotypic abnormality (e.g.,  Primary congenital glaucoma ) and is assigned a unique persis-tent identi\ufb01 er (e.g.,  HP:0001087 ). HPO terms are related to parent terms by \u201cis a\u201d relationships and terms can have multiple parent terms. The HPO is not primarily designed to capture and document quantitative information (e.g., systolic blood pressure, body mass index) but does provide qualitative descriptions of excess or reduc-tion in quantity leading to a phenotypic abnormality (e.g., markedly reduced T cell function).  Interoperability between molecular and phenotypic data and research areas is accomplished through a comprehensive set of term 4.1  Human Phenotype OntologyIntegrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f282annotations. The majority of HPO terms contain a reference to the Uni\ufb01 ed Medical Language System [ 47 ], enabling the mapping of terms between controlled clinical terminologies and other sources in the UMLS Metathesaurus. Additionally, HPO terms contain annotations that provide pointers to speci\ufb01 c diseases or genes cre-ated in other external knowledge sources such as Online Mendelian Inheritance in Man (OMIM) database (  http://omim.org/    ), DECIPHER (  https://decipher.sanger.ac.uk/    ), and Orphanet (  http://www.orpha.net/    ). HPO annotations have a number of metadata \ufb01 elds associated with them for further specifying onset, frequency and quantifying modi\ufb01 er effects. Annotations evidence codes, analogous to GO Evidence Codes, describe the manner in which a particular annotation was assigned to a term (e.g., inferred by text mining, traceable author statement, inferred from electronic annotation, public clinical study).     Using malignant neoplasms of the breast as a hypothetical case study, this section presents a potential pathway of linking biologi-cal knowledge on genotypic variation and molecular functions to clinical phenotypes encountered within the health care system. Drilling down from the right-hand side of clinical phenotypes down to the left-hand side of genotypic variation,  Figure  1  illustrates details of all potential sources and annota-tion mechanisms used within each source to capture and record information.    Genotypic information : HPO annotations provide a cross-link to the Online Mendelian Inheritance in Man (OMIM)  Breast Cancer, Familial  phenotype entity (OMIM #114480\u2014URL   www.omim.org/entry/114480    ). OMIM provides curated lists of disease phe-notypes and genes associated with that phenotype, in this case for example the BRCA2 gene entry (OMIM 600185\u2014   www.omim.4.2  From Base Pairs to Bedside Phenotypes: Breast Cancer Case StudyGenomicvariationGenotypeTranscriptsPhenotypeClinicalphenotypeAnnotation:Resources:Resources:Resources:Resources:Resources:Annotation:Annotation:Annotation:HUGO/HGNCRefSeqGeneLocGeneIddbSNPEntrezEnsembIUniProtOMIMUMLSOrphanetGOHPOSNOMED-CTNCTITRxNormCPS,OPCSDO  Fig. 1    Along one potential path from genomic variation to genotypic information, transcripts and phenotypic information observed in clinical care there are multiple annotation mechanisms that are being utilized to record information in a structured way and enable the machine-driven interoperability between different platforms        Spiros C. Denaxas\f283org/entry/600185    ). Additionally, entries provide cross- links with Entrez [ 53 ] (Gene ID 675\u2014URL   http://www.ncbi.nlm.nih.gov/gene/675    ) and Ensembl [ 54 ] (ENSG00000139618\u2014URL   http://www.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000139618;r=13:32315474-32400266    ).  Breast Cancer 2, early onset  ( BRCA2 ) is a protein-coding gene and belongs to the Fanconi anemia, complementation group (FANC) family of genes.   Genotypic variation : The NCBI dbSNP (  http://www.ncbi.nlm.nih.gov/SNP/    ) provides curated and annotated information link-ing Single Nucleotide Polymorphisms (SNPs) and individual genes. rs144848 is one of the multiple mutations in the BRCA2 gene that have been reported to represent an independently minor but cumulatively signi\ufb01 cant increased risk for developing breast cancer [ 55 ]. dbSNP provides information the SNPs location (e.g., chromosome and chromosomal position), source assays, discor-dant genotypes and population diversity. (URL   http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=rs144848    )   Molecular function : UniProt [ 56 ] provides information on gene transcripts, in this case BRCA2_HUMAN (P51587, Breast cancer type 2 susceptibility protein). The biological process and molecular functions of the gene product are annotated using the Gene Ontology:  double-strand break repair via homologous recombination  (GO:0000724),  DNA Repair  (GO:0006281),  cytokinesis  (GO:0000910),  protease binding  (GO:0002020), and positive reg-ulation of transcription, DNA-templated (GO:0045893). Using the GO, researchers are able to identify other gene products that share a common biological pathway or molecular function and incorporate that knowledge in their experiments. (URL:   http://www.uniprot.org/uniprot/P51587    )   Phenotypic information : The HPO  Breast carcinoma  term (HP: 0003002\u2014  http://purl.obolibrary.org/obo/HP_0003002    ) de\ufb01 nes the presence of a carcinoma of the breast and is a child node of  Neoplasms of the breast  (HP:0100013). The HPO term contains a cross-reference to the Uni\ufb01 ed Medical Language System (UMLS)  Malignant Neoplasm of Breast  (UMLS:C0006142\u2014URL   https://uts.nlm.nih.gov//metathesaurus.html#C0006142;0;1;CUI;2015AA;EXACT_MATCH    ;;)  Concept  which in turns provides mappings to other major controlled clinical terminologies such as the International Classi\ufb01 cation of Diseases 10th revision (C50, Malignant neoplasm of breast\u2014  http://apps.who.int/classifications/icd10/browse/2010/en#/C50-C50    ) and SNOMED- Clinical Terms (254837009, Malignant tumor of breast\u2014  http://bioportal.bioontology.org/ontologies/SNOMEDCT?p=classes&amp;conceptid=254837009    ).   Clinical phenotype : Oncology data in hospitals are stored in diverse locations and formats since diagnosis and treatment is a multidisci-plinary process between pathology, radiology, surgery, medical Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f284oncology and radiotherapy. Breast cancer diagnosis and severity is usually evaluated through imaging tests such as mammograms, ultrasounds, magnetic resonance imaging or by performing a biopsy. Medical images and their associated metadata are stored in a picture archiving and communication system (PACS) system and information about these procedures and the results obtained would be recorded using intervention and procedure terms. Diagnosis and staging information would be stored and coded in pathology sys-tems using a medical terminology such as SNOMED-CT or other bespoke data structures. Treatment data would be stored in the pharmacy information systems.   5    Conclusion  The amount of clinical data that are generated and captured during routine clinical care is increasing in size and complexity. Integrating clinical data from disparate sources however is a challenging task due to their lack of common structure and annotation. Similar to the Gene Ontology, controlled clinical terminologies have been created to facilitate the systematic capture, curation, and description of health care related events such as diagnoses, prescriptions and procedures from EHR data and enable their subsequent usage for clinical care, research, or administrative purposes. Furthermore, linking EHR data with biological knowledge is increasingly becoming possibly through tools such as the Human Phenotype Ontology (HPO) and the Disease Ontology that aim to provide the semantic  scaffolding for computationally integrating biomedical knowledge across sources.       Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not permitted by statutory regulation, users will need to obtain per-mission from the license holder to duplicate, adapt or reproduce the material.  Spiros C. Denaxas\f285    1.    Collins F, Varmus H (2015) A New Initiative on Precision Medicine. N Engl J Med 372(9):793\u2013795. doi:  10.1056/nejmp1500523          2.    Shah N, Tenenbaum J (2012) The coming age of data-driven medicine: translational bioinfor-matics\u2019 next frontier. J Am Med Inform Assoc 19:e1. doi:  10.1136/amiajnl-2012-000969          3.    Jensen P, Jensen L, Brunak S (2012) Mining electronic health records: towards better research applications and clinical care. Nat Rev Genet 13(6):395\u2013405. doi:  10.1038/nrg3208         4.    Khoury M, Gwinn M, Ioannidis J (2010) The emergence of translational epidemiology: from scienti\ufb01 c discovery to population health impact. Am J Epidemiol 172(5):517\u2013524. doi:  10.1093/aje/kwq211         5.    Khoury M, Lam TK, Ioannidis J, Hartge P, Spitz M, Buring J, Chanock S, Croyle R, Goddard K, Ginsburg G, Herceg Z, Hiatt R, Hoover R, Hunter D, Kramer B, Lauer M, Meyerhardt J, Olopade O, Palmer J, Sellers T, Seminara D, Ransohoff D, Rebbeck T, Tourassi G, Winn D, Zauber A, Schully S (2013) Transforming epidemiology for 21st century medicine and public health. Cancer Epidemiol Biomark Prev 22(4):508\u2013516. doi:  10.1158/1055-9965.epi-13-0146          6.    Liao K, Cai T, Savova G, Murphy S, Karlson E, Ananthakrishnan A, Gainer V, Shaw S, Xia Z, Szolovits P, Churchill S, Kohane I (2015) Development of phenotype algorithms using electronic medical records and incorporating natural language processing. BMJ 350:h1885. doi:  10.1136/bmj.h1885          7.    Ashburner M, Ball C, Blake J, Botstein D, Butler H, Cherry M, Davis A, Dolinski K, Dwight S, Eppig J, Harris M, Hill D, Issel- Tarver L, Kasarskis A, Lewis S, Matese J, Richardson J, Ringwald M, Rubin G, Sherlock G (2000) Gene Ontology: tool for the uni\ufb01 cation of biology. Nat Genet 25(1):25\u201329. doi:  10.1038/75556          8.    Gene Ontology C (2004) The Gene Ontology (GO) database and informatics resource. Nucleic Acids Res 32(Suppl 1):D258\u2013D261. doi:  10.1093/nar/gkh036          9.   Cantor M, Lussier Y (2003) Putting data inte-gration into practice: using biomedical termi-nologies to add structure to existing data sources. AMIA Annual Symposium proceed-ings/AMIA Symposium AMIA Symposium, pp 125\u2013129      10.    Smith B, Ashburner M, Rosse C, Bard J, Bug W, Ceusters W, Goldberg L, Eilbeck K, Ireland A, Mungall C, Leontis N, Rocca-Serra P, Ruttenberg A, Sansone S-A, Scheuermann R, Shah N, Whetzel P, Lewis S (2007) The OBO Foundry: coordinated evolution of ontologies to support biomedical data integration. Nat Biotechnol 25(11):1251\u20131255. doi:  10.1038/nbt1346           11.    Bard J, Rhee S (2004) Ontologies in biology: design, applications and future challenges. Nat Rev Genet 5(3):213\u2013222. doi:  10.1038/nrg1295         12.    Cimino JJ (1998) Desiderata for controlled medical vocabularies in the twenty-\ufb01 rst cen-tury. Methods Inf Med 37(4-5):394\u2013403     13.    Chute CG, Cohn SP, Campbell KE, Oliver DE, Campbell JR (1996) The content coverage of clinical classi\ufb01 cations. For The Computer-Based Patient Record Institute\u2019s Work Group on Codes &amp; Structures. J Am Med Inform Assoc 3(3):224\u2013233     14.    Pathak J, Wang J, Kashyap S, Basford M, Li R, Masys D, Chute C (2011) Mapping clinical phenotype data elements to standardized metadata repositories and controlled termi-nologies: the eMERGE Network experience. J Am Med Inform Assoc 18(4):376\u2013386. doi:  10.1136/amiajnl-2010-000061         15.    de Lusignan S, Minmagh C, Kennedy J, Zeimet M, Bommezijn H, Bryant J (2001) A survey to identify the clinical coding and clas-si\ufb01 cation systems currently in use across Europe. Stud Health Technol Inform 84(Pt 1):86\u201389      16.    de Lusignan S (2005) Codes, classi\ufb01 cations, terminologies and nomenclatures: de\ufb01 nition, development and application in practice. Inform Prim Care 13(1):65\u201370      17.    Donnelly K (2006) SNOMED-CT: the advanced terminology and coding system for eHealth. Stud Health Technol Inform 121:279\u2013290      18.   Wang A, Sable J, Spackman K (2002) The SNOMED clinical terms development process: re\ufb01 nement and analysis of content. Proceedings/AMIA Annual Symposium AMIA Symposium, pp 845\u2013849      19.    Lee D, de Keizer N, Lau F, Cornet R (2014) Literature review of SNOMED CT use. J Am Med Inform Assoc 21:e1. doi:  10.1136/amiajnl- 2013- 001636          20.    Denny J, Crawford D, Ritchie M, Bielinski S, Basford M, Bradford Y, Chai HS, Bastarache L, Zuvich R, Peissig P, Carrell D, Ramirez A, Pathak J, Wilke R, Rasmussen L, Wang X, Pacheco J, Kho A, Hayes G, Weston N, Matsumoto M, Kopp P, Newton K, Jarvik G, Li R, Manolio T, Kullo I, Chute C, Chisholm R, Larson E, McCarty C, Masys D, Roden D, de Andrade M (2011) Variants near FOXE1 are associated with hypothyroidism and other thyroid conditions:    References Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f286using electronic medical records for genome- and phenome-wide studies. Am J Hum Genet 89(4):529\u2013542. doi:  10.1016/j.ajhg.2011.09.008          21.    Quan H, Sundararajan V, Halfon P, Fong A, Burnand B, Luthi J-C, Saunders D, Beck C, Feasby T, Ghali W (2005) Coding algorithms for de\ufb01 ning comorbidities in ICD-9-CM and ICD-10 administrative data. Med Care 43(11):1130\u20131139      22.    Rubbo B, Fitzpatrick N, Denaxas S, Daskalopoulou M, Yu N, Patel R, Hemingway H (2015) Use of electronic health records to ascertain, validate and phenotype acute myocardial infarction: a systematic review and recommendations. Int J Cardiol. doi:  10.1016/j.ijcard.2015.03.075          23.    Taylor P (2013) Standardized mortality ratios. Int J Epidemiol 42(6):1882\u20131890. doi:  10.1093/ije/dyt209           24.    van Staa T-P, Dyson L, McCann G, Padmanabhan S, Belatri R, Goldacre B, Cassell J, Pirmohamed M, Torgerson D, Ronaldson S, Adamson J, Taweel A, Delaney B, Mahmood S, Baracaia S, Round T, Fox R, Hunter T, Gulliford M, Smeeth L (2014) The opportunities and challenges of pragmatic point-of-care randomised trials using routinely collected electronic records: evalua-tions of two exemplar trials. Health Technol Assess (Winchester, England) 18(43):1\u2013146      25.    Scannell J, Blanckley A, Boldon H, Warrington B (2012) Diagnosing the decline in pharma-ceutical R&amp;D ef\ufb01 ciency. Nat Rev Drug Discov 11(3):191\u2013200. doi:  10.1038/nrd3681          26.    Bakken S, Cimino JJ, Haskell R, Kukafka R, Matsumoto C, Chan GK, Huff SM (2000) Evaluation of the clinical LOINC (Logical Observation Identi\ufb01 ers, Names, and Codes) semantic structure as a terminology model for standardized assessment measures. J Am Med Inform Assoc 7(6):529\u2013538     27.    Huff SM, Rocha RA, McDonald CJ, De Moor GJ, Fiers T, Bidgood WD, Forrey AW, Francis WG, Tracy WR, Leavelle D, Stalling F, Grif\ufb01 n B, Maloney P, Leland D, Charles L, Hutchins K, Baenziger J (1998) Development of the Logical Observation Identi\ufb01 er Names and Codes (LOINC) vocabulary. J Am Med Inform Assoc 5(3):276\u2013292      28.    McDonald C, Huff S, Suico J, Hill G, Leavelle D, Aller R, Forrey A, Mercer K, DeMoor G, Hook J, Williams W, Case J, Maloney P (2003) LOINC, a universal standard for identifying laboratory observations: a 5-year update. Clin Chem 49(4):624\u2013633. doi:  10.1373/49.4.624          29.    Nelson S, Zeng K, Kilbourne J, Powell T, Moore R (2011) Normalized names for clinical drugs: RxNorm at 6 years. J Am Med Inform Assoc 18(4):441\u2013448. doi:  10.1136/amiajnl- 2011- 000116          30.    Bouhaddou O, Warnekar P, Parrish F, Do N, Mandel J, Kilbourne J, Lincoln M (2008) Exchange of computable patient data between the Department of Veterans Affairs (VA) and the Department of Defense (DoD): terminology mediation strategy. J Am Med Inform Assoc 15(2):174\u2013183      31.   Zeng K, Bodenreider O, Nelson S (2008) Design and implementation of a personal medi-cation record-MyMedicationList. AMIA Annual Symposium proceedings/AMIA Symposium AMIA Symposium, pp 844\u2013848      32.    Duke J, Friedlin J (2010) ADESSA: a real-time decision support service for delivery of semanti-cally coded adverse drug event data. AMIA Annu Symp Proc 2010:177\u2013181      33.    Weber G, Mandl K, Kohane I (2014) Finding the missing link for big biomedical data. JAMA. doi:  10.1001/jama.2014.4228          34.   Denaxas S, Morley K (2015) Big biomedical data and cardiovascular disease research: opportunities and challenges. Eur Heart J 1(1): qcv005. doi:   10.1093/ehjqcco/qcv005          35.    Morley K, Wallace J, Denaxas S, Hunter R, Patel R, Perel P, Shah A, Timmis A, Schilling R, Hemingway H (2014) De\ufb01 ning disease pheno-types using national linked electronic health records: a case study of atrial \ufb01 brillation. PLOS ONE 9(11):e110900      36.    Rapsomaniki E, Timmis A, George J, Pujades- Rodriguez M, Shah A, Denaxas S, White I, Caul\ufb01 eld M, Dean\ufb01 eld J, Smeeth L, Williams B, Hingorani A, Hemingway H (2014) Blood pressure and incidence of twelve cardiovascular diseases: lifetime risks, healthy life-years lost, and age-speci\ufb01 c associations in 1\u00b725 million people. Lancet 383(9932):1899\u20131911      37.    Shah AD, Langenberg C, Rapsomaniki E, Denaxas S, Pujades-Rodriguez M, Gale C, Dean\ufb01 eld J, Smeeth L, Timmis A, Hemingway H (2015) Type 2 diabetes and incidence of cardiovascular diseases: a cohort study in 1\u00b79 million people. Lancet Diabetes Endocrinol 3(2):105\u2013113      38.    Newton K, Peissig P, Kho A, Bielinski S, Berg R, Choudhary V, Basford M, Chute C, Kullo I, Li R, Pacheco J, Rasmussen L, Spangler L, Denny J (2013) Validation of electronic medi-cal record-based phenotyping algorithms: results and lessons learned from the eMERGE network. J Am Med Inform Assoc 20(e1):e147\u2013e154. doi:  10.1136/amiajnl-2012-000896          39.    Gottesman O, Kuivaniemi H, Tromp G, Faucett A, Li R, Manolio T, Sanderson S, Kannry J, Zinberg R, Basford M, Brilliant M, Carey D, Chisholm R, Chute C, Connolly J, Crosslin D, Denny J, Gallego C, Haines J, Hakonarson H, Harley J, Jarvik G, Kohane I, Kullo I, Larson E, Spiros C. Denaxas\f287McCarty C, Ritchie M, Roden D, Smith M, B\u00f6ttinger E, Williams M (2013) The Electronic Medical Records and Genomics (eMERGE) Network: past, present, and future. Genet Med 15(10):761\u2013771. doi:  10.1038/gim.2013.72          40.   Rapsomaniki E, Shah A, Perel P, Denaxas S, George J, Nicholas O, Udumyan R, Feder G, Hingorani A, Timmis A, Smeeth L, Hemingway H (2013) Prognostic models for stable coro-nary artery disease based on electronic health record cohort of 102 023 patients. Eur Heart J:eht533. doi:  10.1093/eurheartj/eht533          41.    Chung S-C, Gedeborg R, Nicholas O, James S, Jeppsson A, Wolfe C, Heuschmann P, Wallentin L, Dean\ufb01 eld J, Timmis A, Jernberg T, Hemingway H (2014) Acute myocardial infarction: a comparison of short-term survival in national outcome registries in Sweden and the UK. Lancet 383(9925):1305\u20131312. doi:  10.1016/s0140-6736(13)62070-x          42.    Shivade C, Raghavan P, Fosler-Lussier E, Embi P, Elhadad N, Johnson S, Lai A (2014) A review of approaches to identifying patient phenotype cohorts using electronic health records. J Am Med Inform Assoc 21(2):221\u2013230. doi:  10.1136/amiajnl-2013-001935          43.    Denny J (2012) Chapter 13: Mining electronic health records in the genomics era. PLoS Comput Biol 8(12):e1002823. doi:  10.1371/journal.pcbi.1002823         44.    Bodenreider O (2008) Biomedical ontologies in action: role in knowledge management, data inte-gration and decision support. Yearb Med Inform 2008:67\u201379     45.    Bodenreider O, Stevens R (2006) Bio- ontologies: current trends and future directions. Brief Bioinform 7(3):256\u2013274. doi:  10.1093/bib/bbl027          46.    Stan\ufb01 ll M, Williams M, Fenton S, Jenders R, Hersh W (2010) A systematic literature review of automated clinical coding and classi\ufb01 cation systems. J Am Med Inform Assoc 17(6):646\u2013651. doi:  10.1136/jamia.2009.001024           47.    Bodenreider O (2004) The Uni\ufb01 ed Medical Language System (UMLS): integrating bio-medical terminology. Nucleic Acids Res 32(Suppl 1):D267\u2013D270. doi:  10.1093/nar/gkh061          48.    Biesecker L (2004) Phenotype matters. Nat Genet 36(4):323\u2013324. doi:  10.1038/ng0404- 323          49.    Robinson P, K\u00f6hler S, Bauer S, Seelow D, Horn D, Mundlos S (2008) The Human Phenotype Ontology: a tool for annotating and analyzing human hereditary disease. Am J Hum Genet 83(5):610\u2013615. doi:  10.1016/j.ajhg.2008.09.017          50.    K\u00f6hler S, Doelken S, Mungall C, Bauer S, Firth H, Bailleul-Forestier I, Black G, Brown D, Brudno M, Campbell J, FitzPatrick D, Eppig J, Jackson A, Freson K, Girdea M, Helbig I, Hurst J, J\u00e4hn J, Jackson L, Kelly A, Ledbetter D, Mansour S, Martin C, Moss C, Mumford A, Ouwehand W, Park S-M, Riggs E, Scott R, Sisodiya S, Van Vooren S, Wapner R, Wilkie A, Wright C, Vulto-van Silfhout A, de Leeuw N, de Vries B, Washingthon N, Smith C, Wester\ufb01 eld M, Scho\ufb01 eld P, Ruef B, Gkoutos G, Haendel M, Smedley D, Lewis S, Robinson P (2014) The Human Phenotype Ontology project: linking molecular biology and disease through phenotype data. Nucleic Acids Res 42(D1):D966\u2013D974. doi:  10.1093/nar/gkt1026          51.    Osborne J, Flatow J, Holko M, Lin S, Kibbe W, Zhu L, Danila M, Feng G, Chisholm R (2009) Annotating the human genome with Disease Ontology. BMC Genomics 10(Suppl 1):S6. doi:  10.1186/1471-2164-10-s1-s6          52.    Schriml LM, Arze C, Nadendla S, Chang Y-WW, Mazaitis M, Felix V, Feng G, Kibbe WA (2012) Disease Ontology: a backbone for disease semantic integration. Nucleic Acids Res 40(Database issue):D940\u2013D946. doi:  10.1093/nar/gkr972          53.    Maglott D, Ostell J, Pruitt K, Tatusova T (2005) Entrez Gene: gene-centered informa-tion at NCBI. Nucleic Acids Res 33(Suppl 1):D54\u2013D58. doi:  10.1093/nar/gki031    ,      54.    Hubbard T, Barker D, Birney E, Cameron G, Chen Y, Clark L, Cox T, Cuff J, Curwen V, Down T, Durbin R, Eyras E, Gilbert J, Hammond M, Huminiecki L, Kasprzyk A, Lehvaslaiho H, Lijnzaad P, Melsopp C, Mongin E, Pettett R, Pocock M, Potter S, Rust A, Schmidt E, Searle S, Slater G, Smith J, Spooner W, Stabenau A, Stalker J, Stupka E, Ureta- Vidal A, Vastrik I, Clamp M (2002) The Ensembl genome database project. Nucleic Acids Res 30(1):38\u201341. doi:  10.1093/nar/30.1.38          55.    Johnson N, Fletcher O, Palles C, Rudd M, Webb E, Sellick G, dos Santos SI, McCormack V, Gibson L, Fraser A, Leonard A, Gilham C, Tavtigian S, Ashworth A, Houlston R, Peto J (2007) Counting potentially functional vari-ants in BRCA1, BRCA2 and ATM predicts breast cancer susceptibility. Hum Mol Genet 16(9):1051\u20131057. doi:  10.1093/hmg/ddm050          56.    Apweiler R, Bairoch A, Wu C, Barker W, Boeckmann B, Ferro S, Gasteiger E, Huang H, Lopez R, Magrane M, Martin M, Natale D, O\u2019Donovan C, Redaschi N, Yeh LS (2004) UniProt: the Universal Protein knowledge-base. Nucleic Acids Res 32(Suppl 1):D115\u2013D119. doi:  10.1093/nar/gkh131        Integrating Bio-ontologies and Controlled Clinical Terminologies: From Base Pairs\u2026\f   Part VII    Conclusion        \f291    Chapter 21    The Vision and Challenges of the Gene Ontology                          Suzanna     E.     Lewis        Abstract    The overarching goal of the Gene Ontology (GO) Consortium is to provide researchers in biology and biomedicine with all current functional information concerning genes and the cellular context under which these occur. When the GO was started in the 1990s surprisingly little attention had been given to how functional information about genes was to be uniformly captured, structured in a computable form, and made accessible to biologists. Because knowledge of gene, protein, ncRNA, and molecular complex roles is continuously accumulating and changing, the GO needed to be a dynamic resource, accurately tracking ongoing research results over time. Here I describe the progress that has been made over the years towards this goal, and the work that still remains to be done, to make of the Gene Ontology (GO) Consortium realize its goal of offering the most comprehensive and up-to-date resource for information on gene function.    Key words     Gene Ontology  ,   Gene function  ,   Genomics  ,   Biological modeling  1      Motivation  From their outset in the early 1990s it was obvious that biological databases demanded a methodical way of describing the function of genes. For one thing, a model system\u2019s  raison d \u2019 etre  was to gain insight into human health and, in the days before entire genomes and proteomes were available, the relevant connections to human biology were largely based on textual descriptions of biological role. In conjunction, as genomes such as yeast were being com-pleted, new laboratory techniques were being developed for sur-veying the genome, such as microarray expression panels, and these data cried out for systematic description of the voluminous results. Finally, lest we forget, this period also saw the advent of the \u201cWorld Wide Web.\u201d The early pioneers in biological databases were quick to take advantage of the latest technologies for data dissemination (much easier than shipping a copy of GenBank on tape or disk drive as was the norm), but exchanging data in a rational and ef\ufb01 -cient manner required concomitant syntactic and semantic Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1_21, \u00a9 The Author(s) 2017\f292agreement. Those of us building these data resources (Including Amos Bairoch, Jonathan Bard, David Botstein, Michelle Gwinn, Minoru Kanehisa, Stan Letovsky, and Monica Riley) were avidly discussing what might be done. Biologists needed a way of making some sense of the information we were so diligently collecting about genes, both to locate information and to traverse across taxa.  Speci\ufb01 cally one slightly obsessive biologist, Michael Ashburner, wanted to classify all \ufb02 y genes and have the corresponding worm, mouse, human, yeast groups use the same classi\ufb01 cation scheme (see   ftp://ftp.ebi.ac.uk/pub/databases/edgp/misc/ashburner/\ufb02 y_function_tree     for an early example, and   ftp://ftp.geneontol-ogy.org/pub/go/www/gene.ontology.discussion.shtml     for the white paper as it was \ufb01 rst publicly presented in 1998). That way, if he found a \ufb02 y gene involved in a particular process, he could then ask what genes in other taxa are (thought) to be involved in the \u201csame\u201d process, and what insights can be gleaned from its counter-part? We needed a way to describe the attributes of gene products in a rigorous way that would enable biologists to roam the universe of genomes and biology, to explore: temporally and spatially char-acteristic expression patterns; the speci\ufb01 c (often) cellular compart-ment localization where they acted; whether they were constitutive parts of particular cellular components and/or complexes; and their biochemical or physiological functions and activities. These are attributes of genes that are of great interest to all biologists. And in an ideal world all biological databases would agree on how such information can be made discoverable and comparable.  2     Desiderata  (Principles) Circa 1996\u20131997 (Banbury &amp; Les Treilles)  Two seminal workshops were organized in 1996 and 1997 largely devoted to discussing the need for agreement among the genomic resources on how semantic comparability should be achieved. The \ufb01 rst of these was sponsored by the Banbury Center, 1  (organized by M. Ashburner, E. Harlow, P. Karp and J. Witkowski), and the sec-ond on building genome databases sponsored by the Fondation des Treilles 2  (organized by W.M. Gelbart, and M. Ashburner). These meetings set the stage for the Gene Ontology Consortium by de\ufb01 ning our working de\ufb01 nitions and essential principles.  These axiomatic working de\ufb01 nitions, begin with \u201cgene prod-uct\u201d: a physical object, typically associated with a gene or genes indi-rectly through transcription and translation (for proteins), affecting some biological process. Such things as proteins, ncRNAs, protein complexes, and so forth are all typical functional objects. These were the objects to be described. In turn the essential attributes of a gene 1   http://www.cshl.edu/Banbury 2   http://www.les-treilles.com Suzanna E. Lewis\f293product\u2014its function, the process(es) it  participates in, and the cel-lular location at which these occur\u2014were also de\ufb01 ned: Function being a capability that a physical gene product carries as a potential, describing only what a gene product can do, without necessarily specifying where or when this usage actually occurs; Process as a transformation that has a temporal aspect to it, even if virtually instantaneous, accomplished via one or more ordered assemblies of functions; And (originally) cellular component as an anatomical structure within the cell, a location in which a function or process occurs (since expanded to include extracellular space).  Following agreement on these basic de\ufb01 nitions came the ani-mated discussions on the desired (and required) characteristics for actual operations.  3    Essentials for the \u201cOntology\u201d  The name \u201cGene Ontology\u201d was originally a jest, but the joke was on us, as it turns out GO is indeed an ontology\u2014at least in the computational sense, with the primary operational data structure now being OWL. Every attribute mandated at the outset has proven its worth and remains at the core of the GO. Some of these essential criteria are outlined here.    It was rapidly understood that unique identi\ufb01 ers were essential operationally. This allowed the collaborating resources to reference the ontology classes (terms) unambiguously and stably. Furthermore by using a semantically meaningless identi\ufb01 er, as opposed to using the label as the identi\ufb01 er, we were free to change the label at any time, and to display different preferred labels for different com-munities. At the time this was a major difference compared to other frame based systems such as \u201cOntolingua\u201d or even Ontology Web Language (OWL, although OWL did not exist at the time) which used the label (name) as the identi\ufb01 er.     It was also determined that it would be essential for the GO terms to have a graphical relationship to each other, rather than the prevalent norm in biology at the time: a \ufb02 at list of keywords used for tagging. In the early, consciously simplistic, model GO began with there were only two relationship types:  is_a  and  part_of . But it was recognized even then that more relationships would ultimately be required.     The decision to make numerical identi\ufb01 ers the stable GO \u201cobject\u201d had implications for the human readable labels. And, in addition, rather than attempting to convey all pertinent biological informa-tion by encoding it directly into the label, human readable de\ufb01 ni-tions would provide the de\ufb01 nitive de\ufb01 nition. Thus it is the de\ufb01 nition,  not  the label, which de\ufb01 nes an ontology class in GO. If a label 3.1  Unique IDs3.2  Graph Structure3.3  Human Readable De\ufb01 nitions and LabelsThe Vision and Challenges of the Gene Ontology\f294changes it means nothing and there are no serious consequences. If a de\ufb01 nition changes, such that the meaning of the class has changed, then this has obvious consequences for any gene product that was annotated to the original class. Thus the original class is made obsolete, with a reference to the new class as a suggestion, and the new class is given a new identi\ufb01 er.  Another misconception that often needs to be clari\ufb01 ed is that GO has nothing to do with nomenclature. The confusion arises because we are using (and often have to use) exactly the same words to describe both the product and its function. For example, \u201calcohol dehydrogenase\u201d can describe what you can put in an Eppendorf tube (the gene product) or it can describe the function of this protein. There is, however, a formal difference\u2014a \u201cgene product\u201d has (potentially) a many-to-many relationship with a \u201cfunction.\u201d That is to say there are many gene products that have the function \u201calcohol dehydrogenase\u201d (and some of these may indeed be encoded by a gene with the name alcohol dehydroge-nase, but many will not be). Moreover a particular gene product may have both functions \u201calcohol dehydrogenase\u201d and \u201cacetalde-hyde dismutase\u201d and possibly more. Since GO\u2019s remit is describing functions and processes, nomenclature is irrelevant to its purpose.  Finally, the labels themselves are intended to be familiar to researchers using GO. Over the years some unfortunate \u201cstandard-ization\u201d efforts, have rendered terms non-user-friendly (for exam-ple what researchers call a transcription factor is \u201csequence-speci\ufb01 c DNA binding RNA polymerase II transcription factor activity\u201d in the GO). The consequence is that both annotation and searching are made more error-prone and dif\ufb01 cult because the familiar term, that a biologist would instinctively use, cannot be quickly located. The GO Consortium continues working to rectify these labeling issues, both by an effort to use familiar labels and through the judi-cious use of synonyms.     Multiple synonyms of different \ufb02 avors are essential for allowing GO to deal with: colloquialisms, community preferences, abbrevia-tions, legacy names, the multiple ways of referring to chemical ele-ments, capitalization, and all the possible variations that occur in natural language. Because our top priority was communication of biological knowledge, we needed GO to accommodate every indi-vidual researcher by speaking in their particular idiom.     In 2000 we began to maintain a history of the ontology and of each term. Comprehensive snapshots of both the ontology and the annotations are taken on a monthly basis enabling progress to be quanti\ufb01 ed and retrospective analyses to be carried out. Additionally, from the outset, date stamping and authorship for each class were captured. Originally, and currently, the form is 3.4  Synonyms3.5  Versioning the Ontology and Classes: The History of ChangesSuzanna E. Lewis\f295rather rudimentary: (Modi\ufb01 ed|Added|Deleted|Split from  |Merged with ) by \ufb01 rstnameorinitial,surname yymmdd. This early decision to support \u201cmicro-attribution\u201d remains valid, but the form is gradually transitioning into a more modern approach through the development of online editing and annotation tools with authen-tication and authorization.     From the outset members of the community were asking for sub-sets of the GO containing only the major categories and subcatego-ries, or a branch of relevance to their particular application. These \u201cSlims\u201d enable the users to broadly group their gene products using a very limited set of broad categories, or con\ufb01 ne themselves to spe-ci\ufb01 c branches dealing with a particular biological topic, or constrain the GO by a taxonomic criterion. \u201cSlims\u201d are handled internally by tagging the different GO classes as members of various categories. These GO subsets are used in multiple different ways: for high-level classi\ufb01 cation; for de\ufb01 ning sub-branches at the \ufb01 nest granularity; for clade speci\ufb01 c versions; and other utility subsets.   4    Applying the GO    We determined that collaborating databases would be responsible for attributing any functional assignment to a source (e.g., a litera-ture reference or computational analysis) and for indicating the type evidence used by this attribution source. The initial set of \u201cevidence codes\u201d was primed from this short list: \u25cf   Inferred from genetic interaction with     \u25cf  Inferred from protein interaction with     \u25cf  Inferred from sequence similarity with     \u25cf  Inferred from direct assay     This enabled statements such as \u201cPublication NNN\u201d asserted that \u201cgene A\u201d has \u201cfunction XYZ\u201d by inference from a \u201cdirect assay.\u201d Since this time evidence codes have developed into an autonomous ontology [ 1 ] and discussed in Chap.   18     [ 2 ] but the principle remains the same: if you are asserting that something is true then you must provide the evidence\u2014its general category and the published reference\u2014for making this assertion.     GO did not arise from nothing. Like every technology it used what came before it. Furthermore, given that we wanted to give attribu-tion to our predecessors and provide a migration path for anyone with legacy data that had utilized these prior vocabularies. This practice came out of our own need as well. As the ontology was being built up we wanted to track some of our original sources. 3.6  Slims4.1  Evidence and Attribution4.2  Database Cross-ReferenceThe Vision and Challenges of the Gene Ontology\f296Thus references to Monica Riley\u2019s functional categories for  E. coli  [ 3 ], Enzyme Commission numbers (EC\u2014  http://www.chem.qmul.ac.uk/iubmb/enzyme/    ) and SwissProt keywords (SP\u2014  http://www.uniprot.org/docs/keywlist    ) helped to bootstrap GO at the outset, and additional cross-references, such as Medical Subject Headings (MESH\u2014  https://www.nlm.nih.gov/mesh/    ) [ 4 ], were added shortly thereafter to aid in interoperability.     Another expressivity requirement was to allow assertions stating that a given gene product does not hold for a given GO class. Experimentalists often test for an expected function, with negative results. Rather than lose this information we needed to provide a solution that could convey such negative results. Hence we pro-vide for quali\ufb01 ers on the GO annotations.     Like most of the challenges facing the GO we recognized the need for identifying classes that are taxon speci\ufb01 c in the very early years (1996 or earlier). The solution \ufb01 nally fell into place when the taxon-constraint resource and corresponding web service were implemented (e.g.,   http://owlservices.berkeleybop.org/isClassApplicableForTaxon?format=txt&amp;idstyle=obo&amp;id=GO:0005737&amp;taxid=NCBITaxon:131567    ) [ 5 ].     Following the precept of test early and often, the \ufb01 rst annotation effort began at SGD in early 1999. Fly genes were already \u201canno-tated\u201d because these were the seeds that GO grew from. The ques-tion was how well proto-GO, based on the needs of \ufb02 y, would translate to another, very different, organism. An extremely simple tab-delimited annotation format was devised and the dialog began. Similarly the \ufb01 rst automated pipeline \u201clove-at-\ufb01 rst-sight\u201d was developed by Mark Yandell in late 1999 [ 6 ,  7 ] to describe the genes of the newly completed \ufb02 y and human genomes. It was straightforward inference based on BLAST alignments, but it pro-vided a reasonable overview of the landscape. The response to these \ufb01 rst efforts was overwhelmingly positive and adoption of GO very quickly accelerated.  The GO project remains focused on providing an integrated data resource for functional information, both experimental (Chaps.   4     and   6     [ 8 ,  9 ]) and predicted (Chap.   5     [ 10 ]), for all known proteins, noncoding RNA sequences, and cellular components. In other words, carrying out comprehensive functional annotation is what drives the project, not the ontology itself. The ontology provides the biological model that serves as the conceptual scaffolding for the bio-logical data. The Gene Ontology database contains currently over 5.2 million function annotations for almost 900,000 gene products (mostly proteins but also some noncoding RNAs). About 660,000 of these annotations are based on experimental results reported in the 4.3  Negation4.4  Taxon Constraints, aka Taxonomic Scope4.5  AnnotationSuzanna E. Lewis\f297published literature, and the remainder are predictions derived from a variety of different methods. All of which are freely available for the community to use. That said, there is still considerable room for improvement. There was, and remains, a signi\ufb01 cant amount of accu-mulated knowledge to be captured. In particular for human, the annotation task is still more about capturing old data than capturing new data because an equivalent to a Model Organism Database does not exist. Until the day the GO catches up it will need to capture existing data in parallel with capturing more recent data to achieve the coverage it aims for.   5    Where We Stand Today  Based on the wide adoption by the community, we can claim that the project met a real need. The GO is a useful alternative to simple nomenclature, as nomenclature fails to fully convey the biology and is too limited to describe protein roles fully. There is still a long way ahead: several of the key elements that we recognized as essen-tial in the nineties are still works in progress today.    In 1999 we decided at the \ufb01 rst of\ufb01 cial GO meeting against imple-menting relationships across the three branches of the GO until a later time. Needless to say this drastically over-simpli\ufb01 ed the bio-logical model, a simpli\ufb01 cation we were fully cognizant of but one that allowed us to prioritize our work. In this simplistic model with which GO began there were only two relationship types:  is_a  and  part_of.  And even here the meaning of  part_of  was con\ufb02 ated, since  part_of  in the cellular component branch of GO meant that that it was a sub-component while  part_of  in BP meant a step or sub- process. Since that time we continue to work on enriching the Relations Ontology and applying it appropriately (  https://github.com/oborel/obo-relations    ). Currently there are eight relation-ships in use. Most signi\ufb01 cantly the three branches of the GO the ontologies are now being linked.     We did not and do not want multiple \u201crival\u201d ontologies for one domain. The initial necessity for embedding terms within other terms led to the creation of numerous implicit ontologies embed-ded within the GO (chemicals, anatomical parts, tissues, and cell types). In the early years, while we recognized that this might be dealt with by incorporating the unique identi\ufb01 er that refers to the full de\ufb01 nition elsewhere, in practice this could not be reliably accomplished at that time and it is taking some time to remedy.  Work to rectify the situation began shortly after the turn of the century [ 11 ] and has given rise to a small set of core ontologies, 5.1  Multiple Relationship Types and Relations Between BP, MF, and CC5.2  OrthogonalityThe Vision and Challenges of the Gene Ontology\f298which have been teased out of the GO and replaced by including the unique identi\ufb01 er for the new class as part of the logical de\ufb01 ni-tion of the GO class. The \ufb01 rst exercise was replacing all implicit references to chemicals in the GO with explicit references to ChEBI classes [ 12 ]. Similarly the Cell Type ontology was derived from the GO [ 13 \u2013 15 ] and, as an autonomous ontology, has proven its own value for other applications. Expression analyses and RNASeq experiments often draw their samples from particular cell types and projects such as ENCODE [ 16 ] and FANTOM [ 17 ] are using the cell type ontology to indicate the source cell type for their data. In addition, there are coordinated efforts connecting the cell line ontology, used in cancer studies, to the cell type ontology to indi-cate the original cell type [ 18 ]. There is immense bene\ufb01 t to con-structing any ontology from its most element components because it provides a connective route across the widest possible network of projects. For example, RNA expression data from a cancer study that used a particular cell line can be automatically connected to an ENCODE RNA expression data from a normal cell type.  As regards anatomy, Jonathan Bard initially raised the question of how we might consider a common language for anatomy. It was clear that we needed a methodology for anatomical interoperability and querying data across our various organisms, not just for gene function, but ultimately for phenotypes as well. As with chemicals and cell types, a species-neutral anatomical ontology was extracted from GO, but also incorporated existing anatomical ontologies (e.g., mouse, zebra\ufb01 sh, fossils) thereby creating bridges between them [ 19 \u2013 21 ]. Beyond its use by GO Uberon is connecting pheno-type data, for example, from human (it is used for the logical de\ufb01 ni-tions of the Human Phenotype Ontology) to mouse (likewise there are logical de\ufb01 nitions underlying the Mouse Phenotype ontology) with direct applicability to human health research [ 22 ].  The challenge of comparability and interoperability can largely be overcome by community adoption of a small set of standard elemental core ontologies, from which special purpose ontologies, which meet the unique needs of a given project, can be constructed. It is hard to emphasize this enough. While the community seems to be blooming with a cacophony of idiosyncratic \u201contologies\u201d the GO is actively working to reduce the proliferation by deconstruct-ing its terms into the elemental core set of conceptual classes needed to de\ufb01 ne its complex terms. This approach is producing enormous dividends in terms of interoperability and comparability across widely divergent data sets.     The context in which a function is carried out was recognized from the outset as crucial. For example, the role of glucagon-mediated signal transduction in liver concerns gluconeogenesis, glycogenol-ysis and plasma glucose homeostasis, whereas the role of this pro-cess in adipose tissue is lipolysis. At the level of gene products, the role of cytochrome C is in oxidative phosphorylation and energy 5.3  Contextual AnnotationSuzanna E. Lewis\f299supply (when it is in the mitochondrion), and apoptosis (when it is in the cytoplasm). This has proven operationally (that is: how easy it is for someone to annotate) to be one of our biggest challenges ( see  Chap.   17     [ 23 ] on annotation extensions). While this has given curators a great deal more expressivity it still can be improved upon, and developing new annotation strategies and methods is where GO is actively working.   6    What Lies Ahead  The fundamental motivation driving the GO has remained unchanged: we are attempting to build a realistic model of biology to enable research, based on the collective evidence gathered by the research community. As originally envisioned we needed a way to describe the attributes of gene products in a rigorous way that would enable biologists to explore the universe of genomes and biology. As described above we were cognizant of them all initially and incrementally are addressing them and taking advantage of technological advances as we go.  That said, the GO is predicated upon a reliable foundation of \u201cannotation.\u201d To gather accumulated knowledge as well as keep up with new research requires us to continue to seek new, more ef\ufb01 cient approaches for biologists to provide their data. This is one of our current big challenges. One approach is collaborative data exchange with other annotation initiatives. For example, our  collaborations with Reactome (  http://www.reactome.org/    ) and IntAct (  http://www.ebi.ac.uk/intact/    ) allow data from these resources to be incorporated into GO. Another key strat-egy is community annotation, such as described in Chap.   7     [ 24 ], which has provided GO with additional annotations. Our future plans are to provide online community annotation tools, which will also be used by GO Consortium curators\u2014tools that will also support re\ufb01 nement of the GO itself in addition to providing annotations.    Providing a resource that captures functional data for every extant protein is, to say the least, a formidable challenge. One obvious reason is that most sequences are not, nor ever will be, experimen-tally characterized (and not just because of volume, but also because some are experimentally intractable). Therefore most annotations must necessarily be based on predictions. Furthermore, for inferences to be as accurate as possible they should be predi-cated on an explicit evolutionary framework. For the past several years a small group of GO curators have been using an annotation tool, Phylogenetic Annotation and INference Tool (PAINT) [ 25 ] to infer annotations among members of a protein family. PAINT allows curators to make precise assertions as to when functions were gained and lost during evolution and record the evidence 6.1  Phylogenetic AnnotationThe Vision and Challenges of the Gene Ontology\f300(i.e., the experimentally supported GO annotations from the leaves of the tree and their phylogenetic relationship to an ancestral pro-tein) for those assertions. PAINT is as yet a stand-alone desktop application, but work is underway to incorporate it into a suite of integrated, online annotation tools for GO curators and commu-nity contributors. Among the other tools in current development is one based on biological modules.     Biological systems are modular at many levels. For example, within a single domain a catalytic site may be coupled to an (allosteric) bind-ing site that regulates the catalytic activity. Or, within a single pro-tein different domains may form a module, e.g., the ligand binding domain and protein kinase domain of a transmembrane protein kinase receptor. And further up the size are functional modules com-posed from subunits within a macromolecular complex (e.g., the ribosome). And, at an even higher level, molecular interactions can de\ufb01 ne a pathway that can be used or reused in multiple different processes (e.g., the ubiquitin-dependent proteolysis pathway or JAK-STAT pathway). The goal of this modular approach is to de\ufb01 ne each GO term through a combination of terms, and enable exten-sible representation of biological modularity: how elemental molec-ular interactions are combined in different ways to produce compound molecular functions, how molecular functions are com-bined to produce processes, and how processes are combined to produce larger processes. A \ufb01 rst release of this curation tool (dubbed \u201cNoctua\u201d 3 ) is now being evaluated by GO curators. One notable feature of this new tool is that it combines the tasks of annotation  and  ontology construction. Historically the arti\ufb01 cial disconnect between these two inseparable tasks created serious bottlenecks, as annotators were forced to wait for a separate group to create or modify requisite terms. With Noctua the curators will more directly describing biology, with known relationships in the ontology associ-ated with speci\ufb01 c instances that support this model. 7  SummaryThe goal of the Gene Ontology (GO) project is to provide a uniform way to describe the functions of gene products from organisms across all kingdoms of life and thereby enable analysis of genomic data. It is an ongoing enterprise as our understanding of biology grows and is re\ufb01 ned. It is a computational model of biological reality that we ulti-mately hope every researcher will happily contribute to and regard as the optimum means of sharing the knowledge they have gained from their own research with the wider community.      3   Little owl ( Athene noctua ) is a bird that was sacred to the goddess  Athena , the Greek goddess of wisdom. 6.2  Modular AnnotationSuzanna E. Lewis\f301  Funding Open Access charges were funded by the University College London Library, the Swiss Institute of Bioinformatics, the Agassiz Foundation, and the Foundation for the University of Lausanne.Open Access This chapter is distributed under the terms of the Creative Commons Attribution 4.0 International License (  http://creativecommons.org/licenses/by/4.0/    ), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license and any changes made are indicated.  The images or other third party material in this chapter are included in the work\u2019s Creative Commons license, unless indicated otherwise in the credit line; if such material is not included in the work\u2019s Creative Commons license and the respective action is not per-mitted by statutory regulation, users will need to obtain permission from the license holder to duplicate, adapt or reproduce the material.     References     1.   Chibucos MC, Mungall CJ, Balakrishnan R, Christie KR, Huntley RP, White O, Blake JA, Lewis SE, Giglio M (2014) Standardized descrip-tion of scienti\ufb01 c evidence using the Evidence Ontology (ECO). Database (Oxford):pii:bau075. doi:   10.1093/database/bau075    . Print 2014. PubMed PMID: 25052702; PubMed Central PMCID: PMC4105709      2.   Chibucos MC, Siegele DA, Hu JC, Giglio M (2016) The evidence and conclusion ontology (ECO): supporting GO annotations. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 18      3.    Riley M (1993) Functions of the gene products of Escherichia coli. Microbiol Rev 57(4):862\u2013952, PubMed PMID: 7508076, PubMed Central PMCID:PMC372942, Review      4.    Lomax J, McCray AT (2004) Mapping the gene ontology into the uni\ufb01 ed medical lan-guage system. Comp Funct Genomics 5(4):354\u201361. doi:  10.1002/cfg.407    , PubMed PMID: 18629164, PubMed Central PMCID: PMC2447454      5.    Deegan n\u00e9e Clark JI, Dimmer EC, Mungall CJ (2010) Formalization of taxon-based constraints to detect inconsistencies in annotation and ontology development. BMC Bioinformatics 11:530. doi:  10.1186/1471- 2105- 11-530    , PubMed PMID:20973947, PubMed Central PMCID: PMC3098089      6.    Rubin GM, Yandell MD, Wortman JR, Gabor Miklos GL, Nelson CR, Hariharan IK, Fortini ME, Li PW, Apweiler R, Fleischmann W, Cherry JM, Henikoff S, Skupski MP, Misra S, Ashburner M, Birney E, Boguski MS, Brody T, Brokstein P, Celniker SE, Chervitz SA, Coates D, Cravchik A, Gabrielian A, Galle RF, Gelbart WM, George RA, Goldstein LS, Gong F, Guan P, Harris NL, Hay BA, Hoskins RA, Li J, Li Z, Hynes RO, Jones SJ, Kuehl PM, Lemaitre B, Littleton JT, Morrison DK, Mungall C, O'Farrell PH, Pickeral OK, Shue C, Vosshall LB, Zhang J, Zhao Q, Zheng XH, Lewis S (2000) Comparative genomics of the eukaryotes. Science 287(5461):2204\u201315, PubMed PMID: 10731134; PubMed Central PMCID: PMC2754258      7.    Venter JC, Adams MD, Myers EW et al (2001) The sequence of the human genome. Science 291(5507):1304\u201351, Erratum in: Science 2001 Jun 5;292(5523):1838      8.   Poux S, Gaudet P (2016) Best practices in manual annotation with the gene ontology. In: Dessimoz C, \u0160kunca N (eds) The gene ontol-ogy handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 4      9.   Ruch P (2016) Text mining to support gene ontology curation and vice versa. In: Dessimoz C, \u0160kunca N (eds) The gene ontology hand-book. Methods in molecular biology, vol 1446. Humana Press. Chapter 6      10.   Cozzetto D, Jones DT (2016) Computational methods for annotation transfers from sequence. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 5      11.    Mungall CJ, Bada M, Berardini TZ, Deegan J, Ireland A, Harris MA, Hill DP, Lomax J (2011) Cross-product extensions of the Gene Ontology. J Biomed Inform 44(1):80\u20136. doi:  10.1016/j.jbi.2010.02.002    , PubMed PMID:20152934, The Vision and Challenges of the Gene Ontology\f302PubMed Central PMCID:PMC2910209, Epub 2010 Feb 10      12.    Hill DP, Adams N, Bada M, Batchelor C, Berardini TZ, Dietze H, Drabkin HJ, Ennis M, Foulger RE, Harris MA, Hastings J, Kale NS, de Matos P, Mungall CJ, Owen G, Roncaglia P, Steinbeck C, Turner S, Lomax J (2013) Dovetailing biology and chemistry: integrating the Gene Ontology with the ChEBI chemical ontology. BMC Genomics 14:513. doi:  10.1186/1471-2164-14-513    , PubMed PMID:23895341, PubMed Central PMCID: PMC3733925      13.    Masci AM, Arighi CN, Diehl AD, Lieberman AE, Mungall C, Scheuermann RH, Smith B, Cowell LG (2009) An improved ontological representation of dendritic cells as a paradigm for all cell types. BMC Bioinformatics 10:70. doi:  10.1186/1471-2105-10-70    , PubMed PMID: 19243617, PubMed Central PMCID: PMC2662812     14.    Diehl AD, Augustine AD, Blake JA, Cowell LG, Gold ES, Gondr\u00e9-Lewis TA, Masci AM, Meehan TF, Morel PA, Nijnik A, Peters B, Pulendran B, Scheuermann RH, Yao QA, Zand MS, Mungall CJ (2011) Hematopoietic cell types: prototype for a revised cell ontology. J Biomed Inform 44(1):75\u20139. doi:  10.1016/j.jbi.2010.01.006    , PubMed PMID: 20123131, PubMed Central PMCID: PMC2892030, Epub 2010 Feb 1      15.    Meehan TF, Masci AM, Abdulla A, Cowell LG, Blake JA, Mungall CJ, Diehl AD (2011) Logical development of the cell ontology. BMC Bioinformatics 12:6. doi:  10.1186/1471- 2105- 12-6    , PubMed PMID: 21208450, PubMed Central PMCID:PMC3024222      16.    ENCODE Project Consortium (2012) An integrated encyclopedia of DNA elements in the human genome. Nature 489(7414):57\u201374. doi:  10.1038/nature11247    , PubMed PMID: 22955616, PubMed Central PMCID: PMC3439153      17.    FANTOM Consortium and the RIKEN PMI and CLST (DGT) et al (2014) A promoter- level mammalian expression atlas. Nature 507(7493):462\u201370. doi:  10.1038/nature13182    , PubMed PMID: 24670764, PubMed Central PMCID: PMC4529748      18.    Sarntivijai S, Lin Y, Xiang Z, Meehan TF, Diehl AD, Vempati UD, Sch\u00fcrer SC, Pang C, Malone J, Parkinson H, Liu Y, Takatsuki T, Saijo K, Masuya H, Nakamura Y, Brush MH, Haendel MA, Zheng J, Stoeckert CJ, Peters B, Mungall CJ, Carey TE, States DJ, Athey BD, He Y (2014) CLO: the cell line ontology. J Biomed Semantics 5:37. doi:  10.1186/2041-1480- 5- 37    , PubMed PMID:25852852, PubMed Central PMCID: PMC4387853, eCollection 2014      19.    Mungall CJ, Torniai C, Gkoutos GV, Lewis SE, Haendel MA (2012) Uberon, an integrative multi-species anatomy ontology. Genome Biol 13(1):R5. doi:  10.1186/gb-2012-13- 1-r5    , PubMed PMID: 22293552, PubMed Central PMCID:PMC3334586     20.    Dahdul WM, Balhoff JP, Blackburn DC, Diehl AD, Haendel MA, Hall BK, Lapp H, Lundberg JG, Mungall CJ, Ringwald M, Segerdell E, Van Slyke CE, Vickaryous MK, Wester\ufb01 eld M, Mabee PM (2012) A uni\ufb01 ed anatomy ontol-ogy of the vertebrate skeletal system. PLoS One 7(12):e51070. doi:  10.1371/journal.pone.0051070    , PubMed PMID: 23251424, PubMed Central PMCID: PMC3519498, Epub 2012 Dec 10      21.    Haendel MA, Balhoff JP, Bastian FB, Blackburn DC, Blake JA, Bradford Y, Comte A, Dahdul WM, Dececchi TA, Druzinsky RE, Hayamizu TF, Ibrahim N, Lewis SE, Mabee PM, Niknejad A, Robinson-Rechavi M, Sereno PC, Mungall CJ (2014) Uni\ufb01 cation of multi-species verte-brate anatomy ontologies for comparative biology in Uberon. J Biomed Semantics 5:21. doi:  10.1186/2041-1480-5-21    , PubMed PMID: 25009735, PubMed Central PMCID: PMC4089931, eCollection 2014      22.    K\u00f6hler S, Doelken SC, Mungall CJ, Bauer S, Firth HV, Bailleul-Forestier I, Black GC, Brown DL, Brudno M, Campbell J, FitzPatrick DR, Eppig JT, Jackson AP, Freson K, Girdea M, Helbig I, Hurst JA, J\u00e4hn J, Jackson LG, Kelly AM, Ledbetter DH, Mansour S, Martin CL, Moss C, Mumford A, Ouwehand WH, Park SM, Riggs ER, Scott RH, Sisodiya S, Van Vooren S, Wapner RJ, Wilkie AO, Wright CF, Vulto-van Silfhout AT, de Leeuw N, de Vries BB, Washingthon NL, Smith CL, Wester\ufb01 eld M, Scho\ufb01 eld P, Ruef BJ, Gkoutos GV, Haendel M, Smedley D, Lewis SE, Robinson PN (2014) The Human Phenotype Ontology project: linking molecular biology and disease through phenotype data. Nucleic Acids Res 42(Database issue):D966\u201374. doi:  10.1093/nar/gkt1026    , Epub 2013 Nov 11. PubMed PMID: 24217912; PubMed Central PMCID: PMC3965098      23.   Huntley RP, Lovering RC (2016) Annotation extensions. In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 17      24.   Lovering RC (2016) How does the scienti\ufb01 c community contribute to gene ontology? In: Dessimoz C, \u0160kunca N (eds) The gene ontology handbook. Methods in molecular biology, vol 1446. Humana Press. Chapter 7      25.   Gaudet P, Livstone MS, Lewis SE, Thomas PD (2011) Phylogenetic-based propagation of func-tional annotations within the Gene Ontology consortium. Brief Bioinform. 12(5):449-462. doi:  10.1093/bib/bbr042    . Epub 2011 Aug 27. PubMed PMID: 21873635; PubMed Central PMCID: PMC3178059    Suzanna E. Lewis\f303  A   AmiGO  ....................................9, 26, 34, 149\u2013159, 197, 210, 240, 241, 253, 255     Annotation extension  .............30\u201331, 48, 150, 196, 197, 202, 233\u2013242, 272, 299     Application programming interface (API)  ...............149\u2013159      B   Bayesian network  ..............................................141\u2013143, 184     Benjamini\u2013Hochberg approach  ........................................179     Bias  .......................34, 115, 139, 166, 190, 191, 199\u2013203, 239     BioCreative  ..................................70, 71, 74, 77\u201379, 103, 105     Biocurator  .............................................................50, 70, 246   curator  ...........................29, 32, 33, 44, 45, 76, 77, 79, 87, 90, 98, 99, 101, 103, 106, 115, 156, 191, 236, 237, 239, 249, 267     Biological process ontology (BPO)  ...112, 114, 216, 251, 252     BioPython  ........................................................................225     Bonferroni correction  .......................................178, 180, 227      C   CAFA   . See  Critical assessment of functional annotation (CAFA)    CATH  .........................................60, 116, 124, 268\u2013269, 271     Causal role (CR)  ...........................................................15\u201318     Cellular localization ontology (CC, CCO)  ............26, 33, 43, 222, 266, 297     Chemical entities of biological interest (ChEBI)  ............4\u20136, 9, 11, 114, 154, 155, 170, 235, 298     Child term  ..........................................26, 100, 137, 217, 222, 234, 241, 247, 249   Clinical terminology  .................................................278, 280     Closed world assumption (CWA)  ....................100, 102, 201     Clustering (clusters/clustered)  ........................32, 59, 60, 116, 119, 124, 211, 212, 215\u2013217, 268, 271     COMBREX  .......................................................81, 102\u2013103     Confounder  ......................................................190, 202, 203     Co-occurrence  ......................................................58, 62, 191     Correlation  ..........................................61, 123, 166, 168, 179     Critical assessment of functional annotation (CAFA)  ..................................103, 114, 134\u2013144     Cross-reference  .........................................264, 279, 295\u2013296     Curator/curation  .......................29, 32, 33, 35, 41, 43\u201352, 56, 60, 69\u201381, 87, 90, 98, 99, 101, 103, 106, 115, 156, 191, 236, 237, 239, 249, 267     Cytoscape  .................................................118, 210, 216, 218      D   Data mining  .....................................................................189     DAVID .............................................................................194     Depletion analysis  ....................................................226\u2013227   enrichment analysis  ............................122, 123, 152, 178, 186, 199, 202, 210, 211, 269     Directed acyclic graph (DAG)  .......5, 123, 136, 154, 208, 209     Disease  ................................11, 48, 70, 73, 89, 161, 276\u2013284      E   EC-Blast  ..........................................................265\u2013267, 270     Enrichment analysis  .........................122, 123, 152, 178, 186, 199, 202, 210, 211, 227, 269     Enzyme  ......................................................6, 47, 48, 57, 102, 111\u2013128, 196, 198, 236, 239, 264\u2013266, 270     Enzyme Commission number (EC number)  ..........112, 158, 198, 296     E-value  ..........................................57, 58, 118, 120\u2013122, 125     Evidence code  .............................30\u201335, 75, 98, 99, 101, 105, 115, 123, 126, 137, 156, 157, 166, 170, 191, 193, 197\u2013200, 202, 226, 248\u2013250, 282, 295     Evidence ontology (ECO)  ................................................157      F   False discovery rate (FDR)  .......................................179, 227     False-negative  ...........................................180, 184, 185, 203     False-positive  .....................................177, 179, 181, 184, 203     Family-wise error rate  ...............................................178, 179     FANTOM  ........................................................................298     FFPred  .........................................................................61, 62     Fisher\u2019s exact test  ..............................176\u2013177, 180, 181, 183, 184, 187, 215, 227     Frequency  ...........................74, 139, 164, 169, 191, 198, 199, 217, 228, 267, 282     Full-text  ............................................................72, 75, 77\u201379                         INDEX Christophe Dessimoz and Nives \u0160kunca (eds.), The Gene Ontology Handbook, Methods in Molecular Biology, vol. 1446,DOI 10.1007/978-1-4939-3743-1, \u00a9 The Author(s) 2017\f   Functional similarity  ...........................59, 162, 165, 167, 170, 171, 200, 201, 217, 266, 267   semantic similarity  ......................123, 161\u2013171, 209\u2013211, 217, 218, 227, 266, 267, 270, 272     Function prediction, function propagation  ..................32, 33, 56, 57, 59, 60, 62, 97, 100\u2013102, 105, 106, 114, 124, 133\u2013144, 191      G   Gene Association File (GAF)  .......................29\u201331, 34, 156, 157, 197, 225, 250, 251     Gene expression  .................16, 55, 57, 62, 134, 175, 208, 211     Gene Ontology Consortium (GOC)  ................85, 136, 149, 187, 194, 221, 292     Gene set enrichment analysis (GSEA)  .............................186     Ggplot2  ............................................................................218     GOATOOLS  ...................................................222, 223, 226     GOCat  .............................................................70, 75\u201379, 81     GOCat4FT  ..................................................................78, 79     Gold standard  ............43\u201344, 76\u201377, 100, 103\u2013104, 137, 167     GOminer  ..........................................................................215     GOrilla  .....................................................................210\u2013214     GO Slims  .........................................................................156     GOSummaries  .........................................................211, 217     GOtcha  ..............................................................................58     Guilt-by-association  ...........................................................62      H   Hidden Markov model (HMM)  ....................57, 60, 61, 117, 119\u2013121, 124, 125     Human Phenotype Ontology (HPO)  .......................48, 269, 281\u2013284, 298     Hypergeometric distribution  ....................................176, 187      I   Information content (IC)  .......................33, 61, 99, 136, 138, 141\u2013143, 164\u2013166, 168, 170\u2013171, 198, 216\u2013217, 227, 228, 266     IntAct  .......................................................235, 269, 271, 299      K   KEGG  ..............5, 57, 158, 175, 208, 210, 263, 265, 269, 270     k-Nearest Neighbour (k-NN)  ......................................74\u201376     Kolmogorov-Smirnov test (KS)  ........................................186      M   MACiE  ............................................................263, 265, 270     Medical ontology  ................................................................77     MetaCyc  ...................................................................263, 269     Microarray  .........................156, 176, 184, 212, 216, 233, 291     Misannotation  ...................................115, 117\u2013119, 126, 127     Molecular function ontology (MFO)  ...............26, 27, 33, 43, 112\u2013114, 116, 144, 193, 216, 222, 270, 297     Moonlighting proteins ......................................................126     Most informative common ancestor (MICA)  ..........164\u2013165     Multi-domain protein  ........................................................59     Multiple test correction  ............................................178\u2013180      N   Namespace ....................................................................4, 222     Non-transitive (relationship)  ............................................192     Normalization  ......................................................71, 73, 198     NOT annotations  .....................................................104\u2013105      O   OBO-Edit  ............................................................................9     OBO-XML (OBOXML)  ........................................223\u2013225     Obsolete (term, annotation, evidence code)  ..............4, 6, 11, 27, 32, 52, 294     OLSVis  ....................................................................152, 210     OMA ..........................................................................59, 101     OntoBee  .......................................................................9, 152     Ontologizer  ..............................................................187, 211     Open Biomedical Ontologies (OBO)  .................7, 9\u201311, 31, 114, 154, 155, 157, 169, 222\u2013225, 276     Open world assumption (OWA)  ..............101, 190\u2013191, 201     Ortholog conjecture  ............................................................35     Orthologs/orthology ......................32, 35, 101, 191, 198, 200     OWL   . See  Web Ontology Language (OWL)     P   PAINT  ..............................................33, 51, 52, 59, 299, 300     PANTHER  ........................................................59, 116, 152     Parent term  .......................................................114, 182, 191     Pathway analysis  ...............................................................234   enrichment analysis  ............................122, 123, 152, 178, 186, 199, 202, 210, 211, 227, 269     PFam  ....................................61, 98\u2013100, 116, 120, 124, 168, 169, 267, 268, 271     PomBase  .......................................................87\u201390, 235, 240     Precision-recall curve  ........................................................201     Probabilistic (inference, approach, annotation, model)  .....185     Protein2GO  ...........................................................49, 88, 90     Protein-protein interaction  .........................................33, 126      p -value  ..............................................177\u2013184, 186, 211\u2013213     Python  ..............................................................215, 221\u2013229      Q   Qualifier(s)  .................30\u201331, 34, 49, 101, 104, 105, 195, 226     QuickGO  ..............9, 113, 149\u2013159, 197, 210, 223\u2013225, 240      R   RedundancyMiner  ............................................211, 215\u2013217     Relationship types  has_direct_input  .................................................236\u2013239   has_part  ........................................................6\u20138, 26, 154  304   THE GENE ONTOLOGY HANDBOOK Index\f is_a ......................5, 7, 26, 27, 30, 113, 154, 209, 293, 297   negatively_regulates  ..............................................27, 154   part_of  ...........................6, 26, 27, 31, 113, 154, 209, 235, 236, 238, 293, 297   positively_regulates  ...............................................27, 154   regulates  ..................6, 22, 26, 27, 154, 192, 202, 239, 300     Resnik (semantic similarity)  .....................165, 168, 171, 228     REVIGO ..................................................211\u2013215, 217, 218      S   SCOP  ....................................................60, 61, 116, 269, 271     Selected effects (SE)  ...........................................................16     Semantic distance  ..............................142, 143, 162\u2013164, 228     Semantic similarity  ...........................123, 161\u2013171, 209, 210, 217, 218, 227, 228, 266, 267, 270, 272     SIFTER  .............................................................................59     Signaling pathway  ...............5, 21, 47, 86, 196, 208, 223, 239     SimGIC  ...........................................................166, 168, 171     Slims   . See  GO Slims    Software  library  .........................................................155, 202, 221   package  .......................................................................169   tool-package  ...............................................................215     Structured Query Language (SQL)  .................................158     SUPERFAMILY  ...............................60, 115\u2013117, 119, 122, 124\u2013126, 128, 268, 269, 271     Systematized Nomenclature of Medicine-Clinical Terms (SNOMED-CT)  ..................80, 276\u2013278, 280, 283, 284      T   TermGenie  .......................................................................156     TIGRFAMs  .....................................................................116     TopGO  .............................................................................187     Transitive (relationship)  ........................................6, 192, 202     True-negative  ...........................................................101, 192     True-positive  ....................................................119, 121, 192      U   Uber Anatomy Ontology (Uberon)  ..................154, 235, 298     UniProt-GOA  ......................88, 98, 101\u2013107, 135, 138, 201, 212, 217, 225, 253, 254      V   Visualization  ......................................152, 207\u2013218, 223, 224      W   Web-based (tool, service)  ...........................28, 150, 156, 211     Web Ontology Language (OWL)  .............7\u20139, 11, 154\u2013157, 169, 170, 293          THE GENE ONTOLOGY HANDBOOK    305 Index</p>","text":""},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/","title":"Comprehensive Review: Addressing Over-Annotation in GO Curation","text":""},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#executive-summary","title":"Executive Summary","text":"<p>After reviewing all 21 chapter summaries from the Gene Ontology Handbook, a clear pattern emerges: over-annotation is a pervasive and multifaceted challenge that requires systematic, evidence-based approaches to detect and remediate. The chapters collectively provide a comprehensive framework for understanding how over-annotations arise and how they can be systematically addressed through improved curation practices.</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#key-over-annotation-themes-across-all-chapters","title":"Key Over-Annotation Themes Across All Chapters","text":""},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#1-computational-propagation-errors-chapters-5-8-10-14","title":"1. Computational Propagation Errors (Chapters 5, 8, 10, 14)","text":"<p>The Problem: - Chapter 5: Error propagation through iterative transfers compounds computational annotation errors - Chapter 8: IEA (electronic) annotations often lack experimental validation and can perpetuate through similarity chains - Chapter 10: CAFA challenges reveal systematic biases toward overprediction in computational methods - Chapter 14: Simpson's paradox shows how aggregated computational annotations can be misleading</p> <p>Detection Strategies: - Track annotation provenance and identify chains of computational inference - Prioritize experimental evidence over computational predictions - Use temporal analysis to identify annotations that lack subsequent experimental support - Implement evidence quality hierarchies from ECO (Chapter 18)</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#2-evidence-quality-and-documentation-issues-chapters-4-6-7-18","title":"2. Evidence Quality and Documentation Issues (Chapters 4, 6, 7, 18)","text":"<p>The Problem: - Chapter 4: Manual annotation quality varies significantly based on curator experience and time constraints - Chapter 6: Text mining can introduce false positives from ambiguous language interpretation - Chapter 7: Community contributions lack consistent quality control mechanisms - Chapter 18: Inadequate evidence documentation obscures annotation reliability</p> <p>Detection Strategies: - Implement systematic evidence evaluation using ECO hierarchy - Require multiple independent lines of evidence for complex functional annotations - Flag annotations lacking direct experimental support - Use author statement vs. experimental evidence distinction</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#3-ontology-structure-and-relationship-misuse-chapters-1-3-14-17","title":"3. Ontology Structure and Relationship Misuse (Chapters 1, 3, 14, 17)","text":"<p>The Problem: - Chapter 1: Misunderstanding of ontological relationships leads to inappropriate term usage - Chapter 3: True Path Rule violations and incorrect hierarchical assumptions - Chapter 14: Non-transitive relationship misinterpretation (especially \"regulates\" relations) - Chapter 17: Annotation extensions misuse can create overly specific or inappropriate contextual claims</p> <p>Detection Strategies: - Validate True Path Rule compliance systematically - Check for appropriate use of transitive vs. non-transitive relationships - Review annotation extensions for experimental support of contextual claims - Flag annotations that violate ontological logic</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#4-domain-and-specificity-issues-chapters-2-9-19","title":"4. Domain and Specificity Issues (Chapters 2, 9, 19)","text":"<p>The Problem: - Chapter 2: Confusion between molecular function, biological process, and cellular component domains - Chapter 9: Enzyme annotations often over-generalize or over-specify catalytic activities - Chapter 19: Whole protein annotations when domain-specific functions are more appropriate</p> <p>Detection Strategies: - Cross-validate GO annotations with enzyme classification (EC) numbers - Use domain analysis to determine appropriate annotation granularity - Flag proteins annotated with contradictory domain-level functions - Verify molecular function-biological process consistency</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#5-clinical-and-phenotypic-disconnects-chapters-12-20","title":"5. Clinical and Phenotypic Disconnects (Chapters 12, 20)","text":"<p>The Problem: - Chapter 12: Semantic similarity measures can group functionally distinct proteins - Chapter 20: GO annotations lacking clinical phenotype correlation may indicate over-interpretation</p> <p>Detection Strategies: - Cross-validate against Human Phenotype Ontology (HPO) when medically relevant - Check for consistency between molecular functions and known disease associations - Use clinical terminologies to verify biological relevance - Flag annotations inconsistent with therapeutic targeting</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#systematic-over-annotation-detection-framework","title":"Systematic Over-Annotation Detection Framework","text":"<p>Based on the comprehensive chapter review, our AI gene review project should implement the following systematic approach:</p>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#phase-1-evidence-quality-assessment-chapters-4-6-18","title":"Phase 1: Evidence Quality Assessment (Chapters 4, 6, 18)","text":"<ol> <li>Evidence Code Analysis: Prioritize ECO experimental evidence over computational inference</li> <li>Publication Quality: Distinguish high-impact experimental studies from preliminary reports</li> <li>Author Statement Validation: Verify direct experimental support for author claims</li> <li>Temporal Consistency: Track annotation persistence across database releases</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#phase-2-multi-resource-cross-validation-chapters-19-20","title":"Phase 2: Multi-Resource Cross-Validation (Chapters 19, 20)","text":"<ol> <li>Enzyme Consistency: Compare GO molecular functions with EC classifications</li> <li>Domain Alignment: Validate whole-protein annotations against domain-specific functions</li> <li>Clinical Correlation: Check medically-relevant annotations against clinical phenotypes</li> <li>Pathway Integration: Verify biological process annotations against pathway databases</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#phase-3-ontological-logic-validation-chapters-1-3-14-17","title":"Phase 3: Ontological Logic Validation (Chapters 1, 3, 14, 17)","text":"<ol> <li>True Path Rule: Ensure all parent terms are biologically appropriate</li> <li>Relationship Logic: Validate appropriate use of transitive/non-transitive relations</li> <li>Cross-Ontology Links: Check consistency between MF, BP, and CC annotations</li> <li>Extension Validation: Verify experimental support for contextual claims</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#phase-4-computational-bias-detection-chapters-5-8-10","title":"Phase 4: Computational Bias Detection (Chapters 5, 8, 10)","text":"<ol> <li>IEA Skepticism: Flag genes with disproportionate electronic annotation reliance</li> <li>Propagation Chains: Identify annotation chains lacking experimental foundation</li> <li>Algorithm Bias: Recognize systematic overprediction patterns from specific methods</li> <li>Training Set Limitations: Account for computational method scope restrictions</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#phase-5-community-integration-chapters-7-11-13","title":"Phase 5: Community Integration (Chapters 7, 11, 13)","text":"<ol> <li>Curator Variability: Account for systematic differences in curation approaches</li> <li>Database Differences: Recognize institution-specific annotation biases</li> <li>Community Feedback: Integrate expert domain knowledge for validation</li> <li>Educational Consistency: Use standardized evaluation criteria across all genes</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#high-priority-over-annotation-patterns-to-address","title":"High-Priority Over-Annotation Patterns to Address","text":""},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#1-protein-binding-over-use","title":"1. \"Protein Binding\" Over-Use","text":"<ul> <li>Chapters 2, 4: Generic \"protein binding\" annotations lack informative content</li> <li>Action: Replace with specific binding partner or functional context annotations</li> </ul>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#2-developmental-process-over-annotation","title":"2. Developmental Process Over-Annotation","text":"<ul> <li>Chapters 13, 14: Many proteins involved in development are over-annotated for specific developmental stages</li> <li>Action: Distinguish core function from developmental context using annotation extensions</li> </ul>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#3-metabolic-pathway-over-specificity","title":"3. Metabolic Pathway Over-Specificity","text":"<ul> <li>Chapters 9, 19: Enzymes annotated to overly specific metabolic processes without experimental validation</li> <li>Action: Use EC number cross-validation and pathway database verification</li> </ul>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#4-cellular-component-misassignment","title":"4. Cellular Component Misassignment","text":"<ul> <li>Chapters 3, 17: Localization annotations based on weak computational predictions</li> <li>Action: Require experimental localization evidence or remove unsupported localizations</li> </ul>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#5-regulation-term-misuse","title":"5. Regulation Term Misuse","text":"<ul> <li>Chapters 14, 17: \"Regulates\" relationships applied without understanding non-transitive semantics</li> <li>Action: Validate regulatory relationships with mechanistic evidence</li> </ul>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#implementation-priority-for-ai-gene-review-project","title":"Implementation Priority for AI Gene Review Project","text":""},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#immediate-actions","title":"Immediate Actions:","text":"<ol> <li>Implement ECO-based evidence quality stratification</li> <li>Cross-validate with complementary resources (EC, KEGG, domain databases)</li> <li>Flag annotations violating True Path Rule or relationship logic</li> <li>Identify genes with excessive IEA annotation dependence</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#medium-term-development","title":"Medium-term Development:","text":"<ol> <li>Integrate clinical phenotype validation for medically-relevant genes</li> <li>Develop automated ontological consistency checking</li> <li>Implement temporal annotation stability analysis</li> <li>Create systematic bias detection for computational methods</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#long-term-goals","title":"Long-term Goals:","text":"<ol> <li>Contribute curated annotations to community-wide quality improvement</li> <li>Develop tools for automated over-annotation detection</li> <li>Establish training datasets for computational method improvement</li> <li>Create feedback mechanisms for continuous curation quality enhancement</li> </ol>"},{"location":"paper/literature/OVER-ANNOTATION_SUMMARY_REVIEW/#conclusion","title":"Conclusion","text":"<p>The comprehensive review of all 21 chapters reveals that over-annotation is not a simple binary problem but a complex, multifaceted challenge requiring systematic, evidence-based approaches. Our AI gene review project is well-positioned to address these challenges by implementing the frameworks and strategies outlined across the GO Handbook, with particular emphasis on evidence quality assessment, multi-resource validation, and ontological consistency checking.</p> <p>The systematic curation approach outlined here, informed by the collective wisdom of the GO community, provides a robust foundation for detecting and remediating over-annotations while maintaining comprehensive, high-quality functional descriptions of gene products.</p>"},{"location":"paper/literature/over-annotation-lit-review/","title":"Over-Annotation in the Gene Ontology: Causes, Impact, and Solutions","text":""},{"location":"paper/literature/over-annotation-lit-review/#understanding-over-annotation-in-go","title":"Understanding Over-Annotation in GO","text":"<p>Over-annotation in the Gene Ontology (GO) refers to a situation where a gene product is associated with an excessive number of GO terms, often including very general or indirectly supported terms. In principle, GO curators strive to annotate each gene with the most specific terms supported by evidence, rather than a multitude of broad terms[1]. For example, if a gene\u2019s role is known to be the induction of apoptosis by hormones, it should be annotated to \u201cinduction of apoptosis by hormones\u201d (a specific term) instead of higher-level terms like \u201cinduction of apoptosis\u201d or \u201capoptosis\u201d[1]. Over-annotation arises when this principle is not followed, or when annotations accumulate without consistent curation, leading some genes to have dozens of GO terms. In extreme cases, curators may unintentionally \u201cannotate to the experiment\u201d \u2013 i.e. assign GO terms corresponding to a broad phenotype or experimental outcome rather than the gene\u2019s direct role \u2013 which can introduce overly general Biological Process annotations. GO\u2019s documentation explicitly notes that annotations should capture a gene product\u2019s normal function, process, or location, whereas mutant phenotypes or disease roles are out of scope for GO annotations[2]. When curators or automated pipelines do not adhere strictly to these guidelines, a gene can end up with many high-level or redundant terms, obscuring its core functions. Over-annotation thus reflects not deliberate misuse, but the challenge of consistently applying annotation rules across different curators, organisms, and eras of curation.</p>"},{"location":"paper/literature/over-annotation-lit-review/#causes-and-processes-leading-to-over-annotation","title":"Causes and Processes Leading to Over-Annotation","text":"<p>Several factors contribute to over-annotation in GO. A primary cause is inconsistent curatorial practices across different groups or time periods. In the past, some curators annotated genes to very broad Biological Process (BP) terms based on observable phenotypes. For instance, a knockout that causes a slow-growth phenotype might have led to annotating the gene to a broad process like \u201cgrowth\u201d or \u201cdevelopment,\u201d even if the gene\u2019s direct action was in a specific pathway. This practice \u201cannotates the phenotype\u201d rather than the gene\u2019s mechanistic role, inflating the number of BP annotations per gene. Modern GO standards discourage such broad attributions; curators are expected to find a more specific child term (e.g. a particular signaling or metabolic process affecting growth) or use phenotype ontologies separately, since GO\u2019s scope is normal biological function[2][3]. Another driver of over-annotation is the hierarchical structure of GO. By GO\u2019s true-path rule, an annotation to a specific term implies that all parent terms are also valid for that gene[4]. In well-maintained annotations, curators usually add only the most specific term and allow parent terms to be inferred; however, if curators manually add multiple parent terms (for thoroughness or due to older tool pipelines), this creates redundant annotations. A historical annotation might list both a granular term and all its ancestors for a single piece of evidence, effectively over-annotating the gene with many levels of the ontology.</p> <p>Automated annotation pipelines can also contribute. Electronic annotations (e.g. InterPro2GO mappings or automated transfer of annotations between orthologs) sometimes use broad terms when specific ones cannot be identified. For example, a conserved protein domain might only be linked to a high-level process term, leading all proteins with that domain to get that broad annotation automatically. Similarly, early versions of annotation propagation could add general \u201cresponse to stress\u201d or \u201ctranscription\u201d terms to many genes based on limited data. GO curators recognized this issue: since 2012 the consortium has flagged certain terms as not for direct annotation because they are overly general[5]. For instance, the term \u201cresponse to stress\u201d (GO:0006950) is considered too broad to be useful for manual curation; curators are instructed to choose a more specific child term detailing the type of stress whenever possible[6]. If a paper only says a gene is involved in \u201cstress response\u201d without specifics, a direct annotation to \u201cresponse to stress\u201d is now avoided in manual annotation. (The term is still allowed in automated electronic annotations, where specificity might not be attainable[3].) Such guidelines aim to prevent over-annotation with catch-all terms.</p> <p>Another contributing factor is annotation transfer among gene families and paralogs. Modern GO curation uses tools like PAINT (Phylogenetic Annotation and INference Tool) to propagate experimentally-supported annotations across orthologous genes. This greatly expands annotation coverage, especially for less-studied species, but if not careful it can also propagate a broad function to many family members that may not all truly perform that role. PAINT curators mitigate this by manually reviewing each propagated annotation in the context of the phylogenetic tree, adding a \u201cNOT\u201d qualifier to genes where the function was lost or is not present[7][8]. Nonetheless, the propagation process can increase the number of annotations per gene (since a single experimentally characterized function in one species may be assigned to dozens of orthologs). In some cases paralogous genes get over-annotated \u2013 one well-studied paralog\u2019s many functions might be bulk-assigned to its relatives by sequence similarity inference, even if some functions are lineage-specific. Ensuring that ISS/ISA (sequence similarity) annotations are made only when the source gene has experimental evidence for that term is one safeguard: for example, FlyBase curators require that a sequence-based annotation (ISS) be traceable to an experimentally annotated ortholog, to avoid propagating dubious functions[9]. High-throughput experiments pose another challenge: GO has special evidence codes (HDA, HMP, etc.) for high-throughput data, and curators only accept such annotations if they meet strict criteria to minimize false positives[10]. In summary, over-annotation often stems from well-intentioned attempts to be comprehensive or to leverage all available data, but without consistent rules it leads to too many or too general GO terms per gene.</p>"},{"location":"paper/literature/over-annotation-lit-review/#impact-of-over-annotation-on-research","title":"Impact of Over-Annotation on Research","text":"<p>Over-annotation has significant downstream consequences for both biologists and computational analyses. One major impact is the introduction of bias in functional enrichment and gene function prediction analyses. Genes with many annotations \u2013 sometimes called \u201cmultifunctional\u201d genes \u2013 can skew results by appearing relevant to numerous processes or functions simply because they are annotated to so many GO terms. Pavlidis et al. demonstrated this effect: if one ranks genes by the sheer number of GO categories they belong to, that ranking alone achieves surprisingly high performance in gene function prediction benchmarks[11]. In their study, a single list of genes ordered by annotation count yielded an average AUC of 0.90 in predicting GO term membership \u2013 a essentially \u201cpredicting\u201d functions by picking genes that are annotated with many functions already[12]. This result is not because those genes truly drive all functions, but because any gene in 100 GO categories is statistically likely to be in whatever category you test (relative to a gene in only one category)[11]. The authors point out this is a circular and spurious form of prediction \u2013 it reveals that many computational methods inadvertently latch onto multifunctionality signals rather than specific biological associations[13][14]. In other words, over-annotated genes inflate performance metrics in gene network analysis and \u201cguilt-by-association\u201d predictions, calling into question how much of the signal is biologically meaningful[15][16]. Algorithms may appear to predict gene functions well by simply picking hub genes that have high annotation counts, a bias that needs to be controlled[15].</p> <p>Another impact is on GO enrichment analysis, a common step in genomics studies. Over-annotated genes (often pivotal, well-studied genes like p53, TNF, etc.) tend to appear in many gene lists and contribute to many GO terms being enriched. This can lead researchers to chase broad, generic processes that are enriched largely due to one or two highly annotated genes in their dataset. A 2018 study quantified the inequality in GO annotations, showing that a small fraction of genes holds a disproportionate number of annotations. Figure: Inequality in GO annotations has increased over time. The Gini coefficient of the human GO annotation distribution rose from 0.25 in 2001 to \\~0.47 by 2017[17], indicating that annotation knowledge became more concentrated in a subset of genes. This bias can mislead researchers via a \u201cstreetlight effect,\u201d where genes that are already well-annotated (and often well-known) are preferentially studied further[18][19]. Haynes et al. warn that scientists tend to focus on genes with rich annotations rather than equally or more relevant genes with sparse annotations, simply because the former are easier to interpret[20][19]. Over-annotation thus perpetuates a cycle: well-annotated genes get more attention and more annotations, while lesser-known genes remain under-characterized[19][21]. This can impede discovery, as novel or important genes might be overlooked. It also means that GO-based analyses may return very broad GO terms (e.g. \u201cprotein binding\u201d or \u201ccellular process\u201d) that aren\u2019t informative, or highlight processes that reflect generic biology (like metabolism or gene expression) simply because ubiquitous, multi-annotated genes are in the list. In summary, over-annotation can reduce the specificity and usefulness of GO analysis results, and it can give both human researchers and machine learning models a distorted view of biology \u2013 one dominated by a few superstar genes and overly general functions[22][18].</p>"},{"location":"paper/literature/over-annotation-lit-review/#why-biological-process-is-most-affected","title":"Why Biological Process is Most Affected","text":"<p>The over-annotation problem is most pronounced in the Biological Process (BP) branch of GO, though it can occur in Molecular Function (MF) and Cellular Component (CC) as well. Biological Process terms are often multi-step pathways or broad outcomes (e.g. \u201cdevelopment,\u201d \u201cstress response,\u201d \u201csignaling pathway\u201d), and a single gene\u2019s activity can be relevant to numerous processes. Curators historically sometimes annotated every process in which a gene was reported to have an effect. For example, a pleiotropic regulator might be annotated to dozens of BP terms ranging from cell cycle to apoptosis to metabolism, especially if mutant phenotypes were used as evidence for each process. Without careful restraint, the BP ontology can become a dumping ground for any observed consequence of altering the gene. In contrast, Molecular Function terms tend to be more discrete (enzyme activities, binding specific molecules, etc.), and a gene product usually has a limited number of molecular functions. It\u2019s rare (and biologically suspect) for a protein to have 20 different molecular activities; thus MF annotations per gene are naturally bounded. Cellular Component annotations, similarly, are limited by the number of subcellular locations a protein resides in. A protein might localize to a few compartments or complexes, but it cannot be in every organelle. BP terms, however, can be very numerous because one gene can influence many pathways. Additionally, BP is where curators might inadvertently encode phenotypes \u2013 for instance, annotating a mouse gene to \u201cheart development\u201d because a knockout causes cardiac defects. GO now prefers such cases to be handled by phenotype ontologies (like the Mammalian Phenotype Ontology) for the phenotypic effect, and to only use GO BP if the gene\u2019s mechanistic role in a developmental process is known. Nonetheless, legacy annotations and differing curator interpretations have made some genes, especially in model organisms, associated with long lists of BP terms.</p> <p>This disparity is confirmed by studies of annotation distribution. Gillis and Pavlidis observed that the \u201cmost multifunctional\u201d genes (those with the highest annotation counts) include many that are biologically central or heavily studied (e.g. TP53, TNF, TGFB1), and most of their plethora of annotations are in the BP domain[23]. Many of those GO terms are high-level processes that these genes appear in due to widespread effects or broad research focus. By contrast, the number of distinct MF terms for a gene is usually much smaller \u2013 even TP53 essentially has a few known molecular functions (DNA-binding transcription factor activity, etc.), but dozens of process annotations. GO Consortium statistics also indicate that the BP ontology has grown larger and receives the most annotations. It is worth noting that over-annotation can occur in MF and CC as well, typically via automated methods. For instance, a protein with many predicted enzyme activities might get multiple MF annotations electronically (some of which could be incorrect). Or an overly zealous annotation pipeline might list a protein in every cellular compartment a GFP-fusion was ever observed, even transiently. However, GO curators have implemented quality control to limit this: terms like \u201ccellular component unknown\u201d are used when data is lacking, and extremely generic CC terms like \u201ccellular part\u201d are disallowed for direct use[24]. Overall, BP remains the area where curatorial discipline is most needed to avoid over-annotation, due to the temptation of capturing whole phenotypes or broad biological themes rather than the precise role of the gene product.</p>"},{"location":"paper/literature/over-annotation-lit-review/#curatorial-standards-and-quality-control","title":"Curatorial Standards and Quality Control","text":"<p>Improving annotation consistency is crucial to curbing over-annotation. The Gene Ontology Consortium has established best practices and rules to guide curators. One fundamental principle is: annotate to the most specific applicable GO term, and let the ontology\u2019s structure imply the broader context[1][25]. This prevents redundancy. For example, if a curator has evidence that a protein kinase activates a specific pathway step, they should annotate \u201cprotein phosphorylation involved in [that process]\u201d rather than separately annotating the kinase to generic terms like \u201csignal transduction\u201d and \u201cphosphorylation\u201d and \u201cbiological_process.\u201d The latter broader terms would be automatically true via the ontology hierarchy once the specific term is in place. As GO evolves, the ontology often gains new granular terms to capture distinctions that were previously lumped into broad categories. Curators periodically revisit older annotations when new terms become available. A notable example was the apoptosis reannotation project: when GO added finer terms under \u201capoptotic process,\u201d many gene annotations that were at the parent term were reviewed and moved to more specific terms reflecting the exact pathway (e.g. \u201cpositive regulation of extrinsic apoptotic signaling pathway via death domain receptors\u201d)[26][27]. This kind of reannotation effort reduces over-annotation by ensuring we don\u2019t keep a gene annotated to a broad term once a better one exists. Importantly, the original broad annotation wasn\u2019t \u201cwrong\u201d \u2013 it adhered to GO\u2019s true-path rule (if a gene is annotated to a child, it is implicitly annotated to all parents)[28]. But removing the redundant high-level term from the annotation file makes the gene\u2019s profile more focused and informative. Users are thereby less likely to be misled by seeing an annotation to an overly general concept when a more precise one applies.</p> <p>The GO Consortium also enforces formal annotation rules and checks. The GOC\u2019s quality control pipeline includes a set of \u201cGO rules\u201d (implemented in validation tools like OWL reasoning and the Protein2GO curation interface) to catch common errors[29]. For example, annotations must use valid IDs, have evidence codes and references, and cannot reference retracted papers[29]. Some rules specifically target biologically inconsistent annotations, often via a curated annotation blacklist[30]. The annotation blacklist enumerates certain gene\u2013term combinations that should not be made because they are known to be biologically nonsensical or artifacts[30]. If an automated pipeline or even a human curator attempts to create such an annotation, the system flags or blocks it[31][32]. For instance, if a mitochondrial protein were erroneously annotated to \u201cnuclear envelope,\u201d a blacklist rule might prevent that. This mechanism helps prevent some forms of over-annotation, especially those arising from erroneous ISS (sequence similarity) inferences across very different proteins. Another standard is to avoid annotating high-level process terms without specificity. We saw that GO marks certain terms like \u201cnuclear part\u201d or cell cycle phase terms as not acceptable for direct annotation[24], and similarly terms like \u201cresponse to stress\u201d are disallowed for manual annotation due to being overly general[3]. Curators are expected to always find a more specific child term (e.g. \u201cresponse to oxidative stress\u201d if the experiment describes peroxide treatment, rather than just \u201cresponse to stress\u201d)[3]. These policies are part of curator training and are often enforced by annotation tools that show warnings if a disallowed term is chosen[5]. Additionally, evidence code usage is governed by guidelines to ensure appropriateness. For example, the IMP (inferred from mutant phenotype) evidence should support an annotation that is a plausible direct role of the gene, not just any phenotypic outcome. If an IMP experiment yields a very downstream effect, curators might use annotation extensions or simply not make a GO annotation if it falls outside GO\u2019s scope of direct gene function[2].</p> <p>Cross-curator and cross-database consistency is also addressed through consortium efforts. Regular annotation jamborees, where curators from different model organism databases discuss tricky cases, help harmonize interpretations. The Alliance of Genome Resources (integrating FlyBase, MGI, SGD, WormBase, etc. with GO) has further improved consistency by sharing curation platforms and standards. Each new annotation (especially manual ones) goes through peer review by another curator or a project manager for accuracy and adherence to guidelines. Community feedback is encouraged too: researchers can report annotations they believe are incorrect or over-stated, and the GO consortium will review and correct them[33][34]. This openness helps catch cases where a gene might have been given an overly broad term historically.</p>"},{"location":"paper/literature/over-annotation-lit-review/#ongoing-initiatives-and-review-mechanisms","title":"Ongoing Initiatives and Review Mechanisms","text":"<p>To address over-annotation and improve annotation quality, the GO Consortium and broader community have launched several initiatives. One is the use of phylogenetic curation (PAINT and IBA evidence) not just to propagate annotations, but also as a review mechanism. In PAINT, curators examine a gene family tree annotated with experimental GO terms across species. This often brings to light inconsistencies: if one ortholog has a certain function but others in the clade do not, curators investigate whether the others truly lack that function or are just understudied. They can then propagate the annotation where appropriate, but also annotate a NOT for those that definitively don\u2019t have the function[7][8]. This process can actually reduce over-annotation by ensuring that broad functions aren\u2019t naively copied to every family member \u2013 each IBA (Inferred from Biological Aspect of ancestor) is added only if it passes the curator\u2019s scrutiny. Moreover, as PAINT curators work, they occasionally spot original experimental annotations that seem odd or too general (for example, a species-specific annotation that doesn\u2019t fit the pattern in related species), and they may flag those for review. Thus, the phylogenetic approach serves as a second layer of quality control across all GO annotations, refining them in an evolutionary context.</p> <p>Another major development is the \u201cFunctionome\u201d project (PAN-GO) for human genes. This recent effort, published in 2025, involved over 150 biologists consolidating knowledge about human gene functions using both literature curation and evolutionary modeling[35][36]. The PAN-GO functionome aimed to create a comprehensive, accurate set of functional annotations (and summary descriptions) for all human protein-coding genes, including those that were sparsely annotated before. By integrating data from model organisms and phylogenetic context, it assigned known functions to 82% of human genes \u2013 over 20,000 genes \u2013 up from the much smaller fraction that had direct experimental annotations in humans[37][36]. This initiative is relevant to over-annotation in two ways: (1) it helps balance the annotation coverage so that lesser-known genes get some annotations (reducing the relative bias where only a few genes had tons of terms while many had none), and (2) it provides expert-curated summaries for each gene, which can help filter what the key functions are. In essence, the functionome project can highlight the most important, well-supported GO terms for a gene out of a long list. If a gene had 40 GO annotations but the functionome summary emphasizes the 5 core functions that are consistently supported across species, researchers can focus on those. The resource thus acts as a high-level review, potentially flagging annotations that might be spurious or of low confidence if they didn\u2019t make it into the integrated summary. By combining computational prediction with human expert oversight, the functionome also likely identified cases of over-annotation (where a gene was annotated with a function that doesn\u2019t actually hold up in comparative analysis) and corrected them. The fact that it\u2019s structured in a machine-readable format means it can be used to improve bioinformatic analyses as well[37] \u2013 e.g. algorithms can weight annotations by whether they are part of this high-confidence compendium.</p> <p>There are also emerging tools leveraging AI and text mining to assist curation. For example, the ai4curation/ai-gene-review project (an experimental GitHub project) is exploring the use of large language models to automatically read papers and suggest GO annotations or reviews. While still in development, such tools could help flag potential over-annotation by comparing new literature statements with existing annotations. If an AI finds that a gene is being annotated to a process without clear support in text, it could alert curators to double-check. Additionally, GO Consortium members have discussed methods to use AI for consistency checking (for instance, detecting if two annotations for a gene appear contradictory or if a gene has an exceptionally high number of broad terms). The GO rules and ontology evolution described in the literature also represent ongoing housekeeping. The consortium regularly obsoletes terms that are prone to misuse or creates relations to infer annotations more sensibly[38][39]. For example, a prior link that inferred a BP annotation from an MF annotation (sequence-specific DNA binding TF activity implying transcription, DNA-dependent) was removed when it became clear not all transcription factors directly trigger transcription[38][40]. That single ontology change automatically removed \\~2,500 improper BP annotations that had been inferred across databases[41] \u2013 essentially cleaning up a bulk over-annotation. This shows the consortium\u2019s willingness to adjust the ontology structure to improve annotation quality.</p> <p>Finally, community-driven projects like CAFA (Critical Assessment of Function Annotation) evaluate how well gene function prediction methods (many of which rely on GO) are doing, and in the process they highlight errors in the existing annotations. CAFA and similar efforts sometimes point out over-annotations or missing annotations as part of their assessments, giving the GO curators external feedback on where the knowledgebase might be over-stating or under-stating a gene\u2019s functions.</p>"},{"location":"paper/literature/over-annotation-lit-review/#action-plan-to-fix-over-annotation","title":"Action Plan to Fix Over-Annotation","text":"<p>Addressing over-annotation in GO requires a multi-pronged approach focused on curation practices, tools, and researcher awareness. Below is an action plan summarizing steps to mitigate over-annotation and its effects:</p> <ul> <li> <p>Strengthen and Enforce Curatorial Guidelines: Continue to train all GO curators in the principle of specificity \u2013 annotate to the most granular term supported by evidence, and avoid adding higher-level terms that don\u2019t convey additional info[1]. Emphasize that curators should not \u201cannotate the whole phenotype\u201d or assign a gene to a process if the connection is indirect (e.g., a mutant screen should prompt mechanistic follow-up, not immediate broad annotations). Regular cross-checks and curator peer-reviews should be instituted, where curators audit each other\u2019s annotations for unnecessary broad terms or redundant entries. Expanding the \u201cnot for direct annotation\u201d term list (and keeping it updated in tools like QuickGO) will guide curators away from problematic high-level terms[5].</p> </li> <li> <p>Curation Consistency and Audits: Establish periodic audits of genes that have unusually large numbers of annotations, especially in the Biological Process category. If a gene has, say, 30+ BP annotations, a review team should evaluate whether some of those are legacy broad terms that could be removed or consolidated. This could be facilitated by an automated report that flags potential over-annotation: for example, identifying genes where many annotations come from IMP evidence without a clear mechanistic link, or where multiple parent-child term pairs are co-annotated. The GO consortium\u2019s annotation QC pipeline can be extended with rules to catch these patterns (some of this is already done via the annotation blacklist and ontology constraints[31][24]). Community input via the GO helpdesk or GitHub issues should be further encouraged for users to report suspect annotations[33][34].</p> </li> <li> <p>Enhance Automated Checks: Leverage the power of AI and text mining to flag potential over-annotations. For instance, an NLP system could read the paper supporting an annotation and judge if the GO term is truly mentioned/supported or if the curator might have over-interpreted. The ai-gene-review concept could be developed into a tool that assigns a confidence score to each annotation by comparing it with literature context. Low-confidence, high-level annotations could then be queued for human review. This human-in-the-loop approach would harness AI to scale up oversight without replacing expert judgment.</p> </li> <li> <p>Reduce Annotation Redundancy: Technically, ensure that pipelines do not duplicate ancestor terms. If any GAF (Gene Association File) production step is still adding implicit parent terms explicitly, that should be stopped \u2013 one specific annotation is enough, thanks to the true-path rule. GO has already mostly eliminated explicit redundant annotations, but continued vigilance is needed, especially as groups integrate legacy data. When reannotating genes or ingesting annotations from external groups, incorporate a step to filter out any term that is an ancestor of another term already annotated to the same gene (unless there\u2019s separate evidence that specifically supports the higher-level term under different conditions). This will keep annotation files leaner and more meaningful[27][28].</p> </li> <li> <p>Focused Updates to Ontology and Annotations: Continue the targeted ontology development projects that create finer terms for complex processes (like the apoptosis, heart development examples[42][26]). Every such project should include a reannotation phase where existing annotations to the older broad terms are redistributed to the new specific terms. This both fixes over-annotation and prevents it from recurring (since curators can now choose the precise term). Likewise, when obsoleting terms that were misused, always provide guidance for reannotation so that curators don\u2019t simply map an obsolete broad term to another broad term[7][8].</p> </li> <li> <p>Improved Tools for Users: From the end-user perspective, develop analysis tools that are aware of the over-annotation bias. For example, GO enrichment software could implement a \u201cmultifunctionality weight\u201d that down-weighs contributions from genes with very high annotation counts[43][11]. In practice, some tools (like ErmineJ from the Pavlidis lab) already allow correction for gene multifunctionality to reduce false enrichments[43]. Encouraging researchers to use these or incorporating such options in popular GO analysis packages will mitigate the impact of any remaining over-annotation. This goes hand-in-hand with GO\u2019s efforts: as we clean the annotations, also educate users to interpret results with an understanding that genes with many annotations could skew results[44][19].</p> </li> <li> <p>Balanced Annotation Growth: The PAN-GO Functionome and similar initiatives should be extended to other species or updated regularly for human. By systematically covering more genes with at least some annotation (through evolutionary inference vetted by experts), we reduce the disparity where only some genes are heavily annotated. This addresses annotation under-representation which is the flip side of the over-annotation coin[17]. A more even annotation landscape (lower Gini coefficient) means analyses won\u2019t always point to the same famous genes. It also spreads curator attention more evenly, hopefully preventing overzealous annotation of any one gene. The functionome project demonstrates a scalable way to add annotations in a controlled manner, and its results (like curated gene descriptions) can guide curators on which annotations are truly significant for a gene.</p> </li> <li> <p>Continual Monitoring and Feedback: Finally, treating the GO knowledgebase as a dynamic resource is key. The consortium should monitor metrics like the distribution of annotation counts per gene over time (the annotation inequality). If those metrics show that inequality is rising or a few genes keep accumulating terms, that\u2019s a signal to investigate why \u2013 perhaps a new high-throughput method is dumping lots of annotations of varying quality. GO releases and NAR annual papers should report on annotation counts, and any unusual spikes in certain genes or terms should trigger a review. By maintaining this feedback loop, GO can catch over-annotation issues early. Engaging the user community via workshops on \u201cbest practices in using GO\u201d will also raise awareness \u2013 many users have an intuition that too many GO terms per gene can be problematic, and now we can give them concrete guidance and improvements.</p> </li> </ul> <p>In conclusion, over-annotation in the Gene Ontology is a recognized challenge rooted in the complexities of biology and curation. By tightening annotation rules, using tools to aid consistency, and proactively reviewing annotations, the GO Consortium is addressing the issue head-on. The goal is a GO knowledgebase where each gene is described comprehensively but not inflationarily \u2013 capturing all its true functions and roles, but avoiding the noise of overly broad or unsupported terms. This will ensure GO remains a reliable, precise resource for decoding gene functions in the era of big data biology. With ongoing efforts like phylogenetic curation and the PAN-GO functionome, along with community vigilance, we can correct past excesses in annotation and prevent future over-annotation, leading to more meaningful analyses and discoveries in genomics.</p> <p>Sources: The analysis above is informed by GO Consortium documentation and studies on annotation practices and biases. For example, GO curatorial guidelines emphasize specificity in annotations[1] and exclude phenotypic context outside normal gene function[2]. Pavlidis and colleagues illustrated how genes with many annotations (high \u201cmultifunctionality\u201d) distort computational predictions[11][13]. Haynes et al. quantified the growing inequality in annotation distribution and its effect on research focus[17][18]. The GO Consortium has implemented quality control such as an annotation blacklist to prevent known incorrect gene-term assignments[30] and disallowed overly general terms for manual annotation[5]. Ongoing projects like PAINT curation and the PAN-GO functionome are improving annotation coverage while maintaining accuracy[37][36]. These combined efforts form the basis of the recommended action plan to refine the GO and tackle over-annotation.</p> <p>[1] [4] What is Gene Ontology (GO) | Advaita Bioinformatics</p> <p>https://advaitabio.com/faq-items/understanding-gene-ontology/</p> <p>[2] [29] Introduction to GO annotations</p> <p>http://geneontology.org/docs/go-annotations/</p> <p>[3] [5] [6] [7] [8] [24] [25] [26] [27] [28] [30] [31] [32] [38] [39] [40] [41] [42] Understanding how and why the Gene Ontology and its annotations evolve: the GO within UniProt | GigaScience | Full Text</p> <p>https://gigascience.biomedcentral.com/articles/10.1186/2047-217X-3-4</p> <p>[9] [10] FlyBase:Gene Ontology (GO) Annotation - FlyBase Wiki</p> <p>https://wiki.flybase.org/wiki/FlyBase:Gene_Ontology_(GO)_Annotation</p> <p>[11] [12] [13] [14] [15] [16] [22] [23] [44] The Impact of Multifunctional Genes on \"Guilt by Association\" Analysis | PLOS One</p> <p>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0017258</p> <p>[17] [18] [19] [20] [21] Gene annotation bias impedes biomedical research | Scientific Reports</p> <p>https://www.nature.com/articles/s41598-018-19333-x?error=cookies_not_supported\\&amp;code=694cfa95-5853-4a93-971b-f974138073d8</p> <p>[33] [34] Contributing GO annotations</p> <p>http://geneontology.org/docs/contributing-to-go/</p> <p>[35] [36] [37] SIB helps create most complete, accurate resource for human gene functions | SIB Swiss Institute of Bioinformatics</p> <p>https://www.sib.swiss/news/sib-helps-create-most-complete-accurate-resource-for-human-gene-functions</p> <p>[43] Multifunctionality - ErmineJ - The University of British Columbia</p> <p>https://erminej.msl.ubc.ca/help/tutorials/multifunctionality/</p>"}]}