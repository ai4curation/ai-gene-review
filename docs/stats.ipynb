{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Review Statistics Dashboard\n",
    "\n",
    "Comprehensive statistical analysis of gene annotation reviews across species, evidence types, and curation actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for beautiful visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flattened annotation data\n",
    "tsv_path = Path('../exports/exported_annotations.tsv')\n",
    "df = pd.read_csv(tsv_path, sep='\\t')\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"üìä Dataset Overview\")\n",
    "print(f\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(f\"Total annotations reviewed: {len(df):,}\")\n",
    "print(f\"Unique genes: {df['gene_symbol'].nunique()}\")\n",
    "print(f\"Unique species: {df['taxon_label'].nunique()}\")\n",
    "print(f\"Unique GO terms: {df['term_id'].nunique()}\")\n",
    "print(f\"\\nSpecies distribution:\")\n",
    "for species, count in df['taxon_label'].value_counts().head().items():\n",
    "    print(f\"  ‚Ä¢ {species}: {count} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Overall Review Actions Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Count of review actions\n",
    "action_counts = df['review_action'].value_counts()\n",
    "colors = sns.color_palette(\"Spectral\", len(action_counts))\n",
    "\n",
    "# Bar chart\n",
    "bars = ax1.bar(range(len(action_counts)), action_counts.values, color=colors)\n",
    "ax1.set_xticks(range(len(action_counts)))\n",
    "ax1.set_xticklabels(action_counts.index, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Number of Annotations')\n",
    "ax1.set_title('Distribution of Review Actions', fontweight='bold', fontsize=14)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, action_counts.values):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{int(value)}\\n({value/len(df)*100:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Pie chart with exploded slices for important actions\n",
    "explode = [0.1 if action in ['MODIFY', 'REMOVE'] else 0 for action in action_counts.index]\n",
    "wedges, texts, autotexts = ax2.pie(action_counts.values, \n",
    "                                     labels=action_counts.index,\n",
    "                                     colors=colors,\n",
    "                                     autopct='%1.1f%%',\n",
    "                                     explode=explode,\n",
    "                                     startangle=90)\n",
    "ax2.set_title('Proportion of Review Actions', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Make percentage text bold\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä Action Summary:\")\n",
    "print(f\"  ‚Ä¢ Accepted as-is: {action_counts.get('ACCEPT', 0)} ({action_counts.get('ACCEPT', 0)/len(df)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Modifications needed: {action_counts.get('MODIFY', 0)} ({action_counts.get('MODIFY', 0)/len(df)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Removed: {action_counts.get('REMOVE', 0)} ({action_counts.get('REMOVE', 0)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Species-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare species data\n",
    "species_action = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index') * 100\n",
    "species_counts = df['taxon_label'].value_counts()\n",
    "\n",
    "# Filter to top species by annotation count\n",
    "top_species = species_counts.head(10).index\n",
    "species_action_filtered = species_action.loc[top_species]\n",
    "\n",
    "# Create stacked bar chart\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Stacked percentage bar chart\n",
    "species_action_filtered.plot(kind='barh', stacked=True, ax=ax1, \n",
    "                             colormap='Spectral', width=0.8)\n",
    "ax1.set_xlabel('Percentage of Annotations (%)')\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('Review Actions by Species (Percentage)', fontweight='bold', fontsize=14)\n",
    "ax1.legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "for container in ax1.containers:\n",
    "    ax1.bar_label(container, fmt='%.0f%%', label_type='center', fontsize=9)\n",
    "\n",
    "# Absolute counts heatmap\n",
    "species_action_abs = pd.crosstab(df['taxon_label'], df['review_action'])\n",
    "species_action_abs_filtered = species_action_abs.loc[top_species]\n",
    "\n",
    "sns.heatmap(species_action_abs_filtered, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            ax=ax2, cbar_kws={'label': 'Number of Annotations'})\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('Review Action')\n",
    "ax2.set_title('Review Actions by Species (Absolute Counts)', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Evidence Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Method analysis (combining evidence type and reference source)\n# This provides a higher-level view than raw evidence codes\nif 'method' in df.columns:\n    method_counts = df['method'].value_counts()\n    \n    # Create action categories if not already present\n    if 'action_category' not in df.columns:\n        def categorize_action(action):\n            if action == 'ACCEPT':\n                return 'Accept'\n            elif action == 'MODIFY':\n                return 'Modify'\n            elif action == 'REMOVE':\n                return 'Remove'\n            elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n                return 'Non-Core/Over-Annotated'\n            else:\n                return 'Other'\n        df['action_category'] = df['review_action'].apply(categorize_action)\n    \n    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n    \n    # 1. Method vs Review Action heatmap - COUNTS\n    method_action = pd.crosstab(df['method'], df['review_action'])\n    \n    sns.heatmap(method_action, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0, 0],\n                cbar_kws={'label': 'Count'})\n    axes[0, 0].set_title('Review Actions by Method (Counts)', fontweight='bold', fontsize=12)\n    axes[0, 0].set_xlabel('Review Action')\n    axes[0, 0].set_ylabel('Method')\n    axes[0, 0].tick_params(axis='both', which='major', labelsize=9)\n    \n    # 2. Method vs Review Action heatmap - PERCENTAGES\n    method_action_pct = pd.crosstab(df['method'], df['review_action'], normalize='index') * 100\n    \n    sns.heatmap(method_action_pct, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=axes[0, 1],\n                cbar_kws={'label': 'Percentage (%)'}, vmin=0, vmax=50)\n    axes[0, 1].set_title('Review Actions by Method (Row %)', fontweight='bold', fontsize=12)\n    axes[0, 1].set_xlabel('Review Action')\n    axes[0, 1].set_ylabel('')\n    axes[0, 1].tick_params(axis='both', which='major', labelsize=9)\n    \n    # 3. ACTION RATES BY METHOD - STACKED BAR CHART\n    # Calculate percentages for each method\n    method_action_rates = pd.crosstab(df['method'], df['action_category'], normalize='index') * 100\n    \n    # Order columns for stacking\n    action_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\n    existing_cols = [col for col in action_order if col in method_action_rates.columns]\n    method_action_rates = method_action_rates[existing_cols]\n    \n    # Sort by total annotations (most common first)\n    method_action_rates = method_action_rates.loc[method_counts.index]\n    \n    # Create stacked bar chart\n    x = np.arange(len(method_action_rates))\n    width = 0.7\n    \n    # Define colors for each action category\n    action_colors = {\n        'Accept': 'green',\n        'Modify': 'orange', \n        'Remove': 'red',\n        'Non-Core/Over-Annotated': 'purple',\n        'Other': 'gray'\n    }\n    \n    # Plot stacked bars\n    bottom = np.zeros(len(method_action_rates))\n    for action in existing_cols:\n        values = method_action_rates[action].values\n        color = action_colors.get(action, 'gray')\n        axes[1, 0].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n        bottom += values\n    \n    axes[1, 0].set_xticks(x)\n    axes[1, 0].set_xticklabels(method_action_rates.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 0].set_ylabel('Percentage (%)')\n    axes[1, 0].set_title('Action Rates by Method', fontweight='bold', fontsize=12)\n    axes[1, 0].legend(loc='upper right')\n    axes[1, 0].grid(axis='y', alpha=0.3)\n    axes[1, 0].set_ylim(0, 100)\n    \n    # Add sample sizes above bars\n    for i, method in enumerate(method_action_rates.index):\n        count = method_counts[method]\n        axes[1, 0].text(i, 102, f'n={count}', ha='center', fontsize=8, color='black')\n    \n    # 4. Method distribution bar chart\n    colors_dist = sns.color_palette(\"viridis\", len(method_counts))\n    bars = axes[1, 1].bar(range(len(method_counts)), method_counts.values, color=colors_dist)\n    axes[1, 1].set_xticks(range(len(method_counts)))\n    axes[1, 1].set_xticklabels(method_counts.index, rotation=45, ha='right', fontsize=9)\n    axes[1, 1].set_ylabel('Number of Annotations')\n    axes[1, 1].set_title('Distribution of Methods', fontweight='bold', fontsize=12)\n    axes[1, 1].grid(axis='y', alpha=0.3)\n    \n    # Add count labels\n    for bar, value in zip(bars, method_counts.values):\n        height = bar.get_height()\n        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 5,\n                        f'{int(value)}', ha='center', va='bottom', fontsize=9)\n    \n    plt.suptitle('Method Analysis Overview', fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n    \n    # Print detailed summary\n    print(\"\\nüìä Method Analysis Summary:\")\n    print(\"=\" * 60)\n    \n    # Create summary DataFrame\n    method_summary = pd.DataFrame({\n        'Count': df.groupby('method').size(),\n        'Accepted': df[df['review_action'] == 'ACCEPT'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Accept_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'ACCEPT').mean() * 100),\n        'Removed': df[df['review_action'] == 'REMOVE'].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n        'Remove_Rate': df.groupby('method')['review_action'].apply(lambda x: (x == 'REMOVE').mean() * 100),\n        'Non-Core/Over': df[df['review_action'].isin(['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED'])].groupby('method').size().reindex(df['method'].unique(), fill_value=0),\n    }).sort_values('Count', ascending=False)\n    \n    print(f\"\\n{'Method':<20} {'Count':>6} {'Accept':>8} {'Accept%':>8} {'Remove':>8} {'Remove%':>8} {'NonCore':>8}\")\n    print(\"-\" * 75)\n    for method, row in method_summary.iterrows():\n        print(f\"{method:<20} {int(row['Count']):6d} {int(row['Accepted']):8d} {row['Accept_Rate']:7.1f}% {int(row['Removed']):8d} {row['Remove_Rate']:7.1f}% {int(row['Non-Core/Over']):8d}\")\n    \n    print(\"\\nüìà Key Insights:\")\n    print(f\"  ‚Ä¢ Total methods: {df['method'].nunique()}\")\n    print(f\"  ‚Ä¢ Most common: {method_counts.index[0]} ({method_counts.iloc[0]} annotations, {method_counts.iloc[0]/len(df)*100:.1f}%)\")\n    \n    # Report on ARBA specifically\n    if 'ARBA' in method_summary.index:\n        arba_row = method_summary.loc['ARBA']\n        print(f\"\\nüîç ARBA Analysis:\")\n        print(f\"  ‚Ä¢ Total: {int(arba_row['Count'])} annotations\")\n        print(f\"  ‚Ä¢ Accepted: {int(arba_row['Accepted'])} ({arba_row['Accept_Rate']:.1f}%)\")\n        print(f\"  ‚Ä¢ Removed: {int(arba_row['Removed'])} ({arba_row['Remove_Rate']:.1f}%)\")\n        print(f\"  ‚Ä¢ Non-Core/Over-Annotated: {int(arba_row['Non-Core/Over'])}\")\nelse:\n    print(\"‚ö†Ô∏è Method column not found in data. Please re-export annotations to include the new method field.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üß™ Method Analysis (Evidence + Reference)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evidence type distribution with action rates\nevidence_counts = df['evidence_type'].value_counts()\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# 1. Overall evidence type distribution\ncolors = sns.color_palette(\"viridis\", len(evidence_counts))\nbars = axes[0, 0].bar(range(len(evidence_counts)), evidence_counts.values, color=colors)\naxes[0, 0].set_xticks(range(len(evidence_counts)))\naxes[0, 0].set_xticklabels(evidence_counts.index, rotation=45, ha='right')\naxes[0, 0].set_ylabel('Number of Annotations')\naxes[0, 0].set_title('Distribution of Evidence Types', fontweight='bold')\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# Add count labels\nfor bar, value in zip(bars, evidence_counts.values):\n    height = bar.get_height()\n    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n                    f'{int(value)}', ha='center', va='bottom')\n\n# 2. Evidence type vs Review action heatmap\nevidence_action = pd.crosstab(df['evidence_type'], df['review_action'])\nsns.heatmap(evidence_action, annot=True, fmt='d', cmap='coolwarm', ax=axes[0, 1],\n            cbar_kws={'label': 'Count'})\naxes[0, 1].set_title('Evidence Type vs Review Action', fontweight='bold')\naxes[0, 1].set_xlabel('Review Action')\naxes[0, 1].set_ylabel('Evidence Type')\n\n# 3. Acceptance rate by evidence type\nevidence_accept_rate = pd.crosstab(df['evidence_type'], \n                                   df['review_action'] == 'ACCEPT', \n                                   normalize='index')[True] * 100\nevidence_accept_rate = evidence_accept_rate.sort_values(ascending=False)\n\nbars = axes[1, 0].barh(range(len(evidence_accept_rate)), \n                       evidence_accept_rate.values,\n                       color=sns.color_palette(\"RdYlGn\", len(evidence_accept_rate))[::-1])\naxes[1, 0].set_yticks(range(len(evidence_accept_rate)))\naxes[1, 0].set_yticklabels(evidence_accept_rate.index)\naxes[1, 0].set_xlabel('Acceptance Rate (%)')\naxes[1, 0].set_title('Acceptance Rate by Evidence Type', fontweight='bold')\naxes[1, 0].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\nfor bar, value in zip(bars, evidence_accept_rate.values):\n    width = bar.get_width()\n    axes[1, 0].text(width + 1, bar.get_y() + bar.get_height()/2.,\n                    f'{value:.1f}%', ha='left', va='center')\n\n# 4. ACTION RATES BY EVIDENCE TYPE - STACKED BAR CHART\n# Group actions into categories\ndef categorize_action(action):\n    if action == 'ACCEPT':\n        return 'Accept'\n    elif action == 'MODIFY':\n        return 'Modify'\n    elif action == 'REMOVE':\n        return 'Remove'\n    elif action in ['KEEP_AS_NON_CORE', 'MARK_AS_OVER_ANNOTATED']:\n        return 'Non-Core/Over-Annotated'\n    else:\n        return 'Other'\n\ndf['action_category'] = df['review_action'].apply(categorize_action)\n\n# Calculate percentages for each evidence type\nevidence_action_rates = pd.crosstab(df['evidence_type'], df['action_category'], normalize='index') * 100\n\n# Order columns for stacking\naction_order = ['Accept', 'Modify', 'Remove', 'Non-Core/Over-Annotated', 'Other']\nexisting_cols = [col for col in action_order if col in evidence_action_rates.columns]\nevidence_action_rates = evidence_action_rates[existing_cols]\n\n# Sort by total annotations (most common first)\nevidence_action_rates = evidence_action_rates.loc[evidence_counts.index]\n\n# Create stacked bar chart\nx = np.arange(len(evidence_action_rates))\nwidth = 0.6\n\n# Define colors for each action category\naction_colors = {\n    'Accept': 'green',\n    'Modify': 'orange', \n    'Remove': 'red',\n    'Non-Core/Over-Annotated': 'purple',\n    'Other': 'gray'\n}\n\n# Plot stacked bars\nbottom = np.zeros(len(evidence_action_rates))\nfor action in existing_cols:\n    values = evidence_action_rates[action].values\n    color = action_colors.get(action, 'gray')\n    axes[1, 1].bar(x, values, width, bottom=bottom, label=action, color=color, alpha=0.8)\n    bottom += values\n\naxes[1, 1].set_xticks(x)\naxes[1, 1].set_xticklabels(evidence_action_rates.index, rotation=45, ha='right')\naxes[1, 1].set_ylabel('Percentage (%)')\naxes[1, 1].set_title('Action Rates by Evidence Type', fontweight='bold')\naxes[1, 1].legend(loc='upper right')\naxes[1, 1].grid(axis='y', alpha=0.3)\naxes[1, 1].set_ylim(0, 100)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "source": "# Compare Method (consolidated) vs Evidence (raw) views\nif 'method' in df.columns:\n    fig = plt.figure(figsize=(18, 12))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n    \n    # 1. Side-by-side pie charts: Method vs Evidence\n    ax1 = fig.add_subplot(gs[0, 0])\n    method_top = df['method'].value_counts().head(8)\n    colors1 = sns.color_palette(\"Set2\", len(method_top))\n    wedges, texts, autotexts = ax1.pie(method_top.values, labels=method_top.index, \n                                        autopct='%1.1f%%', colors=colors1, startangle=90)\n    ax1.set_title('Top Methods (Consolidated)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('white')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n    \n    ax2 = fig.add_subplot(gs[0, 1])\n    evidence_top = df['evidence_type'].value_counts().head(8)\n    colors2 = sns.color_palette(\"Set3\", len(evidence_top))\n    wedges, texts, autotexts = ax2.pie(evidence_top.values, labels=evidence_top.index,\n                                       autopct='%1.1f%%', colors=colors2, startangle=90)\n    ax2.set_title('Top Evidence Types (Raw)', fontweight='bold')\n    for autotext in autotexts:\n        autotext.set_color('black')\n        autotext.set_fontweight('bold')\n        autotext.set_fontsize(9)\n    \n    # 2. Acceptance rates comparison\n    ax3 = fig.add_subplot(gs[0, 2])\n    \n    # Calculate acceptance rates for methods\n    method_accept = df.groupby('method')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n    \n    # Calculate acceptance rates for evidence\n    evidence_accept = df.groupby('evidence_type')['review_action'].apply(\n        lambda x: (x == 'ACCEPT').mean() * 100\n    ).sort_values(ascending=False).head(10)\n    \n    x = np.arange(10)\n    width = 0.35\n    \n    bars1 = ax3.barh(x - width/2, method_accept.values[:10], width, \n                     label='By Method', color='steelblue', alpha=0.8)\n    bars2 = ax3.barh(x + width/2, evidence_accept.values[:10], width,\n                     label='By Evidence', color='coral', alpha=0.8)\n    \n    ax3.set_yticks(x)\n    ax3.set_yticklabels([f\"{i+1}\" for i in range(10)])\n    ax3.set_xlabel('Acceptance Rate (%)')\n    ax3.set_title('Top 10 Acceptance Rates Comparison', fontweight='bold')\n    ax3.legend()\n    ax3.grid(axis='x', alpha=0.3)\n    \n    # 3. Method breakdown for IEA annotations\n    ax4 = fig.add_subplot(gs[1, :])\n    iea_methods = df[df['evidence_type'] == 'IEA']['method'].value_counts()\n    \n    bars = ax4.bar(range(len(iea_methods)), iea_methods.values, \n                   color=sns.color_palette(\"viridis\", len(iea_methods)))\n    ax4.set_xticks(range(len(iea_methods)))\n    ax4.set_xticklabels(iea_methods.index, rotation=45, ha='right')\n    ax4.set_ylabel('Number of Annotations')\n    ax4.set_title('IEA Annotations Breakdown by Method/Source', fontweight='bold', fontsize=14)\n    ax4.grid(axis='y', alpha=0.3)\n    \n    # Add value and percentage labels\n    for bar, (method, count) in zip(bars, iea_methods.items()):\n        height = bar.get_height()\n        pct = count / df[df['evidence_type'] == 'IEA'].shape[0] * 100\n        ax4.text(bar.get_x() + bar.get_width()/2., height + 2,\n                f'{int(count)}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=9)\n    \n    # 4. Sankey-style flow from Evidence to Method\n    ax5 = fig.add_subplot(gs[2, :2])\n    \n    # Create crosstab of evidence to method mapping\n    evidence_method = pd.crosstab(df['evidence_type'], df['method'])\n    \n    # Filter to most common combinations\n    top_evidence = df['evidence_type'].value_counts().head(8).index\n    top_methods = df['method'].value_counts().head(8).index\n    evidence_method_filtered = evidence_method.loc[\n        evidence_method.index.intersection(top_evidence),\n        evidence_method.columns.intersection(top_methods)\n    ]\n    \n    sns.heatmap(evidence_method_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                ax=ax5, cbar_kws={'label': 'Count'})\n    ax5.set_title('Evidence Type to Method Mapping', fontweight='bold', fontsize=12)\n    ax5.set_xlabel('Method (Consolidated)')\n    ax5.set_ylabel('Evidence Type (Raw)')\n    \n    # 5. Summary statistics table\n    ax6 = fig.add_subplot(gs[2, 2])\n    ax6.axis('tight')\n    ax6.axis('off')\n    \n    # Calculate statistics\n    method_stats = {\n        'Unique Methods': df['method'].nunique(),\n        'Unique Evidence Types': df['evidence_type'].nunique(),\n        'Most Common Method': f\"{method_counts.index[0]} ({method_counts.iloc[0]})\",\n        'Most Common Evidence': f\"{evidence_counts.index[0]} ({evidence_counts.iloc[0]})\",\n        'IEA Breakdown': f\"{df[df['evidence_type'] == 'IEA']['method'].nunique()} sources\",\n        'Experimental %': f\"{(df['method'] == 'Experimental').mean() * 100:.1f}%\"\n    }\n    \n    table_data = [[k, str(v)] for k, v in method_stats.items()]\n    table = ax6.table(cellText=table_data, cellLoc='left', loc='center',\n                     colWidths=[0.6, 0.4])\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1.2, 1.8)\n    \n    # Style the table\n    for i in range(len(table_data)):\n        table[(i, 0)].set_facecolor('#E8F4F8')\n        table[(i, 0)].set_text_props(weight='bold')\n    \n    ax6.set_title('Comparison Summary', fontweight='bold', fontsize=12)\n    \n    plt.suptitle('Method vs Evidence Type Analysis', fontsize=16, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.show()\n    \n    # Print detailed comparison\n    print(\"\\nüîç Method vs Evidence Detailed Comparison:\")\n    print(\"=\" * 60)\n    \n    print(\"\\nüìä Consolidation Impact:\")\n    total_experimental = df[df['evidence_type'].isin(['IDA', 'IPI', 'IMP', 'IGI', 'IEP', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP'])].shape[0]\n    print(f\"  ‚Ä¢ {total_experimental} experimental evidence codes ‚Üí 1 'Experimental' method\")\n    \n    iea_count = df[df['evidence_type'] == 'IEA'].shape[0]\n    iea_methods_count = df[df['evidence_type'] == 'IEA']['method'].nunique()\n    print(f\"  ‚Ä¢ {iea_count} IEA annotations ‚Üí {iea_methods_count} distinct methods\")\n    \n    print(\"\\nüìà Quality Indicators:\")\n    exp_accept = df[df['method'] == 'Experimental']['review_action'].eq('ACCEPT').mean() * 100\n    auto_accept = df[df['method'].isin(['ARBA', 'UniProtKB-KW', 'Combined-IEA', 'InterPro2GO'])]['review_action'].eq('ACCEPT').mean() * 100\n    print(f\"  ‚Ä¢ Experimental acceptance rate: {exp_accept:.1f}%\")\n    print(f\"  ‚Ä¢ Automated acceptance rate: {auto_accept:.1f}%\")\n    print(f\"  ‚Ä¢ Difference: {exp_accept - auto_accept:+.1f} percentage points\")\nelse:\n    print(\"‚ö†Ô∏è Method column not found. Please re-export annotations with the updated exporter.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üî¨üìä Method vs Evidence Comparison",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sankey diagram for Method -> Action flow\ntry:\n    import plotly.graph_objects as go\n    import plotly.offline as pyo\n    \n    # Prepare data for Sankey diagram\n    if 'method' in df.columns:\n        # Create the flow data\n        flow_data = df.groupby(['method', 'action_category']).size().reset_index(name='count')\n        \n        # Filter to significant flows (at least 5 annotations) for clarity\n        flow_data = flow_data[flow_data['count'] >= 5]\n        \n        # Create node lists\n        methods = flow_data['method'].unique().tolist()\n        actions = flow_data['action_category'].unique().tolist()\n        \n        # All nodes (methods + actions)\n        all_nodes = methods + actions\n        node_indices = {node: i for i, node in enumerate(all_nodes)}\n        \n        # Create source, target, and value lists for Sankey\n        source = [node_indices[method] for method in flow_data['method']]\n        target = [node_indices[action] for action in flow_data['action_category']]\n        value = flow_data['count'].tolist()\n        \n        # Define colors\n        method_colors = ['lightblue'] * len(methods)\n        action_color_map = {\n            'Accept': 'green',\n            'Modify': 'orange',\n            'Remove': 'red',\n            'Non-Core/Over-Annotated': 'purple',\n            'Other': 'gray'\n        }\n        action_colors = [action_color_map.get(action, 'gray') for action in actions]\n        node_colors = method_colors + action_colors\n        \n        # Create Sankey diagram\n        fig = go.Figure(data=[go.Sankey(\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\", width=0.5),\n                label=all_nodes,\n                color=node_colors,\n                hovertemplate='%{label}<br>Total: %{value}<extra></extra>'\n            ),\n            link=dict(\n                source=source,\n                target=target,\n                value=value,\n                color='rgba(200, 200, 200, 0.4)',\n                hovertemplate='%{source.label} ‚Üí %{target.label}<br>Count: %{value}<extra></extra>'\n            )\n        )])\n        \n        fig.update_layout(\n            title_text=\"Method to Action Flow (flows ‚â•5 annotations)\",\n            font_size=12,\n            height=600,\n            margin=dict(l=50, r=50, t=50, b=50)\n        )\n        \n        # Display the figure\n        pyo.iplot(fig)\n        \n        # Also create a static version using matplotlib\n        fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n        \n        # 1. Top flows table\n        top_flows = flow_data.nlargest(20, 'count')\n        top_flows['percentage'] = (top_flows['count'] / top_flows['count'].sum() * 100).round(1)\n        \n        # Format for display\n        table_data = []\n        table_data.append(['Method', 'Action', 'Count', '%'])\n        table_data.append(['‚îÄ' * 20, '‚îÄ' * 25, '‚îÄ' * 8, '‚îÄ' * 8])\n        \n        for _, row in top_flows.iterrows():\n            table_data.append([\n                row['method'][:20],\n                row['action_category'][:25],\n                f\"{int(row['count']):4d}\",\n                f\"{row['percentage']:5.1f}%\"\n            ])\n        \n        ax1.axis('tight')\n        ax1.axis('off')\n        table = ax1.table(cellText=table_data, cellLoc='left', loc='center',\n                         colWidths=[0.3, 0.35, 0.15, 0.15])\n        table.auto_set_font_size(False)\n        table.set_fontsize(9)\n        table.scale(1.2, 1.2)\n        \n        # Style header\n        for i in range(4):\n            table[(0, i)].set_facecolor('#4CAF50')\n            table[(0, i)].set_text_props(weight='bold', color='white')\n        \n        ax1.set_title('Top 20 Method‚ÜíAction Flows', fontweight='bold', fontsize=12)\n        \n        # 2. Summary by method\n        method_flow_summary = flow_data.pivot_table(\n            index='method', \n            columns='action_category', \n            values='count', \n            aggfunc='sum',\n            fill_value=0\n        )\n        \n        # Sort by total flow\n        method_flow_summary['Total'] = method_flow_summary.sum(axis=1)\n        method_flow_summary = method_flow_summary.sort_values('Total', ascending=False).head(10)\n        \n        # Create stacked bar chart\n        categories = [col for col in method_flow_summary.columns if col != 'Total']\n        x = np.arange(len(method_flow_summary))\n        \n        bottom = np.zeros(len(method_flow_summary))\n        for category in categories:\n            if category in method_flow_summary.columns:\n                values = method_flow_summary[category].values\n                color = action_color_map.get(category, 'gray')\n                ax2.barh(x, values, left=bottom, label=category, color=color, alpha=0.8)\n                bottom += values\n        \n        ax2.set_yticks(x)\n        ax2.set_yticklabels(method_flow_summary.index, fontsize=10)\n        ax2.set_xlabel('Number of Annotations')\n        ax2.set_title('Top 10 Methods: Action Distribution', fontweight='bold', fontsize=12)\n        ax2.legend(loc='lower right')\n        ax2.grid(axis='x', alpha=0.3)\n        \n        # Add totals at the end of bars\n        for i, total in enumerate(method_flow_summary['Total']):\n            ax2.text(total + 5, i, f'{int(total)}', va='center', fontsize=9)\n        \n        plt.suptitle('Method to Action Flow Analysis', fontsize=14, fontweight='bold', y=1.02)\n        plt.tight_layout()\n        plt.show()\n        \n        # Print flow statistics\n        print(\"\\nüåä Flow Analysis Summary:\")\n        print(\"=\" * 60)\n        print(f\"Total unique flows: {len(flow_data)}\")\n        print(f\"Total annotations in flows ‚â•5: {flow_data['count'].sum()}\")\n        print(f\"Most common flow: {top_flows.iloc[0]['method']} ‚Üí {top_flows.iloc[0]['action_category']} ({top_flows.iloc[0]['count']} annotations)\")\n        \n        # Calculate percentage of each action across all methods\n        action_totals = flow_data.groupby('action_category')['count'].sum()\n        print(\"\\nüìä Overall Action Distribution (from flows ‚â•5):\")\n        for action, count in action_totals.sort_values(ascending=False).items():\n            pct = count / action_totals.sum() * 100\n            print(f\"  ‚Ä¢ {action}: {count} ({pct:.1f}%)\")\n            \nexcept ImportError:\n    print(\"‚ö†Ô∏è Plotly not installed. Installing it will enable interactive Sankey diagrams.\")\n    print(\"   To install: uv add plotly\")\n    \n    # Fallback visualization without Plotly\n    if 'method' in df.columns:\n        fig, ax = plt.subplots(figsize=(14, 10))\n        \n        # Create flow matrix\n        flow_matrix = pd.crosstab(df['method'], df['action_category'])\n        \n        # Filter to top methods for readability\n        top_methods = df['method'].value_counts().head(15).index\n        flow_matrix_filtered = flow_matrix.loc[top_methods]\n        \n        # Create heatmap as fallback\n        sns.heatmap(flow_matrix_filtered, annot=True, fmt='d', cmap='YlGnBu',\n                    cbar_kws={'label': 'Count'}, ax=ax)\n        ax.set_title('Method to Action Flow Matrix (Top 15 Methods)', fontweight='bold', fontsize=14)\n        ax.set_xlabel('Action Category', fontsize=12)\n        ax.set_ylabel('Method', fontsize=12)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        print(\"\\nüìä Method‚ÜíAction Flow Summary (Top 15 Methods):\")\n        for method in top_methods[:5]:\n            flows = flow_matrix.loc[method]\n            flows = flows[flows > 0].sort_values(ascending=False)\n            print(f\"\\n{method}:\")\n            for action, count in flows.items():\n                pct = count / flows.sum() * 100\n                print(f\"  ‚Üí {action}: {count} ({pct:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üåä Method to Action Flow Analysis",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ GO Term Ontology Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ontology from term_id (GO:XXXXXXX)\n",
    "# Determine ontology based on term_ontology column or infer from common patterns\n",
    "def get_ontology(row):\n",
    "    if pd.notna(row['term_ontology']):\n",
    "        return row['term_ontology']\n",
    "    # Infer from term label patterns\n",
    "    term = str(row['term_label']).lower()\n",
    "    if 'binding' in term or 'activity' in term or 'transporter' in term:\n",
    "        return 'Molecular Function'\n",
    "    elif 'process' in term or 'regulation' in term or 'pathway' in term:\n",
    "        return 'Biological Process'\n",
    "    elif 'complex' in term or 'membrane' in term or 'region' in term:\n",
    "        return 'Cellular Component'\n",
    "    return 'Unknown'\n",
    "\n",
    "df['ontology'] = df.apply(get_ontology, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Distribution across ontologies\n",
    "ontology_counts = df['ontology'].value_counts()\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "wedges, texts, autotexts = axes[0, 0].pie(ontology_counts.values, \n",
    "                                           labels=ontology_counts.index,\n",
    "                                           colors=colors[:len(ontology_counts)],\n",
    "                                           autopct='%1.1f%%',\n",
    "                                           startangle=90)\n",
    "axes[0, 0].set_title('GO Ontology Distribution', fontweight='bold')\n",
    "\n",
    "# 2. Review actions by ontology\n",
    "ontology_action = pd.crosstab(df['ontology'], df['review_action'], normalize='index') * 100\n",
    "ontology_action.plot(kind='bar', ax=axes[0, 1], colormap='Set3')\n",
    "axes[0, 1].set_xlabel('Ontology')\n",
    "axes[0, 1].set_ylabel('Percentage of Annotations')\n",
    "axes[0, 1].set_title('Review Actions by GO Ontology', fontweight='bold')\n",
    "axes[0, 1].legend(title='Action', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 3. Most frequently reviewed terms\n",
    "top_terms = df['term_label'].value_counts().head(15)\n",
    "axes[1, 0].barh(range(len(top_terms)), top_terms.values, \n",
    "               color=sns.color_palette(\"muted\", len(top_terms)))\n",
    "axes[1, 0].set_yticks(range(len(top_terms)))\n",
    "axes[1, 0].set_yticklabels(top_terms.index, fontsize=9)\n",
    "axes[1, 0].set_xlabel('Number of Annotations')\n",
    "axes[1, 0].set_title('Top 15 Most Frequently Annotated GO Terms', fontweight='bold')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add count labels\n",
    "for i, value in enumerate(top_terms.values):\n",
    "    axes[1, 0].text(value + 0.5, i, str(value), va='center')\n",
    "\n",
    "# 4. Terms with highest modification rates\n",
    "term_stats = df.groupby('term_label').agg({\n",
    "    'review_action': ['count', lambda x: (x == 'MODIFY').mean() * 100]\n",
    "}).reset_index()\n",
    "term_stats.columns = ['term', 'count', 'modify_rate']\n",
    "term_stats = term_stats[term_stats['count'] >= 5]  # Filter for terms with at least 5 annotations\n",
    "term_stats = term_stats.nlargest(10, 'modify_rate')\n",
    "\n",
    "axes[1, 1].barh(range(len(term_stats)), term_stats['modify_rate'].values,\n",
    "               color=sns.color_palette(\"YlOrRd\", len(term_stats)))\n",
    "axes[1, 1].set_yticks(range(len(term_stats)))\n",
    "axes[1, 1].set_yticklabels(term_stats['term'].values, fontsize=9)\n",
    "axes[1, 1].set_xlabel('Modification Rate (%)')\n",
    "axes[1, 1].set_title('GO Terms with Highest Modification Rates (n‚â•5)', fontweight='bold')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (rate, count) in enumerate(zip(term_stats['modify_rate'].values, term_stats['count'].values)):\n",
    "    axes[1, 1].text(rate + 1, i, f'{rate:.1f}% (n={int(count)})', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Gene-Level Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene-level aggregations\n",
    "gene_stats = df.groupby('gene_symbol').agg({\n",
    "    'term_id': 'count',\n",
    "    'review_action': lambda x: (x == 'ACCEPT').sum(),\n",
    "    'taxon_label': 'first'\n",
    "}).reset_index()\n",
    "gene_stats.columns = ['gene', 'total_annotations', 'accepted_annotations', 'species']\n",
    "gene_stats['acceptance_rate'] = (gene_stats['accepted_annotations'] / gene_stats['total_annotations']) * 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Distribution of annotations per gene\n",
    "axes[0, 0].hist(gene_stats['total_annotations'], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_xlabel('Number of Annotations per Gene')\n",
    "axes[0, 0].set_ylabel('Number of Genes')\n",
    "axes[0, 0].set_title('Distribution of Annotation Counts per Gene', fontweight='bold')\n",
    "axes[0, 0].axvline(gene_stats['total_annotations'].mean(), color='red', \n",
    "                   linestyle='--', label=f'Mean: {gene_stats[\"total_annotations\"].mean():.1f}')\n",
    "axes[0, 0].axvline(gene_stats['total_annotations'].median(), color='green', \n",
    "                   linestyle='--', label=f'Median: {gene_stats[\"total_annotations\"].median():.0f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Genes with most annotations\n",
    "top_genes = gene_stats.nlargest(15, 'total_annotations')\n",
    "bars = axes[0, 1].bar(range(len(top_genes)), top_genes['total_annotations'].values,\n",
    "                      color=sns.color_palette(\"viridis\", len(top_genes)))\n",
    "axes[0, 1].set_xticks(range(len(top_genes)))\n",
    "axes[0, 1].set_xticklabels(top_genes['gene'].values, rotation=45, ha='right')\n",
    "axes[0, 1].set_ylabel('Number of Annotations')\n",
    "axes[0, 1].set_title('Top 15 Most Heavily Annotated Genes', fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels\n",
    "for bar, value in zip(bars, top_genes['total_annotations'].values):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                    f'{int(value)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Gene acceptance rate distribution\n",
    "axes[1, 0].hist(gene_stats['acceptance_rate'], bins=20, edgecolor='black', \n",
    "                alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Acceptance Rate (%)')\n",
    "axes[1, 0].set_ylabel('Number of Genes')\n",
    "axes[1, 0].set_title('Distribution of Gene Annotation Acceptance Rates', fontweight='bold')\n",
    "axes[1, 0].axvline(gene_stats['acceptance_rate'].mean(), color='red', \n",
    "                   linestyle='--', label=f'Mean: {gene_stats[\"acceptance_rate\"].mean():.1f}%')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Scatter plot: Total annotations vs acceptance rate\n",
    "scatter = axes[1, 1].scatter(gene_stats['total_annotations'], \n",
    "                             gene_stats['acceptance_rate'],\n",
    "                             c=pd.factorize(gene_stats['species'])[0],\n",
    "                             cmap='tab10', alpha=0.6, s=50)\n",
    "axes[1, 1].set_xlabel('Total Annotations per Gene')\n",
    "axes[1, 1].set_ylabel('Acceptance Rate (%)')\n",
    "axes[1, 1].set_title('Annotation Count vs Acceptance Rate by Gene', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(gene_stats['total_annotations'], gene_stats['acceptance_rate'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 1].plot(gene_stats['total_annotations'].sort_values(), \n",
    "                p(gene_stats['total_annotations'].sort_values()),\n",
    "                \"r--\", alpha=0.5, label='Trend line')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Gene-Level Summary:\")\n",
    "print(f\"  ‚Ä¢ Average annotations per gene: {gene_stats['total_annotations'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Median annotations per gene: {gene_stats['total_annotations'].median():.0f}\")\n",
    "print(f\"  ‚Ä¢ Average acceptance rate: {gene_stats['acceptance_rate'].mean():.1f}%\")\n",
    "print(f\"  ‚Ä¢ Genes with 100% acceptance: {(gene_stats['acceptance_rate'] == 100).sum()}\")\n",
    "print(f\"  ‚Ä¢ Genes with 0% acceptance: {(gene_stats['acceptance_rate'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Quality Metrics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive quality dashboard\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Calculate quality metrics\n",
    "has_supporting_text = df['review_supporting_text'].notna()\n",
    "has_references = df['review_supporting_reference_ids'].notna()\n",
    "has_proposed_terms = df['review_proposed_replacement_terms'].notna()\n",
    "needs_modification = df['review_action'] == 'MODIFY'\n",
    "\n",
    "# 1. Review completeness pie chart\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "completeness_data = [\n",
    "    has_supporting_text.sum(),\n",
    "    has_references.sum(),\n",
    "    (has_supporting_text & has_references).sum()\n",
    "]\n",
    "labels = ['Has Supporting Text', 'Has References', 'Has Both']\n",
    "ax1.pie(completeness_data, labels=labels, autopct='%1.1f%%', \n",
    "        colors=['#3498db', '#2ecc71', '#9b59b6'])\n",
    "ax1.set_title('Review Documentation Completeness', fontweight='bold')\n",
    "\n",
    "# 2. Modification compliance\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "modify_with_terms = (needs_modification & has_proposed_terms).sum()\n",
    "modify_without_terms = (needs_modification & ~has_proposed_terms).sum()\n",
    "ax2.bar(['With Proposed Terms', 'Without Proposed Terms'], \n",
    "        [modify_with_terms, modify_without_terms],\n",
    "        color=['green', 'orange'])\n",
    "ax2.set_title('MODIFY Actions: Proposed Terms Compliance', fontweight='bold')\n",
    "ax2.set_ylabel('Count')\n",
    "compliance_rate = modify_with_terms / (modify_with_terms + modify_without_terms) * 100 if needs_modification.sum() > 0 else 0\n",
    "ax2.text(0.5, ax2.get_ylim()[1] * 0.9, f'Compliance: {compliance_rate:.1f}%', \n",
    "         ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Species coverage\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "species_genes = df.groupby('taxon_label')['gene_symbol'].nunique().sort_values(ascending=False).head(8)\n",
    "ax3.barh(range(len(species_genes)), species_genes.values, \n",
    "         color=sns.color_palette(\"husl\", len(species_genes)))\n",
    "ax3.set_yticks(range(len(species_genes)))\n",
    "ax3.set_yticklabels(species_genes.index, fontsize=9)\n",
    "ax3.set_xlabel('Number of Unique Genes')\n",
    "ax3.set_title('Gene Coverage by Species', fontweight='bold')\n",
    "\n",
    "# 4. Evidence type quality\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "evidence_quality = df.groupby('evidence_type').agg({\n",
    "    'review_action': [\n",
    "        ('Total', 'count'),\n",
    "        ('Accepted', lambda x: (x == 'ACCEPT').sum()),\n",
    "        ('Modified', lambda x: (x == 'MODIFY').sum()),\n",
    "        ('Removed', lambda x: (x == 'REMOVE').sum())\n",
    "    ]\n",
    "}).reset_index()\n",
    "evidence_quality.columns = ['Evidence Type', 'Total', 'Accepted', 'Modified', 'Removed']\n",
    "\n",
    "x = np.arange(len(evidence_quality))\n",
    "width = 0.2\n",
    "ax4.bar(x - 1.5*width, evidence_quality['Total'], width, label='Total', color='gray', alpha=0.5)\n",
    "ax4.bar(x - 0.5*width, evidence_quality['Accepted'], width, label='Accepted', color='green', alpha=0.7)\n",
    "ax4.bar(x + 0.5*width, evidence_quality['Modified'], width, label='Modified', color='orange', alpha=0.7)\n",
    "ax4.bar(x + 1.5*width, evidence_quality['Removed'], width, label='Removed', color='red', alpha=0.7)\n",
    "\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(evidence_quality['Evidence Type'], rotation=45, ha='right')\n",
    "ax4.set_ylabel('Number of Annotations')\n",
    "ax4.set_title('Annotation Quality by Evidence Type', fontweight='bold', fontsize=14)\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Term frequency vs action correlation\n",
    "ax5 = fig.add_subplot(gs[2, 0:2])\n",
    "term_frequency = df['term_label'].value_counts()\n",
    "term_actions = df.groupby('term_label')['review_action'].apply(\n",
    "    lambda x: (x == 'ACCEPT').mean() * 100\n",
    ")\n",
    "\n",
    "# Match indices\n",
    "common_terms = term_frequency.index.intersection(term_actions.index)\n",
    "freq_data = term_frequency[common_terms].head(20)\n",
    "action_data = term_actions[common_terms].head(20)\n",
    "\n",
    "ax5_twin = ax5.twinx()\n",
    "bars = ax5.bar(range(len(freq_data)), freq_data.values, alpha=0.5, color='blue', label='Frequency')\n",
    "line = ax5_twin.plot(range(len(freq_data)), action_data[freq_data.index].values, \n",
    "                     'ro-', label='Acceptance Rate', markersize=6)\n",
    "\n",
    "ax5.set_xticks(range(len(freq_data)))\n",
    "ax5.set_xticklabels(freq_data.index, rotation=45, ha='right', fontsize=8)\n",
    "ax5.set_ylabel('Frequency', color='blue')\n",
    "ax5_twin.set_ylabel('Acceptance Rate (%)', color='red')\n",
    "ax5.set_title('Term Frequency vs Acceptance Rate (Top 20)', fontweight='bold')\n",
    "ax5.tick_params(axis='y', labelcolor='blue')\n",
    "ax5_twin.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# 6. Overall quality score\n",
    "ax6 = fig.add_subplot(gs[2, 2])\n",
    "quality_scores = {\n",
    "    'Documentation\\nCompleteness': (has_supporting_text.sum() / len(df)) * 100,\n",
    "    'Reference\\nCoverage': (has_references.sum() / len(df)) * 100,\n",
    "    'Modification\\nCompliance': compliance_rate,\n",
    "    'Overall\\nAcceptance': (df['review_action'] == 'ACCEPT').mean() * 100\n",
    "}\n",
    "\n",
    "colors_score = ['green' if v >= 70 else 'orange' if v >= 40 else 'red' \n",
    "                for v in quality_scores.values()]\n",
    "bars = ax6.bar(range(len(quality_scores)), list(quality_scores.values()), \n",
    "               color=colors_score, alpha=0.7)\n",
    "ax6.set_xticks(range(len(quality_scores)))\n",
    "ax6.set_xticklabels(list(quality_scores.keys()), fontsize=9)\n",
    "ax6.set_ylabel('Score (%)')\n",
    "ax6.set_title('Quality Metrics Summary', fontweight='bold')\n",
    "ax6.axhline(y=70, color='green', linestyle='--', alpha=0.3, label='Good (>70%)')\n",
    "ax6.axhline(y=40, color='orange', linestyle='--', alpha=0.3, label='Fair (>40%)')\n",
    "ax6.set_ylim(0, 100)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, quality_scores.values()):\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{value:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Gene Annotation Review Quality Dashboard', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print quality summary\n",
    "print(\"\\nüèÜ Quality Summary:\")\n",
    "print(\"‚îÅ\" * 50)\n",
    "for metric, score in quality_scores.items():\n",
    "    metric_clean = metric.replace('\\n', ' ')\n",
    "    status = \"‚úÖ\" if score >= 70 else \"‚ö†Ô∏è\" if score >= 40 else \"‚ùå\"\n",
    "    print(f\"{status} {metric_clean}: {score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Temporal and Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis: Identify patterns and outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Action distribution by species (normalized heatmap)\n",
    "species_action_norm = pd.crosstab(df['taxon_label'], df['review_action'], normalize='index')\n",
    "sns.heatmap(species_action_norm, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            ax=axes[0, 0], vmin=0, vmax=1, cbar_kws={'label': 'Proportion'})\n",
    "axes[0, 0].set_title('Review Action Proportions by Species', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Review Action')\n",
    "axes[0, 0].set_ylabel('Species')\n",
    "\n",
    "# 2. Outlier detection - genes with unusual patterns\n",
    "gene_pattern = df.groupby('gene_symbol').agg({\n",
    "    'review_action': lambda x: (x == 'REMOVE').mean() * 100,\n",
    "    'term_id': 'count'\n",
    "}).reset_index()\n",
    "gene_pattern.columns = ['gene', 'removal_rate', 'n_annotations']\n",
    "gene_pattern = gene_pattern[gene_pattern['n_annotations'] >= 5]  # Filter for statistical significance\n",
    "\n",
    "# Identify outliers (high removal rate)\n",
    "outliers = gene_pattern[gene_pattern['removal_rate'] > gene_pattern['removal_rate'].quantile(0.9)]\n",
    "\n",
    "axes[0, 1].scatter(gene_pattern['n_annotations'], gene_pattern['removal_rate'], \n",
    "                   alpha=0.5, s=30, color='blue', label='Normal')\n",
    "axes[0, 1].scatter(outliers['n_annotations'], outliers['removal_rate'], \n",
    "                   alpha=0.8, s=60, color='red', label='High removal rate')\n",
    "\n",
    "# Annotate outliers\n",
    "for _, row in outliers.head(5).iterrows():\n",
    "    axes[0, 1].annotate(row['gene'], (row['n_annotations'], row['removal_rate']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "axes[0, 1].set_xlabel('Number of Annotations')\n",
    "axes[0, 1].set_ylabel('Removal Rate (%)')\n",
    "axes[0, 1].set_title('Genes with Unusual Annotation Patterns', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Co-occurrence matrix of review actions and evidence types\n",
    "action_evidence_matrix = pd.crosstab(df['review_action'], df['evidence_type'])\n",
    "action_evidence_norm = action_evidence_matrix.div(action_evidence_matrix.sum(axis=1), axis=0)\n",
    "\n",
    "sns.heatmap(action_evidence_norm, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            ax=axes[1, 0], cbar_kws={'label': 'Proportion'})\n",
    "axes[1, 0].set_title('Review Action - Evidence Type Associations', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Evidence Type')\n",
    "axes[1, 0].set_ylabel('Review Action')\n",
    "\n",
    "# 4. Summary statistics table\n",
    "axes[1, 1].axis('tight')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['‚îÄ' * 20, '‚îÄ' * 20],\n",
    "    ['Total Annotations', f'{len(df):,}'],\n",
    "    ['Unique Genes', f'{df[\"gene_symbol\"].nunique()}'],\n",
    "    ['Unique Species', f'{df[\"taxon_label\"].nunique()}'],\n",
    "    ['Unique GO Terms', f'{df[\"term_id\"].nunique()}'],\n",
    "    ['‚îÄ' * 20, '‚îÄ' * 20],\n",
    "    ['Acceptance Rate', f'{(df[\"review_action\"] == \"ACCEPT\").mean() * 100:.1f}%'],\n",
    "    ['Modification Rate', f'{(df[\"review_action\"] == \"MODIFY\").mean() * 100:.1f}%'],\n",
    "    ['Removal Rate', f'{(df[\"review_action\"] == \"REMOVE\").mean() * 100:.1f}%'],\n",
    "    ['‚îÄ' * 20, '‚îÄ' * 20],\n",
    "    ['Avg Annotations/Gene', f'{df.groupby(\"gene_symbol\")[\"term_id\"].count().mean():.1f}'],\n",
    "    ['Documentation Rate', f'{has_supporting_text.mean() * 100:.1f}%'],\n",
    "    ['Reference Coverage', f'{has_references.mean() * 100:.1f}%']\n",
    "]\n",
    "\n",
    "table = axes[1, 1].table(cellText=summary_data, cellLoc='left', loc='center',\n",
    "                        colWidths=[0.6, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "# Style the header\n",
    "for i in range(2):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "axes[1, 1].set_title('Summary Statistics', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.suptitle('Advanced Analytics & Pattern Detection', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Key Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate automated insights\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä KEY INSIGHTS FROM GENE ANNOTATION REVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate key metrics\n",
    "total_annotations = len(df)\n",
    "acceptance_rate = (df['review_action'] == 'ACCEPT').mean() * 100\n",
    "modification_rate = (df['review_action'] == 'MODIFY').mean() * 100\n",
    "removal_rate = (df['review_action'] == 'REMOVE').mean() * 100\n",
    "\n",
    "# Evidence type insights\n",
    "evidence_accept = df.groupby('evidence_type')['review_action'].apply(\n",
    "    lambda x: (x == 'ACCEPT').mean() * 100\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüéØ Overall Performance:\")\n",
    "print(f\"  ‚Ä¢ {acceptance_rate:.1f}% of annotations were accepted as-is\")\n",
    "print(f\"  ‚Ä¢ {modification_rate:.1f}% need modifications\")\n",
    "print(f\"  ‚Ä¢ {removal_rate:.1f}% should be removed\")\n",
    "\n",
    "print(\"\\nüî¨ Evidence Type Analysis:\")\n",
    "print(f\"  ‚Ä¢ Most reliable evidence: {evidence_accept.index[0]} ({evidence_accept.iloc[0]:.1f}% acceptance)\")\n",
    "print(f\"  ‚Ä¢ Least reliable evidence: {evidence_accept.index[-1]} ({evidence_accept.iloc[-1]:.1f}% acceptance)\")\n",
    "\n",
    "# Species insights\n",
    "species_stats = df.groupby('taxon_label').agg({\n",
    "    'review_action': lambda x: (x == 'ACCEPT').mean() * 100,\n",
    "    'gene_symbol': 'nunique'\n",
    "}).sort_values('review_action', ascending=False)\n",
    "\n",
    "print(\"\\nüß¨ Species Quality Rankings:\")\n",
    "for i, (species, row) in enumerate(species_stats.head(3).iterrows(), 1):\n",
    "    print(f\"  {i}. {species}: {row['review_action']:.1f}% acceptance ({row['gene_symbol']} genes)\")\n",
    "\n",
    "# Problem areas\n",
    "print(\"\\n‚ö†Ô∏è Areas Requiring Attention:\")\n",
    "\n",
    "# Terms with high modification rates\n",
    "problem_terms = df[df['review_action'].isin(['MODIFY', 'REMOVE'])].groupby('term_label').size()\n",
    "problem_terms = problem_terms.sort_values(ascending=False).head(3)\n",
    "\n",
    "print(\"  Most problematic GO terms:\")\n",
    "for term, count in problem_terms.items():\n",
    "    print(f\"    ‚Ä¢ {term}: {count} issues\")\n",
    "\n",
    "# Compliance issues\n",
    "modify_compliance = (df[df['review_action'] == 'MODIFY']['review_proposed_replacement_terms'].notna()).mean() * 100\n",
    "print(f\"\\n  Modification compliance: {modify_compliance:.1f}% have proposed replacements\")\n",
    "\n",
    "print(\"\\n‚úÖ Recommendations:\")\n",
    "if modification_rate > 30:\n",
    "    print(\"  1. High modification rate suggests need for annotation guidelines review\")\n",
    "if removal_rate > 20:\n",
    "    print(\"  2. High removal rate indicates quality control issues in original annotations\")\n",
    "if modify_compliance < 80:\n",
    "    print(\"  3. Improve documentation of proposed replacement terms for modifications\")\n",
    "if evidence_accept.iloc[-1] < 50:\n",
    "    print(f\"  4. Review {evidence_accept.index[-1]} evidence type annotations more carefully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}