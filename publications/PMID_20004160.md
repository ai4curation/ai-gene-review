---
pmid: '20004160'
title: Averaging of electron subtomograms and random conical tilt reconstructions
  through likelihood optimization.
authors:
- Scheres SHW
- Melero R
- Valle M
- Carazo JM
journal: Structure
year: '2009'
full_text_available: true
full_text_extraction_method: html
pmcid: PMC2940245
doi: 10.1016/j.str.2009.10.009
---

# Averaging of electron subtomograms and random conical tilt reconstructions through likelihood optimization.
**Authors:** Scheres SHW, Melero R, Valle M, Carazo JM
**Journal:** Structure (2009)
**DOI:** [10.1016/j.str.2009.10.009](https://doi.org/10.1016/j.str.2009.10.009)
**PMC:** [PMC2940245](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2940245/)

## Abstract

1. Structure. 2009 Dec 9;17(12):1563-1572. doi: 10.1016/j.str.2009.10.009.

Averaging of electron subtomograms and random conical tilt reconstructions 
through likelihood optimization.

Scheres SHW(1), Melero R(2), Valle M(3), Carazo JM(2).

Author information:
(1)Biocomputing Unit, Centro Nacional de Biotecnología - CSIC, Darwin 3, 
Cantoblanco, 28049, Madrid, Spain. Electronic address: scheres@cnb.csic.es.
(2)Biocomputing Unit, Centro Nacional de Biotecnología - CSIC, Darwin 3, 
Cantoblanco, 28049, Madrid, Spain.
(3)CICBiogune, Parque Tecnológico de Bizkaia, 48160, Derio-Bizkaia, Spain.

The reference-free averaging of three-dimensional electron microscopy (3D-EM) 
reconstructions with empty regions in Fourier space represents a pressing 
problem in electron tomography and single-particle analysis. We present a 
maximum likelihood algorithm for the simultaneous alignment and classification 
of subtomograms or random conical tilt (RCT) reconstructions, where the Fourier 
components in the missing data regions are treated as hidden variables. The 
behavior of this algorithm was explored using tests on simulated data, while 
application to experimental data was shown to yield unsupervised class averages 
for subtomograms of groEL/groES complexes and RCT reconstructions of p53. The 
latter application served to obtain a reliable de novo structure for p53 that 
may resolve uncertainties about its quaternary structure.

DOI: 10.1016/j.str.2009.10.009
PMCID: PMC2940245
PMID: 20004160 [Indexed for MEDLINE]

## Full Text

INTRODUCTION

Modern electron microscopes allow the visualization of individual copies of biological macromolecular complexes in a hydrated environment ( Stahlberg and Walz, 2008 ). Because the electron dose needs to be strictly limited to prevent radiation damage, the resulting images are extremely noisy and averaging over multiple copies of identical complexes is often a prerequisite to obtain reliable structural information. However, because of the high noise levels, averaging approaches in three-dimensional electron microscopy (3D-EM) often rely on comparison with a reference structure, and thereby may become sensitive to bias toward this reference. This problem may be particularly aggravated when the data are not measured in its totality, which is the case for subtomograms or RCT reconstructions. Because in both types of experiment the tilt angle in the microscope is physically limited, one cannot collect the data to completeness and the resulting reconstructions contain empty regions in Fourier space. In this contribution, we present an unsupervised averaging approach that can simultaneously align and classify such 3D reconstructions with missing data regions in Fourier space.

In electron tomography, a 3D density map of a unique object (e.g., an entire cell) is obtained by tilting the sample over a controlled series of angles and combining the corresponding projection images in a single reconstruction ( Hoenger and McIntosh, 2009 ; Leis et al., 2009 ). In the case of single-axis tilting, the missing region in Fourier space is wedge -shaped, whereas dualaxis tilting reduces this region to a pyramid. The incompleteness of the data in Fourier space results in serious artifacts in the 3D density maps. However, if multiple copies of the same macromolecular complex can be identified and extracted from this reconstruction, one can average over these so-called subtomograms, provided that their relative orientations can be determined and they can be separated into structurally homogeneous classes. Apart from reducing the high levels of noise, averaging also reduces the real-space artifacts due to the incompleteness of the data by “filling in” the missing data regions ( Forster and Hegerl, 2007 ). The latter is true because those data points that are missing in a particle in a given orientation may be observed for another particle in a different orientation, and vice versa. Moreover, by placing the averaged structures back into the cellular reconstruction, one could obtain the “molecular atlas” of the cell, i.e., the spatial distribution of the different functional states of multiple macromolecular complexes throughout the cell. However, because of the high noise levels of individual subtomograms, their incomplete character, and problems related to model bias, the unsupervised alignment and classification of subtomograms currently still represents an important hurdle for what has been called the visual proteomics application of cellular tomography ( Nickell et al., 2006 ).

In single-particle analysis, isolated and purified complexes are imaged in a thin layer of vitreous ice, and multiple projections of assumedly identical copies of the complexes are combined in a single 3D reconstruction ( Frank, 2006 ). Because the molecules adopt unknown orientations on the experimental support, their relative projection directions are typically determined a posteriori by comparison of the experimental images with computer-simulated projections of a 3D reference structure. However, the generation of a suitable initial reference map is a highly complicated task, especially for small (i.e., < 400 kDa) or flexible molecules with no or low symmetry ( Llorca, 2005 ). A proven way to generate 3D reconstructions de novo is the random conical tilt (RCT) method, where one records image pairs at two different tilt angles in the microscope ( Radermacher, 1988 ; Radermacher et al., 1986 ). In the general case that the molecules adopt multiple orientations on the support, RCT processing will produce multiple reconstructions in different orientations and, if the molecules are structurally variable, also in distinct conformations. Moreover, the geometrical design of the RCT experiment results in reconstructions with missing regions in Fourier space that are cone shaped. Thereby, averaging over RCT reconstructions again involves alignment and classification of incomplete reconstructions, and is conceptually very similar to the problem of subtomogram averaging.

Early work on aligning RCT reconstructions includes Penczek et al. (1994) . More recently, the potentials of averaging RCT reconstructions have been illustrated by pioneering work on highly flexible spliceosome complexes by Stark and co-workers ( Sander et al., 2006 ), and also Radermacher employed the RCT technique to study highly flexible complexes ( Radermacher, 2009 ). Nevertheless, to date no specific algorithms for the averaging of RCT reconstructions that take the missing cones into account have been described. More contributions are available on subtomogram averaging, and several efforts to obtain molecular atlases of cells have already been reported (e.g., Brandt et al., 2009 ; Malmstrom et al., 2009 ). Initial approaches to subtomogram averaging that did not take the missing wedges into account were observed to suffer from the alignment or classification of artifacts ( Walz et al., 1997 ). More recently, the treatment of the missing wedges has played an increasingly important role. The Baumeister group was the first to propose a scoring function that accounts for missing wedges, the constrained cross-correlation coefficient, which limits the comparison of two maps to those regions in Fourier space where both maps contain data. Although initially only used for subtomogram alignment ( Beck et al., 2004 ; Forster et al., 2005 ; Frangakis et al., 2002 ), more recently pairwise calculation of this similarity measure for aligned subtomograms was also employed for classification purposes ( Forster et al., 2008 ). Similar approaches to take the missing wedge into account were also used by other groups. Subramaniam and coworkers used a multiplicative mask for the missing wedge in Fourier space and proposed an iterative procedure of efficient subtomogram alignment based on spherical harmonics analysis, and classification based on hierarchical clustering ( Bartesaghi et al., 2008 ; Liu et al., 2008 ). Winkler et al. classify and align subtomograms based on constrained cross-correlation using either “alignment by classification” ( Dube et al., 1993 ), or iterative schemes involving multivariate statistical analysis, hierarchical clustering, and realignment of the classes ( Winkler et al., 2009 ). Schmid and Booth proposed a simpler scoring function that also restricts the comparison to the mutually observed regions in Fourier space, but is much faster to calculate ( Schmid and Booth, 2008 ).

Common characteristics of existing approaches for subtomogram averaging are that alignment and classification are often performed in separate steps, and that the resulting averages are calculated in Fourier space by dividing the sum of all images by the number of times that each Fourier component was observed. (The latter has been called weighted averaging , andwewill use the same term throughout this paper.) Both characteristics may behave suboptimally in specific situations. Depending on the type of structural heterogeneity and the overall shape of the particles, the problemsof alignment and classificationmaybe strongly intertwined, while weighted averaging in Fourier space may put too strong emphasis on noisy Fourier components that were observed only a few times in cases where the particles adopt a preferred orientation and the missing regions are not filled up.

Our proposal is to tackle alignment and classification simultaneously through a multireference refinement, and to obtain the parameters of a statistical data model by maximum likelihood estimation. Similar approaches have proven highly effective for the alignment and classification of structurally heterogeneous two-dimensional (2D) projection data sets in single-particle analysis ( Scheres et al., 2005 , 2007a ). A major benefit of the maximum-likelihood approach is the explicit, statistical description of the abundant experimental noise in the data, which allows one to “marginalize,” i.e., calculate probability-weighted assignments, over the so-called hidden variables. These variables are necessary to solve the problem, but were not observed in the experiment. Here, obvious hidden variables are the class and orientational assignments of every particle. In addition, to explicitly reflect the unobserved character of the missing data in our statistical model, we also treat all Fourier components in the missing data regions as hidden variables. We will derive the corresponding algorithm, where the missing data regions are complemented with the current estimates for the model parameters, and we will show that this algorithm may be employed in a completely unsupervised manner for the alignment and classification of subtomograms or RCT reconstructions.

DISCUSSION

We have presented a new approach for averaging 3D maps with missing regions in Fourier space. The novelty of our approach lies in three general aspects. First, whereas many existing approaches separate alignment and classification, we tackle both problems simultaneously through multireference refinements. Second, we use maximum-likelihood estimation to calculate our model parameters as weighted averages over all possible orientation and class assignments, rather than assigning a single optimal orientation and class based on a noisy (constrained) cross-correlation function. And third, we explicitly treat the notion of incomplete experimental data in our statistical model by treating the Fourier components in the missing data regions as hidden variables. The latter results in an algorithm where one fills in the missing Fourier components with the corresponding components of the current model estimates, rather than dividing each Fourier component by the times it has been observed (as in previously proposed approaches based on weighted averaging). This gives rise to a “conservative” algorithm, which changes the model much more slowly compared with weighted averaging for those regions in Fourier space that are sparsely observed among all particles. The user may tune this degree of conservatism, because one could perform multiple iterations of marginalization over the missing data regions for every iteration of marginalization over the orientations and classes. In the limit of an infinite number of iterations of marginalization over the missing data regions, this algorithm then becomes equivalent to its weighted averaging counterpart. Although not used in the calculations presented in this paper, this option was implemented in the program and comes at virtually no additional computational cost.

The concept of complementing the missing data with the available model estimates is not restricted to the ML approach presented here. Also in approaches based on constrained cross-correlation, weighted averaging may be replaced by complementing the missing Fourier components with the current model estimates. Such changes would probably require only minor adjustments to the code of existing programs and may provide more robust algorithms for cases where the particles adopt preferred orientations. In this light, we also note the work of Bostina et al., who fill up the missing data regions of their aligned subtomograms with the corresponding values of the weighted average of all data, prior to application of standard 3D classification tools that lacked the notion of missing data ( Bostina et al., 2007 ).

Initial tests of the presented algorithm were performed with simulated data that were in agreement with the assumptions of the underlying data model. For data with white, Gaussian noise in a wide range of SNRs, the proposed ML algorithm was shown to outperform a multireference refinement approach based on weighted averaging and constrained cross-correlation, which is in good agreement with similar observations for single-particle refinements ( Scheres et al., 2005 ; Sigworth, 1998 ).

For both the ML and the CC approaches, the classification results were greatly improved using an empirical regularization term. We note that, in general, regularization may be employed to prevent overfitting or to solve ill-posed problems. Often, regularization terms tend to smooth the energy landscape of a target function, thereby lowering the number of local minima. Also in this case, our understanding of this effect is that the regularization prevents the multireference refinement runs from getting stuck in local minima at early stages of the refinement. During the initial iterations, the quality of the references is still relatively low due to suboptimal alignment parameters, and separation of the images into distinct groups at these stages may converge to mediocre solutions. The regularization term that acts during these initial iterations enforces similarity among the references, so that these local minima may be overcome. Starting from initially random assignments of rotations and classes, the ML algorithm was then shown to be capable of yielding simultaneous classification and alignment in a completely unsupervised manner.

As explained above, the main differences of the ML algorithm with conventional approaches lie in the probability-weighted averaging over all possible orientational and class assignments on one hand and the filling of the missing regions with the current model estimates on the other hand. In experiments designed to separate these two types of marginalization, in particular the probability-weighted averaging over the orientation and class assignments appeared to have a large effect on the refinement results. Complementing the missing data regions seems to be of secondary importance, although this effect became more noticeable for data with severe preferred orientations where the missing regions were not filled up in the averages.

The experimental data set of GroEL/groES subtomograms that we used was previously published by Foerster et al., who used constrained cross-correlation to align all particles against a reference based on a low-pass filtered crystal structure, and then classified these data using hierarchical clustering based on the same similarity measure ( Forster et al., 2008 ). We obtained similar classification results, but in a completely unsupervised manner. Moreover, the maps for the groEL 14 and groES 14 groES 7 complexes obtained in our work appear to agree somewhat better with the fitted crystal structures than those presented by Foerster et al., although a quantitative comparison is not available at this point. Apart from the theoretical considerations outlined above, such an improvement could also be explained by the simultaneous alignment and classification in our refinement scheme, whereas Foerster et al. separated alignment against a single reference from subsequent classification and did not re-align the resulting classes.

The reference-free alignment of p53-DNA RCT reconstructions showed that, despite a low number of noisy RCT reconstructions, the ML approach was capable of generating an averaged map with remarkable similarities to a previously observed superdomain organization of human p53 ( Tidow et al., 2007 ). Apart from illustrating the potentials of the ML approach in generating de novo models for subsequent single-particle refinement, these results also have relevance for p53 structural biology. Previously, two strikingly different quaternary structures were proposed based on common-lines EM-reconstructions. Tidow et al. (2007) used negative-stain EM to study a stabilized mutant of human full-length p53. Enforcing C2 symmetry, they obtained models with similar domain organizations as those shown in Figure 3 , either for free p53 tetramers and for complexes with dsDNA. ( Okorokov et al., 2006 ) used cryo-EM on full-length murine p53, and enforced D2 symmetry to obtain a model with the shape of a hollow, skewed cube. As p53 may adopt an intrinsically flexible quaternary organization to fulfill its multiple functionalities in the cell, it is possible that both EM reconstructions represent relevant oligomerization states ( Okorokov and Orlova, 2009 ). On the other hand, some caution may be at place, because the imposition of an incorrect symmetry in the generation and refinement of common-lines models may lead to important artifacts, and the inherent flexibility combined with its small size (200 kDa) further complicate (cryo-) EM analysis of p53 samples. Our RCT averaging experiments yielded the first de novo p53 model that is not based on common lines. Moreover, whereas the previously proposed common-lines models could not be obtained without imposing symmetry, our model could be generated and refined in the absence of any symmetry.

Summarizing, this contribution provides a general framework for maximum-likelihood refinement of 3D maps with missing data, and the usefulness of this approach has been illustrated using both simulated and experimental data of subtomograms and RCT reconstructions. As has happened previously with similar approaches the field of single-particle analysis, it is likely that the underlying statistical data model may need to be adapted to describe a wide variety of experimental characteristics. Apart from the theoretical considerations about the data model outlined above, neighboring particles from the crowded environment of the cell could interfere with the correct normalization of subtomograms, as was previously observed for single-particle analyses ( Scheres et al., 2009 ). In addition, densities in cellular subtomograms for neighboring complexes, gold particles, or membranes that are not described by the data model may lead to artifacts in the alignment and classification process, whereas real-space masks (to remove such artifacts) may lead to additional dependencies in Fourier space and to underestimation of the noise variance. To facilitate further testing and possible adaptation in the field, the presented algorithm has been made freely available through its implementation in the open-source Xmipp package ( Sorzano et al., 2004 ). Extrapolating our experience with maximum likelihood refinement of structurally heterogeneous single-particle projection data ( Scheres et al., 2005 , 2007a ), we expect that this implementation may provide a useful tool for unsupervised alignment and classification of electron subtomograms or RCT reconstructions.
